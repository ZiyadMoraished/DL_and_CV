{"cells":[{"cell_type":"code","execution_count":null,"id":"YBnrIgsJkp3p","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26936,"status":"ok","timestamp":1651882915394,"user":{"displayName":"Ziyad Moraished","userId":"09734916932076943331"},"user_tz":-60},"id":"YBnrIgsJkp3p","outputId":"78d407ad-0392-4859-b7d8-ef356e93fed1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ipython-autotime\n","  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n","Installing collected packages: ipython-autotime\n","Successfully installed ipython-autotime-0.3.1\n","Mounted at /content/drive\n","time: 23 s (started: 2022-05-07 00:21:32 +00:00)\n"]}],"source":["!pip install ipython-autotime\n","%load_ext autotime\n","\n","from google.colab import drive\n","import os\n","from datetime import datetime\n","\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/DL and CV')"]},{"cell_type":"code","execution_count":null,"id":"y3RSRQFjcH4R","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1651882915394,"user":{"displayName":"Ziyad Moraished","userId":"09734916932076943331"},"user_tz":-60},"id":"y3RSRQFjcH4R","outputId":"1eb8d063-2a11-4262-ea4e-6705c2c0b1a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-54285c3c-3c93-7d77-1a5f-297613c4f30d)\n","time: 117 ms (started: 2022-05-07 00:21:55 +00:00)\n"]}],"source":["#-- Check the running GPU\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"id":"xLsg-qCtok3H","metadata":{"id":"xLsg-qCtok3H"},"outputs":[],"source":["#-- Running Tensorboard within google colab noebook\n","%load_ext tensorboard\n","%tensorboard --logdir=\"./models/MNIST/runs\" #-- Read logs from MNIST directory\n","# %tensorboard --logdir=\"./models/CIFAR/runs\" #-- Read logs from CIFAR directory"]},{"cell_type":"markdown","id":"UjKy3vkAdpZJ","metadata":{"id":"UjKy3vkAdpZJ"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"id":"3lk5ZYhanody","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3803,"status":"ok","timestamp":1651882925083,"user":{"displayName":"Ziyad Moraished","userId":"09734916932076943331"},"user_tz":-60},"id":"3lk5ZYhanody","outputId":"5d27aaeb-3b81-401a-cdf5-06a8727dbabf"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 3.83 s (started: 2022-05-07 00:22:00 +00:00)\n"]}],"source":["import time\n","import random\n","from tqdm.notebook import tqdm_notebook\n","from pathlib import Path\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from torch import nn\n","\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","from torch.utils.data import DataLoader\n","from torchvision.models import vgg19_batch_norm\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":null,"id":"WHN8UY6QkoeO","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1651882925083,"user":{"displayName":"Ziyad Moraished","userId":"09734916932076943331"},"user_tz":-60},"id":"WHN8UY6QkoeO","outputId":"9eb82f41-3f77-4dae-9575-eca053d71f47"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 3.68 ms (started: 2022-05-07 00:22:04 +00:00)\n"]}],"source":["def seed():\n","  \"\"\" This function is used when running any cell to make sure all the seed are the same\"\"\"\n","  rand_seed = 0\n","  random.seed(rand_seed)\n","  os.environ['PYTHONHASHSEED'] = str(rand_seed)\n","  np.random.seed(rand_seed)\n","  torch.manual_seed(rand_seed)\n","  torch.cuda.manual_seed(rand_seed)\n","  torch.cuda.manual_seed_all(rand_seed) # if you are using multi-GPU.\n","  torch.backends.cudnn.benchmark = False\n","  torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","id":"b7ojWkqhd1xb","metadata":{"id":"b7ojWkqhd1xb"},"source":["# Train & Validate"]},{"cell_type":"code","execution_count":null,"id":"EGYyT8IfyGb7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":638,"status":"ok","timestamp":1651882925719,"user":{"displayName":"Ziyad Moraished","userId":"09734916932076943331"},"user_tz":-60},"id":"EGYyT8IfyGb7","outputId":"3df59850-2a46-421f-e452-0deb7d67f830"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 254 ms (started: 2022-05-07 00:22:04 +00:00)\n"]}],"source":["seed()\n","def model_train(model, model_name, lr, momentum, optimizer, epochs, tb_writer, parameters):\n","  #-- Build a lamba function to get the current time stamp when it is called\n","  ts = lambda x: x.now().strftime('%d_%m_%Y__%H:%M:%S')  \n","  #-- Change the VGG output layer to 10 to match the number of MNIST and CIFAR classes\n","  model.classifier[6] = nn.Linear(4096, 10)  \n","  #-- Pass model to to cuda\n","  model.to(device)  \n","  # Add VGG model graph to tensorboard\n","  # writer.add_graph(model, images)  \n","  loss_criterion = nn.CrossEntropyLoss()  \n","\n","  print('###################### Training {} {} model for {} epochs ######################'.format(model_name, parameters, epochs))\n","  #-- Set the lowest validation loss to positive infinity \n","  best_val_loss = np.inf\n","  #-- loop over the dataset for a number of epochs \n","  for epoch in range(epochs):\n","      ###################\n","      # train the model #\n","      ###################\n","      #-- Initiate train loss, correct training , epoch loss, epoch accuracy, and epoch_accuracy\n","      train_loss = 0.0\n","      train_correct = 0\n","      total = 0 ####################### CHANGE names\n","      epoch_loss = 0.0\n","      epoch_acc = 0.0\n","      # start_time = time.time()\n","      model.train()\n","      for i, (images, labels) in tqdm_notebook(enumerate(train_loader)): \n","          #-- Pass images and labels to cuda\n","          images, labels = images.to(device), labels.to(device)\n","          #-- Empty the gradiant\n","          optimizer.zero_grad() \n","          #-- Feed-forward pass\n","          outputs = model(images) \n","          # outputs = outputs.logits\n","          #-- Get the predictions \n","          _, preds = torch.max(outputs, 1)  \n","          #-- training loss calculation\n","          loss = loss_criterion(outputs, labels)  \n","          #-- Apply backpropagation to calculate gradients\n","          loss.backward()\n","          #--  Adjusting learning weights\n","          optimizer.step() \n","          \n","          #-- Gather data and report\n","          # https://discuss.pytorch.org/t/why-do-we-multiply-loss-function-with-a-constant/112893/2\n","          train_loss += loss.item() * images.size(0) \n","          total += labels.size(0)\n","          train_correct += (preds == labels).sum().item()  \n","\n","          # Print results every 100 batch\n","          if (i + 1) % 100 == 0:\n","            print_ = 'Epoch {} of {}, Step: {} of {}, Training loss: {:.7f}, Training accuracy: {:.7f}, Time: {}'\n","            print(print_.format(epoch + 1, epochs, i + 1, len(train_loader), (train_loss / total), (train_correct / total), ts(datetime) ))\n","            \n","            # writer.add_scalar('train_loss', train_loss / (i + 1),\n","            #                   epoch * outputs.shape[0] + i + 1)\n","            # writer.add_scalar('train_accuracy', train_correct / (i + 1),\n","            #                   epoch * outputs.shape[0] + i + 1)\n","          epoch_loss = train_loss / total\n","          epoch_acc = train_correct / total\n","\n","      #-- Print end of epoch training's results and save them in tensorboard\n","      print_ = 'Epoch {} of {}, Average training loss: {:.7f}, Average training accuracy: {:.7f}, Time: {}'\n","      print(print_.format(epoch + 1, epochs, epoch_loss,epoch_acc, ts(datetime)))\n","      \n","      # tb_writer.add_scalar('epoch_train_loss+'+parameters, epoch_loss, epoch + 1)\n","      # tb_writer.add_scalar('epoch_train_accuracy_'+parameters, epoch_acc, epoch + 1)\n","      tb_writer.add_scalars(model_name+'_epoch_loss_accuracy_'+parameters, {'train_loss':epoch_loss, 'train_accuracy':epoch_acc}, epoch + 1)\n","      \n","      print('###################### Validating {} {} model ######################'.format(model_name, parameters))\n","      # ts = lambda x: x.now().strftime('%d_%m_%Y__%H:%M:%S')\n","\n","      # loss_criterion = nn.CrossEntropyLoss()  \n","      # for epoch in range(epochs):\n","      ######################    \n","      # validate the model #\n","      ######################\n","      #-- Initiate validation loss, correct validation , epoch loss, epoch accuracy, and epoch_accuracy\n","      val_loss = 0.0\n","      val_correct = 0\n","      total = 0\n","      val_epoch_loss = 0.0\n","      val_epoch_acc = 0.0\n","      # start_time = time.time()\n","\n","\n","      with torch.no_grad(): \n","        model.eval()\n","        for i, (val_images, val_labels) in tqdm_notebook(enumerate(val_loader)):\n","            #-- Pass images and labels to cuda\n","            val_images, val_labels = val_images.to(device), val_labels.to(device)\n","            # with torch.no_grad():\n","                #-- Feed-forward pass\n","            outputs = model(val_images)  \n","            #-- Get the predictions\n","            _, predicted = torch.max(outputs.data, 1)\n","            #-- Validation loss calculation\n","            loss = loss_criterion(outputs, val_labels)\n","            #-- Empty the gradiant\n","            # optimizer.zero_grad() \n","\n","            #-- Print results every 100 batch\n","            val_loss += loss.item() * val_images.size(0)  \n","            total += val_labels.size(0)\n","            val_correct += (predicted == val_labels).sum().item()\n","            \n","            if (i + 1) % 100 == 0:\n","              #-- if there a new loss that is ower than best_val_loss , save model\n","              if val_epoch_loss < best_val_loss :\n","                print_ = 'Step: {} of {}, Validation loss: {:.7f}, Validation accuracy: {:.7f}, Time: {}'\n","                print(print_.format(i + 1, len(val_loader), (val_loss / total), (val_correct / total) ,ts(datetime)), end=' | ')\n","\n","                print('Loss decreased from {:.7f} to {:.7f} .... Saving the model'.format(best_val_loss, val_epoch_loss))\n","                best_val_loss = val_epoch_loss\n","\n","                #-- Saving the model state dict\n","                model_name_extra = '__lr {}__momentum {}__epochs {}'.format(lr, momentum, epochs)\n","                model_save_path = os.path.join(model_dir, model_name+model_name_extra)\n","                torch.save(model.state_dict(), model_save_path)\n","\n","              else:\n","                print_ = 'Step: {} of {}, Validation loss: {:.7f}, Validation accuracy: {:.7f}, Time: {}'\n","                print(print_.format(i + 1, len(val_loader), (val_loss / total), (val_correct / total),ts(datetime)))\n","\n","            val_epoch_loss = val_loss / total\n","            val_epoch_acc = val_correct / total\n","\n","        #-- Print end of epoch training's results and save them in tensorboard\n","        print_ = 'Average validation loss: {:.7f}, Average validation accuracy: {:.7f}, Time: {}'\n","        print(print_.format(val_epoch_loss, val_epoch_acc,ts(datetime)))\n","\n","        # tb_writer.add_scalar('epoch_val_loss_'+parameters, val_epoch_loss, epoch + 1)\n","        # tb_writer.add_scalar('epoch_val_accuracy_'+parameters, val_epoch_acc, epoch + 1)\n","        tb_writer.add_scalars(model_name+'_epoch_loss_accuracy_'+parameters, {'val_loss':val_epoch_loss, 'val_accuracy':val_epoch_acc}, epoch + 1)\n","\n","  return model, model_save_path\n"]},{"cell_type":"markdown","id":"qLvjCVTunqNs","metadata":{"id":"qLvjCVTunqNs"},"source":["# Test"]},{"cell_type":"code","execution_count":null,"id":"R13lZRXXt63w","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1651882925720,"user":{"displayName":"Ziyad Moraished","userId":"09734916932076943331"},"user_tz":-60},"id":"R13lZRXXt63w","outputId":"5ba2b7c0-627b-4918-93c2-fd4416deeeeb"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 45.1 ms (started: 2022-05-07 00:22:05 +00:00)\n"]}],"source":["#-- Freeze the randomness\n","seed()\n","\n","def model_test(model, model_name, tb_writer, parameters):  \n","  ts = lambda x: x.now().strftime('%d_%m_%Y__%H:%M:%S')\n","\n","  print('###################### Testing {} {} model ######################'.format(model_name, parameters))\n","  correct = 0\n","  total = 0\n","  test_pred_labels = []\n","  test_actual_labels = []\n","  incorrect_pred = 0\n","  correct_pred = 0\n","\n","  with torch.no_grad():\n","    for i, (test_images, test_labels) in tqdm_notebook(enumerate(test_loader)):\n","      #-- Pass images and labels to Cuda\n","      test_images, test_labels = test_images.to(device), test_labels.to(device)\n","      #-- Feed-forward pass\n","      outputs = model(test_images)  \n","      #-- Get the predictions\n","      _, predicted = torch.max(outputs.data, 1)\n","      #-- Change CPU to numpy\n","      temp = predicted.detach().cpu().numpy()  \n","      #-- Add the prediction to the test_pred_labels list\n","      test_pred_labels.append(temp)  \n","      #-- Add the acutal labels to the test_actual_labels list\n","      test_actual_labels.append(test_labels.detach().cpu().numpy())\n","      total += test_labels.size(0)\n","      correct += (predicted == test_labels).sum().item()\n","      #-- Check if the ground truth labels match the predicted labels\n","      if ~test_labels.all().eq(predicted.all()): #-- If so, save 10 sample images\n","        if incorrect_pred < 10:\n","          plot_results(test_images, test_labels, predicted, i, model_name, parameters, 'incorrect')\n","          incorrect_pred +=1\n","      else:\n","        if correct_pred < 10: #-- If not, save 10 sample images\n","          plot_results(test_images, test_labels, predicted, i, model_name, parameters, 'correct')\n","          correct_pred +=1\n","      #-- Print results every 100 batch\n","      if (i + 1) % 100 == 0:\n","        print('Step: {} of {}, Test accuracy: {:.7f}, Time: {}'.format(i+1, len(test_loader), (correct / total), ts(datetime) ))\n","  \n","  #-- Calculate the final accuracy and then print it\n","  acc = correct / total\n","  print('Average testing accuracy: {:.7f}, Time: {}'.format(acc, ts(datetime)))\n","  tb_writer.add_text(model_name+'_test_accuracy_'+parameters, str(acc))"]},{"cell_type":"markdown","id":"8TZZlEvguwCN","metadata":{"id":"8TZZlEvguwCN"},"source":["# Plot results"]},{"cell_type":"code","execution_count":null,"id":"Oy_hrRtouvbs","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1651882925720,"user":{"displayName":"Ziyad Moraished","userId":"09734916932076943331"},"user_tz":-60},"id":"Oy_hrRtouvbs","outputId":"707235b5-b711-4a87-a56d-0d766f8e2ad9"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 15.2 ms (started: 2022-05-07 00:22:05 +00:00)\n"]}],"source":["#-- Create a graph to compare the the actual labels with the predicted results\n","def plot_results(test_images, test_labels, predicted, index, model_name, parameters, correct_incorrect):\n","  fig = plt.figure()\n","  fig.suptitle('Testing {} model ({}) {} \\n {}'.format(model_name, index+1, parameters, time.ctime()), fontsize=13)\n","  for i, (image, label, pred) in enumerate(zip(test_images, test_labels, predicted)):\n","    plt.subplot(1,test_images.shape[0], i+1) \n","    plt.tight_layout(pad=0)\n","    plt.imshow(image[0].cpu(), cmap='gray')\n","    plt.title(\"Actual: {} \\n Prediction: {}\".format(label, pred), fontsize=10)\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","  #-- Save images to disk and tensorboard\n","  tb_writer.add_figure('Testing {} model ({}) {}'.format(model_name, index+1, parameters), fig, 0)\n","  image_save_path = os.path.join(output_dir, 'Test {} model_{}_{}_{}.png'.format(model_name, index+1, parameters, correct_incorrect))\n","  fig.savefig(image_save_path, bbox_inches='tight', pad_inches=0, transparent=True)"]},{"cell_type":"markdown","id":"60B_Fk32duP3","metadata":{"id":"60B_Fk32duP3"},"source":["# Loading and Spliting MNIST Data"]},{"cell_type":"code","execution_count":null,"id":"iKFHL9BYE3Fp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7904,"status":"ok","timestamp":1651753401776,"user":{"displayName":"Ziyad Moraished","userId":"09734916932076943331"},"user_tz":-60},"id":"iKFHL9BYE3Fp","outputId":"41207968-64aa-42db-beda-8bdd09f3806a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Samples in Training Dataset:  55000\n","Number of Samples in Validation Dataset:  5000\n","Number of Samples in Testing Dataset:  10000\n","time: 7.85 s (started: 2022-05-05 12:23:13 +00:00)\n"]}],"source":["#-- Freeze the randomness\n","seed()\n","\n","#-- Prepare GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#-- Create data, train, and test directories\n","data_dir  = './datasets/MNIST'\n","train_dir = os.path.join(data_dir, 'train')\n","test_dir  = os.path.join(data_dir, 'test')\n","\n","#-- Create directories for models and outputs\n","model_dir  = './models/MNIST'\n","output_dir = '/content/drive/MyDrive/DL and CV/outputs/MNIST'\n","Path(output_dir).mkdir(parents=True, exist_ok=True)\n","\n","trans = transforms.Compose([transforms.Resize(224), #-- VGG model requires this image shape\n","                              transforms.RandomRotation(15), #-- images augmentation to challenge the model\n","                              transforms.Grayscale(num_output_channels=3), #-- VGG model requires 3 channels\n","                              transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) #-- Values normalization\n","\n","#-- Download MNIST training data, and splitting it to training and validation\n","train_data = datasets.MNIST(root=train_dir, train=True, download=True, transform=trans)\n","\n","#-- Split the training data to training and validation datasets.\n","train_indices, val_indices = train_test_split(list(range(len(train_data.targets))), test_size=5000, stratify=train_data.targets, random_state=0)\n","train = torch.utils.data.Subset(train_data, train_indices)\n","val = torch.utils.data.Subset(train_data, val_indices)\n","\n","#-- Download MNIST test data\n","test = datasets.MNIST(root=test_dir, train=False, download=True, transform=trans)\n","\n","#-- Setting training batch size:\n","batch_size = 4\n","\n","#-- Build the training, validation, and test data loaders\n","train_loader = DataLoader(dataset=train, batch_size=batch_size, shuffle=False)  \n","val_loader   = DataLoader(dataset=val,   batch_size=batch_size, shuffle=False)  \n","test_loader  = DataLoader(dataset=test,  batch_size=batch_size, shuffle=False) \n","\n","#-- Print out the number of salmples for training, vlidation, and test sets.\n","print(\"Number of Samples in Training Dataset: \",   len(train))\n","print(\"Number of Samples in Validation Dataset: \", len(val))\n","print(\"Number of Samples in Testing Dataset: \",    len(test))"]},{"cell_type":"markdown","id":"E2dSUL8AyJcD","metadata":{"id":"E2dSUL8AyJcD"},"source":["# MNIST Main"]},{"cell_type":"code","execution_count":null,"id":"1SNpV_DS2t0Y","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8c4c8f731ae6481884ad3f58fb627ca1","10761583a686408d8163027d13df4165","25bbaebf704942c49d0d5ff0e5770e3b","95480473830048a29631d7b91d9570b3","58542fa9bcbe419793754cb6f2e77e88","f8163b7de04945ca9a387270d0514321","a76f940488fe497283fbaf9f6df68739","f93738cbca814f6cb120b8eeb3ac24a8","60c684df641a46a2aa842bd8d61d7b9e","0a3df10ed2964448b91398aa469a9625","43afc900ee0143f2a7808b589a2fdc32","79d824a4a5a04eafb5c6a6e795b1642f","b95d5ac469694199ba017e208843cc86","555cb9f817404a999f14b550ae260fbf","dfe60f16f0cf479aa3ecf3846c38aa10","3281b244d1ee4077aa054243798594ea","069431d84a674a74b73e0f7c8a36a3d7","3b623df4c8694e59a24c347c11fd74db","2477aac0dec248b09f63b4dfc0de2885","4449653518bc479b9fcd91503231743d","c6a9acd403314a89b5abc7d5bafb08d6","0479eaa34a5e4cee9ddda60f00865242","83af5c88c0ff46f08674edb6123eaf7c","17ee361190164ee78266be8ea6bc8128","1f016edfea424f4ca43a8017f95704fb","a6d167b8cfdc4b7380b9208f6abd022b","8611b33cfc6a4754a4b1b50f2d8d93ee","6d21a9f1d33d41f4a7900545f14a9467","d148031e2c09499682546e5c0f4afab5","cd87cb5f076b4fd687cfb9131034f333","f4d99463276a42aea49cb8b9aebdf011","e6abb9e9a015416da88efc5b247cef6f","e5e64bc33b9741c688883570cd308da7","e036c87206384edaa2b08285f373ebb8","17de12ae1e614c4f92243fd84256358f","a0bf5962f7c740d7b7522804b380c8dd","a8d4825def8d4469ad481464990bba88","fbab56b1c4c9408ba61b28c8750232c6","fc13f4303be446278715f71fc6ade3fe","93ab4d9cfc084a9cb64d0b9d87628291","4b29436299df447fb15761741325ec10","c4d942362de3486a96bc79b8524ebe89","f93823075cb44a66934de0985a9158c6","5d6144115a564c949c33832cde92a48c","1d908177b90b4b5281968ddefd3269a9","31f7499b9cc941ebb587cb4ac226f6e2","62f6cc52cf3d4d6d843bb6265e8cfafc","b7a503c8dfb744ec972983bf54ea2fa0","818e9fea5f4145029cb4266477c1faa6","ad65845f89124836be11755e9ba67e25","5043cbedf51b4960846921956f9b8c10","333048cd075b4f4198636232c94ede83","05d78297f96f48988072dd89c507b3e0","30682558099743709f5a8c4f97c4dda3","c75184024a144881985e991b786590b7","d21682052b994d6bae9d1b1ab4eed6c6","1cc7f02fae164923bd67cd07f53ede56","9d400cc9e02244fd96f9e8745d29ed13","c997258009bd43f383711a36876192b7","735825ee44eb4d4a84b853574a4c2b12","254473fa23c44d4d891484a2e2d8d25b","1d470758e0354a2baf3bc1c0d190615b","fc1ed05cbe874817bb0685bd3d737b69","9f5793c7a89e498a8fdb840bed017f1f","44168802b35a465783d6046dbd271015","f8e3d0f74e964773a23fb6d0b922f494","876f9f1513634376a175d68a9f38c7e0","332119c04d0b4b31a38c5c0b35a50a75","a71953325a704ad68e63c947dc23b159","d92f80ee4b96499794e700287cbd14f7","8439cbc24a0a4b4789ca7537a3aca3bf","e2db3d1fb1f94458aae970ab53f6af42","964c0790a60e4b73a4597e548af57800","8174ac30b9c24664b3b303dfccd464ff","0b65678eb5a04de8887ddce4a92fcc3c","a294a23f5e354dd8a7b0445828cb99cc","2bb8feb4a5174ee1b43bd577d2d45166","ed2320c12bfd4c478e90546caeebfb63","b86e1703f3314be984699cf72316116d","a282367b207e43d6bd404c4d99dc4268","2607e72472984ceda603a8999b206133","d1cb0116419d4b80b1f1b73bb1389a2f","c034173c304d4b8da0baaae2527ad965","dbb41404ac074f1381830b1d67bde10d","3f90d4df8f764858871c1f7f0271c209","9aba9339dfb24fdaadecf5b296c796a6","0a66f63bedd7405fb8e84a9d6fc6f6ac","0880b88e106f4b0388813637648b612a","caefaa2c8eee426aaaf176e148dbb270","fc1085bea0894807847dda6143d45aee","0cc25f8afe3e424e9b1221b7eb7f2c74","f20e1c0212d1431cafd70526b4262b8a","43856f64ef8b492dbc60aefb6c28db53","6bfa326c227d43ccac6feb974a7184ad","55fe9ba47e274fe7b7c6f7139381eecd","3f1d5409987940939e6bb254e95f5c51","d7cddd084dbc4917b480690f905495fd","a5126bbb66b44f37979e70e35c76ae70","6805ec6e01804d61a2e6766d2044b29d","94380945025a422c9f79cb45ac83e89d","31c63e2868cf44efa9daecf6d3ef9195","3728255eddb34c2c893c9fe0f615297f","bb14b0a8d80046d293189c5019aa44de","71390e23e082447791c84c9c41ec1dde","88b7981ee86a4b5489f9332f5d5c4b8a","3b6ab3955b6745cb930d6cecd6b9b792","dc90c0db651d4eb4bc04706396af18f1","8cac29c8591a482baacee7d7fb3f4242","01f0d457baed4bd8b8a6779b264ef369","d01f29cad6bb4a03af8f6d3b6674f75f","63172a7c5f514cbeb45932de1e9668e0","c1e7166b5f9a42c4b155be3c933fc3fb","23f01273cf75446aa584b1e62d43d57e","3eaa74034b644021937cbedb3c5248f9","4aa5a3ff9a594a87ae7a0fa2fc99d2df","fa744b9534154260a01c3d2cb70d3266","701c6b1c05a5467ab6b70c7edd3be2ec","b8fbc9a477b44b9ba144996ca71cb1d6","50f8ad9d72fd40febd8202f98fec1b44","8a88b4aff1f24e9f83eee99b2849d269","e3dbf418326d47f6bed7e0a9b3d3a9e2","2a31667afc0d4599b071c96b73945abe","9f09bcccdc314a64bb957f7f9ac33d3c","c4f1d8f4f03d451a859ce7a7917c3297","684b5010ddfd4987939df5464fcd0723","2ddafa21637742eaa61176c1653207e8","c0dbddea6c50450d8d8e76c870d69808","9eb276acd2544bb89b7185dd3b732be6","8a3342c19ab84382a3d7b29fa166f03e","2b569e3c02c942bba8fd2a41cde02135","c31ef7318f594742a5e9f891ab3b2279","420c28ff9487476b931aafa988f39f40","06eebef75d1d47f899ee115d42b49eb8","996f5a64a8024efea37bcc3e567871fd","6f7418d7a0024907a395e607aaccf6c6","eeacb562b02643c89c7f890683713bee","e96aaa5c2cfa4be8b47974e7bc014c9e","cf7829e58c51491bab2e03e12ca98dc7","71e62f9ed5db430cb357a498676785fb","a28558311ba84702bd627f64f5d86579","42687bb647d046af889992261f279d3b","bf9a51f8d3414766bf20d25e98ce84ac","2d7e6571344f4dbfadda201286eb8b3d","94106dcff9174189aefc11e139c6084c","3acfa82b74764f02b430cdc1e3b31936","c0c8d887952743efa417cd6d50834d6b","d291cbba0b5841739f7a806b86566c71","f44bdc6477db4d198c67336a65b44157","b27e2f5a49c7464f8edbd9809a3540d9","a422405f854e4475860c5fd07f9f304c","3b94bc624b854b9ca51c195445750da2","fde1d0e50c1b4f178e3f2421dc107d19","d967bb54eeda4905b972aacf81cdcdf6","76cac93eef9c422fbce327279575090b","8bc8fd38c05a4b889f6a25b521591fc2","f5bcf621bd94460a9df06f534e4bb718","443bf8d7b36e44a58767f21754cf9ff6","c570c039116b41b18c208ba024393e62","109cce74e3034c56a5b422f0d6858ef1","515398c92c124ca9a99b4b4dbbfc8c3c","c01e13fd9ec34c0b89a4c3ae059a823c","78e7a42263504d96ac060fea68325f05","b2b126a422554a738cb1aa706de1c58a","fe4a9b6df3cf4350ae3760c5c339260b","abb53c7e5a7648f6b655d2fe9c3458d8","0c46a71e0bc941e1968d8443f3f68dc4","98c4c7e35e2f458b9561e9d622ad9cbf","4b318c3c35e44429a91c4b3983d7856c","ea7ddc32b0b743b68d78b17c0d137dbb","e689a51f3bc248ac877f555664a86906","14e7de82dda8469dab5b3cc825379329","be8d2c7e049b4c03927805292015e73e","94921abf4edf41a5b69b8ec968ad748a","50f66a774c3b4bb3906678f36c3a6aa7","ff887b70b9394e1ab7b484f80c1cd41f","28cec4e34c4949af90ee918710b84b1b","a11ebfd732cd4b9695a3cc8561f51b5b","73ed5a778fec4ef28f38fd970eedb7e8","2e2974c2903e4d048c438af35d2638c6","85354e26e29744e78c76a231408bba7c","df12419ff8974da1b7baf13f9bdda7cb","30b5512d2b994afda3aae92034b0de24","714279eb03b144168d79a2c81f0fe6f8","4e445d1841ce43e6b4ee6b98ea747d57","c83041b6271e4549b7d3b4fea6a7e9bb","05cc3f5045bc4cffbd1549cf1da7a3f0","1ff64a66efc14656827ed21f32085605","df88d6001af54345ade6e7a9197fcf3d","8da14e2a44ea4d73a00168a2c90f7040","831dd82a1f184a76a877d97be364b2a6","22aa0d378d9147048ff2265c821244d3","f749fbb799ae4546943cd41dcf235ef8","76706ff0286b40908026cec3023ad2eb","820eb0a7d6d2492b98683cc4b28e9c60","6c290027764d4ee1979492e641339370","a8fabaf2179b435db26d78ba94055298","463365f327994a58b4ecea91ef653b8c","3ffd083c88c7484abc9d5f61c6e36b38","00919d8ee5f44d1c850841009b6e53aa","11e46d47191f4ebda2e5df179375055c","134bc08709e1430da4e216516722631c","9acfee58033340cba8446e02b7de429a","580a7544479d48f495a05397328e0f3f","0db11ec73d804ed1a7842a27440ad2f4","2501d0bdb50f4ec4aea3ade7b77d723e","320d07bfeb02410fa6219c9c9e13696c","9380c4ac7d034a5ebca8c8f2888696fe","372cea71d30d4511a6e74be81433b9d4","79f731ed94af4909898dbb2943162175","110d6216f4b2491a9f2145e5751824d4","367faa90e77245b085259f2f1ab221e1","850660bf5ac54f628669f085eb8631ec","98093a0e9018490c8db85d1f02efd510","eb6e61cb71e34b559a7b49c44385517c","0141a3312a2c440d8b041902722c3b0f","4dcecc13a732438785622b5efc8daa17","d23e9f3cefef4e61bff001e8ed160cee","095c6735afa74d7085c501dde02f6532","c7bdd5b60b6c4605b63621a0472faa25","5f8c860caea84e3f985031ec4ac3acf5","429c92391fef42ad882703ba721bef85","c8fef86ab95c4c5d88a233f17c148f08","0db76d27bc0743dcb79264341866c6f2","4ff9497d19a741ebab02d5248934d673","61b8f7c8f65942cf8ae7c025b6380c3f","dda3e4d36201429a8214f01bd0a4fc3f","0a307bbbd2d84c5ea9073a17ac7f5858","fbc00246ce25453d9242660c1d51e9ec","7e76a7d3c6e54221a75b7c2634807d5e","80b6864075c54eaca953422fff19b6ee","594ced9d38cf476196ff77673d2dc842","e6b9a42d3d5a43f8b7337342b73df3e9","816fcbee3366416487b9bfb79f57ff4e","ee0ec0eaeb5d427eae3998960af504e3","d42d8fd669bd4fd196ea752765b1267b","3834c42cc5c54d21b0d2e92c558a9317","9330d948fcfd45d1aaa07a636c6a8be5","63a57c4ccd4245afa8faa646388f81bd","aff2fa41c1244ac19ca2fc1c5b03d1ff","a4a3dee47c724c0b8b9b571a8ef07772","266bf26654724326a1b3e28ec1ea5738","c6e145622b20463bb2830521b2360b3c","fccd5aacbd584eb288d237792c0aeda2","322b9c6efef54c81bf092140d37004d4","34cbce1becc0489e9179d24c0e656112","faef163acda8431888a8df7e1f2db9be","8d11e5f76d684c2cb8a9ad337f47ea25","7f3e135bc08649e4b2a2ddbdc7518fb0","1e2e621ab67f45fbb2cfd6ade49b3923","2f1e3a6f3d38458cbdc1dba56e4ab566","02cea3ce34554a51a0b857849ee34d30","495fa4666b5b42c89e29bd42b4f2da79","1e6a5be430bf4d938dff4a4cfa8d1122","d74cbd27fd7f41aa9c659f4423faff82","2edee44bda6c4496bedbde1d1b42b681","d238061e81724440b297fc0d864470b8","f22f83ccf08145e5897df519c188729b","e76dd078fff94852b513cbc6359c0a1d","fee451d6ffdd48c692424c5e7416b1b4","061f8af0106e497d9292c8a436451341","087a130042864180b14ab2bf29d3a954","a1ed6c53b7214120ab27b0b023381061","e8439aea20584bb982bd37d2fc9d96e6","d359e82b927e42dbb44d6dbeb6f079e0","9960b9457fd5437084eba4b28666c5e6","ba8a55c4fb664d2db89f3512b9009dec","bc377684b7f94a2fab0602ece1b19f78","763bdbcadb944f8aa4cd487ed2119df2","b242d7f504d940fbb2ff40b238fa4c5f","7b187e343a72461484555a1a12004ee3","1ad48934aafd4db189cdce0cf6713354","8fa354c480a04eb6aed4bc4ece6b5b75","4f79b2072f0949d1a958aba53d024786","1ae7410aa6384499a9d69fec95f43e18","120e82ba948f4f6eb5b9e56dfa83597d","86fa20f1f0974fdba512e0a768291444","6cb740897cb849d79ce89c3c09a0348a","54ee59a1f24443ccbef385a2f057ff68","1402f26e69884365bdb8e2f7f069250d","7bc07df0eb67434c956d8d7bccfa78fd","af3eb0543c414381a68c9ec9d2f6d853","8d47e1f70280434587b57dbb4556dc0a","72c9a9a2d6de46a0ac1c75c1092b6bce","b210278462fc41eca9efc3c2240f66d0","b4bdeea4c6d848ca87ba93d1ec71689b","e1cc2fde68894591acf0793b27d99ddb","eb42e8d2b2154066a0fcf44324ba7ee7","21569a0ddbde4e31acdd86f14f0c4f27","c34838b455454812a7ad358a4919c441","ef8720c024284f0bbc33075cd103f449","514d233e1b6e42e38cd84ad67cae31a4","cd5c2ef6a8164d0d92af19313023f877","5d53654842bd4f7191806ca3d5c2f27a","177702beb79249cdafef6e0ec8118e84","cb2915e039e2479798d42ad6777ebff8","6ec3b66035624444b371077f8ff38b9b","bf951211e0c542e4999daf349f16aad1","89b73f037ebf40b4b157acc88d0153dc","b5f3a8e9988244f28e684750e3f1f678","0b49b37ce20d4c54b88890b9cbe3f1cd","3c49651cdeb1497486e3c5f6d962e86e","fd6d06412ec84945b9dbe81eaae7209d","7f034b6ce4aa4808a37be8dda40a93e2","56f9d1dbf50740628b7e033e59fb9a91","1756cf0f477a4607b36196bb0c257238","4af73a14f3a3478b8cc1438978a979d5","2bcf5655502f4a19b3e21b032658b964","66cda6503de5420f803b03723d15b4f8","c71e3570e3284807a8f238fda34518b5","2aef8155248b43a5881e54344387a45b","be82ac2f99c34838887d036763f7e92a","97158e7a49364f138a04472d01e177ea","b83a50959b874d8f9179cca75ee86047","864f4582ae7246c89b0d2e4a30726a58","0cabe33574a94ca5a1a253bd411e06c9","456f246193cc4d8d9348bb5269f1e384","3441ca387b074f65808d964e3628bcb4","00544322d09642428aacb91ebcd66956","b73bf01c73a148c5932b73b2118700a4","352cb8b1dcf647788a2482fed75e5c94","67e88bd195c442949465803aaf91282f","ffe3ea66132445af9ee480e7f8b3f824","b42d8df78bca47748d443aac11baef14","7277bc7014d941b496793c1569de05b8","50e5cc7c4c10407393ad3a940d5346f4","43fe70054c664a3094c353267fd39afa","3a03fa97f93a40b888349631e09ec526","e8c76264337b494394b752be08fa45ef","0986f4ad0d2c4857ac32623911d351a4","39aebe0573094272bee81894aa421611","fa401d14edc6455f8e9e111f51518915","af2c91af09fc4ef3bc5287a9c106edd5","93719c0467df46a7b9f7bf049414bfc1","b4f97e2af0474b06a101959e4caf26b8","ed09f82273eb4a688f550b92c193919b","df80b1d14f4c41baa40ca4f7cb7399ad","3fb66ee77c394bfcb8f5963db485a703","23cdd8a9e7ca4e288f8136be3d02495d","c84e33ab2af045a2a46b2fa818bc3124","1b87480e4ba7457ca143f3991999c85c","a098c33967ad40f893cad10f5e3c4497","cf54fbae7a394b988ea0a03a4735a462","4ed65dde635a4f7db69332b6969cdab9","571616fe0a6f44efbb2a311e4a78e37b","a8443369630640c2beb24dff8bece714","aae5b141d81a46a882a503d91bc5a496","22239f0708934db7a1c430145d600815","8ac301f73daf457d95abe3b5fc194cdd","34ef262442ca47028f02aa41f9d75cb4","dc6973b42bac4b43aba50f17c71a9ce0","b71b43591b264f9b80df6ac41ba2ce3c","5c7a77cb4845409b99301d36eb9edf51","f369a7e6b73c4137b0b9e6a66fbaf953","2e9daa6d5e2d44af8fe4f1f94d617f52","6586e7df45e840d0b3c430e826cf4f7f","3cc1a19fe46d483bb2938dc98fe64ea8","167a97ba943447d081f8354a28b606c7","861244358d3a4e8e8d98029728427ebb","feaa63c0bcbb4706a217ebf161a09224","c9efc869a69a4204ae89e32af3c7dfba","a099f4e26fc447b68c248a0cbdc867ff","0631f86b9d3d4c9198095558a43998be","1d468baaf5ec44958a9ff6697143bd4c","bf9626f28084445bb3961033c6cde6ec","b656f2d9868a49d78ce85b8a1121e965","993b6e8c4cc240318e9b24be269884e7","1236f50319f54568ab76599513630a80","f9a1a08252bb45f388a610492a9996c1","284b6f6040c24de7b9611da9f187bd63","40bd03f0234245cfa781f59720ef223e","c82110c9c27d4edcbb7b6bcdee66134b","d2b843f63f3e48c1ac54ddd6e6da0e8f","7b27a525ab6444cd9e2185f5607aba80","8fa03ac193c6471da242b7f00311d05f","21b86af3bfd44f4b8c145a745ae0b14c","76683aef1706469b88ebba06c104bfe7","7a3d0d94a8b54e68aac704656430af0a","016ba34b4c2745c39a77e73d966a4eb7","09ceafdabc7d40e194a719d23f801c2d","f72ac6f2e32f42b99c8c530b60192530","c96c1c946d404c0f8ad967c9af998a33","afcca26259da4d428721c6179fdf5dc5","8db1bdf60ccf4393addb1c427b020508","660967e0c9364bf990bf15b22a78a331","e161e75e5e1d4fae9c522f86adddf658","0ef027d6365447888677ab79a7a8b996","47188d4751204e739118079159b2d1b9","767e93d42b904b29b595dab10145fc76","8a60a78bc026415a90d81549eaf095f3","cacb4330aff540079323b31326121dfb","8028103bd5fa47e383a2f696d6e7a028","993cbd74aa0849f88800c526c3072465","1d1e4a479c9c429bb8f45f0418d9f560","22ccd15ce04d431da194b7a3ecb39454","6a2e0e22b28042859321170da312b047","b4940cdc15874adfa55b4dab3b543701","436839a265974a1e9502a6878135f239","8662666787ed4cadb87da14d68e5d4b6","d8669ffb74ee4798ad9aea71129436db","b16c9b262d6646c6b70a65c0fb1e840b","6161c32b28e540b49c7c0c2e534740db","b20525b13de14b86bd1214ea41cc70c1","3429920725024d6884b12d2da9680067","452e2b63566149518b3cccf842f3d7cf","b3d212ab9dd649a58cce830b3b8bccd4","de0417f4cbf146de960f24991ae22a38","d2fc598b9f504c90a1f698e6b2e3443d","7071817d29934e84bd0cd2d2ecb08a91","86573ccfddd14868b196313e46fb76db","cc1470445d6c4b548a72c3da9b09d69e","6c1d0b5780c34dd8a1201002de721438","6a4c4094dd854831bca0d8aa6bd7c55d","f98844b1639f48efa00f93fe99548627","aa2c7654bb8940ac98838ff0c4f586f0","93e8100ec67448198d836cdf0e5cf5c6","cf6d5ad994d5442bad53a8733e5ebbe9","8fe488e8defb4d5d9eb6ada349c621fd","b3047380558d432faac16dafeb7ff87c","a5d7a7f04a15496eba8ddcb0aa8a6329","89f87b5a7cc043e88b92b785d8bfe72c","5bf15aef927c4b7f88f5a6adbd42cc8b","3c5e73074e0043cb903ce1354964bbe9","ce30894b17ba4521837582ee3698e6f5","9002de4513d94659baaee21d5b9c9fae","390bb9468f1d4891b5feade82178ef31","b537d9e8bb104af1b5bb3fb32112994b","1b68c6b6998f4aee965e2400ce424c20","ba922c0d00a64a4e877659727e451986","f910f464a3c04619b74c2414e43a1ff1","39e4b2397adf49ec95df6258c70e6acf","5e05ae9c935345f58565494707306700","1ead213580284aabbb44bb609de76166","e1ce0176b2bc45ca8fd9bd6b4f35d69d","8325851b23bf478ba2323ad1a2daaa5b","6d458943125941048ccca5759ab4c0b9","102bf9fbf4064c438b54c68550102e73","58eb79b5f7ed440793ddc7686cb5f8f1","d6495da9b25340cbba9905fc21c96448","bed5ad6ae7ca4737b3ce0f75610b6bda","3e7642a36e2d4890a54a93b60888d281","f54df648e49841b3acd5839ba8b9ac43","f372d9ba220146cdbd646ea1747dcb22","d1d6403e929d464386b78786bcf95b17","5608a2f99594433ba1beaa1678c45f9e","6f176d32ccae416d9fd97985c97adc9c","25d57a7a459e40bbb071a8376fe36fd6","651b1e11f0854989865b683ec1a27436","50e29bc583594f58bb15a00d580226cd","4c8d33f68df34703aefac0402e8cd4d7","f83cc2cb446c4b35b1ab4476aeb714c2","aa040766abad4f7b91a553f4250c0d52","8198d3f4dc6e4a2c8f12fc51ff718eb6","47b10dc178ec462198d0d10d04508a4a","c2c0fe35380340aea2d37b0afebb0fbb","8ec4ea3a56dc45d18de6f34680e2fcf5","e1270729e14e462d99bee5f004bcdfe2","0507ad76e4fd4783971c32ad71762aac","cf1b25cca0584e3cb3a52649722bc985","9450f7644c6341559f11088ca90195c4","355f5115681e479b8bacc172ed4714e2","7f451b1b928e4ae2bc3f182d8ea100db","c7de4c9f221942b080c3e41a35939b2e","1f8973bd3b64492e96f4c0d2258b2678","3104009aba1b4d0ab41bdc0a110b2ad3","4301ae8415714ee0b121cbebfd7536b9","6f4f08f9cc71453791d260fd798894bf","bd10db7b40984617bff36db35cfc080a","fb74dd7306ec435791db27e79cb14d6d","57bcecbaa15f4d29856a38c520749145","f32b2d522f644d35a21a11bcb7be6b9f","bd6997ee2869405f9c65821dd0b39369","4ffdd5a4f391430f81a42d5fcb251e36","b9805eeb9f344bf8b16d1cd770c3c22b","0046e09c5d0746e1b45ce72057f0f3bc","c36312eea2134530ac7f6a763b693fd8","8488ed9d2887440c84a17cbae7c11213","11ed85864ff54a2db2a0ecc66de4c5d4","3d8f88b16a7c4d6da9c163ddc5507d0e","d171bb1b6c2045318b21e027aac4e7d4","1ffbcf8d68ad4133aa31045ecf9d86db","0ed3226fe20a4da8893bb3904414f345","58d1f98331bc471aa3214ba13bb9d559","8be509d6dad049b1b3c227c676ea6ec0","9f9b466830cb4528a76b167684322456"]},"id":"1SNpV_DS2t0Y","outputId":"a3489c94-1419-4264-f23e-3d132c310f14","executionInfo":{"status":"ok","timestamp":1651812204653,"user_tz":-60,"elapsed":58802880,"user":{"displayName":"Ziyad Moraished","userId":"09734916932076943331"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["###################### Training vgg19_batch_norm SGD, lr_0.0001, momentum_0 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c4c8f731ae6481884ad3f58fb627ca1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 13750, Training loss: 2.4102863, Training accuracy: 0.1100000, Time: 05_05_2022__12:23:59\n","Epoch 1 of 5, Step: 200 of 13750, Training loss: 2.3937677, Training accuracy: 0.1200000, Time: 05_05_2022__12:24:17\n","Epoch 1 of 5, Step: 300 of 13750, Training loss: 2.3815683, Training accuracy: 0.1250000, Time: 05_05_2022__12:24:35\n","Epoch 1 of 5, Step: 400 of 13750, Training loss: 2.3545620, Training accuracy: 0.1318750, Time: 05_05_2022__12:24:54\n","Epoch 1 of 5, Step: 500 of 13750, Training loss: 2.3390508, Training accuracy: 0.1470000, Time: 05_05_2022__12:25:12\n","Epoch 1 of 5, Step: 600 of 13750, Training loss: 2.3194239, Training accuracy: 0.1595833, Time: 05_05_2022__12:25:31\n","Epoch 1 of 5, Step: 700 of 13750, Training loss: 2.2935714, Training accuracy: 0.1717857, Time: 05_05_2022__12:25:50\n","Epoch 1 of 5, Step: 800 of 13750, Training loss: 2.2748892, Training accuracy: 0.1787500, Time: 05_05_2022__12:26:09\n","Epoch 1 of 5, Step: 900 of 13750, Training loss: 2.2563591, Training accuracy: 0.1902778, Time: 05_05_2022__12:26:29\n","Epoch 1 of 5, Step: 1000 of 13750, Training loss: 2.2351210, Training accuracy: 0.1985000, Time: 05_05_2022__12:26:48\n","Epoch 1 of 5, Step: 1100 of 13750, Training loss: 2.2173612, Training accuracy: 0.2100000, Time: 05_05_2022__12:27:07\n","Epoch 1 of 5, Step: 1200 of 13750, Training loss: 2.1972272, Training accuracy: 0.2181250, Time: 05_05_2022__12:27:27\n","Epoch 1 of 5, Step: 1300 of 13750, Training loss: 2.1748356, Training accuracy: 0.2319231, Time: 05_05_2022__12:27:47\n","Epoch 1 of 5, Step: 1400 of 13750, Training loss: 2.1550643, Training accuracy: 0.2441071, Time: 05_05_2022__12:28:06\n","Epoch 1 of 5, Step: 1500 of 13750, Training loss: 2.1376764, Training accuracy: 0.2546667, Time: 05_05_2022__12:28:26\n","Epoch 1 of 5, Step: 1600 of 13750, Training loss: 2.1192239, Training accuracy: 0.2631250, Time: 05_05_2022__12:28:46\n","Epoch 1 of 5, Step: 1700 of 13750, Training loss: 2.1007452, Training accuracy: 0.2720588, Time: 05_05_2022__12:29:06\n","Epoch 1 of 5, Step: 1800 of 13750, Training loss: 2.0764743, Training accuracy: 0.2823611, Time: 05_05_2022__12:29:25\n","Epoch 1 of 5, Step: 1900 of 13750, Training loss: 2.0542745, Training accuracy: 0.2930263, Time: 05_05_2022__12:29:45\n","Epoch 1 of 5, Step: 2000 of 13750, Training loss: 2.0329674, Training accuracy: 0.3035000, Time: 05_05_2022__12:30:05\n","Epoch 1 of 5, Step: 2100 of 13750, Training loss: 2.0132415, Training accuracy: 0.3123810, Time: 05_05_2022__12:30:25\n","Epoch 1 of 5, Step: 2200 of 13750, Training loss: 1.9922709, Training accuracy: 0.3234091, Time: 05_05_2022__12:30:44\n","Epoch 1 of 5, Step: 2300 of 13750, Training loss: 1.9721693, Training accuracy: 0.3330435, Time: 05_05_2022__12:31:04\n","Epoch 1 of 5, Step: 2400 of 13750, Training loss: 1.9527710, Training accuracy: 0.3414583, Time: 05_05_2022__12:31:24\n","Epoch 1 of 5, Step: 2500 of 13750, Training loss: 1.9327970, Training accuracy: 0.3511000, Time: 05_05_2022__12:31:44\n","Epoch 1 of 5, Step: 2600 of 13750, Training loss: 1.9145550, Training accuracy: 0.3591346, Time: 05_05_2022__12:32:04\n","Epoch 1 of 5, Step: 2700 of 13750, Training loss: 1.8953648, Training accuracy: 0.3679630, Time: 05_05_2022__12:32:23\n","Epoch 1 of 5, Step: 2800 of 13750, Training loss: 1.8750894, Training accuracy: 0.3770536, Time: 05_05_2022__12:32:43\n","Epoch 1 of 5, Step: 2900 of 13750, Training loss: 1.8534950, Training accuracy: 0.3863793, Time: 05_05_2022__12:33:03\n","Epoch 1 of 5, Step: 3000 of 13750, Training loss: 1.8322213, Training accuracy: 0.3964167, Time: 05_05_2022__12:33:23\n","Epoch 1 of 5, Step: 3100 of 13750, Training loss: 1.8122521, Training accuracy: 0.4045968, Time: 05_05_2022__12:33:42\n","Epoch 1 of 5, Step: 3200 of 13750, Training loss: 1.7934735, Training accuracy: 0.4122656, Time: 05_05_2022__12:34:02\n","Epoch 1 of 5, Step: 3300 of 13750, Training loss: 1.7730571, Training accuracy: 0.4212121, Time: 05_05_2022__12:34:22\n","Epoch 1 of 5, Step: 3400 of 13750, Training loss: 1.7542654, Training accuracy: 0.4286765, Time: 05_05_2022__12:34:42\n","Epoch 1 of 5, Step: 3500 of 13750, Training loss: 1.7360645, Training accuracy: 0.4365714, Time: 05_05_2022__12:35:01\n","Epoch 1 of 5, Step: 3600 of 13750, Training loss: 1.7186808, Training accuracy: 0.4429167, Time: 05_05_2022__12:35:21\n","Epoch 1 of 5, Step: 3700 of 13750, Training loss: 1.7025752, Training accuracy: 0.4491892, Time: 05_05_2022__12:35:41\n","Epoch 1 of 5, Step: 3800 of 13750, Training loss: 1.6850829, Training accuracy: 0.4567763, Time: 05_05_2022__12:36:01\n","Epoch 1 of 5, Step: 3900 of 13750, Training loss: 1.6678737, Training accuracy: 0.4639103, Time: 05_05_2022__12:36:20\n","Epoch 1 of 5, Step: 4000 of 13750, Training loss: 1.6502397, Training accuracy: 0.4709375, Time: 05_05_2022__12:36:40\n","Epoch 1 of 5, Step: 4100 of 13750, Training loss: 1.6339967, Training accuracy: 0.4775610, Time: 05_05_2022__12:37:00\n","Epoch 1 of 5, Step: 4200 of 13750, Training loss: 1.6169136, Training accuracy: 0.4847619, Time: 05_05_2022__12:37:20\n","Epoch 1 of 5, Step: 4300 of 13750, Training loss: 1.6011060, Training accuracy: 0.4910465, Time: 05_05_2022__12:37:39\n","Epoch 1 of 5, Step: 4400 of 13750, Training loss: 1.5850601, Training accuracy: 0.4973295, Time: 05_05_2022__12:37:59\n","Epoch 1 of 5, Step: 4500 of 13750, Training loss: 1.5680390, Training accuracy: 0.5036111, Time: 05_05_2022__12:38:19\n","Epoch 1 of 5, Step: 4600 of 13750, Training loss: 1.5507370, Training accuracy: 0.5098913, Time: 05_05_2022__12:38:39\n","Epoch 1 of 5, Step: 4700 of 13750, Training loss: 1.5361853, Training accuracy: 0.5155319, Time: 05_05_2022__12:38:58\n","Epoch 1 of 5, Step: 4800 of 13750, Training loss: 1.5209442, Training accuracy: 0.5214062, Time: 05_05_2022__12:39:18\n","Epoch 1 of 5, Step: 4900 of 13750, Training loss: 1.5054076, Training accuracy: 0.5273980, Time: 05_05_2022__12:39:38\n","Epoch 1 of 5, Step: 5000 of 13750, Training loss: 1.4908756, Training accuracy: 0.5327500, Time: 05_05_2022__12:39:58\n","Epoch 1 of 5, Step: 5100 of 13750, Training loss: 1.4761608, Training accuracy: 0.5379902, Time: 05_05_2022__12:40:17\n","Epoch 1 of 5, Step: 5200 of 13750, Training loss: 1.4614383, Training accuracy: 0.5430769, Time: 05_05_2022__12:40:37\n","Epoch 1 of 5, Step: 5300 of 13750, Training loss: 1.4480487, Training accuracy: 0.5475472, Time: 05_05_2022__12:40:57\n","Epoch 1 of 5, Step: 5400 of 13750, Training loss: 1.4334077, Training accuracy: 0.5527778, Time: 05_05_2022__12:41:17\n","Epoch 1 of 5, Step: 5500 of 13750, Training loss: 1.4192475, Training accuracy: 0.5576364, Time: 05_05_2022__12:41:36\n","Epoch 1 of 5, Step: 5600 of 13750, Training loss: 1.4063388, Training accuracy: 0.5621875, Time: 05_05_2022__12:41:56\n","Epoch 1 of 5, Step: 5700 of 13750, Training loss: 1.3935973, Training accuracy: 0.5667105, Time: 05_05_2022__12:42:16\n","Epoch 1 of 5, Step: 5800 of 13750, Training loss: 1.3803170, Training accuracy: 0.5715086, Time: 05_05_2022__12:42:36\n","Epoch 1 of 5, Step: 5900 of 13750, Training loss: 1.3679161, Training accuracy: 0.5758898, Time: 05_05_2022__12:42:55\n","Epoch 1 of 5, Step: 6000 of 13750, Training loss: 1.3571726, Training accuracy: 0.5796250, Time: 05_05_2022__12:43:15\n","Epoch 1 of 5, Step: 6100 of 13750, Training loss: 1.3444174, Training accuracy: 0.5843443, Time: 05_05_2022__12:43:35\n","Epoch 1 of 5, Step: 6200 of 13750, Training loss: 1.3333673, Training accuracy: 0.5881452, Time: 05_05_2022__12:43:55\n","Epoch 1 of 5, Step: 6300 of 13750, Training loss: 1.3218958, Training accuracy: 0.5919841, Time: 05_05_2022__12:44:14\n","Epoch 1 of 5, Step: 6400 of 13750, Training loss: 1.3100404, Training accuracy: 0.5958594, Time: 05_05_2022__12:44:34\n","Epoch 1 of 5, Step: 6500 of 13750, Training loss: 1.2981355, Training accuracy: 0.5999231, Time: 05_05_2022__12:44:54\n","Epoch 1 of 5, Step: 6600 of 13750, Training loss: 1.2870526, Training accuracy: 0.6040152, Time: 05_05_2022__12:45:14\n","Epoch 1 of 5, Step: 6700 of 13750, Training loss: 1.2754885, Training accuracy: 0.6078731, Time: 05_05_2022__12:45:33\n","Epoch 1 of 5, Step: 6800 of 13750, Training loss: 1.2642731, Training accuracy: 0.6117647, Time: 05_05_2022__12:45:53\n","Epoch 1 of 5, Step: 6900 of 13750, Training loss: 1.2537392, Training accuracy: 0.6150725, Time: 05_05_2022__12:46:13\n","Epoch 1 of 5, Step: 7000 of 13750, Training loss: 1.2435324, Training accuracy: 0.6185357, Time: 05_05_2022__12:46:33\n","Epoch 1 of 5, Step: 7100 of 13750, Training loss: 1.2337011, Training accuracy: 0.6219014, Time: 05_05_2022__12:46:52\n","Epoch 1 of 5, Step: 7200 of 13750, Training loss: 1.2237797, Training accuracy: 0.6251389, Time: 05_05_2022__12:47:12\n","Epoch 1 of 5, Step: 7300 of 13750, Training loss: 1.2139925, Training accuracy: 0.6283904, Time: 05_05_2022__12:47:32\n","Epoch 1 of 5, Step: 7400 of 13750, Training loss: 1.2036486, Training accuracy: 0.6320946, Time: 05_05_2022__12:47:52\n","Epoch 1 of 5, Step: 7500 of 13750, Training loss: 1.1941271, Training accuracy: 0.6352667, Time: 05_05_2022__12:48:11\n","Epoch 1 of 5, Step: 7600 of 13750, Training loss: 1.1849434, Training accuracy: 0.6383224, Time: 05_05_2022__12:48:31\n","Epoch 1 of 5, Step: 7700 of 13750, Training loss: 1.1754072, Training accuracy: 0.6416234, Time: 05_05_2022__12:48:51\n","Epoch 1 of 5, Step: 7800 of 13750, Training loss: 1.1665098, Training accuracy: 0.6447436, Time: 05_05_2022__12:49:11\n","Epoch 1 of 5, Step: 7900 of 13750, Training loss: 1.1583185, Training accuracy: 0.6474684, Time: 05_05_2022__12:49:30\n","Epoch 1 of 5, Step: 8000 of 13750, Training loss: 1.1497173, Training accuracy: 0.6502813, Time: 05_05_2022__12:49:50\n","Epoch 1 of 5, Step: 8100 of 13750, Training loss: 1.1404131, Training accuracy: 0.6535185, Time: 05_05_2022__12:50:10\n","Epoch 1 of 5, Step: 8200 of 13750, Training loss: 1.1319126, Training accuracy: 0.6562805, Time: 05_05_2022__12:50:30\n","Epoch 1 of 5, Step: 8300 of 13750, Training loss: 1.1234813, Training accuracy: 0.6591867, Time: 05_05_2022__12:50:49\n","Epoch 1 of 5, Step: 8400 of 13750, Training loss: 1.1160106, Training accuracy: 0.6617262, Time: 05_05_2022__12:51:09\n","Epoch 1 of 5, Step: 8500 of 13750, Training loss: 1.1079908, Training accuracy: 0.6642941, Time: 05_05_2022__12:51:29\n","Epoch 1 of 5, Step: 8600 of 13750, Training loss: 1.1004324, Training accuracy: 0.6668314, Time: 05_05_2022__12:51:48\n","Epoch 1 of 5, Step: 8700 of 13750, Training loss: 1.0933097, Training accuracy: 0.6691379, Time: 05_05_2022__12:52:08\n","Epoch 1 of 5, Step: 8800 of 13750, Training loss: 1.0857626, Training accuracy: 0.6717898, Time: 05_05_2022__12:52:28\n","Epoch 1 of 5, Step: 8900 of 13750, Training loss: 1.0780141, Training accuracy: 0.6742978, Time: 05_05_2022__12:52:48\n","Epoch 1 of 5, Step: 9000 of 13750, Training loss: 1.0708477, Training accuracy: 0.6765000, Time: 05_05_2022__12:53:07\n","Epoch 1 of 5, Step: 9100 of 13750, Training loss: 1.0633159, Training accuracy: 0.6790659, Time: 05_05_2022__12:53:27\n","Epoch 1 of 5, Step: 9200 of 13750, Training loss: 1.0566658, Training accuracy: 0.6810326, Time: 05_05_2022__12:53:47\n","Epoch 1 of 5, Step: 9300 of 13750, Training loss: 1.0492930, Training accuracy: 0.6835753, Time: 05_05_2022__12:54:06\n","Epoch 1 of 5, Step: 9400 of 13750, Training loss: 1.0423198, Training accuracy: 0.6857447, Time: 05_05_2022__12:54:26\n","Epoch 1 of 5, Step: 9500 of 13750, Training loss: 1.0353864, Training accuracy: 0.6880000, Time: 05_05_2022__12:54:46\n","Epoch 1 of 5, Step: 9600 of 13750, Training loss: 1.0287675, Training accuracy: 0.6902604, Time: 05_05_2022__12:55:06\n","Epoch 1 of 5, Step: 9700 of 13750, Training loss: 1.0219047, Training accuracy: 0.6924485, Time: 05_05_2022__12:55:25\n","Epoch 1 of 5, Step: 9800 of 13750, Training loss: 1.0151984, Training accuracy: 0.6946173, Time: 05_05_2022__12:55:45\n","Epoch 1 of 5, Step: 9900 of 13750, Training loss: 1.0085719, Training accuracy: 0.6965909, Time: 05_05_2022__12:56:05\n","Epoch 1 of 5, Step: 10000 of 13750, Training loss: 1.0017602, Training accuracy: 0.6986000, Time: 05_05_2022__12:56:24\n","Epoch 1 of 5, Step: 10100 of 13750, Training loss: 0.9954947, Training accuracy: 0.7007426, Time: 05_05_2022__12:56:44\n","Epoch 1 of 5, Step: 10200 of 13750, Training loss: 0.9892580, Training accuracy: 0.7028186, Time: 05_05_2022__12:57:04\n","Epoch 1 of 5, Step: 10300 of 13750, Training loss: 0.9829203, Training accuracy: 0.7049757, Time: 05_05_2022__12:57:23\n","Epoch 1 of 5, Step: 10400 of 13750, Training loss: 0.9772849, Training accuracy: 0.7068029, Time: 05_05_2022__12:57:43\n","Epoch 1 of 5, Step: 10500 of 13750, Training loss: 0.9711534, Training accuracy: 0.7087619, Time: 05_05_2022__12:58:03\n","Epoch 1 of 5, Step: 10600 of 13750, Training loss: 0.9654255, Training accuracy: 0.7104481, Time: 05_05_2022__12:58:23\n","Epoch 1 of 5, Step: 10700 of 13750, Training loss: 0.9596688, Training accuracy: 0.7122664, Time: 05_05_2022__12:58:42\n","Epoch 1 of 5, Step: 10800 of 13750, Training loss: 0.9541105, Training accuracy: 0.7141435, Time: 05_05_2022__12:59:02\n","Epoch 1 of 5, Step: 10900 of 13750, Training loss: 0.9483232, Training accuracy: 0.7160550, Time: 05_05_2022__12:59:22\n","Epoch 1 of 5, Step: 11000 of 13750, Training loss: 0.9426669, Training accuracy: 0.7177955, Time: 05_05_2022__12:59:41\n","Epoch 1 of 5, Step: 11100 of 13750, Training loss: 0.9375379, Training accuracy: 0.7194144, Time: 05_05_2022__13:00:01\n","Epoch 1 of 5, Step: 11200 of 13750, Training loss: 0.9319894, Training accuracy: 0.7211607, Time: 05_05_2022__13:00:21\n","Epoch 1 of 5, Step: 11300 of 13750, Training loss: 0.9262009, Training accuracy: 0.7230973, Time: 05_05_2022__13:00:41\n","Epoch 1 of 5, Step: 11400 of 13750, Training loss: 0.9209254, Training accuracy: 0.7247588, Time: 05_05_2022__13:01:00\n","Epoch 1 of 5, Step: 11500 of 13750, Training loss: 0.9159867, Training accuracy: 0.7263478, Time: 05_05_2022__13:01:20\n","Epoch 1 of 5, Step: 11600 of 13750, Training loss: 0.9106997, Training accuracy: 0.7280603, Time: 05_05_2022__13:01:40\n","Epoch 1 of 5, Step: 11700 of 13750, Training loss: 0.9057589, Training accuracy: 0.7295940, Time: 05_05_2022__13:02:00\n","Epoch 1 of 5, Step: 11800 of 13750, Training loss: 0.9008318, Training accuracy: 0.7310593, Time: 05_05_2022__13:02:19\n","Epoch 1 of 5, Step: 11900 of 13750, Training loss: 0.8958920, Training accuracy: 0.7326050, Time: 05_05_2022__13:02:39\n","Epoch 1 of 5, Step: 12000 of 13750, Training loss: 0.8910930, Training accuracy: 0.7342292, Time: 05_05_2022__13:02:59\n","Epoch 1 of 5, Step: 12100 of 13750, Training loss: 0.8864176, Training accuracy: 0.7355992, Time: 05_05_2022__13:03:18\n","Epoch 1 of 5, Step: 12200 of 13750, Training loss: 0.8820619, Training accuracy: 0.7368238, Time: 05_05_2022__13:03:38\n","Epoch 1 of 5, Step: 12300 of 13750, Training loss: 0.8774527, Training accuracy: 0.7382927, Time: 05_05_2022__13:03:58\n","Epoch 1 of 5, Step: 12400 of 13750, Training loss: 0.8723996, Training accuracy: 0.7398790, Time: 05_05_2022__13:04:18\n","Epoch 1 of 5, Step: 12500 of 13750, Training loss: 0.8681810, Training accuracy: 0.7412200, Time: 05_05_2022__13:04:37\n","Epoch 1 of 5, Step: 12600 of 13750, Training loss: 0.8632701, Training accuracy: 0.7427183, Time: 05_05_2022__13:04:57\n","Epoch 1 of 5, Step: 12700 of 13750, Training loss: 0.8586225, Training accuracy: 0.7442323, Time: 05_05_2022__13:05:17\n","Epoch 1 of 5, Step: 12800 of 13750, Training loss: 0.8543767, Training accuracy: 0.7456836, Time: 05_05_2022__13:05:36\n","Epoch 1 of 5, Step: 12900 of 13750, Training loss: 0.8500262, Training accuracy: 0.7471318, Time: 05_05_2022__13:05:56\n","Epoch 1 of 5, Step: 13000 of 13750, Training loss: 0.8458337, Training accuracy: 0.7484038, Time: 05_05_2022__13:06:16\n","Epoch 1 of 5, Step: 13100 of 13750, Training loss: 0.8421929, Training accuracy: 0.7496183, Time: 05_05_2022__13:06:35\n","Epoch 1 of 5, Step: 13200 of 13750, Training loss: 0.8377102, Training accuracy: 0.7510038, Time: 05_05_2022__13:06:55\n","Epoch 1 of 5, Step: 13300 of 13750, Training loss: 0.8335317, Training accuracy: 0.7523120, Time: 05_05_2022__13:07:15\n","Epoch 1 of 5, Step: 13400 of 13750, Training loss: 0.8294268, Training accuracy: 0.7536381, Time: 05_05_2022__13:07:35\n","Epoch 1 of 5, Step: 13500 of 13750, Training loss: 0.8253914, Training accuracy: 0.7548519, Time: 05_05_2022__13:07:54\n","Epoch 1 of 5, Step: 13600 of 13750, Training loss: 0.8213625, Training accuracy: 0.7561213, Time: 05_05_2022__13:08:14\n","Epoch 1 of 5, Step: 13700 of 13750, Training loss: 0.8171096, Training accuracy: 0.7574270, Time: 05_05_2022__13:08:34\n","Epoch 1 of 5, Average training loss: 0.8150853, Average training accuracy: 0.7580000, Time: 05_05_2022__13:08:43\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79d824a4a5a04eafb5c6a6e795b1642f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.1741140, Validation accuracy: 0.9525000, Time: 05_05_2022__13:08:49 | Loss decreased from inf to 0.1755758 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.1690242, Validation accuracy: 0.9525000, Time: 05_05_2022__13:08:57 | Loss decreased from 0.1755758 to 0.1696449 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.1835095, Validation accuracy: 0.9491667, Time: 05_05_2022__13:09:04\n","Step: 400 of 1250, Validation loss: 0.1778716, Validation accuracy: 0.9506250, Time: 05_05_2022__13:09:09\n","Step: 500 of 1250, Validation loss: 0.1841958, Validation accuracy: 0.9500000, Time: 05_05_2022__13:09:14\n","Step: 600 of 1250, Validation loss: 0.1779419, Validation accuracy: 0.9529167, Time: 05_05_2022__13:09:19\n","Step: 700 of 1250, Validation loss: 0.1696081, Validation accuracy: 0.9557143, Time: 05_05_2022__13:09:25 | Loss decreased from 0.1696449 to 0.1686986 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.1745188, Validation accuracy: 0.9537500, Time: 05_05_2022__13:09:32\n","Step: 900 of 1250, Validation loss: 0.1792745, Validation accuracy: 0.9530556, Time: 05_05_2022__13:09:37\n","Step: 1000 of 1250, Validation loss: 0.1833502, Validation accuracy: 0.9525000, Time: 05_05_2022__13:09:43\n","Step: 1100 of 1250, Validation loss: 0.1816220, Validation accuracy: 0.9527273, Time: 05_05_2022__13:09:48\n","Step: 1200 of 1250, Validation loss: 0.1798398, Validation accuracy: 0.9533333, Time: 05_05_2022__13:09:53\n","Average validation loss: 0.1798404, Average validation accuracy: 0.9530000, Time: 05_05_2022__13:09:56\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83af5c88c0ff46f08674edb6123eaf7c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 13750, Training loss: 0.2451047, Training accuracy: 0.9375000, Time: 05_05_2022__13:10:15\n","Epoch 2 of 5, Step: 200 of 13750, Training loss: 0.2467549, Training accuracy: 0.9362500, Time: 05_05_2022__13:10:35\n","Epoch 2 of 5, Step: 300 of 13750, Training loss: 0.2566948, Training accuracy: 0.9350000, Time: 05_05_2022__13:10:55\n","Epoch 2 of 5, Step: 400 of 13750, Training loss: 0.2591063, Training accuracy: 0.9325000, Time: 05_05_2022__13:11:14\n","Epoch 2 of 5, Step: 500 of 13750, Training loss: 0.2591703, Training accuracy: 0.9315000, Time: 05_05_2022__13:11:34\n","Epoch 2 of 5, Step: 600 of 13750, Training loss: 0.2600703, Training accuracy: 0.9300000, Time: 05_05_2022__13:11:54\n","Epoch 2 of 5, Step: 700 of 13750, Training loss: 0.2634985, Training accuracy: 0.9278571, Time: 05_05_2022__13:12:13\n","Epoch 2 of 5, Step: 800 of 13750, Training loss: 0.2643959, Training accuracy: 0.9259375, Time: 05_05_2022__13:12:33\n","Epoch 2 of 5, Step: 900 of 13750, Training loss: 0.2613573, Training accuracy: 0.9275000, Time: 05_05_2022__13:12:53\n","Epoch 2 of 5, Step: 1000 of 13750, Training loss: 0.2611772, Training accuracy: 0.9285000, Time: 05_05_2022__13:13:13\n","Epoch 2 of 5, Step: 1100 of 13750, Training loss: 0.2614630, Training accuracy: 0.9284091, Time: 05_05_2022__13:13:32\n","Epoch 2 of 5, Step: 1200 of 13750, Training loss: 0.2605188, Training accuracy: 0.9287500, Time: 05_05_2022__13:13:52\n","Epoch 2 of 5, Step: 1300 of 13750, Training loss: 0.2589808, Training accuracy: 0.9294231, Time: 05_05_2022__13:14:12\n","Epoch 2 of 5, Step: 1400 of 13750, Training loss: 0.2564483, Training accuracy: 0.9300000, Time: 05_05_2022__13:14:31\n","Epoch 2 of 5, Step: 1500 of 13750, Training loss: 0.2556742, Training accuracy: 0.9298333, Time: 05_05_2022__13:14:51\n","Epoch 2 of 5, Step: 1600 of 13750, Training loss: 0.2563430, Training accuracy: 0.9300000, Time: 05_05_2022__13:15:11\n","Epoch 2 of 5, Step: 1700 of 13750, Training loss: 0.2568163, Training accuracy: 0.9292647, Time: 05_05_2022__13:15:31\n","Epoch 2 of 5, Step: 1800 of 13750, Training loss: 0.2550062, Training accuracy: 0.9291667, Time: 05_05_2022__13:15:50\n","Epoch 2 of 5, Step: 1900 of 13750, Training loss: 0.2545619, Training accuracy: 0.9298684, Time: 05_05_2022__13:16:10\n","Epoch 2 of 5, Step: 2000 of 13750, Training loss: 0.2516436, Training accuracy: 0.9307500, Time: 05_05_2022__13:16:30\n","Epoch 2 of 5, Step: 2100 of 13750, Training loss: 0.2503089, Training accuracy: 0.9309524, Time: 05_05_2022__13:16:49\n","Epoch 2 of 5, Step: 2200 of 13750, Training loss: 0.2496600, Training accuracy: 0.9312500, Time: 05_05_2022__13:17:09\n","Epoch 2 of 5, Step: 2300 of 13750, Training loss: 0.2482737, Training accuracy: 0.9320652, Time: 05_05_2022__13:17:29\n","Epoch 2 of 5, Step: 2400 of 13750, Training loss: 0.2486003, Training accuracy: 0.9316667, Time: 05_05_2022__13:17:48\n","Epoch 2 of 5, Step: 2500 of 13750, Training loss: 0.2487402, Training accuracy: 0.9316000, Time: 05_05_2022__13:18:08\n","Epoch 2 of 5, Step: 2600 of 13750, Training loss: 0.2491806, Training accuracy: 0.9316346, Time: 05_05_2022__13:18:28\n","Epoch 2 of 5, Step: 2700 of 13750, Training loss: 0.2480632, Training accuracy: 0.9315741, Time: 05_05_2022__13:18:48\n","Epoch 2 of 5, Step: 2800 of 13750, Training loss: 0.2483484, Training accuracy: 0.9316964, Time: 05_05_2022__13:19:07\n","Epoch 2 of 5, Step: 2900 of 13750, Training loss: 0.2482898, Training accuracy: 0.9318966, Time: 05_05_2022__13:19:27\n","Epoch 2 of 5, Step: 3000 of 13750, Training loss: 0.2470431, Training accuracy: 0.9323333, Time: 05_05_2022__13:19:47\n","Epoch 2 of 5, Step: 3100 of 13750, Training loss: 0.2468616, Training accuracy: 0.9321774, Time: 05_05_2022__13:20:07\n","Epoch 2 of 5, Step: 3200 of 13750, Training loss: 0.2458496, Training accuracy: 0.9322656, Time: 05_05_2022__13:20:26\n","Epoch 2 of 5, Step: 3300 of 13750, Training loss: 0.2446327, Training accuracy: 0.9327273, Time: 05_05_2022__13:20:46\n","Epoch 2 of 5, Step: 3400 of 13750, Training loss: 0.2439489, Training accuracy: 0.9327941, Time: 05_05_2022__13:21:06\n","Epoch 2 of 5, Step: 3500 of 13750, Training loss: 0.2428735, Training accuracy: 0.9331429, Time: 05_05_2022__13:21:25\n","Epoch 2 of 5, Step: 3600 of 13750, Training loss: 0.2424176, Training accuracy: 0.9334028, Time: 05_05_2022__13:21:45\n","Epoch 2 of 5, Step: 3700 of 13750, Training loss: 0.2428924, Training accuracy: 0.9332432, Time: 05_05_2022__13:22:05\n","Epoch 2 of 5, Step: 3800 of 13750, Training loss: 0.2422875, Training accuracy: 0.9336184, Time: 05_05_2022__13:22:24\n","Epoch 2 of 5, Step: 3900 of 13750, Training loss: 0.2418512, Training accuracy: 0.9339103, Time: 05_05_2022__13:22:44\n","Epoch 2 of 5, Step: 4000 of 13750, Training loss: 0.2414067, Training accuracy: 0.9338125, Time: 05_05_2022__13:23:04\n","Epoch 2 of 5, Step: 4100 of 13750, Training loss: 0.2408855, Training accuracy: 0.9337805, Time: 05_05_2022__13:23:24\n","Epoch 2 of 5, Step: 4200 of 13750, Training loss: 0.2412235, Training accuracy: 0.9336905, Time: 05_05_2022__13:23:43\n","Epoch 2 of 5, Step: 4300 of 13750, Training loss: 0.2400382, Training accuracy: 0.9338953, Time: 05_05_2022__13:24:03\n","Epoch 2 of 5, Step: 4400 of 13750, Training loss: 0.2391133, Training accuracy: 0.9340909, Time: 05_05_2022__13:24:23\n","Epoch 2 of 5, Step: 4500 of 13750, Training loss: 0.2379225, Training accuracy: 0.9345000, Time: 05_05_2022__13:24:43\n","Epoch 2 of 5, Step: 4600 of 13750, Training loss: 0.2366755, Training accuracy: 0.9348913, Time: 05_05_2022__13:25:02\n","Epoch 2 of 5, Step: 4700 of 13750, Training loss: 0.2362915, Training accuracy: 0.9348404, Time: 05_05_2022__13:25:22\n","Epoch 2 of 5, Step: 4800 of 13750, Training loss: 0.2363272, Training accuracy: 0.9350521, Time: 05_05_2022__13:25:42\n","Epoch 2 of 5, Step: 4900 of 13750, Training loss: 0.2360835, Training accuracy: 0.9350000, Time: 05_05_2022__13:26:01\n","Epoch 2 of 5, Step: 5000 of 13750, Training loss: 0.2353848, Training accuracy: 0.9352500, Time: 05_05_2022__13:26:21\n","Epoch 2 of 5, Step: 5100 of 13750, Training loss: 0.2344582, Training accuracy: 0.9355392, Time: 05_05_2022__13:26:41\n","Epoch 2 of 5, Step: 5200 of 13750, Training loss: 0.2339583, Training accuracy: 0.9359615, Time: 05_05_2022__13:27:00\n","Epoch 2 of 5, Step: 5300 of 13750, Training loss: 0.2337918, Training accuracy: 0.9359434, Time: 05_05_2022__13:27:20\n","Epoch 2 of 5, Step: 5400 of 13750, Training loss: 0.2330351, Training accuracy: 0.9361111, Time: 05_05_2022__13:27:40\n","Epoch 2 of 5, Step: 5500 of 13750, Training loss: 0.2323149, Training accuracy: 0.9363636, Time: 05_05_2022__13:27:59\n","Epoch 2 of 5, Step: 5600 of 13750, Training loss: 0.2324781, Training accuracy: 0.9362946, Time: 05_05_2022__13:28:19\n","Epoch 2 of 5, Step: 5700 of 13750, Training loss: 0.2326067, Training accuracy: 0.9361842, Time: 05_05_2022__13:28:39\n","Epoch 2 of 5, Step: 5800 of 13750, Training loss: 0.2317128, Training accuracy: 0.9364655, Time: 05_05_2022__13:28:59\n","Epoch 2 of 5, Step: 5900 of 13750, Training loss: 0.2307573, Training accuracy: 0.9366949, Time: 05_05_2022__13:29:18\n","Epoch 2 of 5, Step: 6000 of 13750, Training loss: 0.2304462, Training accuracy: 0.9366667, Time: 05_05_2022__13:29:38\n","Epoch 2 of 5, Step: 6100 of 13750, Training loss: 0.2291766, Training accuracy: 0.9370082, Time: 05_05_2022__13:29:58\n","Epoch 2 of 5, Step: 6200 of 13750, Training loss: 0.2290598, Training accuracy: 0.9370565, Time: 05_05_2022__13:30:17\n","Epoch 2 of 5, Step: 6300 of 13750, Training loss: 0.2288446, Training accuracy: 0.9372619, Time: 05_05_2022__13:30:37\n","Epoch 2 of 5, Step: 6400 of 13750, Training loss: 0.2281203, Training accuracy: 0.9373438, Time: 05_05_2022__13:30:57\n","Epoch 2 of 5, Step: 6500 of 13750, Training loss: 0.2278650, Training accuracy: 0.9371923, Time: 05_05_2022__13:31:17\n","Epoch 2 of 5, Step: 6600 of 13750, Training loss: 0.2276606, Training accuracy: 0.9370833, Time: 05_05_2022__13:31:36\n","Epoch 2 of 5, Step: 6700 of 13750, Training loss: 0.2269436, Training accuracy: 0.9372761, Time: 05_05_2022__13:31:56\n","Epoch 2 of 5, Step: 6800 of 13750, Training loss: 0.2264229, Training accuracy: 0.9374265, Time: 05_05_2022__13:32:16\n","Epoch 2 of 5, Step: 6900 of 13750, Training loss: 0.2259895, Training accuracy: 0.9375000, Time: 05_05_2022__13:32:35\n","Epoch 2 of 5, Step: 7000 of 13750, Training loss: 0.2255561, Training accuracy: 0.9377143, Time: 05_05_2022__13:32:55\n","Epoch 2 of 5, Step: 7100 of 13750, Training loss: 0.2252691, Training accuracy: 0.9377113, Time: 05_05_2022__13:33:15\n","Epoch 2 of 5, Step: 7200 of 13750, Training loss: 0.2247127, Training accuracy: 0.9378125, Time: 05_05_2022__13:33:35\n","Epoch 2 of 5, Step: 7300 of 13750, Training loss: 0.2241833, Training accuracy: 0.9378425, Time: 05_05_2022__13:33:54\n","Epoch 2 of 5, Step: 7400 of 13750, Training loss: 0.2235879, Training accuracy: 0.9380743, Time: 05_05_2022__13:34:14\n","Epoch 2 of 5, Step: 7500 of 13750, Training loss: 0.2232609, Training accuracy: 0.9382333, Time: 05_05_2022__13:34:34\n","Epoch 2 of 5, Step: 7600 of 13750, Training loss: 0.2230640, Training accuracy: 0.9382566, Time: 05_05_2022__13:34:53\n","Epoch 2 of 5, Step: 7700 of 13750, Training loss: 0.2220408, Training accuracy: 0.9386039, Time: 05_05_2022__13:35:13\n","Epoch 2 of 5, Step: 7800 of 13750, Training loss: 0.2216860, Training accuracy: 0.9385256, Time: 05_05_2022__13:35:33\n","Epoch 2 of 5, Step: 7900 of 13750, Training loss: 0.2215140, Training accuracy: 0.9382911, Time: 05_05_2022__13:35:53\n","Epoch 2 of 5, Step: 8000 of 13750, Training loss: 0.2215200, Training accuracy: 0.9383438, Time: 05_05_2022__13:36:12\n","Epoch 2 of 5, Step: 8100 of 13750, Training loss: 0.2205272, Training accuracy: 0.9386111, Time: 05_05_2022__13:36:32\n","Epoch 2 of 5, Step: 8200 of 13750, Training loss: 0.2200123, Training accuracy: 0.9386585, Time: 05_05_2022__13:36:52\n","Epoch 2 of 5, Step: 8300 of 13750, Training loss: 0.2200537, Training accuracy: 0.9387048, Time: 05_05_2022__13:37:11\n","Epoch 2 of 5, Step: 8400 of 13750, Training loss: 0.2197641, Training accuracy: 0.9388988, Time: 05_05_2022__13:37:31\n","Epoch 2 of 5, Step: 8500 of 13750, Training loss: 0.2190834, Training accuracy: 0.9390882, Time: 05_05_2022__13:37:51\n","Epoch 2 of 5, Step: 8600 of 13750, Training loss: 0.2185493, Training accuracy: 0.9392151, Time: 05_05_2022__13:38:10\n","Epoch 2 of 5, Step: 8700 of 13750, Training loss: 0.2180488, Training accuracy: 0.9392816, Time: 05_05_2022__13:38:30\n","Epoch 2 of 5, Step: 8800 of 13750, Training loss: 0.2180558, Training accuracy: 0.9392614, Time: 05_05_2022__13:38:50\n","Epoch 2 of 5, Step: 8900 of 13750, Training loss: 0.2174105, Training accuracy: 0.9395225, Time: 05_05_2022__13:39:10\n","Epoch 2 of 5, Step: 9000 of 13750, Training loss: 0.2171846, Training accuracy: 0.9394444, Time: 05_05_2022__13:39:29\n","Epoch 2 of 5, Step: 9100 of 13750, Training loss: 0.2169240, Training accuracy: 0.9395879, Time: 05_05_2022__13:39:49\n","Epoch 2 of 5, Step: 9200 of 13750, Training loss: 0.2170663, Training accuracy: 0.9394565, Time: 05_05_2022__13:40:09\n","Epoch 2 of 5, Step: 9300 of 13750, Training loss: 0.2166277, Training accuracy: 0.9395161, Time: 05_05_2022__13:40:28\n","Epoch 2 of 5, Step: 9400 of 13750, Training loss: 0.2163257, Training accuracy: 0.9396011, Time: 05_05_2022__13:40:48\n","Epoch 2 of 5, Step: 9500 of 13750, Training loss: 0.2157840, Training accuracy: 0.9397368, Time: 05_05_2022__13:41:08\n","Epoch 2 of 5, Step: 9600 of 13750, Training loss: 0.2154365, Training accuracy: 0.9396354, Time: 05_05_2022__13:41:28\n","Epoch 2 of 5, Step: 9700 of 13750, Training loss: 0.2148309, Training accuracy: 0.9396907, Time: 05_05_2022__13:41:47\n","Epoch 2 of 5, Step: 9800 of 13750, Training loss: 0.2146441, Training accuracy: 0.9397194, Time: 05_05_2022__13:42:07\n","Epoch 2 of 5, Step: 9900 of 13750, Training loss: 0.2141514, Training accuracy: 0.9398990, Time: 05_05_2022__13:42:27\n","Epoch 2 of 5, Step: 10000 of 13750, Training loss: 0.2134752, Training accuracy: 0.9399500, Time: 05_05_2022__13:42:46\n","Epoch 2 of 5, Step: 10100 of 13750, Training loss: 0.2133134, Training accuracy: 0.9399010, Time: 05_05_2022__13:43:06\n","Epoch 2 of 5, Step: 10200 of 13750, Training loss: 0.2127018, Training accuracy: 0.9400735, Time: 05_05_2022__13:43:26\n","Epoch 2 of 5, Step: 10300 of 13750, Training loss: 0.2119322, Training accuracy: 0.9403398, Time: 05_05_2022__13:43:46\n","Epoch 2 of 5, Step: 10400 of 13750, Training loss: 0.2115865, Training accuracy: 0.9403606, Time: 05_05_2022__13:44:05\n","Epoch 2 of 5, Step: 10500 of 13750, Training loss: 0.2111943, Training accuracy: 0.9405000, Time: 05_05_2022__13:44:25\n","Epoch 2 of 5, Step: 10600 of 13750, Training loss: 0.2107679, Training accuracy: 0.9405896, Time: 05_05_2022__13:44:45\n","Epoch 2 of 5, Step: 10700 of 13750, Training loss: 0.2106987, Training accuracy: 0.9405841, Time: 05_05_2022__13:45:04\n","Epoch 2 of 5, Step: 10800 of 13750, Training loss: 0.2105398, Training accuracy: 0.9405324, Time: 05_05_2022__13:45:24\n","Epoch 2 of 5, Step: 10900 of 13750, Training loss: 0.2101876, Training accuracy: 0.9406193, Time: 05_05_2022__13:45:44\n","Epoch 2 of 5, Step: 11000 of 13750, Training loss: 0.2095243, Training accuracy: 0.9409318, Time: 05_05_2022__13:46:04\n","Epoch 2 of 5, Step: 11100 of 13750, Training loss: 0.2091436, Training accuracy: 0.9409910, Time: 05_05_2022__13:46:23\n","Epoch 2 of 5, Step: 11200 of 13750, Training loss: 0.2086837, Training accuracy: 0.9411384, Time: 05_05_2022__13:46:43\n","Epoch 2 of 5, Step: 11300 of 13750, Training loss: 0.2083521, Training accuracy: 0.9412611, Time: 05_05_2022__13:47:03\n","Epoch 2 of 5, Step: 11400 of 13750, Training loss: 0.2078073, Training accuracy: 0.9415351, Time: 05_05_2022__13:47:22\n","Epoch 2 of 5, Step: 11500 of 13750, Training loss: 0.2077540, Training accuracy: 0.9416522, Time: 05_05_2022__13:47:42\n","Epoch 2 of 5, Step: 11600 of 13750, Training loss: 0.2074660, Training accuracy: 0.9417241, Time: 05_05_2022__13:48:02\n","Epoch 2 of 5, Step: 11700 of 13750, Training loss: 0.2067697, Training accuracy: 0.9419444, Time: 05_05_2022__13:48:22\n","Epoch 2 of 5, Step: 11800 of 13750, Training loss: 0.2065690, Training accuracy: 0.9419280, Time: 05_05_2022__13:48:41\n","Epoch 2 of 5, Step: 11900 of 13750, Training loss: 0.2060915, Training accuracy: 0.9420798, Time: 05_05_2022__13:49:01\n","Epoch 2 of 5, Step: 12000 of 13750, Training loss: 0.2054071, Training accuracy: 0.9422917, Time: 05_05_2022__13:49:21\n","Epoch 2 of 5, Step: 12100 of 13750, Training loss: 0.2051223, Training accuracy: 0.9423760, Time: 05_05_2022__13:49:40\n","Epoch 2 of 5, Step: 12200 of 13750, Training loss: 0.2050487, Training accuracy: 0.9423156, Time: 05_05_2022__13:50:00\n","Epoch 2 of 5, Step: 12300 of 13750, Training loss: 0.2046856, Training accuracy: 0.9424390, Time: 05_05_2022__13:50:20\n","Epoch 2 of 5, Step: 12400 of 13750, Training loss: 0.2040860, Training accuracy: 0.9426210, Time: 05_05_2022__13:50:40\n","Epoch 2 of 5, Step: 12500 of 13750, Training loss: 0.2037636, Training accuracy: 0.9427000, Time: 05_05_2022__13:50:59\n","Epoch 2 of 5, Step: 12600 of 13750, Training loss: 0.2030933, Training accuracy: 0.9428968, Time: 05_05_2022__13:51:19\n","Epoch 2 of 5, Step: 12700 of 13750, Training loss: 0.2027224, Training accuracy: 0.9429528, Time: 05_05_2022__13:51:39\n","Epoch 2 of 5, Step: 12800 of 13750, Training loss: 0.2025842, Training accuracy: 0.9430273, Time: 05_05_2022__13:51:58\n","Epoch 2 of 5, Step: 12900 of 13750, Training loss: 0.2024886, Training accuracy: 0.9430426, Time: 05_05_2022__13:52:18\n","Epoch 2 of 5, Step: 13000 of 13750, Training loss: 0.2022326, Training accuracy: 0.9430962, Time: 05_05_2022__13:52:38\n","Epoch 2 of 5, Step: 13100 of 13750, Training loss: 0.2024159, Training accuracy: 0.9429962, Time: 05_05_2022__13:52:57\n","Epoch 2 of 5, Step: 13200 of 13750, Training loss: 0.2020247, Training accuracy: 0.9430492, Time: 05_05_2022__13:53:17\n","Epoch 2 of 5, Step: 13300 of 13750, Training loss: 0.2017584, Training accuracy: 0.9431391, Time: 05_05_2022__13:53:37\n","Epoch 2 of 5, Step: 13400 of 13750, Training loss: 0.2015764, Training accuracy: 0.9432649, Time: 05_05_2022__13:53:57\n","Epoch 2 of 5, Step: 13500 of 13750, Training loss: 0.2011484, Training accuracy: 0.9434074, Time: 05_05_2022__13:54:16\n","Epoch 2 of 5, Step: 13600 of 13750, Training loss: 0.2007552, Training accuracy: 0.9435846, Time: 05_05_2022__13:54:36\n","Epoch 2 of 5, Step: 13700 of 13750, Training loss: 0.2001122, Training accuracy: 0.9437409, Time: 05_05_2022__13:54:56\n","Epoch 2 of 5, Average training loss: 0.1999627, Average training accuracy: 0.9437636, Time: 05_05_2022__13:55:06\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e036c87206384edaa2b08285f373ebb8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.1069654, Validation accuracy: 0.9675000, Time: 05_05_2022__13:55:11 | Loss decreased from 0.1686986 to 0.1079976 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0997842, Validation accuracy: 0.9700000, Time: 05_05_2022__13:55:19 | Loss decreased from 0.1079976 to 0.1002247 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.1075191, Validation accuracy: 0.9691667, Time: 05_05_2022__13:55:26\n","Step: 400 of 1250, Validation loss: 0.1011120, Validation accuracy: 0.9712500, Time: 05_05_2022__13:55:31\n","Step: 500 of 1250, Validation loss: 0.1046985, Validation accuracy: 0.9695000, Time: 05_05_2022__13:55:36\n","Step: 600 of 1250, Validation loss: 0.1005533, Validation accuracy: 0.9704167, Time: 05_05_2022__13:55:42\n","Step: 700 of 1250, Validation loss: 0.0961424, Validation accuracy: 0.9714286, Time: 05_05_2022__13:55:47 | Loss decreased from 0.1002247 to 0.0950092 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0995983, Validation accuracy: 0.9706250, Time: 05_05_2022__13:55:54\n","Step: 900 of 1250, Validation loss: 0.1014075, Validation accuracy: 0.9702778, Time: 05_05_2022__13:55:59\n","Step: 1000 of 1250, Validation loss: 0.1039076, Validation accuracy: 0.9700000, Time: 05_05_2022__13:56:04\n","Step: 1100 of 1250, Validation loss: 0.1019043, Validation accuracy: 0.9706818, Time: 05_05_2022__13:56:10\n","Step: 1200 of 1250, Validation loss: 0.1017336, Validation accuracy: 0.9697917, Time: 05_05_2022__13:56:15\n","Average validation loss: 0.1014735, Average validation accuracy: 0.9696000, Time: 05_05_2022__13:56:17\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d908177b90b4b5281968ddefd3269a9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 13750, Training loss: 0.1405492, Training accuracy: 0.9550000, Time: 05_05_2022__13:56:37\n","Epoch 3 of 5, Step: 200 of 13750, Training loss: 0.1357431, Training accuracy: 0.9600000, Time: 05_05_2022__13:56:57\n","Epoch 3 of 5, Step: 300 of 13750, Training loss: 0.1465614, Training accuracy: 0.9566667, Time: 05_05_2022__13:57:16\n","Epoch 3 of 5, Step: 400 of 13750, Training loss: 0.1427964, Training accuracy: 0.9593750, Time: 05_05_2022__13:57:36\n","Epoch 3 of 5, Step: 500 of 13750, Training loss: 0.1447849, Training accuracy: 0.9575000, Time: 05_05_2022__13:57:56\n","Epoch 3 of 5, Step: 600 of 13750, Training loss: 0.1526258, Training accuracy: 0.9558333, Time: 05_05_2022__13:58:15\n","Epoch 3 of 5, Step: 700 of 13750, Training loss: 0.1547058, Training accuracy: 0.9546429, Time: 05_05_2022__13:58:35\n","Epoch 3 of 5, Step: 800 of 13750, Training loss: 0.1532904, Training accuracy: 0.9546875, Time: 05_05_2022__13:58:55\n","Epoch 3 of 5, Step: 900 of 13750, Training loss: 0.1558900, Training accuracy: 0.9538889, Time: 05_05_2022__13:59:15\n","Epoch 3 of 5, Step: 1000 of 13750, Training loss: 0.1564741, Training accuracy: 0.9540000, Time: 05_05_2022__13:59:34\n","Epoch 3 of 5, Step: 1100 of 13750, Training loss: 0.1588460, Training accuracy: 0.9527273, Time: 05_05_2022__13:59:54\n","Epoch 3 of 5, Step: 1200 of 13750, Training loss: 0.1592376, Training accuracy: 0.9535417, Time: 05_05_2022__14:00:14\n","Epoch 3 of 5, Step: 1300 of 13750, Training loss: 0.1582148, Training accuracy: 0.9536538, Time: 05_05_2022__14:00:33\n","Epoch 3 of 5, Step: 1400 of 13750, Training loss: 0.1577326, Training accuracy: 0.9533929, Time: 05_05_2022__14:00:53\n","Epoch 3 of 5, Step: 1500 of 13750, Training loss: 0.1583233, Training accuracy: 0.9528333, Time: 05_05_2022__14:01:13\n","Epoch 3 of 5, Step: 1600 of 13750, Training loss: 0.1584322, Training accuracy: 0.9526562, Time: 05_05_2022__14:01:32\n","Epoch 3 of 5, Step: 1700 of 13750, Training loss: 0.1570454, Training accuracy: 0.9530882, Time: 05_05_2022__14:01:52\n","Epoch 3 of 5, Step: 1800 of 13750, Training loss: 0.1569353, Training accuracy: 0.9536111, Time: 05_05_2022__14:02:12\n","Epoch 3 of 5, Step: 1900 of 13750, Training loss: 0.1557414, Training accuracy: 0.9546053, Time: 05_05_2022__14:02:31\n","Epoch 3 of 5, Step: 2000 of 13750, Training loss: 0.1533486, Training accuracy: 0.9557500, Time: 05_05_2022__14:02:51\n","Epoch 3 of 5, Step: 2100 of 13750, Training loss: 0.1502795, Training accuracy: 0.9566667, Time: 05_05_2022__14:03:11\n","Epoch 3 of 5, Step: 2200 of 13750, Training loss: 0.1498398, Training accuracy: 0.9571591, Time: 05_05_2022__14:03:30\n","Epoch 3 of 5, Step: 2300 of 13750, Training loss: 0.1489509, Training accuracy: 0.9579348, Time: 05_05_2022__14:03:50\n","Epoch 3 of 5, Step: 2400 of 13750, Training loss: 0.1494550, Training accuracy: 0.9579167, Time: 05_05_2022__14:04:10\n","Epoch 3 of 5, Step: 2500 of 13750, Training loss: 0.1488205, Training accuracy: 0.9581000, Time: 05_05_2022__14:04:30\n","Epoch 3 of 5, Step: 2600 of 13750, Training loss: 0.1496015, Training accuracy: 0.9575962, Time: 05_05_2022__14:04:49\n","Epoch 3 of 5, Step: 2700 of 13750, Training loss: 0.1486635, Training accuracy: 0.9579630, Time: 05_05_2022__14:05:09\n","Epoch 3 of 5, Step: 2800 of 13750, Training loss: 0.1489819, Training accuracy: 0.9578571, Time: 05_05_2022__14:05:29\n","Epoch 3 of 5, Step: 2900 of 13750, Training loss: 0.1499142, Training accuracy: 0.9573276, Time: 05_05_2022__14:05:48\n","Epoch 3 of 5, Step: 3000 of 13750, Training loss: 0.1489503, Training accuracy: 0.9575000, Time: 05_05_2022__14:06:08\n","Epoch 3 of 5, Step: 3100 of 13750, Training loss: 0.1488067, Training accuracy: 0.9577419, Time: 05_05_2022__14:06:28\n","Epoch 3 of 5, Step: 3200 of 13750, Training loss: 0.1478059, Training accuracy: 0.9581250, Time: 05_05_2022__14:06:47\n","Epoch 3 of 5, Step: 3300 of 13750, Training loss: 0.1476501, Training accuracy: 0.9581818, Time: 05_05_2022__14:07:07\n","Epoch 3 of 5, Step: 3400 of 13750, Training loss: 0.1469946, Training accuracy: 0.9583088, Time: 05_05_2022__14:07:27\n","Epoch 3 of 5, Step: 3500 of 13750, Training loss: 0.1464842, Training accuracy: 0.9584286, Time: 05_05_2022__14:07:46\n","Epoch 3 of 5, Step: 3600 of 13750, Training loss: 0.1458248, Training accuracy: 0.9586111, Time: 05_05_2022__14:08:06\n","Epoch 3 of 5, Step: 3700 of 13750, Training loss: 0.1458102, Training accuracy: 0.9585811, Time: 05_05_2022__14:08:26\n","Epoch 3 of 5, Step: 3800 of 13750, Training loss: 0.1464205, Training accuracy: 0.9583553, Time: 05_05_2022__14:08:45\n","Epoch 3 of 5, Step: 3900 of 13750, Training loss: 0.1470887, Training accuracy: 0.9581410, Time: 05_05_2022__14:09:05\n","Epoch 3 of 5, Step: 4000 of 13750, Training loss: 0.1468424, Training accuracy: 0.9581250, Time: 05_05_2022__14:09:25\n","Epoch 3 of 5, Step: 4100 of 13750, Training loss: 0.1465735, Training accuracy: 0.9580488, Time: 05_05_2022__14:09:44\n","Epoch 3 of 5, Step: 4200 of 13750, Training loss: 0.1480931, Training accuracy: 0.9578571, Time: 05_05_2022__14:10:04\n","Epoch 3 of 5, Step: 4300 of 13750, Training loss: 0.1477557, Training accuracy: 0.9578488, Time: 05_05_2022__14:10:24\n","Epoch 3 of 5, Step: 4400 of 13750, Training loss: 0.1476738, Training accuracy: 0.9578977, Time: 05_05_2022__14:10:44\n","Epoch 3 of 5, Step: 4500 of 13750, Training loss: 0.1465728, Training accuracy: 0.9581667, Time: 05_05_2022__14:11:03\n","Epoch 3 of 5, Step: 4600 of 13750, Training loss: 0.1456144, Training accuracy: 0.9584783, Time: 05_05_2022__14:11:23\n","Epoch 3 of 5, Step: 4700 of 13750, Training loss: 0.1460885, Training accuracy: 0.9578723, Time: 05_05_2022__14:11:43\n","Epoch 3 of 5, Step: 4800 of 13750, Training loss: 0.1461790, Training accuracy: 0.9577604, Time: 05_05_2022__14:12:02\n","Epoch 3 of 5, Step: 4900 of 13750, Training loss: 0.1468194, Training accuracy: 0.9574490, Time: 05_05_2022__14:12:22\n","Epoch 3 of 5, Step: 5000 of 13750, Training loss: 0.1465559, Training accuracy: 0.9575000, Time: 05_05_2022__14:12:42\n","Epoch 3 of 5, Step: 5100 of 13750, Training loss: 0.1460692, Training accuracy: 0.9576471, Time: 05_05_2022__14:13:02\n","Epoch 3 of 5, Step: 5200 of 13750, Training loss: 0.1460578, Training accuracy: 0.9575962, Time: 05_05_2022__14:13:21\n","Epoch 3 of 5, Step: 5300 of 13750, Training loss: 0.1460142, Training accuracy: 0.9576887, Time: 05_05_2022__14:13:41\n","Epoch 3 of 5, Step: 5400 of 13750, Training loss: 0.1456091, Training accuracy: 0.9578704, Time: 05_05_2022__14:14:01\n","Epoch 3 of 5, Step: 5500 of 13750, Training loss: 0.1451649, Training accuracy: 0.9580000, Time: 05_05_2022__14:14:20\n","Epoch 3 of 5, Step: 5600 of 13750, Training loss: 0.1454610, Training accuracy: 0.9576786, Time: 05_05_2022__14:14:40\n","Epoch 3 of 5, Step: 5700 of 13750, Training loss: 0.1459985, Training accuracy: 0.9575000, Time: 05_05_2022__14:15:00\n","Epoch 3 of 5, Step: 5800 of 13750, Training loss: 0.1454869, Training accuracy: 0.9576724, Time: 05_05_2022__14:15:20\n","Epoch 3 of 5, Step: 5900 of 13750, Training loss: 0.1449777, Training accuracy: 0.9578390, Time: 05_05_2022__14:15:39\n","Epoch 3 of 5, Step: 6000 of 13750, Training loss: 0.1457583, Training accuracy: 0.9576250, Time: 05_05_2022__14:15:59\n","Epoch 3 of 5, Step: 6100 of 13750, Training loss: 0.1450964, Training accuracy: 0.9579098, Time: 05_05_2022__14:16:19\n","Epoch 3 of 5, Step: 6200 of 13750, Training loss: 0.1449536, Training accuracy: 0.9579032, Time: 05_05_2022__14:16:39\n","Epoch 3 of 5, Step: 6300 of 13750, Training loss: 0.1455399, Training accuracy: 0.9578571, Time: 05_05_2022__14:16:58\n","Epoch 3 of 5, Step: 6400 of 13750, Training loss: 0.1449074, Training accuracy: 0.9580469, Time: 05_05_2022__14:17:18\n","Epoch 3 of 5, Step: 6500 of 13750, Training loss: 0.1449304, Training accuracy: 0.9580000, Time: 05_05_2022__14:17:38\n","Epoch 3 of 5, Step: 6600 of 13750, Training loss: 0.1445401, Training accuracy: 0.9581061, Time: 05_05_2022__14:17:57\n","Epoch 3 of 5, Step: 6700 of 13750, Training loss: 0.1437774, Training accuracy: 0.9583955, Time: 05_05_2022__14:18:17\n","Epoch 3 of 5, Step: 6800 of 13750, Training loss: 0.1433703, Training accuracy: 0.9584191, Time: 05_05_2022__14:18:37\n","Epoch 3 of 5, Step: 6900 of 13750, Training loss: 0.1429326, Training accuracy: 0.9586232, Time: 05_05_2022__14:18:57\n","Epoch 3 of 5, Step: 7000 of 13750, Training loss: 0.1426171, Training accuracy: 0.9587500, Time: 05_05_2022__14:19:16\n","Epoch 3 of 5, Step: 7100 of 13750, Training loss: 0.1425027, Training accuracy: 0.9589437, Time: 05_05_2022__14:19:36\n","Epoch 3 of 5, Step: 7200 of 13750, Training loss: 0.1425172, Training accuracy: 0.9588889, Time: 05_05_2022__14:19:56\n","Epoch 3 of 5, Step: 7300 of 13750, Training loss: 0.1420504, Training accuracy: 0.9590411, Time: 05_05_2022__14:20:15\n","Epoch 3 of 5, Step: 7400 of 13750, Training loss: 0.1421688, Training accuracy: 0.9590203, Time: 05_05_2022__14:20:35\n","Epoch 3 of 5, Step: 7500 of 13750, Training loss: 0.1420173, Training accuracy: 0.9590667, Time: 05_05_2022__14:20:55\n","Epoch 3 of 5, Step: 7600 of 13750, Training loss: 0.1421963, Training accuracy: 0.9590461, Time: 05_05_2022__14:21:15\n","Epoch 3 of 5, Step: 7700 of 13750, Training loss: 0.1418275, Training accuracy: 0.9589935, Time: 05_05_2022__14:21:34\n","Epoch 3 of 5, Step: 7800 of 13750, Training loss: 0.1417796, Training accuracy: 0.9589423, Time: 05_05_2022__14:21:54\n","Epoch 3 of 5, Step: 7900 of 13750, Training loss: 0.1418853, Training accuracy: 0.9588924, Time: 05_05_2022__14:22:14\n","Epoch 3 of 5, Step: 8000 of 13750, Training loss: 0.1417379, Training accuracy: 0.9588750, Time: 05_05_2022__14:22:34\n","Epoch 3 of 5, Step: 8100 of 13750, Training loss: 0.1411406, Training accuracy: 0.9590432, Time: 05_05_2022__14:22:53\n","Epoch 3 of 5, Step: 8200 of 13750, Training loss: 0.1407787, Training accuracy: 0.9591768, Time: 05_05_2022__14:23:13\n","Epoch 3 of 5, Step: 8300 of 13750, Training loss: 0.1413323, Training accuracy: 0.9591867, Time: 05_05_2022__14:23:33\n","Epoch 3 of 5, Step: 8400 of 13750, Training loss: 0.1416321, Training accuracy: 0.9588690, Time: 05_05_2022__14:23:52\n","Epoch 3 of 5, Step: 8500 of 13750, Training loss: 0.1413930, Training accuracy: 0.9589412, Time: 05_05_2022__14:24:12\n","Epoch 3 of 5, Step: 8600 of 13750, Training loss: 0.1408134, Training accuracy: 0.9591860, Time: 05_05_2022__14:24:32\n","Epoch 3 of 5, Step: 8700 of 13750, Training loss: 0.1405386, Training accuracy: 0.9593391, Time: 05_05_2022__14:24:52\n","Epoch 3 of 5, Step: 8800 of 13750, Training loss: 0.1409716, Training accuracy: 0.9592045, Time: 05_05_2022__14:25:11\n","Epoch 3 of 5, Step: 8900 of 13750, Training loss: 0.1406369, Training accuracy: 0.9592978, Time: 05_05_2022__14:25:31\n","Epoch 3 of 5, Step: 9000 of 13750, Training loss: 0.1406819, Training accuracy: 0.9593056, Time: 05_05_2022__14:25:51\n","Epoch 3 of 5, Step: 9100 of 13750, Training loss: 0.1406881, Training accuracy: 0.9593407, Time: 05_05_2022__14:26:11\n","Epoch 3 of 5, Step: 9200 of 13750, Training loss: 0.1406553, Training accuracy: 0.9592663, Time: 05_05_2022__14:26:30\n","Epoch 3 of 5, Step: 9300 of 13750, Training loss: 0.1405345, Training accuracy: 0.9592204, Time: 05_05_2022__14:26:50\n","Epoch 3 of 5, Step: 9400 of 13750, Training loss: 0.1406855, Training accuracy: 0.9591223, Time: 05_05_2022__14:27:10\n","Epoch 3 of 5, Step: 9500 of 13750, Training loss: 0.1405583, Training accuracy: 0.9590789, Time: 05_05_2022__14:27:30\n","Epoch 3 of 5, Step: 9600 of 13750, Training loss: 0.1403427, Training accuracy: 0.9590625, Time: 05_05_2022__14:27:49\n","Epoch 3 of 5, Step: 9700 of 13750, Training loss: 0.1399117, Training accuracy: 0.9592010, Time: 05_05_2022__14:28:09\n","Epoch 3 of 5, Step: 9800 of 13750, Training loss: 0.1397302, Training accuracy: 0.9592602, Time: 05_05_2022__14:28:29\n","Epoch 3 of 5, Step: 9900 of 13750, Training loss: 0.1394775, Training accuracy: 0.9592424, Time: 05_05_2022__14:28:48\n","Epoch 3 of 5, Step: 10000 of 13750, Training loss: 0.1392654, Training accuracy: 0.9593250, Time: 05_05_2022__14:29:08\n","Epoch 3 of 5, Step: 10100 of 13750, Training loss: 0.1396590, Training accuracy: 0.9593069, Time: 05_05_2022__14:29:28\n","Epoch 3 of 5, Step: 10200 of 13750, Training loss: 0.1395480, Training accuracy: 0.9594363, Time: 05_05_2022__14:29:48\n","Epoch 3 of 5, Step: 10300 of 13750, Training loss: 0.1390330, Training accuracy: 0.9596602, Time: 05_05_2022__14:30:07\n","Epoch 3 of 5, Step: 10400 of 13750, Training loss: 0.1390240, Training accuracy: 0.9596154, Time: 05_05_2022__14:30:27\n","Epoch 3 of 5, Step: 10500 of 13750, Training loss: 0.1387682, Training accuracy: 0.9596667, Time: 05_05_2022__14:30:47\n","Epoch 3 of 5, Step: 10600 of 13750, Training loss: 0.1385063, Training accuracy: 0.9598113, Time: 05_05_2022__14:31:07\n","Epoch 3 of 5, Step: 10700 of 13750, Training loss: 0.1381337, Training accuracy: 0.9598598, Time: 05_05_2022__14:31:26\n","Epoch 3 of 5, Step: 10800 of 13750, Training loss: 0.1382241, Training accuracy: 0.9598380, Time: 05_05_2022__14:31:46\n","Epoch 3 of 5, Step: 10900 of 13750, Training loss: 0.1382365, Training accuracy: 0.9598394, Time: 05_05_2022__14:32:06\n","Epoch 3 of 5, Step: 11000 of 13750, Training loss: 0.1379275, Training accuracy: 0.9599318, Time: 05_05_2022__14:32:26\n","Epoch 3 of 5, Step: 11100 of 13750, Training loss: 0.1379722, Training accuracy: 0.9598874, Time: 05_05_2022__14:32:45\n","Epoch 3 of 5, Step: 11200 of 13750, Training loss: 0.1378371, Training accuracy: 0.9599107, Time: 05_05_2022__14:33:05\n","Epoch 3 of 5, Step: 11300 of 13750, Training loss: 0.1376489, Training accuracy: 0.9599336, Time: 05_05_2022__14:33:25\n","Epoch 3 of 5, Step: 11400 of 13750, Training loss: 0.1374308, Training accuracy: 0.9599781, Time: 05_05_2022__14:33:45\n","Epoch 3 of 5, Step: 11500 of 13750, Training loss: 0.1378278, Training accuracy: 0.9600000, Time: 05_05_2022__14:34:04\n","Epoch 3 of 5, Step: 11600 of 13750, Training loss: 0.1376290, Training accuracy: 0.9601293, Time: 05_05_2022__14:34:24\n","Epoch 3 of 5, Step: 11700 of 13750, Training loss: 0.1374090, Training accuracy: 0.9601709, Time: 05_05_2022__14:34:44\n","Epoch 3 of 5, Step: 11800 of 13750, Training loss: 0.1374939, Training accuracy: 0.9600636, Time: 05_05_2022__14:35:03\n","Epoch 3 of 5, Step: 11900 of 13750, Training loss: 0.1373985, Training accuracy: 0.9601050, Time: 05_05_2022__14:35:23\n","Epoch 3 of 5, Step: 12000 of 13750, Training loss: 0.1370513, Training accuracy: 0.9602292, Time: 05_05_2022__14:35:43\n","Epoch 3 of 5, Step: 12100 of 13750, Training loss: 0.1369413, Training accuracy: 0.9602893, Time: 05_05_2022__14:36:03\n","Epoch 3 of 5, Step: 12200 of 13750, Training loss: 0.1370130, Training accuracy: 0.9603279, Time: 05_05_2022__14:36:22\n","Epoch 3 of 5, Step: 12300 of 13750, Training loss: 0.1366723, Training accuracy: 0.9604065, Time: 05_05_2022__14:36:42\n","Epoch 3 of 5, Step: 12400 of 13750, Training loss: 0.1362703, Training accuracy: 0.9605847, Time: 05_05_2022__14:37:02\n","Epoch 3 of 5, Step: 12500 of 13750, Training loss: 0.1362895, Training accuracy: 0.9604800, Time: 05_05_2022__14:37:22\n","Epoch 3 of 5, Step: 12600 of 13750, Training loss: 0.1361174, Training accuracy: 0.9604960, Time: 05_05_2022__14:37:41\n","Epoch 3 of 5, Step: 12700 of 13750, Training loss: 0.1361977, Training accuracy: 0.9604528, Time: 05_05_2022__14:38:01\n","Epoch 3 of 5, Step: 12800 of 13750, Training loss: 0.1360732, Training accuracy: 0.9604883, Time: 05_05_2022__14:38:21\n","Epoch 3 of 5, Step: 12900 of 13750, Training loss: 0.1361418, Training accuracy: 0.9604845, Time: 05_05_2022__14:38:40\n","Epoch 3 of 5, Step: 13000 of 13750, Training loss: 0.1360093, Training accuracy: 0.9605577, Time: 05_05_2022__14:39:00\n","Epoch 3 of 5, Step: 13100 of 13750, Training loss: 0.1362030, Training accuracy: 0.9605534, Time: 05_05_2022__14:39:20\n","Epoch 3 of 5, Step: 13200 of 13750, Training loss: 0.1358038, Training accuracy: 0.9606818, Time: 05_05_2022__14:39:40\n","Epoch 3 of 5, Step: 13300 of 13750, Training loss: 0.1357022, Training accuracy: 0.9607143, Time: 05_05_2022__14:39:59\n","Epoch 3 of 5, Step: 13400 of 13750, Training loss: 0.1355070, Training accuracy: 0.9608209, Time: 05_05_2022__14:40:19\n","Epoch 3 of 5, Step: 13500 of 13750, Training loss: 0.1354774, Training accuracy: 0.9608519, Time: 05_05_2022__14:40:39\n","Epoch 3 of 5, Step: 13600 of 13750, Training loss: 0.1352974, Training accuracy: 0.9609007, Time: 05_05_2022__14:40:59\n","Epoch 3 of 5, Step: 13700 of 13750, Training loss: 0.1351907, Training accuracy: 0.9609672, Time: 05_05_2022__14:41:18\n","Epoch 3 of 5, Average training loss: 0.1350377, Average training accuracy: 0.9610182, Time: 05_05_2022__14:41:28\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d21682052b994d6bae9d1b1ab4eed6c6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0790902, Validation accuracy: 0.9800000, Time: 05_05_2022__14:41:33 | Loss decreased from 0.0950092 to 0.0798016 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0827129, Validation accuracy: 0.9750000, Time: 05_05_2022__14:41:41\n","Step: 300 of 1250, Validation loss: 0.0893404, Validation accuracy: 0.9750000, Time: 05_05_2022__14:41:46\n","Step: 400 of 1250, Validation loss: 0.0807862, Validation accuracy: 0.9768750, Time: 05_05_2022__14:41:51\n","Step: 500 of 1250, Validation loss: 0.0823210, Validation accuracy: 0.9750000, Time: 05_05_2022__14:41:56\n","Step: 600 of 1250, Validation loss: 0.0795680, Validation accuracy: 0.9750000, Time: 05_05_2022__14:42:01 | Loss decreased from 0.0798016 to 0.0795725 .... Saving the model\n","Step: 700 of 1250, Validation loss: 0.0760597, Validation accuracy: 0.9757143, Time: 05_05_2022__14:42:09 | Loss decreased from 0.0795725 to 0.0752121 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0769052, Validation accuracy: 0.9753125, Time: 05_05_2022__14:42:16\n","Step: 900 of 1250, Validation loss: 0.0787748, Validation accuracy: 0.9750000, Time: 05_05_2022__14:42:21\n","Step: 1000 of 1250, Validation loss: 0.0809576, Validation accuracy: 0.9745000, Time: 05_05_2022__14:42:26\n","Step: 1100 of 1250, Validation loss: 0.0788516, Validation accuracy: 0.9750000, Time: 05_05_2022__14:42:32\n","Step: 1200 of 1250, Validation loss: 0.0785151, Validation accuracy: 0.9752083, Time: 05_05_2022__14:42:37\n","Average validation loss: 0.0785698, Average validation accuracy: 0.9752000, Time: 05_05_2022__14:42:39\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"876f9f1513634376a175d68a9f38c7e0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 13750, Training loss: 0.1232547, Training accuracy: 0.9675000, Time: 05_05_2022__14:42:59\n","Epoch 4 of 5, Step: 200 of 13750, Training loss: 0.1051058, Training accuracy: 0.9750000, Time: 05_05_2022__14:43:19\n","Epoch 4 of 5, Step: 300 of 13750, Training loss: 0.1173195, Training accuracy: 0.9708333, Time: 05_05_2022__14:43:39\n","Epoch 4 of 5, Step: 400 of 13750, Training loss: 0.1172081, Training accuracy: 0.9675000, Time: 05_05_2022__14:43:58\n","Epoch 4 of 5, Step: 500 of 13750, Training loss: 0.1170537, Training accuracy: 0.9670000, Time: 05_05_2022__14:44:18\n","Epoch 4 of 5, Step: 600 of 13750, Training loss: 0.1178979, Training accuracy: 0.9666667, Time: 05_05_2022__14:44:38\n","Epoch 4 of 5, Step: 700 of 13750, Training loss: 0.1204161, Training accuracy: 0.9660714, Time: 05_05_2022__14:44:58\n","Epoch 4 of 5, Step: 800 of 13750, Training loss: 0.1189824, Training accuracy: 0.9653125, Time: 05_05_2022__14:45:17\n","Epoch 4 of 5, Step: 900 of 13750, Training loss: 0.1203505, Training accuracy: 0.9650000, Time: 05_05_2022__14:45:37\n","Epoch 4 of 5, Step: 1000 of 13750, Training loss: 0.1200424, Training accuracy: 0.9652500, Time: 05_05_2022__14:45:57\n","Epoch 4 of 5, Step: 1100 of 13750, Training loss: 0.1235080, Training accuracy: 0.9650000, Time: 05_05_2022__14:46:16\n","Epoch 4 of 5, Step: 1200 of 13750, Training loss: 0.1230452, Training accuracy: 0.9641667, Time: 05_05_2022__14:46:36\n","Epoch 4 of 5, Step: 1300 of 13750, Training loss: 0.1234882, Training accuracy: 0.9638462, Time: 05_05_2022__14:46:56\n","Epoch 4 of 5, Step: 1400 of 13750, Training loss: 0.1223778, Training accuracy: 0.9642857, Time: 05_05_2022__14:47:16\n","Epoch 4 of 5, Step: 1500 of 13750, Training loss: 0.1228188, Training accuracy: 0.9638333, Time: 05_05_2022__14:47:35\n","Epoch 4 of 5, Step: 1600 of 13750, Training loss: 0.1225929, Training accuracy: 0.9640625, Time: 05_05_2022__14:47:55\n","Epoch 4 of 5, Step: 1700 of 13750, Training loss: 0.1222565, Training accuracy: 0.9639706, Time: 05_05_2022__14:48:15\n","Epoch 4 of 5, Step: 1800 of 13750, Training loss: 0.1210795, Training accuracy: 0.9648611, Time: 05_05_2022__14:48:35\n","Epoch 4 of 5, Step: 1900 of 13750, Training loss: 0.1201668, Training accuracy: 0.9656579, Time: 05_05_2022__14:48:54\n","Epoch 4 of 5, Step: 2000 of 13750, Training loss: 0.1193352, Training accuracy: 0.9657500, Time: 05_05_2022__14:49:14\n","Epoch 4 of 5, Step: 2100 of 13750, Training loss: 0.1171862, Training accuracy: 0.9666667, Time: 05_05_2022__14:49:34\n","Epoch 4 of 5, Step: 2200 of 13750, Training loss: 0.1165243, Training accuracy: 0.9667045, Time: 05_05_2022__14:49:53\n","Epoch 4 of 5, Step: 2300 of 13750, Training loss: 0.1149446, Training accuracy: 0.9673913, Time: 05_05_2022__14:50:13\n","Epoch 4 of 5, Step: 2400 of 13750, Training loss: 0.1151570, Training accuracy: 0.9678125, Time: 05_05_2022__14:50:33\n","Epoch 4 of 5, Step: 2500 of 13750, Training loss: 0.1145478, Training accuracy: 0.9679000, Time: 05_05_2022__14:50:53\n","Epoch 4 of 5, Step: 2600 of 13750, Training loss: 0.1156481, Training accuracy: 0.9675000, Time: 05_05_2022__14:51:12\n","Epoch 4 of 5, Step: 2700 of 13750, Training loss: 0.1149977, Training accuracy: 0.9677778, Time: 05_05_2022__14:51:32\n","Epoch 4 of 5, Step: 2800 of 13750, Training loss: 0.1157825, Training accuracy: 0.9674107, Time: 05_05_2022__14:51:52\n","Epoch 4 of 5, Step: 2900 of 13750, Training loss: 0.1155871, Training accuracy: 0.9676724, Time: 05_05_2022__14:52:12\n","Epoch 4 of 5, Step: 3000 of 13750, Training loss: 0.1147298, Training accuracy: 0.9680833, Time: 05_05_2022__14:52:31\n","Epoch 4 of 5, Step: 3100 of 13750, Training loss: 0.1144734, Training accuracy: 0.9680645, Time: 05_05_2022__14:52:51\n","Epoch 4 of 5, Step: 3200 of 13750, Training loss: 0.1138540, Training accuracy: 0.9681250, Time: 05_05_2022__14:53:11\n","Epoch 4 of 5, Step: 3300 of 13750, Training loss: 0.1138432, Training accuracy: 0.9678030, Time: 05_05_2022__14:53:31\n","Epoch 4 of 5, Step: 3400 of 13750, Training loss: 0.1134646, Training accuracy: 0.9678676, Time: 05_05_2022__14:53:50\n","Epoch 4 of 5, Step: 3500 of 13750, Training loss: 0.1134739, Training accuracy: 0.9678571, Time: 05_05_2022__14:54:10\n","Epoch 4 of 5, Step: 3600 of 13750, Training loss: 0.1127419, Training accuracy: 0.9681250, Time: 05_05_2022__14:54:30\n","Epoch 4 of 5, Step: 3700 of 13750, Training loss: 0.1133561, Training accuracy: 0.9679730, Time: 05_05_2022__14:54:49\n","Epoch 4 of 5, Step: 3800 of 13750, Training loss: 0.1129960, Training accuracy: 0.9680263, Time: 05_05_2022__14:55:09\n","Epoch 4 of 5, Step: 3900 of 13750, Training loss: 0.1134865, Training accuracy: 0.9678205, Time: 05_05_2022__14:55:29\n","Epoch 4 of 5, Step: 4000 of 13750, Training loss: 0.1134881, Training accuracy: 0.9679375, Time: 05_05_2022__14:55:49\n","Epoch 4 of 5, Step: 4100 of 13750, Training loss: 0.1133942, Training accuracy: 0.9679268, Time: 05_05_2022__14:56:08\n","Epoch 4 of 5, Step: 4200 of 13750, Training loss: 0.1147837, Training accuracy: 0.9677976, Time: 05_05_2022__14:56:28\n","Epoch 4 of 5, Step: 4300 of 13750, Training loss: 0.1148173, Training accuracy: 0.9676744, Time: 05_05_2022__14:56:48\n","Epoch 4 of 5, Step: 4400 of 13750, Training loss: 0.1146300, Training accuracy: 0.9675000, Time: 05_05_2022__14:57:08\n","Epoch 4 of 5, Step: 4500 of 13750, Training loss: 0.1138675, Training accuracy: 0.9676667, Time: 05_05_2022__14:57:27\n","Epoch 4 of 5, Step: 4600 of 13750, Training loss: 0.1133888, Training accuracy: 0.9678261, Time: 05_05_2022__14:57:47\n","Epoch 4 of 5, Step: 4700 of 13750, Training loss: 0.1136944, Training accuracy: 0.9677128, Time: 05_05_2022__14:58:07\n","Epoch 4 of 5, Step: 4800 of 13750, Training loss: 0.1140809, Training accuracy: 0.9675000, Time: 05_05_2022__14:58:27\n","Epoch 4 of 5, Step: 4900 of 13750, Training loss: 0.1145844, Training accuracy: 0.9672959, Time: 05_05_2022__14:58:46\n","Epoch 4 of 5, Step: 5000 of 13750, Training loss: 0.1137510, Training accuracy: 0.9676500, Time: 05_05_2022__14:59:06\n","Epoch 4 of 5, Step: 5100 of 13750, Training loss: 0.1134253, Training accuracy: 0.9677451, Time: 05_05_2022__14:59:26\n","Epoch 4 of 5, Step: 5200 of 13750, Training loss: 0.1136473, Training accuracy: 0.9676442, Time: 05_05_2022__14:59:46\n","Epoch 4 of 5, Step: 5300 of 13750, Training loss: 0.1139872, Training accuracy: 0.9675472, Time: 05_05_2022__15:00:05\n","Epoch 4 of 5, Step: 5400 of 13750, Training loss: 0.1136593, Training accuracy: 0.9677778, Time: 05_05_2022__15:00:25\n","Epoch 4 of 5, Step: 5500 of 13750, Training loss: 0.1132404, Training accuracy: 0.9680000, Time: 05_05_2022__15:00:45\n","Epoch 4 of 5, Step: 5600 of 13750, Training loss: 0.1134459, Training accuracy: 0.9679018, Time: 05_05_2022__15:01:05\n","Epoch 4 of 5, Step: 5700 of 13750, Training loss: 0.1139327, Training accuracy: 0.9675877, Time: 05_05_2022__15:01:24\n","Epoch 4 of 5, Step: 5800 of 13750, Training loss: 0.1132100, Training accuracy: 0.9677155, Time: 05_05_2022__15:01:44\n","Epoch 4 of 5, Step: 5900 of 13750, Training loss: 0.1124721, Training accuracy: 0.9679237, Time: 05_05_2022__15:02:04\n","Epoch 4 of 5, Step: 6000 of 13750, Training loss: 0.1125741, Training accuracy: 0.9677917, Time: 05_05_2022__15:02:24\n","Epoch 4 of 5, Step: 6100 of 13750, Training loss: 0.1121536, Training accuracy: 0.9679098, Time: 05_05_2022__15:02:43\n","Epoch 4 of 5, Step: 6200 of 13750, Training loss: 0.1121522, Training accuracy: 0.9679032, Time: 05_05_2022__15:03:03\n","Epoch 4 of 5, Step: 6300 of 13750, Training loss: 0.1125415, Training accuracy: 0.9678175, Time: 05_05_2022__15:03:23\n","Epoch 4 of 5, Step: 6400 of 13750, Training loss: 0.1122365, Training accuracy: 0.9679688, Time: 05_05_2022__15:03:43\n","Epoch 4 of 5, Step: 6500 of 13750, Training loss: 0.1125248, Training accuracy: 0.9678846, Time: 05_05_2022__15:04:02\n","Epoch 4 of 5, Step: 6600 of 13750, Training loss: 0.1118066, Training accuracy: 0.9681061, Time: 05_05_2022__15:04:22\n","Epoch 4 of 5, Step: 6700 of 13750, Training loss: 0.1115599, Training accuracy: 0.9680970, Time: 05_05_2022__15:04:42\n","Epoch 4 of 5, Step: 6800 of 13750, Training loss: 0.1111595, Training accuracy: 0.9681985, Time: 05_05_2022__15:05:01\n","Epoch 4 of 5, Step: 6900 of 13750, Training loss: 0.1111126, Training accuracy: 0.9681884, Time: 05_05_2022__15:05:21\n","Epoch 4 of 5, Step: 7000 of 13750, Training loss: 0.1107900, Training accuracy: 0.9683571, Time: 05_05_2022__15:05:41\n","Epoch 4 of 5, Step: 7100 of 13750, Training loss: 0.1109283, Training accuracy: 0.9683803, Time: 05_05_2022__15:06:01\n","Epoch 4 of 5, Step: 7200 of 13750, Training loss: 0.1109641, Training accuracy: 0.9683681, Time: 05_05_2022__15:06:20\n","Epoch 4 of 5, Step: 7300 of 13750, Training loss: 0.1104500, Training accuracy: 0.9685959, Time: 05_05_2022__15:06:40\n","Epoch 4 of 5, Step: 7400 of 13750, Training loss: 0.1102216, Training accuracy: 0.9686824, Time: 05_05_2022__15:07:00\n","Epoch 4 of 5, Step: 7500 of 13750, Training loss: 0.1102418, Training accuracy: 0.9686333, Time: 05_05_2022__15:07:20\n","Epoch 4 of 5, Step: 7600 of 13750, Training loss: 0.1104682, Training accuracy: 0.9684539, Time: 05_05_2022__15:07:39\n","Epoch 4 of 5, Step: 7700 of 13750, Training loss: 0.1099010, Training accuracy: 0.9686688, Time: 05_05_2022__15:07:59\n","Epoch 4 of 5, Step: 7800 of 13750, Training loss: 0.1098726, Training accuracy: 0.9686538, Time: 05_05_2022__15:08:19\n","Epoch 4 of 5, Step: 7900 of 13750, Training loss: 0.1102389, Training accuracy: 0.9684810, Time: 05_05_2022__15:08:38\n","Epoch 4 of 5, Step: 8000 of 13750, Training loss: 0.1101008, Training accuracy: 0.9685000, Time: 05_05_2022__15:08:58\n","Epoch 4 of 5, Step: 8100 of 13750, Training loss: 0.1098167, Training accuracy: 0.9685494, Time: 05_05_2022__15:09:18\n","Epoch 4 of 5, Step: 8200 of 13750, Training loss: 0.1093612, Training accuracy: 0.9686585, Time: 05_05_2022__15:09:38\n","Epoch 4 of 5, Step: 8300 of 13750, Training loss: 0.1099708, Training accuracy: 0.9685542, Time: 05_05_2022__15:09:57\n","Epoch 4 of 5, Step: 8400 of 13750, Training loss: 0.1102339, Training accuracy: 0.9683929, Time: 05_05_2022__15:10:17\n","Epoch 4 of 5, Step: 8500 of 13750, Training loss: 0.1098857, Training accuracy: 0.9685588, Time: 05_05_2022__15:10:37\n","Epoch 4 of 5, Step: 8600 of 13750, Training loss: 0.1097463, Training accuracy: 0.9686337, Time: 05_05_2022__15:10:57\n","Epoch 4 of 5, Step: 8700 of 13750, Training loss: 0.1096061, Training accuracy: 0.9686494, Time: 05_05_2022__15:11:16\n","Epoch 4 of 5, Step: 8800 of 13750, Training loss: 0.1099579, Training accuracy: 0.9684943, Time: 05_05_2022__15:11:36\n","Epoch 4 of 5, Step: 8900 of 13750, Training loss: 0.1095014, Training accuracy: 0.9686517, Time: 05_05_2022__15:11:56\n","Epoch 4 of 5, Step: 9000 of 13750, Training loss: 0.1097093, Training accuracy: 0.9684444, Time: 05_05_2022__15:12:15\n","Epoch 4 of 5, Step: 9100 of 13750, Training loss: 0.1098866, Training accuracy: 0.9684341, Time: 05_05_2022__15:12:35\n","Epoch 4 of 5, Step: 9200 of 13750, Training loss: 0.1098444, Training accuracy: 0.9684511, Time: 05_05_2022__15:12:55\n","Epoch 4 of 5, Step: 9300 of 13750, Training loss: 0.1097004, Training accuracy: 0.9685484, Time: 05_05_2022__15:13:15\n","Epoch 4 of 5, Step: 9400 of 13750, Training loss: 0.1098170, Training accuracy: 0.9684309, Time: 05_05_2022__15:13:34\n","Epoch 4 of 5, Step: 9500 of 13750, Training loss: 0.1097497, Training accuracy: 0.9683947, Time: 05_05_2022__15:13:54\n","Epoch 4 of 5, Step: 9600 of 13750, Training loss: 0.1097136, Training accuracy: 0.9683854, Time: 05_05_2022__15:14:14\n","Epoch 4 of 5, Step: 9700 of 13750, Training loss: 0.1095438, Training accuracy: 0.9684278, Time: 05_05_2022__15:14:34\n","Epoch 4 of 5, Step: 9800 of 13750, Training loss: 0.1094776, Training accuracy: 0.9684949, Time: 05_05_2022__15:14:53\n","Epoch 4 of 5, Step: 9900 of 13750, Training loss: 0.1090485, Training accuracy: 0.9686616, Time: 05_05_2022__15:15:13\n","Epoch 4 of 5, Step: 10000 of 13750, Training loss: 0.1089661, Training accuracy: 0.9687000, Time: 05_05_2022__15:15:33\n","Epoch 4 of 5, Step: 10100 of 13750, Training loss: 0.1092640, Training accuracy: 0.9687129, Time: 05_05_2022__15:15:53\n","Epoch 4 of 5, Step: 10200 of 13750, Training loss: 0.1092363, Training accuracy: 0.9686520, Time: 05_05_2022__15:16:12\n","Epoch 4 of 5, Step: 10300 of 13750, Training loss: 0.1089301, Training accuracy: 0.9687136, Time: 05_05_2022__15:16:32\n","Epoch 4 of 5, Step: 10400 of 13750, Training loss: 0.1087007, Training accuracy: 0.9688221, Time: 05_05_2022__15:16:52\n","Epoch 4 of 5, Step: 10500 of 13750, Training loss: 0.1086293, Training accuracy: 0.9688095, Time: 05_05_2022__15:17:12\n","Epoch 4 of 5, Step: 10600 of 13750, Training loss: 0.1085554, Training accuracy: 0.9688208, Time: 05_05_2022__15:17:31\n","Epoch 4 of 5, Step: 10700 of 13750, Training loss: 0.1084957, Training accuracy: 0.9688318, Time: 05_05_2022__15:17:51\n","Epoch 4 of 5, Step: 10800 of 13750, Training loss: 0.1085900, Training accuracy: 0.9687500, Time: 05_05_2022__15:18:11\n","Epoch 4 of 5, Step: 10900 of 13750, Training loss: 0.1084714, Training accuracy: 0.9688303, Time: 05_05_2022__15:18:30\n","Epoch 4 of 5, Step: 11000 of 13750, Training loss: 0.1081524, Training accuracy: 0.9689773, Time: 05_05_2022__15:18:50\n","Epoch 4 of 5, Step: 11100 of 13750, Training loss: 0.1079330, Training accuracy: 0.9690541, Time: 05_05_2022__15:19:10\n","Epoch 4 of 5, Step: 11200 of 13750, Training loss: 0.1077925, Training accuracy: 0.9691518, Time: 05_05_2022__15:19:30\n","Epoch 4 of 5, Step: 11300 of 13750, Training loss: 0.1075237, Training accuracy: 0.9692035, Time: 05_05_2022__15:19:50\n","Epoch 4 of 5, Step: 11400 of 13750, Training loss: 0.1074187, Training accuracy: 0.9692105, Time: 05_05_2022__15:20:09\n","Epoch 4 of 5, Step: 11500 of 13750, Training loss: 0.1076424, Training accuracy: 0.9692174, Time: 05_05_2022__15:20:29\n","Epoch 4 of 5, Step: 11600 of 13750, Training loss: 0.1075333, Training accuracy: 0.9691810, Time: 05_05_2022__15:20:49\n","Epoch 4 of 5, Step: 11700 of 13750, Training loss: 0.1072928, Training accuracy: 0.9692521, Time: 05_05_2022__15:21:09\n","Epoch 4 of 5, Step: 11800 of 13750, Training loss: 0.1073605, Training accuracy: 0.9692161, Time: 05_05_2022__15:21:28\n","Epoch 4 of 5, Step: 11900 of 13750, Training loss: 0.1071226, Training accuracy: 0.9693277, Time: 05_05_2022__15:21:48\n","Epoch 4 of 5, Step: 12000 of 13750, Training loss: 0.1068797, Training accuracy: 0.9694375, Time: 05_05_2022__15:22:08\n","Epoch 4 of 5, Step: 12100 of 13750, Training loss: 0.1068421, Training accuracy: 0.9694628, Time: 05_05_2022__15:22:28\n","Epoch 4 of 5, Step: 12200 of 13750, Training loss: 0.1071026, Training accuracy: 0.9694262, Time: 05_05_2022__15:22:47\n","Epoch 4 of 5, Step: 12300 of 13750, Training loss: 0.1069093, Training accuracy: 0.9695122, Time: 05_05_2022__15:23:07\n","Epoch 4 of 5, Step: 12400 of 13750, Training loss: 0.1067212, Training accuracy: 0.9695766, Time: 05_05_2022__15:23:27\n","Epoch 4 of 5, Step: 12500 of 13750, Training loss: 0.1066908, Training accuracy: 0.9696000, Time: 05_05_2022__15:23:47\n","Epoch 4 of 5, Step: 12600 of 13750, Training loss: 0.1064409, Training accuracy: 0.9696825, Time: 05_05_2022__15:24:07\n","Epoch 4 of 5, Step: 12700 of 13750, Training loss: 0.1062797, Training accuracy: 0.9696850, Time: 05_05_2022__15:24:26\n","Epoch 4 of 5, Step: 12800 of 13750, Training loss: 0.1062488, Training accuracy: 0.9696875, Time: 05_05_2022__15:24:46\n","Epoch 4 of 5, Step: 12900 of 13750, Training loss: 0.1064788, Training accuracy: 0.9695930, Time: 05_05_2022__15:25:06\n","Epoch 4 of 5, Step: 13000 of 13750, Training loss: 0.1063064, Training accuracy: 0.9696538, Time: 05_05_2022__15:25:25\n","Epoch 4 of 5, Step: 13100 of 13750, Training loss: 0.1066432, Training accuracy: 0.9696374, Time: 05_05_2022__15:25:45\n","Epoch 4 of 5, Step: 13200 of 13750, Training loss: 0.1064262, Training accuracy: 0.9696970, Time: 05_05_2022__15:26:05\n","Epoch 4 of 5, Step: 13300 of 13750, Training loss: 0.1064202, Training accuracy: 0.9697180, Time: 05_05_2022__15:26:25\n","Epoch 4 of 5, Step: 13400 of 13750, Training loss: 0.1064170, Training accuracy: 0.9697575, Time: 05_05_2022__15:26:44\n","Epoch 4 of 5, Step: 13500 of 13750, Training loss: 0.1062714, Training accuracy: 0.9697963, Time: 05_05_2022__15:27:04\n","Epoch 4 of 5, Step: 13600 of 13750, Training loss: 0.1060834, Training accuracy: 0.9698346, Time: 05_05_2022__15:27:24\n","Epoch 4 of 5, Step: 13700 of 13750, Training loss: 0.1058632, Training accuracy: 0.9698723, Time: 05_05_2022__15:27:44\n","Epoch 4 of 5, Average training loss: 0.1058268, Average training accuracy: 0.9698545, Time: 05_05_2022__15:27:53\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed2320c12bfd4c478e90546caeebfb63"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0547933, Validation accuracy: 0.9875000, Time: 05_05_2022__15:27:59 | Loss decreased from 0.0752121 to 0.0553165 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0568267, Validation accuracy: 0.9825000, Time: 05_05_2022__15:28:06\n","Step: 300 of 1250, Validation loss: 0.0600502, Validation accuracy: 0.9808333, Time: 05_05_2022__15:28:11\n","Step: 400 of 1250, Validation loss: 0.0572470, Validation accuracy: 0.9825000, Time: 05_05_2022__15:28:16\n","Step: 500 of 1250, Validation loss: 0.0581827, Validation accuracy: 0.9815000, Time: 05_05_2022__15:28:22\n","Step: 600 of 1250, Validation loss: 0.0569051, Validation accuracy: 0.9825000, Time: 05_05_2022__15:28:27\n","Step: 700 of 1250, Validation loss: 0.0561286, Validation accuracy: 0.9817857, Time: 05_05_2022__15:28:32\n","Step: 800 of 1250, Validation loss: 0.0565427, Validation accuracy: 0.9815625, Time: 05_05_2022__15:28:37\n","Step: 900 of 1250, Validation loss: 0.0599010, Validation accuracy: 0.9813889, Time: 05_05_2022__15:28:42\n","Step: 1000 of 1250, Validation loss: 0.0628044, Validation accuracy: 0.9810000, Time: 05_05_2022__15:28:47\n","Step: 1100 of 1250, Validation loss: 0.0619934, Validation accuracy: 0.9813636, Time: 05_05_2022__15:28:52\n","Step: 1200 of 1250, Validation loss: 0.0616613, Validation accuracy: 0.9814583, Time: 05_05_2022__15:28:58\n","Average validation loss: 0.0622630, Average validation accuracy: 0.9810000, Time: 05_05_2022__15:29:00\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caefaa2c8eee426aaaf176e148dbb270"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 13750, Training loss: 0.0915116, Training accuracy: 0.9750000, Time: 05_05_2022__15:29:20\n","Epoch 5 of 5, Step: 200 of 13750, Training loss: 0.0751866, Training accuracy: 0.9787500, Time: 05_05_2022__15:29:40\n","Epoch 5 of 5, Step: 300 of 13750, Training loss: 0.0833547, Training accuracy: 0.9766667, Time: 05_05_2022__15:29:59\n","Epoch 5 of 5, Step: 400 of 13750, Training loss: 0.0837349, Training accuracy: 0.9781250, Time: 05_05_2022__15:30:19\n","Epoch 5 of 5, Step: 500 of 13750, Training loss: 0.0853806, Training accuracy: 0.9770000, Time: 05_05_2022__15:30:39\n","Epoch 5 of 5, Step: 600 of 13750, Training loss: 0.0883040, Training accuracy: 0.9762500, Time: 05_05_2022__15:30:59\n","Epoch 5 of 5, Step: 700 of 13750, Training loss: 0.0919021, Training accuracy: 0.9746429, Time: 05_05_2022__15:31:18\n","Epoch 5 of 5, Step: 800 of 13750, Training loss: 0.0897607, Training accuracy: 0.9746875, Time: 05_05_2022__15:31:38\n","Epoch 5 of 5, Step: 900 of 13750, Training loss: 0.0898809, Training accuracy: 0.9744444, Time: 05_05_2022__15:31:58\n","Epoch 5 of 5, Step: 1000 of 13750, Training loss: 0.0899282, Training accuracy: 0.9740000, Time: 05_05_2022__15:32:17\n","Epoch 5 of 5, Step: 1100 of 13750, Training loss: 0.0920381, Training accuracy: 0.9734091, Time: 05_05_2022__15:32:37\n","Epoch 5 of 5, Step: 1200 of 13750, Training loss: 0.0910651, Training accuracy: 0.9735417, Time: 05_05_2022__15:32:57\n","Epoch 5 of 5, Step: 1300 of 13750, Training loss: 0.0913170, Training accuracy: 0.9740385, Time: 05_05_2022__15:33:17\n","Epoch 5 of 5, Step: 1400 of 13750, Training loss: 0.0897895, Training accuracy: 0.9748214, Time: 05_05_2022__15:33:36\n","Epoch 5 of 5, Step: 1500 of 13750, Training loss: 0.0907422, Training accuracy: 0.9746667, Time: 05_05_2022__15:33:56\n","Epoch 5 of 5, Step: 1600 of 13750, Training loss: 0.0908423, Training accuracy: 0.9743750, Time: 05_05_2022__15:34:16\n","Epoch 5 of 5, Step: 1700 of 13750, Training loss: 0.0903725, Training accuracy: 0.9744118, Time: 05_05_2022__15:34:36\n","Epoch 5 of 5, Step: 1800 of 13750, Training loss: 0.0897477, Training accuracy: 0.9750000, Time: 05_05_2022__15:34:55\n","Epoch 5 of 5, Step: 1900 of 13750, Training loss: 0.0898658, Training accuracy: 0.9750000, Time: 05_05_2022__15:35:15\n","Epoch 5 of 5, Step: 2000 of 13750, Training loss: 0.0888448, Training accuracy: 0.9752500, Time: 05_05_2022__15:35:35\n","Epoch 5 of 5, Step: 2100 of 13750, Training loss: 0.0875894, Training accuracy: 0.9754762, Time: 05_05_2022__15:35:55\n","Epoch 5 of 5, Step: 2200 of 13750, Training loss: 0.0871560, Training accuracy: 0.9754545, Time: 05_05_2022__15:36:14\n","Epoch 5 of 5, Step: 2300 of 13750, Training loss: 0.0876153, Training accuracy: 0.9751087, Time: 05_05_2022__15:36:34\n","Epoch 5 of 5, Step: 2400 of 13750, Training loss: 0.0893984, Training accuracy: 0.9746875, Time: 05_05_2022__15:36:54\n","Epoch 5 of 5, Step: 2500 of 13750, Training loss: 0.0892498, Training accuracy: 0.9744000, Time: 05_05_2022__15:37:14\n","Epoch 5 of 5, Step: 2600 of 13750, Training loss: 0.0906021, Training accuracy: 0.9737500, Time: 05_05_2022__15:37:33\n","Epoch 5 of 5, Step: 2700 of 13750, Training loss: 0.0902344, Training accuracy: 0.9737037, Time: 05_05_2022__15:37:53\n","Epoch 5 of 5, Step: 2800 of 13750, Training loss: 0.0906479, Training accuracy: 0.9733929, Time: 05_05_2022__15:38:13\n","Epoch 5 of 5, Step: 2900 of 13750, Training loss: 0.0911884, Training accuracy: 0.9731034, Time: 05_05_2022__15:38:33\n","Epoch 5 of 5, Step: 3000 of 13750, Training loss: 0.0908945, Training accuracy: 0.9732500, Time: 05_05_2022__15:38:52\n","Epoch 5 of 5, Step: 3100 of 13750, Training loss: 0.0913782, Training accuracy: 0.9728226, Time: 05_05_2022__15:39:12\n","Epoch 5 of 5, Step: 3200 of 13750, Training loss: 0.0906103, Training accuracy: 0.9732812, Time: 05_05_2022__15:39:32\n","Epoch 5 of 5, Step: 3300 of 13750, Training loss: 0.0900283, Training accuracy: 0.9734091, Time: 05_05_2022__15:39:52\n","Epoch 5 of 5, Step: 3400 of 13750, Training loss: 0.0902907, Training accuracy: 0.9733088, Time: 05_05_2022__15:40:11\n","Epoch 5 of 5, Step: 3500 of 13750, Training loss: 0.0900990, Training accuracy: 0.9735714, Time: 05_05_2022__15:40:31\n","Epoch 5 of 5, Step: 3600 of 13750, Training loss: 0.0897007, Training accuracy: 0.9734722, Time: 05_05_2022__15:40:51\n","Epoch 5 of 5, Step: 3700 of 13750, Training loss: 0.0896061, Training accuracy: 0.9737162, Time: 05_05_2022__15:41:10\n","Epoch 5 of 5, Step: 3800 of 13750, Training loss: 0.0897537, Training accuracy: 0.9736184, Time: 05_05_2022__15:41:30\n","Epoch 5 of 5, Step: 3900 of 13750, Training loss: 0.0899015, Training accuracy: 0.9737179, Time: 05_05_2022__15:41:50\n","Epoch 5 of 5, Step: 4000 of 13750, Training loss: 0.0904739, Training accuracy: 0.9732500, Time: 05_05_2022__15:42:10\n","Epoch 5 of 5, Step: 4100 of 13750, Training loss: 0.0904997, Training accuracy: 0.9732317, Time: 05_05_2022__15:42:29\n","Epoch 5 of 5, Step: 4200 of 13750, Training loss: 0.0920850, Training accuracy: 0.9729167, Time: 05_05_2022__15:42:49\n","Epoch 5 of 5, Step: 4300 of 13750, Training loss: 0.0922331, Training accuracy: 0.9730233, Time: 05_05_2022__15:43:09\n","Epoch 5 of 5, Step: 4400 of 13750, Training loss: 0.0925615, Training accuracy: 0.9729545, Time: 05_05_2022__15:43:29\n","Epoch 5 of 5, Step: 4500 of 13750, Training loss: 0.0918703, Training accuracy: 0.9731667, Time: 05_05_2022__15:43:48\n","Epoch 5 of 5, Step: 4600 of 13750, Training loss: 0.0914400, Training accuracy: 0.9733152, Time: 05_05_2022__15:44:08\n","Epoch 5 of 5, Step: 4700 of 13750, Training loss: 0.0915995, Training accuracy: 0.9730851, Time: 05_05_2022__15:44:28\n","Epoch 5 of 5, Step: 4800 of 13750, Training loss: 0.0919694, Training accuracy: 0.9731250, Time: 05_05_2022__15:44:48\n","Epoch 5 of 5, Step: 4900 of 13750, Training loss: 0.0920477, Training accuracy: 0.9729592, Time: 05_05_2022__15:45:07\n","Epoch 5 of 5, Step: 5000 of 13750, Training loss: 0.0919784, Training accuracy: 0.9729500, Time: 05_05_2022__15:45:27\n","Epoch 5 of 5, Step: 5100 of 13750, Training loss: 0.0917441, Training accuracy: 0.9728922, Time: 05_05_2022__15:45:47\n","Epoch 5 of 5, Step: 5200 of 13750, Training loss: 0.0920523, Training accuracy: 0.9727885, Time: 05_05_2022__15:46:07\n","Epoch 5 of 5, Step: 5300 of 13750, Training loss: 0.0925292, Training accuracy: 0.9725000, Time: 05_05_2022__15:46:26\n","Epoch 5 of 5, Step: 5400 of 13750, Training loss: 0.0922673, Training accuracy: 0.9726389, Time: 05_05_2022__15:46:46\n","Epoch 5 of 5, Step: 5500 of 13750, Training loss: 0.0922341, Training accuracy: 0.9728182, Time: 05_05_2022__15:47:06\n","Epoch 5 of 5, Step: 5600 of 13750, Training loss: 0.0925624, Training accuracy: 0.9726339, Time: 05_05_2022__15:47:26\n","Epoch 5 of 5, Step: 5700 of 13750, Training loss: 0.0935204, Training accuracy: 0.9720614, Time: 05_05_2022__15:47:45\n","Epoch 5 of 5, Step: 5800 of 13750, Training loss: 0.0935418, Training accuracy: 0.9719828, Time: 05_05_2022__15:48:05\n","Epoch 5 of 5, Step: 5900 of 13750, Training loss: 0.0931297, Training accuracy: 0.9720763, Time: 05_05_2022__15:48:25\n","Epoch 5 of 5, Step: 6000 of 13750, Training loss: 0.0934621, Training accuracy: 0.9717917, Time: 05_05_2022__15:48:44\n","Epoch 5 of 5, Step: 6100 of 13750, Training loss: 0.0932116, Training accuracy: 0.9719672, Time: 05_05_2022__15:49:04\n","Epoch 5 of 5, Step: 6200 of 13750, Training loss: 0.0932073, Training accuracy: 0.9720161, Time: 05_05_2022__15:49:24\n","Epoch 5 of 5, Step: 6300 of 13750, Training loss: 0.0931679, Training accuracy: 0.9719841, Time: 05_05_2022__15:49:44\n","Epoch 5 of 5, Step: 6400 of 13750, Training loss: 0.0931106, Training accuracy: 0.9721094, Time: 05_05_2022__15:50:03\n","Epoch 5 of 5, Step: 6500 of 13750, Training loss: 0.0935905, Training accuracy: 0.9719231, Time: 05_05_2022__15:50:23\n","Epoch 5 of 5, Step: 6600 of 13750, Training loss: 0.0932177, Training accuracy: 0.9720833, Time: 05_05_2022__15:50:43\n","Epoch 5 of 5, Step: 6700 of 13750, Training loss: 0.0929009, Training accuracy: 0.9722015, Time: 05_05_2022__15:51:03\n","Epoch 5 of 5, Step: 6800 of 13750, Training loss: 0.0927392, Training accuracy: 0.9722426, Time: 05_05_2022__15:51:22\n","Epoch 5 of 5, Step: 6900 of 13750, Training loss: 0.0927198, Training accuracy: 0.9723551, Time: 05_05_2022__15:51:42\n","Epoch 5 of 5, Step: 7000 of 13750, Training loss: 0.0926010, Training accuracy: 0.9725000, Time: 05_05_2022__15:52:02\n","Epoch 5 of 5, Step: 7100 of 13750, Training loss: 0.0926179, Training accuracy: 0.9726056, Time: 05_05_2022__15:52:22\n","Epoch 5 of 5, Step: 7200 of 13750, Training loss: 0.0924100, Training accuracy: 0.9725694, Time: 05_05_2022__15:52:41\n","Epoch 5 of 5, Step: 7300 of 13750, Training loss: 0.0921557, Training accuracy: 0.9727397, Time: 05_05_2022__15:53:01\n","Epoch 5 of 5, Step: 7400 of 13750, Training loss: 0.0919888, Training accuracy: 0.9728716, Time: 05_05_2022__15:53:21\n","Epoch 5 of 5, Step: 7500 of 13750, Training loss: 0.0920941, Training accuracy: 0.9729333, Time: 05_05_2022__15:53:41\n","Epoch 5 of 5, Step: 7600 of 13750, Training loss: 0.0921640, Training accuracy: 0.9728289, Time: 05_05_2022__15:54:00\n","Epoch 5 of 5, Step: 7700 of 13750, Training loss: 0.0919420, Training accuracy: 0.9729221, Time: 05_05_2022__15:54:20\n","Epoch 5 of 5, Step: 7800 of 13750, Training loss: 0.0918178, Training accuracy: 0.9728846, Time: 05_05_2022__15:54:40\n","Epoch 5 of 5, Step: 7900 of 13750, Training loss: 0.0917773, Training accuracy: 0.9728481, Time: 05_05_2022__15:54:59\n","Epoch 5 of 5, Step: 8000 of 13750, Training loss: 0.0919495, Training accuracy: 0.9726250, Time: 05_05_2022__15:55:19\n","Epoch 5 of 5, Step: 8100 of 13750, Training loss: 0.0915727, Training accuracy: 0.9727160, Time: 05_05_2022__15:55:39\n","Epoch 5 of 5, Step: 8200 of 13750, Training loss: 0.0914338, Training accuracy: 0.9728049, Time: 05_05_2022__15:55:59\n","Epoch 5 of 5, Step: 8300 of 13750, Training loss: 0.0921962, Training accuracy: 0.9726205, Time: 05_05_2022__15:56:18\n","Epoch 5 of 5, Step: 8400 of 13750, Training loss: 0.0922052, Training accuracy: 0.9726488, Time: 05_05_2022__15:56:38\n","Epoch 5 of 5, Step: 8500 of 13750, Training loss: 0.0919924, Training accuracy: 0.9727647, Time: 05_05_2022__15:56:58\n","Epoch 5 of 5, Step: 8600 of 13750, Training loss: 0.0920191, Training accuracy: 0.9727616, Time: 05_05_2022__15:57:18\n","Epoch 5 of 5, Step: 8700 of 13750, Training loss: 0.0919138, Training accuracy: 0.9727586, Time: 05_05_2022__15:57:37\n","Epoch 5 of 5, Step: 8800 of 13750, Training loss: 0.0922391, Training accuracy: 0.9727273, Time: 05_05_2022__15:57:57\n","Epoch 5 of 5, Step: 8900 of 13750, Training loss: 0.0918940, Training accuracy: 0.9729213, Time: 05_05_2022__15:58:17\n","Epoch 5 of 5, Step: 9000 of 13750, Training loss: 0.0919398, Training accuracy: 0.9728056, Time: 05_05_2022__15:58:36\n","Epoch 5 of 5, Step: 9100 of 13750, Training loss: 0.0919455, Training accuracy: 0.9727473, Time: 05_05_2022__15:58:56\n","Epoch 5 of 5, Step: 9200 of 13750, Training loss: 0.0920325, Training accuracy: 0.9727446, Time: 05_05_2022__15:59:16\n","Epoch 5 of 5, Step: 9300 of 13750, Training loss: 0.0918313, Training accuracy: 0.9728226, Time: 05_05_2022__15:59:36\n","Epoch 5 of 5, Step: 9400 of 13750, Training loss: 0.0919019, Training accuracy: 0.9727926, Time: 05_05_2022__15:59:55\n","Epoch 5 of 5, Step: 9500 of 13750, Training loss: 0.0918081, Training accuracy: 0.9727632, Time: 05_05_2022__16:00:15\n","Epoch 5 of 5, Step: 9600 of 13750, Training loss: 0.0919800, Training accuracy: 0.9726302, Time: 05_05_2022__16:00:35\n","Epoch 5 of 5, Step: 9700 of 13750, Training loss: 0.0917475, Training accuracy: 0.9726289, Time: 05_05_2022__16:00:55\n","Epoch 5 of 5, Step: 9800 of 13750, Training loss: 0.0918233, Training accuracy: 0.9726276, Time: 05_05_2022__16:01:14\n","Epoch 5 of 5, Step: 9900 of 13750, Training loss: 0.0914600, Training accuracy: 0.9727525, Time: 05_05_2022__16:01:34\n","Epoch 5 of 5, Step: 10000 of 13750, Training loss: 0.0913449, Training accuracy: 0.9728500, Time: 05_05_2022__16:01:54\n","Epoch 5 of 5, Step: 10100 of 13750, Training loss: 0.0918631, Training accuracy: 0.9727228, Time: 05_05_2022__16:02:14\n","Epoch 5 of 5, Step: 10200 of 13750, Training loss: 0.0918833, Training accuracy: 0.9727696, Time: 05_05_2022__16:02:33\n","Epoch 5 of 5, Step: 10300 of 13750, Training loss: 0.0913996, Training accuracy: 0.9729854, Time: 05_05_2022__16:02:53\n","Epoch 5 of 5, Step: 10400 of 13750, Training loss: 0.0913847, Training accuracy: 0.9730288, Time: 05_05_2022__16:03:13\n","Epoch 5 of 5, Step: 10500 of 13750, Training loss: 0.0913719, Training accuracy: 0.9729762, Time: 05_05_2022__16:03:32\n","Epoch 5 of 5, Step: 10600 of 13750, Training loss: 0.0913911, Training accuracy: 0.9730189, Time: 05_05_2022__16:03:52\n","Epoch 5 of 5, Step: 10700 of 13750, Training loss: 0.0913571, Training accuracy: 0.9729907, Time: 05_05_2022__16:04:12\n","Epoch 5 of 5, Step: 10800 of 13750, Training loss: 0.0914322, Training accuracy: 0.9729398, Time: 05_05_2022__16:04:32\n","Epoch 5 of 5, Step: 10900 of 13750, Training loss: 0.0914545, Training accuracy: 0.9730046, Time: 05_05_2022__16:04:51\n","Epoch 5 of 5, Step: 11000 of 13750, Training loss: 0.0911278, Training accuracy: 0.9731136, Time: 05_05_2022__16:05:11\n","Epoch 5 of 5, Step: 11100 of 13750, Training loss: 0.0910030, Training accuracy: 0.9731532, Time: 05_05_2022__16:05:31\n","Epoch 5 of 5, Step: 11200 of 13750, Training loss: 0.0908450, Training accuracy: 0.9732143, Time: 05_05_2022__16:05:50\n","Epoch 5 of 5, Step: 11300 of 13750, Training loss: 0.0907609, Training accuracy: 0.9732522, Time: 05_05_2022__16:06:10\n","Epoch 5 of 5, Step: 11400 of 13750, Training loss: 0.0905510, Training accuracy: 0.9733114, Time: 05_05_2022__16:06:30\n","Epoch 5 of 5, Step: 11500 of 13750, Training loss: 0.0906116, Training accuracy: 0.9733261, Time: 05_05_2022__16:06:50\n","Epoch 5 of 5, Step: 11600 of 13750, Training loss: 0.0904798, Training accuracy: 0.9733836, Time: 05_05_2022__16:07:10\n","Epoch 5 of 5, Step: 11700 of 13750, Training loss: 0.0903135, Training accuracy: 0.9733761, Time: 05_05_2022__16:07:29\n","Epoch 5 of 5, Step: 11800 of 13750, Training loss: 0.0903683, Training accuracy: 0.9732839, Time: 05_05_2022__16:07:49\n","Epoch 5 of 5, Step: 11900 of 13750, Training loss: 0.0903128, Training accuracy: 0.9733193, Time: 05_05_2022__16:08:09\n","Epoch 5 of 5, Step: 12000 of 13750, Training loss: 0.0902464, Training accuracy: 0.9733333, Time: 05_05_2022__16:08:28\n","Epoch 5 of 5, Step: 12100 of 13750, Training loss: 0.0902210, Training accuracy: 0.9733058, Time: 05_05_2022__16:08:48\n","Epoch 5 of 5, Step: 12200 of 13750, Training loss: 0.0902655, Training accuracy: 0.9733197, Time: 05_05_2022__16:09:08\n","Epoch 5 of 5, Step: 12300 of 13750, Training loss: 0.0900129, Training accuracy: 0.9734553, Time: 05_05_2022__16:09:28\n","Epoch 5 of 5, Step: 12400 of 13750, Training loss: 0.0898179, Training accuracy: 0.9735282, Time: 05_05_2022__16:09:47\n","Epoch 5 of 5, Step: 12500 of 13750, Training loss: 0.0897115, Training accuracy: 0.9735800, Time: 05_05_2022__16:10:07\n","Epoch 5 of 5, Step: 12600 of 13750, Training loss: 0.0893810, Training accuracy: 0.9736706, Time: 05_05_2022__16:10:27\n","Epoch 5 of 5, Step: 12700 of 13750, Training loss: 0.0893197, Training accuracy: 0.9736811, Time: 05_05_2022__16:10:47\n","Epoch 5 of 5, Step: 12800 of 13750, Training loss: 0.0892428, Training accuracy: 0.9736914, Time: 05_05_2022__16:11:07\n","Epoch 5 of 5, Step: 12900 of 13750, Training loss: 0.0894076, Training accuracy: 0.9736628, Time: 05_05_2022__16:11:26\n","Epoch 5 of 5, Step: 13000 of 13750, Training loss: 0.0892729, Training accuracy: 0.9737115, Time: 05_05_2022__16:11:46\n","Epoch 5 of 5, Step: 13100 of 13750, Training loss: 0.0895420, Training accuracy: 0.9736069, Time: 05_05_2022__16:12:06\n","Epoch 5 of 5, Step: 13200 of 13750, Training loss: 0.0893479, Training accuracy: 0.9736553, Time: 05_05_2022__16:12:25\n","Epoch 5 of 5, Step: 13300 of 13750, Training loss: 0.0893933, Training accuracy: 0.9736278, Time: 05_05_2022__16:12:45\n","Epoch 5 of 5, Step: 13400 of 13750, Training loss: 0.0894996, Training accuracy: 0.9736194, Time: 05_05_2022__16:13:05\n","Epoch 5 of 5, Step: 13500 of 13750, Training loss: 0.0894784, Training accuracy: 0.9735741, Time: 05_05_2022__16:13:25\n","Epoch 5 of 5, Step: 13600 of 13750, Training loss: 0.0894060, Training accuracy: 0.9736029, Time: 05_05_2022__16:13:44\n","Epoch 5 of 5, Step: 13700 of 13750, Training loss: 0.0892441, Training accuracy: 0.9736679, Time: 05_05_2022__16:14:04\n","Epoch 5 of 5, Average training loss: 0.0892207, Average training accuracy: 0.9736545, Time: 05_05_2022__16:14:14\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94380945025a422c9f79cb45ac83e89d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0376984, Validation accuracy: 0.9925000, Time: 05_05_2022__16:14:19 | Loss decreased from 0.0553165 to 0.0380570 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0502788, Validation accuracy: 0.9862500, Time: 05_05_2022__16:14:26\n","Step: 300 of 1250, Validation loss: 0.0518056, Validation accuracy: 0.9858333, Time: 05_05_2022__16:14:32\n","Step: 400 of 1250, Validation loss: 0.0518840, Validation accuracy: 0.9850000, Time: 05_05_2022__16:14:37\n","Step: 500 of 1250, Validation loss: 0.0539551, Validation accuracy: 0.9845000, Time: 05_05_2022__16:14:42\n","Step: 600 of 1250, Validation loss: 0.0538795, Validation accuracy: 0.9841667, Time: 05_05_2022__16:14:47\n","Step: 700 of 1250, Validation loss: 0.0531379, Validation accuracy: 0.9839286, Time: 05_05_2022__16:14:52\n","Step: 800 of 1250, Validation loss: 0.0540053, Validation accuracy: 0.9834375, Time: 05_05_2022__16:14:57\n","Step: 900 of 1250, Validation loss: 0.0550226, Validation accuracy: 0.9833333, Time: 05_05_2022__16:15:03\n","Step: 1000 of 1250, Validation loss: 0.0562449, Validation accuracy: 0.9827500, Time: 05_05_2022__16:15:08\n","Step: 1100 of 1250, Validation loss: 0.0557141, Validation accuracy: 0.9827273, Time: 05_05_2022__16:15:13\n","Step: 1200 of 1250, Validation loss: 0.0555507, Validation accuracy: 0.9825000, Time: 05_05_2022__16:15:18\n","Average validation loss: 0.0568174, Average validation accuracy: 0.9822000, Time: 05_05_2022__16:15:21\n","###################### Testing vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63172a7c5f514cbeb45932de1e9668e0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.9900000, Time: 05_05_2022__16:15:33\n","Step: 200 of 2500, Test accuracy: 0.9862500, Time: 05_05_2022__16:15:39\n","Step: 300 of 2500, Test accuracy: 0.9800000, Time: 05_05_2022__16:15:44\n","Step: 400 of 2500, Test accuracy: 0.9775000, Time: 05_05_2022__16:15:50\n","Step: 500 of 2500, Test accuracy: 0.9775000, Time: 05_05_2022__16:15:55\n","Step: 600 of 2500, Test accuracy: 0.9758333, Time: 05_05_2022__16:16:01\n","Step: 700 of 2500, Test accuracy: 0.9767857, Time: 05_05_2022__16:16:06\n","Step: 800 of 2500, Test accuracy: 0.9768750, Time: 05_05_2022__16:16:12\n","Step: 900 of 2500, Test accuracy: 0.9772222, Time: 05_05_2022__16:16:18\n","Step: 1000 of 2500, Test accuracy: 0.9770000, Time: 05_05_2022__16:16:23\n","Step: 1100 of 2500, Test accuracy: 0.9775000, Time: 05_05_2022__16:16:28\n","Step: 1200 of 2500, Test accuracy: 0.9770833, Time: 05_05_2022__16:16:33\n","Step: 1300 of 2500, Test accuracy: 0.9776923, Time: 05_05_2022__16:16:38\n","Step: 1400 of 2500, Test accuracy: 0.9792857, Time: 05_05_2022__16:16:43\n","Step: 1500 of 2500, Test accuracy: 0.9798333, Time: 05_05_2022__16:16:49\n","Step: 1600 of 2500, Test accuracy: 0.9807813, Time: 05_05_2022__16:16:54\n","Step: 1700 of 2500, Test accuracy: 0.9804412, Time: 05_05_2022__16:16:59\n","Step: 1800 of 2500, Test accuracy: 0.9815278, Time: 05_05_2022__16:17:04\n","Step: 1900 of 2500, Test accuracy: 0.9822368, Time: 05_05_2022__16:17:09\n","Step: 2000 of 2500, Test accuracy: 0.9827500, Time: 05_05_2022__16:17:14\n","Step: 2100 of 2500, Test accuracy: 0.9830952, Time: 05_05_2022__16:17:19\n","Step: 2200 of 2500, Test accuracy: 0.9836364, Time: 05_05_2022__16:17:25\n","Step: 2300 of 2500, Test accuracy: 0.9839130, Time: 05_05_2022__16:17:30\n","Step: 2400 of 2500, Test accuracy: 0.9844792, Time: 05_05_2022__16:17:35\n","Step: 2500 of 2500, Test accuracy: 0.9838000, Time: 05_05_2022__16:17:40\n","Average testing accuracy: 0.9838000, Time: 05_05_2022__16:17:40\n","###################### Training vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a31667afc0d4599b071c96b73945abe"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 13750, Training loss: 2.4077441, Training accuracy: 0.1150000, Time: 05_05_2022__16:18:03\n","Epoch 1 of 5, Step: 200 of 13750, Training loss: 2.3657236, Training accuracy: 0.1337500, Time: 05_05_2022__16:18:24\n","Epoch 1 of 5, Step: 300 of 13750, Training loss: 2.3498189, Training accuracy: 0.1466667, Time: 05_05_2022__16:18:45\n","Epoch 1 of 5, Step: 400 of 13750, Training loss: 2.3138281, Training accuracy: 0.1612500, Time: 05_05_2022__16:19:06\n","Epoch 1 of 5, Step: 500 of 13750, Training loss: 2.2844994, Training accuracy: 0.1760000, Time: 05_05_2022__16:19:27\n","Epoch 1 of 5, Step: 600 of 13750, Training loss: 2.2616843, Training accuracy: 0.1825000, Time: 05_05_2022__16:19:48\n","Epoch 1 of 5, Step: 700 of 13750, Training loss: 2.2315708, Training accuracy: 0.2003571, Time: 05_05_2022__16:20:09\n","Epoch 1 of 5, Step: 800 of 13750, Training loss: 2.2042390, Training accuracy: 0.2125000, Time: 05_05_2022__16:20:29\n","Epoch 1 of 5, Step: 900 of 13750, Training loss: 2.1735125, Training accuracy: 0.2283333, Time: 05_05_2022__16:20:50\n","Epoch 1 of 5, Step: 1000 of 13750, Training loss: 2.1399939, Training accuracy: 0.2452500, Time: 05_05_2022__16:21:11\n","Epoch 1 of 5, Step: 1100 of 13750, Training loss: 2.1116313, Training accuracy: 0.2590909, Time: 05_05_2022__16:21:32\n","Epoch 1 of 5, Step: 1200 of 13750, Training loss: 2.0801571, Training accuracy: 0.2764583, Time: 05_05_2022__16:21:53\n","Epoch 1 of 5, Step: 1300 of 13750, Training loss: 2.0457589, Training accuracy: 0.2948077, Time: 05_05_2022__16:22:14\n","Epoch 1 of 5, Step: 1400 of 13750, Training loss: 2.0148422, Training accuracy: 0.3108929, Time: 05_05_2022__16:22:35\n","Epoch 1 of 5, Step: 1500 of 13750, Training loss: 1.9833068, Training accuracy: 0.3260000, Time: 05_05_2022__16:22:56\n","Epoch 1 of 5, Step: 1600 of 13750, Training loss: 1.9531189, Training accuracy: 0.3410937, Time: 05_05_2022__16:23:17\n","Epoch 1 of 5, Step: 1700 of 13750, Training loss: 1.9240890, Training accuracy: 0.3554412, Time: 05_05_2022__16:23:37\n","Epoch 1 of 5, Step: 1800 of 13750, Training loss: 1.8886415, Training accuracy: 0.3706944, Time: 05_05_2022__16:23:58\n","Epoch 1 of 5, Step: 1900 of 13750, Training loss: 1.8568447, Training accuracy: 0.3857895, Time: 05_05_2022__16:24:19\n","Epoch 1 of 5, Step: 2000 of 13750, Training loss: 1.8248778, Training accuracy: 0.4006250, Time: 05_05_2022__16:24:40\n","Epoch 1 of 5, Step: 2100 of 13750, Training loss: 1.7954677, Training accuracy: 0.4120238, Time: 05_05_2022__16:25:01\n","Epoch 1 of 5, Step: 2200 of 13750, Training loss: 1.7657756, Training accuracy: 0.4260227, Time: 05_05_2022__16:25:22\n","Epoch 1 of 5, Step: 2300 of 13750, Training loss: 1.7371143, Training accuracy: 0.4379348, Time: 05_05_2022__16:25:43\n","Epoch 1 of 5, Step: 2400 of 13750, Training loss: 1.7093145, Training accuracy: 0.4497917, Time: 05_05_2022__16:26:04\n","Epoch 1 of 5, Step: 2500 of 13750, Training loss: 1.6842774, Training accuracy: 0.4598000, Time: 05_05_2022__16:26:24\n","Epoch 1 of 5, Step: 2600 of 13750, Training loss: 1.6605149, Training accuracy: 0.4693269, Time: 05_05_2022__16:26:45\n","Epoch 1 of 5, Step: 2700 of 13750, Training loss: 1.6342424, Training accuracy: 0.4789815, Time: 05_05_2022__16:27:06\n","Epoch 1 of 5, Step: 2800 of 13750, Training loss: 1.6086272, Training accuracy: 0.4898214, Time: 05_05_2022__16:27:27\n","Epoch 1 of 5, Step: 2900 of 13750, Training loss: 1.5832355, Training accuracy: 0.4991379, Time: 05_05_2022__16:27:48\n","Epoch 1 of 5, Step: 3000 of 13750, Training loss: 1.5572593, Training accuracy: 0.5093333, Time: 05_05_2022__16:28:09\n","Epoch 1 of 5, Step: 3100 of 13750, Training loss: 1.5346771, Training accuracy: 0.5169355, Time: 05_05_2022__16:28:30\n","Epoch 1 of 5, Step: 3200 of 13750, Training loss: 1.5127328, Training accuracy: 0.5246875, Time: 05_05_2022__16:28:51\n","Epoch 1 of 5, Step: 3300 of 13750, Training loss: 1.4896029, Training accuracy: 0.5334848, Time: 05_05_2022__16:29:12\n","Epoch 1 of 5, Step: 3400 of 13750, Training loss: 1.4678179, Training accuracy: 0.5413235, Time: 05_05_2022__16:29:32\n","Epoch 1 of 5, Step: 3500 of 13750, Training loss: 1.4472875, Training accuracy: 0.5485714, Time: 05_05_2022__16:29:53\n","Epoch 1 of 5, Step: 3600 of 13750, Training loss: 1.4271605, Training accuracy: 0.5554861, Time: 05_05_2022__16:30:14\n","Epoch 1 of 5, Step: 3700 of 13750, Training loss: 1.4084045, Training accuracy: 0.5623649, Time: 05_05_2022__16:30:35\n","Epoch 1 of 5, Step: 3800 of 13750, Training loss: 1.3889418, Training accuracy: 0.5695395, Time: 05_05_2022__16:30:56\n","Epoch 1 of 5, Step: 3900 of 13750, Training loss: 1.3711976, Training accuracy: 0.5757692, Time: 05_05_2022__16:31:17\n","Epoch 1 of 5, Step: 4000 of 13750, Training loss: 1.3532143, Training accuracy: 0.5816250, Time: 05_05_2022__16:31:38\n","Epoch 1 of 5, Step: 4100 of 13750, Training loss: 1.3354381, Training accuracy: 0.5879878, Time: 05_05_2022__16:31:59\n","Epoch 1 of 5, Step: 4200 of 13750, Training loss: 1.3183879, Training accuracy: 0.5940476, Time: 05_05_2022__16:32:20\n","Epoch 1 of 5, Step: 4300 of 13750, Training loss: 1.3026073, Training accuracy: 0.5996512, Time: 05_05_2022__16:32:40\n","Epoch 1 of 5, Step: 4400 of 13750, Training loss: 1.2863528, Training accuracy: 0.6053409, Time: 05_05_2022__16:33:01\n","Epoch 1 of 5, Step: 4500 of 13750, Training loss: 1.2696175, Training accuracy: 0.6108333, Time: 05_05_2022__16:33:22\n","Epoch 1 of 5, Step: 4600 of 13750, Training loss: 1.2528281, Training accuracy: 0.6165217, Time: 05_05_2022__16:33:43\n","Epoch 1 of 5, Step: 4700 of 13750, Training loss: 1.2386481, Training accuracy: 0.6211702, Time: 05_05_2022__16:34:04\n","Epoch 1 of 5, Step: 4800 of 13750, Training loss: 1.2246219, Training accuracy: 0.6253646, Time: 05_05_2022__16:34:25\n","Epoch 1 of 5, Step: 4900 of 13750, Training loss: 1.2104089, Training accuracy: 0.6303571, Time: 05_05_2022__16:34:46\n","Epoch 1 of 5, Step: 5000 of 13750, Training loss: 1.1969260, Training accuracy: 0.6346500, Time: 05_05_2022__16:35:07\n","Epoch 1 of 5, Step: 5100 of 13750, Training loss: 1.1831057, Training accuracy: 0.6396078, Time: 05_05_2022__16:35:27\n","Epoch 1 of 5, Step: 5200 of 13750, Training loss: 1.1693158, Training accuracy: 0.6441827, Time: 05_05_2022__16:35:48\n","Epoch 1 of 5, Step: 5300 of 13750, Training loss: 1.1571702, Training accuracy: 0.6478302, Time: 05_05_2022__16:36:09\n","Epoch 1 of 5, Step: 5400 of 13750, Training loss: 1.1438311, Training accuracy: 0.6523611, Time: 05_05_2022__16:36:30\n","Epoch 1 of 5, Step: 5500 of 13750, Training loss: 1.1305182, Training accuracy: 0.6570909, Time: 05_05_2022__16:36:51\n","Epoch 1 of 5, Step: 5600 of 13750, Training loss: 1.1193252, Training accuracy: 0.6608929, Time: 05_05_2022__16:37:12\n","Epoch 1 of 5, Step: 5700 of 13750, Training loss: 1.1079553, Training accuracy: 0.6644298, Time: 05_05_2022__16:37:33\n","Epoch 1 of 5, Step: 5800 of 13750, Training loss: 1.0963231, Training accuracy: 0.6682759, Time: 05_05_2022__16:37:54\n","Epoch 1 of 5, Step: 5900 of 13750, Training loss: 1.0854811, Training accuracy: 0.6717373, Time: 05_05_2022__16:38:14\n","Epoch 1 of 5, Step: 6000 of 13750, Training loss: 1.0758904, Training accuracy: 0.6750417, Time: 05_05_2022__16:38:35\n","Epoch 1 of 5, Step: 6100 of 13750, Training loss: 1.0648263, Training accuracy: 0.6788525, Time: 05_05_2022__16:38:56\n","Epoch 1 of 5, Step: 6200 of 13750, Training loss: 1.0549934, Training accuracy: 0.6820968, Time: 05_05_2022__16:39:17\n","Epoch 1 of 5, Step: 6300 of 13750, Training loss: 1.0451947, Training accuracy: 0.6850000, Time: 05_05_2022__16:39:38\n","Epoch 1 of 5, Step: 6400 of 13750, Training loss: 1.0349104, Training accuracy: 0.6879297, Time: 05_05_2022__16:39:59\n","Epoch 1 of 5, Step: 6500 of 13750, Training loss: 1.0249167, Training accuracy: 0.6913077, Time: 05_05_2022__16:40:20\n","Epoch 1 of 5, Step: 6600 of 13750, Training loss: 1.0150349, Training accuracy: 0.6944697, Time: 05_05_2022__16:40:41\n","Epoch 1 of 5, Step: 6700 of 13750, Training loss: 1.0049974, Training accuracy: 0.6976493, Time: 05_05_2022__16:41:02\n","Epoch 1 of 5, Step: 6800 of 13750, Training loss: 0.9951319, Training accuracy: 0.7008088, Time: 05_05_2022__16:41:22\n","Epoch 1 of 5, Step: 6900 of 13750, Training loss: 0.9859444, Training accuracy: 0.7038043, Time: 05_05_2022__16:41:43\n","Epoch 1 of 5, Step: 7000 of 13750, Training loss: 0.9774194, Training accuracy: 0.7065000, Time: 05_05_2022__16:42:04\n","Epoch 1 of 5, Step: 7100 of 13750, Training loss: 0.9694467, Training accuracy: 0.7089789, Time: 05_05_2022__16:42:25\n","Epoch 1 of 5, Step: 7200 of 13750, Training loss: 0.9609402, Training accuracy: 0.7117361, Time: 05_05_2022__16:42:46\n","Epoch 1 of 5, Step: 7300 of 13750, Training loss: 0.9528125, Training accuracy: 0.7143836, Time: 05_05_2022__16:43:07\n","Epoch 1 of 5, Step: 7400 of 13750, Training loss: 0.9444272, Training accuracy: 0.7170946, Time: 05_05_2022__16:43:28\n","Epoch 1 of 5, Step: 7500 of 13750, Training loss: 0.9367416, Training accuracy: 0.7195000, Time: 05_05_2022__16:43:49\n","Epoch 1 of 5, Step: 7600 of 13750, Training loss: 0.9289463, Training accuracy: 0.7219408, Time: 05_05_2022__16:44:10\n","Epoch 1 of 5, Step: 7700 of 13750, Training loss: 0.9209970, Training accuracy: 0.7243506, Time: 05_05_2022__16:44:30\n","Epoch 1 of 5, Step: 7800 of 13750, Training loss: 0.9139053, Training accuracy: 0.7266667, Time: 05_05_2022__16:44:51\n","Epoch 1 of 5, Step: 7900 of 13750, Training loss: 0.9072340, Training accuracy: 0.7286392, Time: 05_05_2022__16:45:12\n","Epoch 1 of 5, Step: 8000 of 13750, Training loss: 0.9000778, Training accuracy: 0.7307813, Time: 05_05_2022__16:45:33\n","Epoch 1 of 5, Step: 8100 of 13750, Training loss: 0.8925234, Training accuracy: 0.7331481, Time: 05_05_2022__16:45:54\n","Epoch 1 of 5, Step: 8200 of 13750, Training loss: 0.8856934, Training accuracy: 0.7352439, Time: 05_05_2022__16:46:15\n","Epoch 1 of 5, Step: 8300 of 13750, Training loss: 0.8789080, Training accuracy: 0.7376205, Time: 05_05_2022__16:46:36\n","Epoch 1 of 5, Step: 8400 of 13750, Training loss: 0.8726943, Training accuracy: 0.7395238, Time: 05_05_2022__16:46:57\n","Epoch 1 of 5, Step: 8500 of 13750, Training loss: 0.8662262, Training accuracy: 0.7416176, Time: 05_05_2022__16:47:17\n","Epoch 1 of 5, Step: 8600 of 13750, Training loss: 0.8599370, Training accuracy: 0.7435174, Time: 05_05_2022__16:47:38\n","Epoch 1 of 5, Step: 8700 of 13750, Training loss: 0.8540337, Training accuracy: 0.7454310, Time: 05_05_2022__16:47:59\n","Epoch 1 of 5, Step: 8800 of 13750, Training loss: 0.8479752, Training accuracy: 0.7472443, Time: 05_05_2022__16:48:20\n","Epoch 1 of 5, Step: 8900 of 13750, Training loss: 0.8416120, Training accuracy: 0.7493539, Time: 05_05_2022__16:48:41\n","Epoch 1 of 5, Step: 9000 of 13750, Training loss: 0.8357927, Training accuracy: 0.7511111, Time: 05_05_2022__16:49:02\n","Epoch 1 of 5, Step: 9100 of 13750, Training loss: 0.8297045, Training accuracy: 0.7530495, Time: 05_05_2022__16:49:23\n","Epoch 1 of 5, Step: 9200 of 13750, Training loss: 0.8244108, Training accuracy: 0.7547283, Time: 05_05_2022__16:49:43\n","Epoch 1 of 5, Step: 9300 of 13750, Training loss: 0.8184721, Training accuracy: 0.7565591, Time: 05_05_2022__16:50:04\n","Epoch 1 of 5, Step: 9400 of 13750, Training loss: 0.8127850, Training accuracy: 0.7583245, Time: 05_05_2022__16:50:25\n","Epoch 1 of 5, Step: 9500 of 13750, Training loss: 0.8070275, Training accuracy: 0.7601316, Time: 05_05_2022__16:50:46\n","Epoch 1 of 5, Step: 9600 of 13750, Training loss: 0.8016000, Training accuracy: 0.7616667, Time: 05_05_2022__16:51:07\n","Epoch 1 of 5, Step: 9700 of 13750, Training loss: 0.7958986, Training accuracy: 0.7634278, Time: 05_05_2022__16:51:28\n","Epoch 1 of 5, Step: 9800 of 13750, Training loss: 0.7905877, Training accuracy: 0.7651020, Time: 05_05_2022__16:51:49\n","Epoch 1 of 5, Step: 9900 of 13750, Training loss: 0.7851525, Training accuracy: 0.7667929, Time: 05_05_2022__16:52:10\n","Epoch 1 of 5, Step: 10000 of 13750, Training loss: 0.7797379, Training accuracy: 0.7683500, Time: 05_05_2022__16:52:31\n","Epoch 1 of 5, Step: 10100 of 13750, Training loss: 0.7748247, Training accuracy: 0.7699752, Time: 05_05_2022__16:52:51\n","Epoch 1 of 5, Step: 10200 of 13750, Training loss: 0.7698819, Training accuracy: 0.7715441, Time: 05_05_2022__16:53:12\n","Epoch 1 of 5, Step: 10300 of 13750, Training loss: 0.7648072, Training accuracy: 0.7732767, Time: 05_05_2022__16:53:33\n","Epoch 1 of 5, Step: 10400 of 13750, Training loss: 0.7601228, Training accuracy: 0.7747115, Time: 05_05_2022__16:53:54\n","Epoch 1 of 5, Step: 10500 of 13750, Training loss: 0.7551776, Training accuracy: 0.7762143, Time: 05_05_2022__16:54:15\n","Epoch 1 of 5, Step: 10600 of 13750, Training loss: 0.7506658, Training accuracy: 0.7775236, Time: 05_05_2022__16:54:36\n","Epoch 1 of 5, Step: 10700 of 13750, Training loss: 0.7462626, Training accuracy: 0.7787383, Time: 05_05_2022__16:54:57\n","Epoch 1 of 5, Step: 10800 of 13750, Training loss: 0.7420336, Training accuracy: 0.7800231, Time: 05_05_2022__16:55:18\n","Epoch 1 of 5, Step: 10900 of 13750, Training loss: 0.7374565, Training accuracy: 0.7813991, Time: 05_05_2022__16:55:38\n","Epoch 1 of 5, Step: 11000 of 13750, Training loss: 0.7326966, Training accuracy: 0.7828409, Time: 05_05_2022__16:55:59\n","Epoch 1 of 5, Step: 11100 of 13750, Training loss: 0.7285896, Training accuracy: 0.7840541, Time: 05_05_2022__16:56:20\n","Epoch 1 of 5, Step: 11200 of 13750, Training loss: 0.7242790, Training accuracy: 0.7853571, Time: 05_05_2022__16:56:41\n","Epoch 1 of 5, Step: 11300 of 13750, Training loss: 0.7197010, Training accuracy: 0.7867478, Time: 05_05_2022__16:57:02\n","Epoch 1 of 5, Step: 11400 of 13750, Training loss: 0.7153863, Training accuracy: 0.7880921, Time: 05_05_2022__16:57:23\n","Epoch 1 of 5, Step: 11500 of 13750, Training loss: 0.7115354, Training accuracy: 0.7892826, Time: 05_05_2022__16:57:44\n","Epoch 1 of 5, Step: 11600 of 13750, Training loss: 0.7073340, Training accuracy: 0.7904957, Time: 05_05_2022__16:58:05\n","Epoch 1 of 5, Step: 11700 of 13750, Training loss: 0.7032576, Training accuracy: 0.7917521, Time: 05_05_2022__16:58:25\n","Epoch 1 of 5, Step: 11800 of 13750, Training loss: 0.6995516, Training accuracy: 0.7927966, Time: 05_05_2022__16:58:46\n","Epoch 1 of 5, Step: 11900 of 13750, Training loss: 0.6957152, Training accuracy: 0.7939496, Time: 05_05_2022__16:59:07\n","Epoch 1 of 5, Step: 12000 of 13750, Training loss: 0.6918953, Training accuracy: 0.7950833, Time: 05_05_2022__16:59:28\n","Epoch 1 of 5, Step: 12100 of 13750, Training loss: 0.6883397, Training accuracy: 0.7959917, Time: 05_05_2022__16:59:49\n","Epoch 1 of 5, Step: 12200 of 13750, Training loss: 0.6849467, Training accuracy: 0.7969262, Time: 05_05_2022__17:00:10\n","Epoch 1 of 5, Step: 12300 of 13750, Training loss: 0.6812517, Training accuracy: 0.7980488, Time: 05_05_2022__17:00:31\n","Epoch 1 of 5, Step: 12400 of 13750, Training loss: 0.6772840, Training accuracy: 0.7992742, Time: 05_05_2022__17:00:52\n","Epoch 1 of 5, Step: 12500 of 13750, Training loss: 0.6740181, Training accuracy: 0.8003400, Time: 05_05_2022__17:01:12\n","Epoch 1 of 5, Step: 12600 of 13750, Training loss: 0.6700858, Training accuracy: 0.8015675, Time: 05_05_2022__17:01:33\n","Epoch 1 of 5, Step: 12700 of 13750, Training loss: 0.6664750, Training accuracy: 0.8026969, Time: 05_05_2022__17:01:54\n","Epoch 1 of 5, Step: 12800 of 13750, Training loss: 0.6629986, Training accuracy: 0.8037305, Time: 05_05_2022__17:02:15\n","Epoch 1 of 5, Step: 12900 of 13750, Training loss: 0.6597869, Training accuracy: 0.8047868, Time: 05_05_2022__17:02:36\n","Epoch 1 of 5, Step: 13000 of 13750, Training loss: 0.6565860, Training accuracy: 0.8057500, Time: 05_05_2022__17:02:57\n","Epoch 1 of 5, Step: 13100 of 13750, Training loss: 0.6538247, Training accuracy: 0.8066221, Time: 05_05_2022__17:03:18\n","Epoch 1 of 5, Step: 13200 of 13750, Training loss: 0.6502537, Training accuracy: 0.8077273, Time: 05_05_2022__17:03:39\n","Epoch 1 of 5, Step: 13300 of 13750, Training loss: 0.6470270, Training accuracy: 0.8087782, Time: 05_05_2022__17:03:59\n","Epoch 1 of 5, Step: 13400 of 13750, Training loss: 0.6437317, Training accuracy: 0.8097948, Time: 05_05_2022__17:04:20\n","Epoch 1 of 5, Step: 13500 of 13750, Training loss: 0.6405703, Training accuracy: 0.8107778, Time: 05_05_2022__17:04:41\n","Epoch 1 of 5, Step: 13600 of 13750, Training loss: 0.6373510, Training accuracy: 0.8117279, Time: 05_05_2022__17:05:02\n","Epoch 1 of 5, Step: 13700 of 13750, Training loss: 0.6340271, Training accuracy: 0.8128102, Time: 05_05_2022__17:05:23\n","Epoch 1 of 5, Average training loss: 0.6324481, Average training accuracy: 0.8132727, Time: 05_05_2022__17:05:34\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06eebef75d1d47f899ee115d42b49eb8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.1455619, Validation accuracy: 0.9500000, Time: 05_05_2022__17:05:39 | Loss decreased from inf to 0.1468250 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.1397559, Validation accuracy: 0.9550000, Time: 05_05_2022__17:05:46 | Loss decreased from 0.1468250 to 0.1402915 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.1519604, Validation accuracy: 0.9550000, Time: 05_05_2022__17:05:54\n","Step: 400 of 1250, Validation loss: 0.1443756, Validation accuracy: 0.9568750, Time: 05_05_2022__17:05:59\n","Step: 500 of 1250, Validation loss: 0.1452402, Validation accuracy: 0.9565000, Time: 05_05_2022__17:06:04\n","Step: 600 of 1250, Validation loss: 0.1383352, Validation accuracy: 0.9591667, Time: 05_05_2022__17:06:09 | Loss decreased from 0.1402915 to 0.1384289 .... Saving the model\n","Step: 700 of 1250, Validation loss: 0.1309118, Validation accuracy: 0.9614286, Time: 05_05_2022__17:06:17 | Loss decreased from 0.1384289 to 0.1295479 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.1358849, Validation accuracy: 0.9603125, Time: 05_05_2022__17:06:24\n","Step: 900 of 1250, Validation loss: 0.1417938, Validation accuracy: 0.9591667, Time: 05_05_2022__17:06:29\n","Step: 1000 of 1250, Validation loss: 0.1465709, Validation accuracy: 0.9592500, Time: 05_05_2022__17:06:35\n","Step: 1100 of 1250, Validation loss: 0.1439593, Validation accuracy: 0.9600000, Time: 05_05_2022__17:06:40\n","Step: 1200 of 1250, Validation loss: 0.1421994, Validation accuracy: 0.9602083, Time: 05_05_2022__17:06:45\n","Average validation loss: 0.1421843, Average validation accuracy: 0.9594000, Time: 05_05_2022__17:06:48\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94106dcff9174189aefc11e139c6084c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 13750, Training loss: 0.1737357, Training accuracy: 0.9500000, Time: 05_05_2022__17:07:09\n","Epoch 2 of 5, Step: 200 of 13750, Training loss: 0.1821334, Training accuracy: 0.9512500, Time: 05_05_2022__17:07:29\n","Epoch 2 of 5, Step: 300 of 13750, Training loss: 0.1954227, Training accuracy: 0.9508333, Time: 05_05_2022__17:07:50\n","Epoch 2 of 5, Step: 400 of 13750, Training loss: 0.1963508, Training accuracy: 0.9481250, Time: 05_05_2022__17:08:11\n","Epoch 2 of 5, Step: 500 of 13750, Training loss: 0.2007212, Training accuracy: 0.9460000, Time: 05_05_2022__17:08:32\n","Epoch 2 of 5, Step: 600 of 13750, Training loss: 0.1963370, Training accuracy: 0.9462500, Time: 05_05_2022__17:08:53\n","Epoch 2 of 5, Step: 700 of 13750, Training loss: 0.2005206, Training accuracy: 0.9432143, Time: 05_05_2022__17:09:14\n","Epoch 2 of 5, Step: 800 of 13750, Training loss: 0.2016928, Training accuracy: 0.9412500, Time: 05_05_2022__17:09:35\n","Epoch 2 of 5, Step: 900 of 13750, Training loss: 0.1981825, Training accuracy: 0.9427778, Time: 05_05_2022__17:09:56\n","Epoch 2 of 5, Step: 1000 of 13750, Training loss: 0.1970387, Training accuracy: 0.9437500, Time: 05_05_2022__17:10:16\n","Epoch 2 of 5, Step: 1100 of 13750, Training loss: 0.1988974, Training accuracy: 0.9422727, Time: 05_05_2022__17:10:37\n","Epoch 2 of 5, Step: 1200 of 13750, Training loss: 0.1984993, Training accuracy: 0.9427083, Time: 05_05_2022__17:10:58\n","Epoch 2 of 5, Step: 1300 of 13750, Training loss: 0.1984446, Training accuracy: 0.9425000, Time: 05_05_2022__17:11:19\n","Epoch 2 of 5, Step: 1400 of 13750, Training loss: 0.1968356, Training accuracy: 0.9426786, Time: 05_05_2022__17:11:40\n","Epoch 2 of 5, Step: 1500 of 13750, Training loss: 0.1952049, Training accuracy: 0.9438333, Time: 05_05_2022__17:12:01\n","Epoch 2 of 5, Step: 1600 of 13750, Training loss: 0.1962090, Training accuracy: 0.9439062, Time: 05_05_2022__17:12:22\n","Epoch 2 of 5, Step: 1700 of 13750, Training loss: 0.1968175, Training accuracy: 0.9441176, Time: 05_05_2022__17:12:43\n","Epoch 2 of 5, Step: 1800 of 13750, Training loss: 0.1949489, Training accuracy: 0.9447222, Time: 05_05_2022__17:13:04\n","Epoch 2 of 5, Step: 1900 of 13750, Training loss: 0.1949409, Training accuracy: 0.9444737, Time: 05_05_2022__17:13:25\n","Epoch 2 of 5, Step: 2000 of 13750, Training loss: 0.1928176, Training accuracy: 0.9453750, Time: 05_05_2022__17:13:45\n","Epoch 2 of 5, Step: 2100 of 13750, Training loss: 0.1916606, Training accuracy: 0.9451190, Time: 05_05_2022__17:14:06\n","Epoch 2 of 5, Step: 2200 of 13750, Training loss: 0.1919484, Training accuracy: 0.9450000, Time: 05_05_2022__17:14:27\n","Epoch 2 of 5, Step: 2300 of 13750, Training loss: 0.1910657, Training accuracy: 0.9458696, Time: 05_05_2022__17:14:48\n","Epoch 2 of 5, Step: 2400 of 13750, Training loss: 0.1920340, Training accuracy: 0.9456250, Time: 05_05_2022__17:15:09\n","Epoch 2 of 5, Step: 2500 of 13750, Training loss: 0.1921120, Training accuracy: 0.9455000, Time: 05_05_2022__17:15:30\n","Epoch 2 of 5, Step: 2600 of 13750, Training loss: 0.1930664, Training accuracy: 0.9449038, Time: 05_05_2022__17:15:51\n","Epoch 2 of 5, Step: 2700 of 13750, Training loss: 0.1922939, Training accuracy: 0.9448148, Time: 05_05_2022__17:16:12\n","Epoch 2 of 5, Step: 2800 of 13750, Training loss: 0.1928837, Training accuracy: 0.9448214, Time: 05_05_2022__17:16:33\n","Epoch 2 of 5, Step: 2900 of 13750, Training loss: 0.1927986, Training accuracy: 0.9451724, Time: 05_05_2022__17:16:53\n","Epoch 2 of 5, Step: 3000 of 13750, Training loss: 0.1918612, Training accuracy: 0.9454167, Time: 05_05_2022__17:17:14\n","Epoch 2 of 5, Step: 3100 of 13750, Training loss: 0.1916960, Training accuracy: 0.9451613, Time: 05_05_2022__17:17:35\n","Epoch 2 of 5, Step: 3200 of 13750, Training loss: 0.1903425, Training accuracy: 0.9457031, Time: 05_05_2022__17:17:56\n","Epoch 2 of 5, Step: 3300 of 13750, Training loss: 0.1894764, Training accuracy: 0.9459091, Time: 05_05_2022__17:18:17\n","Epoch 2 of 5, Step: 3400 of 13750, Training loss: 0.1888058, Training accuracy: 0.9463235, Time: 05_05_2022__17:18:38\n","Epoch 2 of 5, Step: 3500 of 13750, Training loss: 0.1886608, Training accuracy: 0.9461429, Time: 05_05_2022__17:18:59\n","Epoch 2 of 5, Step: 3600 of 13750, Training loss: 0.1887041, Training accuracy: 0.9462500, Time: 05_05_2022__17:19:20\n","Epoch 2 of 5, Step: 3700 of 13750, Training loss: 0.1893523, Training accuracy: 0.9460811, Time: 05_05_2022__17:19:41\n","Epoch 2 of 5, Step: 3800 of 13750, Training loss: 0.1885239, Training accuracy: 0.9464474, Time: 05_05_2022__17:20:02\n","Epoch 2 of 5, Step: 3900 of 13750, Training loss: 0.1885233, Training accuracy: 0.9462821, Time: 05_05_2022__17:20:23\n","Epoch 2 of 5, Step: 4000 of 13750, Training loss: 0.1882436, Training accuracy: 0.9464375, Time: 05_05_2022__17:20:44\n","Epoch 2 of 5, Step: 4100 of 13750, Training loss: 0.1877265, Training accuracy: 0.9464024, Time: 05_05_2022__17:21:04\n","Epoch 2 of 5, Step: 4200 of 13750, Training loss: 0.1885177, Training accuracy: 0.9463690, Time: 05_05_2022__17:21:25\n","Epoch 2 of 5, Step: 4300 of 13750, Training loss: 0.1879135, Training accuracy: 0.9465698, Time: 05_05_2022__17:21:46\n","Epoch 2 of 5, Step: 4400 of 13750, Training loss: 0.1869831, Training accuracy: 0.9469886, Time: 05_05_2022__17:22:07\n","Epoch 2 of 5, Step: 4500 of 13750, Training loss: 0.1858361, Training accuracy: 0.9473333, Time: 05_05_2022__17:22:28\n","Epoch 2 of 5, Step: 4600 of 13750, Training loss: 0.1845316, Training accuracy: 0.9476630, Time: 05_05_2022__17:22:49\n","Epoch 2 of 5, Step: 4700 of 13750, Training loss: 0.1845189, Training accuracy: 0.9474468, Time: 05_05_2022__17:23:10\n","Epoch 2 of 5, Step: 4800 of 13750, Training loss: 0.1847741, Training accuracy: 0.9475521, Time: 05_05_2022__17:23:30\n","Epoch 2 of 5, Step: 4900 of 13750, Training loss: 0.1848159, Training accuracy: 0.9472959, Time: 05_05_2022__17:23:51\n","Epoch 2 of 5, Step: 5000 of 13750, Training loss: 0.1840299, Training accuracy: 0.9475500, Time: 05_05_2022__17:24:12\n","Epoch 2 of 5, Step: 5100 of 13750, Training loss: 0.1833472, Training accuracy: 0.9477451, Time: 05_05_2022__17:24:33\n","Epoch 2 of 5, Step: 5200 of 13750, Training loss: 0.1829155, Training accuracy: 0.9479327, Time: 05_05_2022__17:24:54\n","Epoch 2 of 5, Step: 5300 of 13750, Training loss: 0.1826967, Training accuracy: 0.9480189, Time: 05_05_2022__17:25:15\n","Epoch 2 of 5, Step: 5400 of 13750, Training loss: 0.1822294, Training accuracy: 0.9480093, Time: 05_05_2022__17:25:36\n","Epoch 2 of 5, Step: 5500 of 13750, Training loss: 0.1817054, Training accuracy: 0.9482273, Time: 05_05_2022__17:25:57\n","Epoch 2 of 5, Step: 5600 of 13750, Training loss: 0.1819998, Training accuracy: 0.9480804, Time: 05_05_2022__17:26:17\n","Epoch 2 of 5, Step: 5700 of 13750, Training loss: 0.1823321, Training accuracy: 0.9479386, Time: 05_05_2022__17:26:38\n","Epoch 2 of 5, Step: 5800 of 13750, Training loss: 0.1816340, Training accuracy: 0.9482759, Time: 05_05_2022__17:26:59\n","Epoch 2 of 5, Step: 5900 of 13750, Training loss: 0.1808007, Training accuracy: 0.9486017, Time: 05_05_2022__17:27:20\n","Epoch 2 of 5, Step: 6000 of 13750, Training loss: 0.1806909, Training accuracy: 0.9485000, Time: 05_05_2022__17:27:41\n","Epoch 2 of 5, Step: 6100 of 13750, Training loss: 0.1795982, Training accuracy: 0.9488934, Time: 05_05_2022__17:28:02\n","Epoch 2 of 5, Step: 6200 of 13750, Training loss: 0.1796292, Training accuracy: 0.9488710, Time: 05_05_2022__17:28:23\n","Epoch 2 of 5, Step: 6300 of 13750, Training loss: 0.1797368, Training accuracy: 0.9490079, Time: 05_05_2022__17:28:43\n","Epoch 2 of 5, Step: 6400 of 13750, Training loss: 0.1792607, Training accuracy: 0.9490625, Time: 05_05_2022__17:29:04\n","Epoch 2 of 5, Step: 6500 of 13750, Training loss: 0.1790917, Training accuracy: 0.9491154, Time: 05_05_2022__17:29:25\n","Epoch 2 of 5, Step: 6600 of 13750, Training loss: 0.1786857, Training accuracy: 0.9490152, Time: 05_05_2022__17:29:46\n","Epoch 2 of 5, Step: 6700 of 13750, Training loss: 0.1782311, Training accuracy: 0.9492537, Time: 05_05_2022__17:30:07\n","Epoch 2 of 5, Step: 6800 of 13750, Training loss: 0.1775817, Training accuracy: 0.9494485, Time: 05_05_2022__17:30:28\n","Epoch 2 of 5, Step: 6900 of 13750, Training loss: 0.1770994, Training accuracy: 0.9495290, Time: 05_05_2022__17:30:49\n","Epoch 2 of 5, Step: 7000 of 13750, Training loss: 0.1769757, Training accuracy: 0.9496071, Time: 05_05_2022__17:31:10\n","Epoch 2 of 5, Step: 7100 of 13750, Training loss: 0.1767602, Training accuracy: 0.9496831, Time: 05_05_2022__17:31:30\n","Epoch 2 of 5, Step: 7200 of 13750, Training loss: 0.1766087, Training accuracy: 0.9497222, Time: 05_05_2022__17:31:51\n","Epoch 2 of 5, Step: 7300 of 13750, Training loss: 0.1762106, Training accuracy: 0.9498630, Time: 05_05_2022__17:32:12\n","Epoch 2 of 5, Step: 7400 of 13750, Training loss: 0.1756253, Training accuracy: 0.9501351, Time: 05_05_2022__17:32:33\n","Epoch 2 of 5, Step: 7500 of 13750, Training loss: 0.1755270, Training accuracy: 0.9503000, Time: 05_05_2022__17:32:54\n","Epoch 2 of 5, Step: 7600 of 13750, Training loss: 0.1755004, Training accuracy: 0.9502632, Time: 05_05_2022__17:33:15\n","Epoch 2 of 5, Step: 7700 of 13750, Training loss: 0.1747293, Training accuracy: 0.9504870, Time: 05_05_2022__17:33:36\n","Epoch 2 of 5, Step: 7800 of 13750, Training loss: 0.1745650, Training accuracy: 0.9504487, Time: 05_05_2022__17:33:57\n","Epoch 2 of 5, Step: 7900 of 13750, Training loss: 0.1745557, Training accuracy: 0.9502848, Time: 05_05_2022__17:34:17\n","Epoch 2 of 5, Step: 8000 of 13750, Training loss: 0.1746300, Training accuracy: 0.9502500, Time: 05_05_2022__17:34:38\n","Epoch 2 of 5, Step: 8100 of 13750, Training loss: 0.1737549, Training accuracy: 0.9505247, Time: 05_05_2022__17:34:59\n","Epoch 2 of 5, Step: 8200 of 13750, Training loss: 0.1733418, Training accuracy: 0.9506098, Time: 05_05_2022__17:35:20\n","Epoch 2 of 5, Step: 8300 of 13750, Training loss: 0.1739451, Training accuracy: 0.9504217, Time: 05_05_2022__17:35:41\n","Epoch 2 of 5, Step: 8400 of 13750, Training loss: 0.1737923, Training accuracy: 0.9505357, Time: 05_05_2022__17:36:02\n","Epoch 2 of 5, Step: 8500 of 13750, Training loss: 0.1732805, Training accuracy: 0.9506471, Time: 05_05_2022__17:36:23\n","Epoch 2 of 5, Step: 8600 of 13750, Training loss: 0.1727984, Training accuracy: 0.9508140, Time: 05_05_2022__17:36:44\n","Epoch 2 of 5, Step: 8700 of 13750, Training loss: 0.1725317, Training accuracy: 0.9509483, Time: 05_05_2022__17:37:04\n","Epoch 2 of 5, Step: 8800 of 13750, Training loss: 0.1727322, Training accuracy: 0.9509375, Time: 05_05_2022__17:37:25\n","Epoch 2 of 5, Step: 8900 of 13750, Training loss: 0.1722891, Training accuracy: 0.9511236, Time: 05_05_2022__17:37:46\n","Epoch 2 of 5, Step: 9000 of 13750, Training loss: 0.1722488, Training accuracy: 0.9509722, Time: 05_05_2022__17:38:07\n","Epoch 2 of 5, Step: 9100 of 13750, Training loss: 0.1721745, Training accuracy: 0.9509890, Time: 05_05_2022__17:38:28\n","Epoch 2 of 5, Step: 9200 of 13750, Training loss: 0.1724414, Training accuracy: 0.9507880, Time: 05_05_2022__17:38:49\n","Epoch 2 of 5, Step: 9300 of 13750, Training loss: 0.1721005, Training accuracy: 0.9509140, Time: 05_05_2022__17:39:10\n","Epoch 2 of 5, Step: 9400 of 13750, Training loss: 0.1720500, Training accuracy: 0.9508511, Time: 05_05_2022__17:39:30\n","Epoch 2 of 5, Step: 9500 of 13750, Training loss: 0.1716685, Training accuracy: 0.9509737, Time: 05_05_2022__17:39:51\n","Epoch 2 of 5, Step: 9600 of 13750, Training loss: 0.1713956, Training accuracy: 0.9509115, Time: 05_05_2022__17:40:12\n","Epoch 2 of 5, Step: 9700 of 13750, Training loss: 0.1708961, Training accuracy: 0.9509794, Time: 05_05_2022__17:40:33\n","Epoch 2 of 5, Step: 9800 of 13750, Training loss: 0.1707797, Training accuracy: 0.9509694, Time: 05_05_2022__17:40:54\n","Epoch 2 of 5, Step: 9900 of 13750, Training loss: 0.1703320, Training accuracy: 0.9511364, Time: 05_05_2022__17:41:15\n","Epoch 2 of 5, Step: 10000 of 13750, Training loss: 0.1697232, Training accuracy: 0.9513750, Time: 05_05_2022__17:41:36\n","Epoch 2 of 5, Step: 10100 of 13750, Training loss: 0.1696328, Training accuracy: 0.9515099, Time: 05_05_2022__17:41:57\n","Epoch 2 of 5, Step: 10200 of 13750, Training loss: 0.1690287, Training accuracy: 0.9517647, Time: 05_05_2022__17:42:17\n","Epoch 2 of 5, Step: 10300 of 13750, Training loss: 0.1685408, Training accuracy: 0.9519660, Time: 05_05_2022__17:42:38\n","Epoch 2 of 5, Step: 10400 of 13750, Training loss: 0.1681687, Training accuracy: 0.9520433, Time: 05_05_2022__17:42:59\n","Epoch 2 of 5, Step: 10500 of 13750, Training loss: 0.1678099, Training accuracy: 0.9522143, Time: 05_05_2022__17:43:20\n","Epoch 2 of 5, Step: 10600 of 13750, Training loss: 0.1675851, Training accuracy: 0.9522170, Time: 05_05_2022__17:43:41\n","Epoch 2 of 5, Step: 10700 of 13750, Training loss: 0.1674542, Training accuracy: 0.9521495, Time: 05_05_2022__17:44:02\n","Epoch 2 of 5, Step: 10800 of 13750, Training loss: 0.1672672, Training accuracy: 0.9521296, Time: 05_05_2022__17:44:23\n","Epoch 2 of 5, Step: 10900 of 13750, Training loss: 0.1670596, Training accuracy: 0.9521330, Time: 05_05_2022__17:44:43\n","Epoch 2 of 5, Step: 11000 of 13750, Training loss: 0.1665040, Training accuracy: 0.9523409, Time: 05_05_2022__17:45:04\n","Epoch 2 of 5, Step: 11100 of 13750, Training loss: 0.1662778, Training accuracy: 0.9523423, Time: 05_05_2022__17:45:25\n","Epoch 2 of 5, Step: 11200 of 13750, Training loss: 0.1658302, Training accuracy: 0.9524554, Time: 05_05_2022__17:45:46\n","Epoch 2 of 5, Step: 11300 of 13750, Training loss: 0.1656581, Training accuracy: 0.9524336, Time: 05_05_2022__17:46:07\n","Epoch 2 of 5, Step: 11400 of 13750, Training loss: 0.1651711, Training accuracy: 0.9526096, Time: 05_05_2022__17:46:28\n","Epoch 2 of 5, Step: 11500 of 13750, Training loss: 0.1651775, Training accuracy: 0.9527174, Time: 05_05_2022__17:46:49\n","Epoch 2 of 5, Step: 11600 of 13750, Training loss: 0.1649636, Training accuracy: 0.9528233, Time: 05_05_2022__17:47:10\n","Epoch 2 of 5, Step: 11700 of 13750, Training loss: 0.1644375, Training accuracy: 0.9529701, Time: 05_05_2022__17:47:31\n","Epoch 2 of 5, Step: 11800 of 13750, Training loss: 0.1643082, Training accuracy: 0.9529661, Time: 05_05_2022__17:47:51\n","Epoch 2 of 5, Step: 11900 of 13750, Training loss: 0.1640930, Training accuracy: 0.9530042, Time: 05_05_2022__17:48:12\n","Epoch 2 of 5, Step: 12000 of 13750, Training loss: 0.1635294, Training accuracy: 0.9531667, Time: 05_05_2022__17:48:33\n","Epoch 2 of 5, Step: 12100 of 13750, Training loss: 0.1632320, Training accuracy: 0.9532231, Time: 05_05_2022__17:48:54\n","Epoch 2 of 5, Step: 12200 of 13750, Training loss: 0.1630884, Training accuracy: 0.9532377, Time: 05_05_2022__17:49:15\n","Epoch 2 of 5, Step: 12300 of 13750, Training loss: 0.1625791, Training accuracy: 0.9533740, Time: 05_05_2022__17:49:36\n","Epoch 2 of 5, Step: 12400 of 13750, Training loss: 0.1620627, Training accuracy: 0.9535081, Time: 05_05_2022__17:49:57\n","Epoch 2 of 5, Step: 12500 of 13750, Training loss: 0.1618727, Training accuracy: 0.9534800, Time: 05_05_2022__17:50:18\n","Epoch 2 of 5, Step: 12600 of 13750, Training loss: 0.1613002, Training accuracy: 0.9536111, Time: 05_05_2022__17:50:39\n","Epoch 2 of 5, Step: 12700 of 13750, Training loss: 0.1610600, Training accuracy: 0.9536614, Time: 05_05_2022__17:50:59\n","Epoch 2 of 5, Step: 12800 of 13750, Training loss: 0.1608440, Training accuracy: 0.9536914, Time: 05_05_2022__17:51:20\n","Epoch 2 of 5, Step: 12900 of 13750, Training loss: 0.1609001, Training accuracy: 0.9536822, Time: 05_05_2022__17:51:41\n","Epoch 2 of 5, Step: 13000 of 13750, Training loss: 0.1606049, Training accuracy: 0.9537692, Time: 05_05_2022__17:52:02\n","Epoch 2 of 5, Step: 13100 of 13750, Training loss: 0.1607124, Training accuracy: 0.9536832, Time: 05_05_2022__17:52:23\n","Epoch 2 of 5, Step: 13200 of 13750, Training loss: 0.1604338, Training accuracy: 0.9537689, Time: 05_05_2022__17:52:44\n","Epoch 2 of 5, Step: 13300 of 13750, Training loss: 0.1601953, Training accuracy: 0.9538534, Time: 05_05_2022__17:53:05\n","Epoch 2 of 5, Step: 13400 of 13750, Training loss: 0.1601253, Training accuracy: 0.9538246, Time: 05_05_2022__17:53:26\n","Epoch 2 of 5, Step: 13500 of 13750, Training loss: 0.1597818, Training accuracy: 0.9539444, Time: 05_05_2022__17:53:46\n","Epoch 2 of 5, Step: 13600 of 13750, Training loss: 0.1593891, Training accuracy: 0.9540993, Time: 05_05_2022__17:54:07\n","Epoch 2 of 5, Step: 13700 of 13750, Training loss: 0.1589252, Training accuracy: 0.9542336, Time: 05_05_2022__17:54:28\n","Epoch 2 of 5, Average training loss: 0.1588410, Average training accuracy: 0.9542364, Time: 05_05_2022__17:54:39\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bc8fd38c05a4b889f6a25b521591fc2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0931927, Validation accuracy: 0.9675000, Time: 05_05_2022__17:54:44 | Loss decreased from 0.1295479 to 0.0941088 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0874427, Validation accuracy: 0.9687500, Time: 05_05_2022__17:54:51 | Loss decreased from 0.0941088 to 0.0878582 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.0905042, Validation accuracy: 0.9725000, Time: 05_05_2022__17:54:59\n","Step: 400 of 1250, Validation loss: 0.0843265, Validation accuracy: 0.9743750, Time: 05_05_2022__17:55:04 | Loss decreased from 0.0878582 to 0.0842953 .... Saving the model\n","Step: 500 of 1250, Validation loss: 0.0848072, Validation accuracy: 0.9730000, Time: 05_05_2022__17:55:11\n","Step: 600 of 1250, Validation loss: 0.0807402, Validation accuracy: 0.9741667, Time: 05_05_2022__17:55:16 | Loss decreased from 0.0842953 to 0.0808348 .... Saving the model\n","Step: 700 of 1250, Validation loss: 0.0775320, Validation accuracy: 0.9746429, Time: 05_05_2022__17:55:24 | Loss decreased from 0.0808348 to 0.0763621 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0799948, Validation accuracy: 0.9746875, Time: 05_05_2022__17:55:31\n","Step: 900 of 1250, Validation loss: 0.0818528, Validation accuracy: 0.9744444, Time: 05_05_2022__17:55:36\n","Step: 1000 of 1250, Validation loss: 0.0851867, Validation accuracy: 0.9742500, Time: 05_05_2022__17:55:42\n","Step: 1100 of 1250, Validation loss: 0.0831807, Validation accuracy: 0.9747727, Time: 05_05_2022__17:55:47\n","Step: 1200 of 1250, Validation loss: 0.0833751, Validation accuracy: 0.9745833, Time: 05_05_2022__17:55:52\n","Average validation loss: 0.0833368, Average validation accuracy: 0.9748000, Time: 05_05_2022__17:55:55\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c46a71e0bc941e1968d8443f3f68dc4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 13750, Training loss: 0.1060701, Training accuracy: 0.9725000, Time: 05_05_2022__17:56:16\n","Epoch 3 of 5, Step: 200 of 13750, Training loss: 0.1061743, Training accuracy: 0.9675000, Time: 05_05_2022__17:56:37\n","Epoch 3 of 5, Step: 300 of 13750, Training loss: 0.1163881, Training accuracy: 0.9650000, Time: 05_05_2022__17:56:57\n","Epoch 3 of 5, Step: 400 of 13750, Training loss: 0.1125225, Training accuracy: 0.9662500, Time: 05_05_2022__17:57:18\n","Epoch 3 of 5, Step: 500 of 13750, Training loss: 0.1159376, Training accuracy: 0.9640000, Time: 05_05_2022__17:57:39\n","Epoch 3 of 5, Step: 600 of 13750, Training loss: 0.1210320, Training accuracy: 0.9637500, Time: 05_05_2022__17:58:00\n","Epoch 3 of 5, Step: 700 of 13750, Training loss: 0.1239852, Training accuracy: 0.9635714, Time: 05_05_2022__17:58:21\n","Epoch 3 of 5, Step: 800 of 13750, Training loss: 0.1228617, Training accuracy: 0.9640625, Time: 05_05_2022__17:58:42\n","Epoch 3 of 5, Step: 900 of 13750, Training loss: 0.1271631, Training accuracy: 0.9633333, Time: 05_05_2022__17:59:03\n","Epoch 3 of 5, Step: 1000 of 13750, Training loss: 0.1267594, Training accuracy: 0.9640000, Time: 05_05_2022__17:59:24\n","Epoch 3 of 5, Step: 1100 of 13750, Training loss: 0.1292508, Training accuracy: 0.9625000, Time: 05_05_2022__17:59:44\n","Epoch 3 of 5, Step: 1200 of 13750, Training loss: 0.1293676, Training accuracy: 0.9629167, Time: 05_05_2022__18:00:05\n","Epoch 3 of 5, Step: 1300 of 13750, Training loss: 0.1280126, Training accuracy: 0.9636538, Time: 05_05_2022__18:00:26\n","Epoch 3 of 5, Step: 1400 of 13750, Training loss: 0.1276198, Training accuracy: 0.9632143, Time: 05_05_2022__18:00:47\n","Epoch 3 of 5, Step: 1500 of 13750, Training loss: 0.1285661, Training accuracy: 0.9621667, Time: 05_05_2022__18:01:08\n","Epoch 3 of 5, Step: 1600 of 13750, Training loss: 0.1286720, Training accuracy: 0.9617187, Time: 05_05_2022__18:01:29\n","Epoch 3 of 5, Step: 1700 of 13750, Training loss: 0.1272082, Training accuracy: 0.9617647, Time: 05_05_2022__18:01:50\n","Epoch 3 of 5, Step: 1800 of 13750, Training loss: 0.1262954, Training accuracy: 0.9620833, Time: 05_05_2022__18:02:11\n","Epoch 3 of 5, Step: 1900 of 13750, Training loss: 0.1249529, Training accuracy: 0.9628947, Time: 05_05_2022__18:02:32\n","Epoch 3 of 5, Step: 2000 of 13750, Training loss: 0.1228492, Training accuracy: 0.9635000, Time: 05_05_2022__18:02:52\n","Epoch 3 of 5, Step: 2100 of 13750, Training loss: 0.1205660, Training accuracy: 0.9642857, Time: 05_05_2022__18:03:13\n","Epoch 3 of 5, Step: 2200 of 13750, Training loss: 0.1207695, Training accuracy: 0.9643182, Time: 05_05_2022__18:03:34\n","Epoch 3 of 5, Step: 2300 of 13750, Training loss: 0.1203872, Training accuracy: 0.9647826, Time: 05_05_2022__18:03:55\n","Epoch 3 of 5, Step: 2400 of 13750, Training loss: 0.1216993, Training accuracy: 0.9644792, Time: 05_05_2022__18:04:16\n","Epoch 3 of 5, Step: 2500 of 13750, Training loss: 0.1211252, Training accuracy: 0.9645000, Time: 05_05_2022__18:04:37\n","Epoch 3 of 5, Step: 2600 of 13750, Training loss: 0.1216594, Training accuracy: 0.9642308, Time: 05_05_2022__18:04:58\n","Epoch 3 of 5, Step: 2700 of 13750, Training loss: 0.1210379, Training accuracy: 0.9643519, Time: 05_05_2022__18:05:19\n","Epoch 3 of 5, Step: 2800 of 13750, Training loss: 0.1214972, Training accuracy: 0.9637500, Time: 05_05_2022__18:05:39\n","Epoch 3 of 5, Step: 2900 of 13750, Training loss: 0.1220413, Training accuracy: 0.9633621, Time: 05_05_2022__18:06:00\n","Epoch 3 of 5, Step: 3000 of 13750, Training loss: 0.1213332, Training accuracy: 0.9634167, Time: 05_05_2022__18:06:21\n","Epoch 3 of 5, Step: 3100 of 13750, Training loss: 0.1217220, Training accuracy: 0.9634677, Time: 05_05_2022__18:06:42\n","Epoch 3 of 5, Step: 3200 of 13750, Training loss: 0.1214396, Training accuracy: 0.9635938, Time: 05_05_2022__18:07:03\n","Epoch 3 of 5, Step: 3300 of 13750, Training loss: 0.1215735, Training accuracy: 0.9636364, Time: 05_05_2022__18:07:24\n","Epoch 3 of 5, Step: 3400 of 13750, Training loss: 0.1205846, Training accuracy: 0.9641176, Time: 05_05_2022__18:07:45\n","Epoch 3 of 5, Step: 3500 of 13750, Training loss: 0.1202128, Training accuracy: 0.9639286, Time: 05_05_2022__18:08:06\n","Epoch 3 of 5, Step: 3600 of 13750, Training loss: 0.1194368, Training accuracy: 0.9640972, Time: 05_05_2022__18:08:26\n","Epoch 3 of 5, Step: 3700 of 13750, Training loss: 0.1195327, Training accuracy: 0.9639189, Time: 05_05_2022__18:08:47\n","Epoch 3 of 5, Step: 3800 of 13750, Training loss: 0.1198896, Training accuracy: 0.9635526, Time: 05_05_2022__18:09:08\n","Epoch 3 of 5, Step: 3900 of 13750, Training loss: 0.1204461, Training accuracy: 0.9633974, Time: 05_05_2022__18:09:29\n","Epoch 3 of 5, Step: 4000 of 13750, Training loss: 0.1204831, Training accuracy: 0.9635000, Time: 05_05_2022__18:09:50\n","Epoch 3 of 5, Step: 4100 of 13750, Training loss: 0.1201421, Training accuracy: 0.9636585, Time: 05_05_2022__18:10:11\n","Epoch 3 of 5, Step: 4200 of 13750, Training loss: 0.1220397, Training accuracy: 0.9632738, Time: 05_05_2022__18:10:32\n","Epoch 3 of 5, Step: 4300 of 13750, Training loss: 0.1219778, Training accuracy: 0.9633721, Time: 05_05_2022__18:10:53\n","Epoch 3 of 5, Step: 4400 of 13750, Training loss: 0.1218542, Training accuracy: 0.9635227, Time: 05_05_2022__18:11:14\n","Epoch 3 of 5, Step: 4500 of 13750, Training loss: 0.1209067, Training accuracy: 0.9638333, Time: 05_05_2022__18:11:34\n","Epoch 3 of 5, Step: 4600 of 13750, Training loss: 0.1200326, Training accuracy: 0.9641304, Time: 05_05_2022__18:11:55\n","Epoch 3 of 5, Step: 4700 of 13750, Training loss: 0.1203292, Training accuracy: 0.9639362, Time: 05_05_2022__18:12:16\n","Epoch 3 of 5, Step: 4800 of 13750, Training loss: 0.1206432, Training accuracy: 0.9639062, Time: 05_05_2022__18:12:37\n","Epoch 3 of 5, Step: 4900 of 13750, Training loss: 0.1213229, Training accuracy: 0.9636735, Time: 05_05_2022__18:12:58\n","Epoch 3 of 5, Step: 5000 of 13750, Training loss: 0.1211945, Training accuracy: 0.9636000, Time: 05_05_2022__18:13:19\n","Epoch 3 of 5, Step: 5100 of 13750, Training loss: 0.1207259, Training accuracy: 0.9638725, Time: 05_05_2022__18:13:40\n","Epoch 3 of 5, Step: 5200 of 13750, Training loss: 0.1205955, Training accuracy: 0.9640385, Time: 05_05_2022__18:14:01\n","Epoch 3 of 5, Step: 5300 of 13750, Training loss: 0.1206323, Training accuracy: 0.9639623, Time: 05_05_2022__18:14:21\n","Epoch 3 of 5, Step: 5400 of 13750, Training loss: 0.1205337, Training accuracy: 0.9640741, Time: 05_05_2022__18:14:42\n","Epoch 3 of 5, Step: 5500 of 13750, Training loss: 0.1202474, Training accuracy: 0.9640909, Time: 05_05_2022__18:15:03\n","Epoch 3 of 5, Step: 5600 of 13750, Training loss: 0.1207063, Training accuracy: 0.9638393, Time: 05_05_2022__18:15:24\n","Epoch 3 of 5, Step: 5700 of 13750, Training loss: 0.1210955, Training accuracy: 0.9635088, Time: 05_05_2022__18:15:45\n","Epoch 3 of 5, Step: 5800 of 13750, Training loss: 0.1206765, Training accuracy: 0.9635345, Time: 05_05_2022__18:16:06\n","Epoch 3 of 5, Step: 5900 of 13750, Training loss: 0.1202203, Training accuracy: 0.9636441, Time: 05_05_2022__18:16:27\n","Epoch 3 of 5, Step: 6000 of 13750, Training loss: 0.1208709, Training accuracy: 0.9633333, Time: 05_05_2022__18:16:48\n","Epoch 3 of 5, Step: 6100 of 13750, Training loss: 0.1203797, Training accuracy: 0.9635246, Time: 05_05_2022__18:17:09\n","Epoch 3 of 5, Step: 6200 of 13750, Training loss: 0.1203078, Training accuracy: 0.9635081, Time: 05_05_2022__18:17:29\n","Epoch 3 of 5, Step: 6300 of 13750, Training loss: 0.1206721, Training accuracy: 0.9633730, Time: 05_05_2022__18:17:50\n","Epoch 3 of 5, Step: 6400 of 13750, Training loss: 0.1201435, Training accuracy: 0.9635938, Time: 05_05_2022__18:18:11\n","Epoch 3 of 5, Step: 6500 of 13750, Training loss: 0.1203576, Training accuracy: 0.9633462, Time: 05_05_2022__18:18:32\n","Epoch 3 of 5, Step: 6600 of 13750, Training loss: 0.1199128, Training accuracy: 0.9635227, Time: 05_05_2022__18:18:53\n","Epoch 3 of 5, Step: 6700 of 13750, Training loss: 0.1192743, Training accuracy: 0.9637313, Time: 05_05_2022__18:19:14\n","Epoch 3 of 5, Step: 6800 of 13750, Training loss: 0.1187761, Training accuracy: 0.9638235, Time: 05_05_2022__18:19:35\n","Epoch 3 of 5, Step: 6900 of 13750, Training loss: 0.1184712, Training accuracy: 0.9639855, Time: 05_05_2022__18:19:56\n","Epoch 3 of 5, Step: 7000 of 13750, Training loss: 0.1182516, Training accuracy: 0.9640357, Time: 05_05_2022__18:20:16\n","Epoch 3 of 5, Step: 7100 of 13750, Training loss: 0.1181370, Training accuracy: 0.9641901, Time: 05_05_2022__18:20:37\n","Epoch 3 of 5, Step: 7200 of 13750, Training loss: 0.1182709, Training accuracy: 0.9642361, Time: 05_05_2022__18:20:58\n","Epoch 3 of 5, Step: 7300 of 13750, Training loss: 0.1177459, Training accuracy: 0.9645890, Time: 05_05_2022__18:21:19\n","Epoch 3 of 5, Step: 7400 of 13750, Training loss: 0.1177994, Training accuracy: 0.9645270, Time: 05_05_2022__18:21:40\n","Epoch 3 of 5, Step: 7500 of 13750, Training loss: 0.1178569, Training accuracy: 0.9646333, Time: 05_05_2022__18:22:01\n","Epoch 3 of 5, Step: 7600 of 13750, Training loss: 0.1180002, Training accuracy: 0.9645066, Time: 05_05_2022__18:22:22\n","Epoch 3 of 5, Step: 7700 of 13750, Training loss: 0.1175804, Training accuracy: 0.9646753, Time: 05_05_2022__18:22:43\n","Epoch 3 of 5, Step: 7800 of 13750, Training loss: 0.1172327, Training accuracy: 0.9648077, Time: 05_05_2022__18:23:04\n","Epoch 3 of 5, Step: 7900 of 13750, Training loss: 0.1174133, Training accuracy: 0.9646519, Time: 05_05_2022__18:23:24\n","Epoch 3 of 5, Step: 8000 of 13750, Training loss: 0.1171781, Training accuracy: 0.9647813, Time: 05_05_2022__18:23:45\n","Epoch 3 of 5, Step: 8100 of 13750, Training loss: 0.1165839, Training accuracy: 0.9649691, Time: 05_05_2022__18:24:06\n","Epoch 3 of 5, Step: 8200 of 13750, Training loss: 0.1162487, Training accuracy: 0.9651220, Time: 05_05_2022__18:24:27\n","Epoch 3 of 5, Step: 8300 of 13750, Training loss: 0.1169552, Training accuracy: 0.9649398, Time: 05_05_2022__18:24:48\n","Epoch 3 of 5, Step: 8400 of 13750, Training loss: 0.1169890, Training accuracy: 0.9647619, Time: 05_05_2022__18:25:09\n","Epoch 3 of 5, Step: 8500 of 13750, Training loss: 0.1167730, Training accuracy: 0.9648235, Time: 05_05_2022__18:25:30\n","Epoch 3 of 5, Step: 8600 of 13750, Training loss: 0.1163589, Training accuracy: 0.9649709, Time: 05_05_2022__18:25:51\n","Epoch 3 of 5, Step: 8700 of 13750, Training loss: 0.1159288, Training accuracy: 0.9651724, Time: 05_05_2022__18:26:12\n","Epoch 3 of 5, Step: 8800 of 13750, Training loss: 0.1164757, Training accuracy: 0.9650284, Time: 05_05_2022__18:26:32\n","Epoch 3 of 5, Step: 8900 of 13750, Training loss: 0.1159770, Training accuracy: 0.9652247, Time: 05_05_2022__18:26:53\n","Epoch 3 of 5, Step: 9000 of 13750, Training loss: 0.1160091, Training accuracy: 0.9652222, Time: 05_05_2022__18:27:14\n","Epoch 3 of 5, Step: 9100 of 13750, Training loss: 0.1159753, Training accuracy: 0.9652473, Time: 05_05_2022__18:27:35\n","Epoch 3 of 5, Step: 9200 of 13750, Training loss: 0.1159912, Training accuracy: 0.9650815, Time: 05_05_2022__18:27:56\n","Epoch 3 of 5, Step: 9300 of 13750, Training loss: 0.1159044, Training accuracy: 0.9651075, Time: 05_05_2022__18:28:17\n","Epoch 3 of 5, Step: 9400 of 13750, Training loss: 0.1161610, Training accuracy: 0.9650000, Time: 05_05_2022__18:28:38\n","Epoch 3 of 5, Step: 9500 of 13750, Training loss: 0.1160307, Training accuracy: 0.9650000, Time: 05_05_2022__18:28:59\n","Epoch 3 of 5, Step: 9600 of 13750, Training loss: 0.1159519, Training accuracy: 0.9649740, Time: 05_05_2022__18:29:19\n","Epoch 3 of 5, Step: 9700 of 13750, Training loss: 0.1156212, Training accuracy: 0.9651031, Time: 05_05_2022__18:29:40\n","Epoch 3 of 5, Step: 9800 of 13750, Training loss: 0.1154763, Training accuracy: 0.9651786, Time: 05_05_2022__18:30:01\n","Epoch 3 of 5, Step: 9900 of 13750, Training loss: 0.1152716, Training accuracy: 0.9652525, Time: 05_05_2022__18:30:22\n","Epoch 3 of 5, Step: 10000 of 13750, Training loss: 0.1150749, Training accuracy: 0.9653250, Time: 05_05_2022__18:30:43\n","Epoch 3 of 5, Step: 10100 of 13750, Training loss: 0.1154482, Training accuracy: 0.9653465, Time: 05_05_2022__18:31:04\n","Epoch 3 of 5, Step: 10200 of 13750, Training loss: 0.1153222, Training accuracy: 0.9654412, Time: 05_05_2022__18:31:25\n","Epoch 3 of 5, Step: 10300 of 13750, Training loss: 0.1148627, Training accuracy: 0.9656553, Time: 05_05_2022__18:31:46\n","Epoch 3 of 5, Step: 10400 of 13750, Training loss: 0.1148478, Training accuracy: 0.9656490, Time: 05_05_2022__18:32:07\n","Epoch 3 of 5, Step: 10500 of 13750, Training loss: 0.1146352, Training accuracy: 0.9656905, Time: 05_05_2022__18:32:28\n","Epoch 3 of 5, Step: 10600 of 13750, Training loss: 0.1144700, Training accuracy: 0.9658255, Time: 05_05_2022__18:32:48\n","Epoch 3 of 5, Step: 10700 of 13750, Training loss: 0.1141870, Training accuracy: 0.9659112, Time: 05_05_2022__18:33:09\n","Epoch 3 of 5, Step: 10800 of 13750, Training loss: 0.1143799, Training accuracy: 0.9657870, Time: 05_05_2022__18:33:30\n","Epoch 3 of 5, Step: 10900 of 13750, Training loss: 0.1144212, Training accuracy: 0.9657798, Time: 05_05_2022__18:33:51\n","Epoch 3 of 5, Step: 11000 of 13750, Training loss: 0.1141659, Training accuracy: 0.9658864, Time: 05_05_2022__18:34:12\n","Epoch 3 of 5, Step: 11100 of 13750, Training loss: 0.1140473, Training accuracy: 0.9658333, Time: 05_05_2022__18:34:33\n","Epoch 3 of 5, Step: 11200 of 13750, Training loss: 0.1139122, Training accuracy: 0.9659152, Time: 05_05_2022__18:34:54\n","Epoch 3 of 5, Step: 11300 of 13750, Training loss: 0.1138091, Training accuracy: 0.9658850, Time: 05_05_2022__18:35:15\n","Epoch 3 of 5, Step: 11400 of 13750, Training loss: 0.1136486, Training accuracy: 0.9658772, Time: 05_05_2022__18:35:36\n","Epoch 3 of 5, Step: 11500 of 13750, Training loss: 0.1139440, Training accuracy: 0.9658043, Time: 05_05_2022__18:35:56\n","Epoch 3 of 5, Step: 11600 of 13750, Training loss: 0.1137239, Training accuracy: 0.9658836, Time: 05_05_2022__18:36:17\n","Epoch 3 of 5, Step: 11700 of 13750, Training loss: 0.1134527, Training accuracy: 0.9659829, Time: 05_05_2022__18:36:38\n","Epoch 3 of 5, Step: 11800 of 13750, Training loss: 0.1135725, Training accuracy: 0.9659322, Time: 05_05_2022__18:36:59\n","Epoch 3 of 5, Step: 11900 of 13750, Training loss: 0.1135614, Training accuracy: 0.9660084, Time: 05_05_2022__18:37:20\n","Epoch 3 of 5, Step: 12000 of 13750, Training loss: 0.1132983, Training accuracy: 0.9660625, Time: 05_05_2022__18:37:41\n","Epoch 3 of 5, Step: 12100 of 13750, Training loss: 0.1132466, Training accuracy: 0.9660744, Time: 05_05_2022__18:38:02\n","Epoch 3 of 5, Step: 12200 of 13750, Training loss: 0.1131984, Training accuracy: 0.9661066, Time: 05_05_2022__18:38:23\n","Epoch 3 of 5, Step: 12300 of 13750, Training loss: 0.1128795, Training accuracy: 0.9662602, Time: 05_05_2022__18:38:44\n","Epoch 3 of 5, Step: 12400 of 13750, Training loss: 0.1125518, Training accuracy: 0.9664113, Time: 05_05_2022__18:39:04\n","Epoch 3 of 5, Step: 12500 of 13750, Training loss: 0.1125500, Training accuracy: 0.9663800, Time: 05_05_2022__18:39:25\n","Epoch 3 of 5, Step: 12600 of 13750, Training loss: 0.1124410, Training accuracy: 0.9664087, Time: 05_05_2022__18:39:46\n","Epoch 3 of 5, Step: 12700 of 13750, Training loss: 0.1125037, Training accuracy: 0.9663976, Time: 05_05_2022__18:40:07\n","Epoch 3 of 5, Step: 12800 of 13750, Training loss: 0.1123987, Training accuracy: 0.9663867, Time: 05_05_2022__18:40:28\n","Epoch 3 of 5, Step: 12900 of 13750, Training loss: 0.1125135, Training accuracy: 0.9663372, Time: 05_05_2022__18:40:49\n","Epoch 3 of 5, Step: 13000 of 13750, Training loss: 0.1123495, Training accuracy: 0.9664231, Time: 05_05_2022__18:41:10\n","Epoch 3 of 5, Step: 13100 of 13750, Training loss: 0.1124894, Training accuracy: 0.9663931, Time: 05_05_2022__18:41:31\n","Epoch 3 of 5, Step: 13200 of 13750, Training loss: 0.1121175, Training accuracy: 0.9665341, Time: 05_05_2022__18:41:52\n","Epoch 3 of 5, Step: 13300 of 13750, Training loss: 0.1119368, Training accuracy: 0.9665977, Time: 05_05_2022__18:42:12\n","Epoch 3 of 5, Step: 13400 of 13750, Training loss: 0.1118508, Training accuracy: 0.9666231, Time: 05_05_2022__18:42:33\n","Epoch 3 of 5, Step: 13500 of 13750, Training loss: 0.1118236, Training accuracy: 0.9666481, Time: 05_05_2022__18:42:54\n","Epoch 3 of 5, Step: 13600 of 13750, Training loss: 0.1117324, Training accuracy: 0.9666544, Time: 05_05_2022__18:43:15\n","Epoch 3 of 5, Step: 13700 of 13750, Training loss: 0.1116467, Training accuracy: 0.9666788, Time: 05_05_2022__18:43:36\n","Epoch 3 of 5, Average training loss: 0.1115287, Average training accuracy: 0.9667273, Time: 05_05_2022__18:43:46\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a11ebfd732cd4b9695a3cc8561f51b5b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0715870, Validation accuracy: 0.9825000, Time: 05_05_2022__18:43:52 | Loss decreased from 0.0763621 to 0.0722357 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0744560, Validation accuracy: 0.9775000, Time: 05_05_2022__18:43:59\n","Step: 300 of 1250, Validation loss: 0.0786643, Validation accuracy: 0.9783333, Time: 05_05_2022__18:44:04\n","Step: 400 of 1250, Validation loss: 0.0709596, Validation accuracy: 0.9787500, Time: 05_05_2022__18:44:09 | Loss decreased from 0.0722357 to 0.0703869 .... Saving the model\n","Step: 500 of 1250, Validation loss: 0.0678413, Validation accuracy: 0.9790000, Time: 05_05_2022__18:44:17 | Loss decreased from 0.0703869 to 0.0679342 .... Saving the model\n","Step: 600 of 1250, Validation loss: 0.0644636, Validation accuracy: 0.9795833, Time: 05_05_2022__18:44:24 | Loss decreased from 0.0679342 to 0.0645235 .... Saving the model\n","Step: 700 of 1250, Validation loss: 0.0610849, Validation accuracy: 0.9800000, Time: 05_05_2022__18:44:31 | Loss decreased from 0.0645235 to 0.0606125 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0616233, Validation accuracy: 0.9803125, Time: 05_05_2022__18:44:39\n","Step: 900 of 1250, Validation loss: 0.0640869, Validation accuracy: 0.9802778, Time: 05_05_2022__18:44:44\n","Step: 1000 of 1250, Validation loss: 0.0668164, Validation accuracy: 0.9800000, Time: 05_05_2022__18:44:49\n","Step: 1100 of 1250, Validation loss: 0.0645701, Validation accuracy: 0.9809091, Time: 05_05_2022__18:44:54\n","Step: 1200 of 1250, Validation loss: 0.0646625, Validation accuracy: 0.9806250, Time: 05_05_2022__18:45:00\n","Average validation loss: 0.0651375, Average validation accuracy: 0.9804000, Time: 05_05_2022__18:45:02\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df88d6001af54345ade6e7a9197fcf3d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 13750, Training loss: 0.0911460, Training accuracy: 0.9750000, Time: 05_05_2022__18:45:23\n","Epoch 4 of 5, Step: 200 of 13750, Training loss: 0.0804344, Training accuracy: 0.9787500, Time: 05_05_2022__18:45:44\n","Epoch 4 of 5, Step: 300 of 13750, Training loss: 0.0889184, Training accuracy: 0.9783333, Time: 05_05_2022__18:46:05\n","Epoch 4 of 5, Step: 400 of 13750, Training loss: 0.0914265, Training accuracy: 0.9775000, Time: 05_05_2022__18:46:26\n","Epoch 4 of 5, Step: 500 of 13750, Training loss: 0.0931986, Training accuracy: 0.9755000, Time: 05_05_2022__18:46:47\n","Epoch 4 of 5, Step: 600 of 13750, Training loss: 0.0937407, Training accuracy: 0.9741667, Time: 05_05_2022__18:47:08\n","Epoch 4 of 5, Step: 700 of 13750, Training loss: 0.0958565, Training accuracy: 0.9728571, Time: 05_05_2022__18:47:29\n","Epoch 4 of 5, Step: 800 of 13750, Training loss: 0.0938387, Training accuracy: 0.9731250, Time: 05_05_2022__18:47:50\n","Epoch 4 of 5, Step: 900 of 13750, Training loss: 0.0954160, Training accuracy: 0.9727778, Time: 05_05_2022__18:48:11\n","Epoch 4 of 5, Step: 1000 of 13750, Training loss: 0.0954673, Training accuracy: 0.9727500, Time: 05_05_2022__18:48:31\n","Epoch 4 of 5, Step: 1100 of 13750, Training loss: 0.0993253, Training accuracy: 0.9715909, Time: 05_05_2022__18:48:52\n","Epoch 4 of 5, Step: 1200 of 13750, Training loss: 0.0982973, Training accuracy: 0.9712500, Time: 05_05_2022__18:49:13\n","Epoch 4 of 5, Step: 1300 of 13750, Training loss: 0.0980583, Training accuracy: 0.9713462, Time: 05_05_2022__18:49:34\n","Epoch 4 of 5, Step: 1400 of 13750, Training loss: 0.0979030, Training accuracy: 0.9712500, Time: 05_05_2022__18:49:55\n","Epoch 4 of 5, Step: 1500 of 13750, Training loss: 0.0979268, Training accuracy: 0.9706667, Time: 05_05_2022__18:50:16\n","Epoch 4 of 5, Step: 1600 of 13750, Training loss: 0.0979345, Training accuracy: 0.9703125, Time: 05_05_2022__18:50:37\n","Epoch 4 of 5, Step: 1700 of 13750, Training loss: 0.0972927, Training accuracy: 0.9708824, Time: 05_05_2022__18:50:58\n","Epoch 4 of 5, Step: 1800 of 13750, Training loss: 0.0965188, Training accuracy: 0.9715278, Time: 05_05_2022__18:51:19\n","Epoch 4 of 5, Step: 1900 of 13750, Training loss: 0.0965324, Training accuracy: 0.9715789, Time: 05_05_2022__18:51:40\n","Epoch 4 of 5, Step: 2000 of 13750, Training loss: 0.0957618, Training accuracy: 0.9716250, Time: 05_05_2022__18:52:00\n","Epoch 4 of 5, Step: 2100 of 13750, Training loss: 0.0938417, Training accuracy: 0.9720238, Time: 05_05_2022__18:52:21\n","Epoch 4 of 5, Step: 2200 of 13750, Training loss: 0.0931841, Training accuracy: 0.9721591, Time: 05_05_2022__18:52:42\n","Epoch 4 of 5, Step: 2300 of 13750, Training loss: 0.0920505, Training accuracy: 0.9725000, Time: 05_05_2022__18:53:03\n","Epoch 4 of 5, Step: 2400 of 13750, Training loss: 0.0921913, Training accuracy: 0.9731250, Time: 05_05_2022__18:53:24\n","Epoch 4 of 5, Step: 2500 of 13750, Training loss: 0.0919054, Training accuracy: 0.9734000, Time: 05_05_2022__18:53:45\n","Epoch 4 of 5, Step: 2600 of 13750, Training loss: 0.0930151, Training accuracy: 0.9727885, Time: 05_05_2022__18:54:06\n","Epoch 4 of 5, Step: 2700 of 13750, Training loss: 0.0924777, Training accuracy: 0.9729630, Time: 05_05_2022__18:54:27\n","Epoch 4 of 5, Step: 2800 of 13750, Training loss: 0.0934108, Training accuracy: 0.9727679, Time: 05_05_2022__18:54:48\n","Epoch 4 of 5, Step: 2900 of 13750, Training loss: 0.0936947, Training accuracy: 0.9728448, Time: 05_05_2022__18:55:08\n","Epoch 4 of 5, Step: 3000 of 13750, Training loss: 0.0931134, Training accuracy: 0.9730000, Time: 05_05_2022__18:55:29\n","Epoch 4 of 5, Step: 3100 of 13750, Training loss: 0.0933790, Training accuracy: 0.9729032, Time: 05_05_2022__18:55:50\n","Epoch 4 of 5, Step: 3200 of 13750, Training loss: 0.0930410, Training accuracy: 0.9729688, Time: 05_05_2022__18:56:11\n","Epoch 4 of 5, Step: 3300 of 13750, Training loss: 0.0927882, Training accuracy: 0.9726515, Time: 05_05_2022__18:56:32\n","Epoch 4 of 5, Step: 3400 of 13750, Training loss: 0.0921263, Training accuracy: 0.9728676, Time: 05_05_2022__18:56:53\n","Epoch 4 of 5, Step: 3500 of 13750, Training loss: 0.0919148, Training accuracy: 0.9728571, Time: 05_05_2022__18:57:14\n","Epoch 4 of 5, Step: 3600 of 13750, Training loss: 0.0913505, Training accuracy: 0.9731944, Time: 05_05_2022__18:57:35\n","Epoch 4 of 5, Step: 3700 of 13750, Training loss: 0.0916839, Training accuracy: 0.9730405, Time: 05_05_2022__18:57:56\n","Epoch 4 of 5, Step: 3800 of 13750, Training loss: 0.0914757, Training accuracy: 0.9731579, Time: 05_05_2022__18:58:16\n","Epoch 4 of 5, Step: 3900 of 13750, Training loss: 0.0922010, Training accuracy: 0.9729487, Time: 05_05_2022__18:58:37\n","Epoch 4 of 5, Step: 4000 of 13750, Training loss: 0.0924040, Training accuracy: 0.9730000, Time: 05_05_2022__18:58:58\n","Epoch 4 of 5, Step: 4100 of 13750, Training loss: 0.0921701, Training accuracy: 0.9731098, Time: 05_05_2022__18:59:19\n","Epoch 4 of 5, Step: 4200 of 13750, Training loss: 0.0935210, Training accuracy: 0.9727381, Time: 05_05_2022__18:59:40\n","Epoch 4 of 5, Step: 4300 of 13750, Training loss: 0.0936445, Training accuracy: 0.9725581, Time: 05_05_2022__19:00:01\n","Epoch 4 of 5, Step: 4400 of 13750, Training loss: 0.0936544, Training accuracy: 0.9724432, Time: 05_05_2022__19:00:22\n","Epoch 4 of 5, Step: 4500 of 13750, Training loss: 0.0928927, Training accuracy: 0.9727222, Time: 05_05_2022__19:00:43\n","Epoch 4 of 5, Step: 4600 of 13750, Training loss: 0.0922772, Training accuracy: 0.9729348, Time: 05_05_2022__19:01:04\n","Epoch 4 of 5, Step: 4700 of 13750, Training loss: 0.0926950, Training accuracy: 0.9729787, Time: 05_05_2022__19:01:25\n","Epoch 4 of 5, Step: 4800 of 13750, Training loss: 0.0931413, Training accuracy: 0.9728125, Time: 05_05_2022__19:01:45\n","Epoch 4 of 5, Step: 4900 of 13750, Training loss: 0.0936701, Training accuracy: 0.9726020, Time: 05_05_2022__19:02:06\n","Epoch 4 of 5, Step: 5000 of 13750, Training loss: 0.0928594, Training accuracy: 0.9730500, Time: 05_05_2022__19:02:27\n","Epoch 4 of 5, Step: 5100 of 13750, Training loss: 0.0924190, Training accuracy: 0.9732353, Time: 05_05_2022__19:02:48\n","Epoch 4 of 5, Step: 5200 of 13750, Training loss: 0.0928872, Training accuracy: 0.9731250, Time: 05_05_2022__19:03:09\n","Epoch 4 of 5, Step: 5300 of 13750, Training loss: 0.0932565, Training accuracy: 0.9728774, Time: 05_05_2022__19:03:30\n","Epoch 4 of 5, Step: 5400 of 13750, Training loss: 0.0931016, Training accuracy: 0.9729167, Time: 05_05_2022__19:03:51\n","Epoch 4 of 5, Step: 5500 of 13750, Training loss: 0.0929093, Training accuracy: 0.9730000, Time: 05_05_2022__19:04:12\n","Epoch 4 of 5, Step: 5600 of 13750, Training loss: 0.0930452, Training accuracy: 0.9728571, Time: 05_05_2022__19:04:33\n","Epoch 4 of 5, Step: 5700 of 13750, Training loss: 0.0934594, Training accuracy: 0.9725439, Time: 05_05_2022__19:04:53\n","Epoch 4 of 5, Step: 5800 of 13750, Training loss: 0.0928455, Training accuracy: 0.9727586, Time: 05_05_2022__19:05:14\n","Epoch 4 of 5, Step: 5900 of 13750, Training loss: 0.0922633, Training accuracy: 0.9728814, Time: 05_05_2022__19:05:35\n","Epoch 4 of 5, Step: 6000 of 13750, Training loss: 0.0923005, Training accuracy: 0.9729583, Time: 05_05_2022__19:05:56\n","Epoch 4 of 5, Step: 6100 of 13750, Training loss: 0.0919293, Training accuracy: 0.9730738, Time: 05_05_2022__19:06:17\n","Epoch 4 of 5, Step: 6200 of 13750, Training loss: 0.0919733, Training accuracy: 0.9729435, Time: 05_05_2022__19:06:38\n","Epoch 4 of 5, Step: 6300 of 13750, Training loss: 0.0921659, Training accuracy: 0.9730159, Time: 05_05_2022__19:06:59\n","Epoch 4 of 5, Step: 6400 of 13750, Training loss: 0.0920755, Training accuracy: 0.9730469, Time: 05_05_2022__19:07:20\n","Epoch 4 of 5, Step: 6500 of 13750, Training loss: 0.0925996, Training accuracy: 0.9730000, Time: 05_05_2022__19:07:41\n","Epoch 4 of 5, Step: 6600 of 13750, Training loss: 0.0918352, Training accuracy: 0.9731818, Time: 05_05_2022__19:08:01\n","Epoch 4 of 5, Step: 6700 of 13750, Training loss: 0.0916337, Training accuracy: 0.9731343, Time: 05_05_2022__19:08:22\n","Epoch 4 of 5, Step: 6800 of 13750, Training loss: 0.0912481, Training accuracy: 0.9732353, Time: 05_05_2022__19:08:43\n","Epoch 4 of 5, Step: 6900 of 13750, Training loss: 0.0911036, Training accuracy: 0.9734058, Time: 05_05_2022__19:09:04\n","Epoch 4 of 5, Step: 7000 of 13750, Training loss: 0.0908132, Training accuracy: 0.9736071, Time: 05_05_2022__19:09:25\n","Epoch 4 of 5, Step: 7100 of 13750, Training loss: 0.0910182, Training accuracy: 0.9734859, Time: 05_05_2022__19:09:46\n","Epoch 4 of 5, Step: 7200 of 13750, Training loss: 0.0909598, Training accuracy: 0.9735069, Time: 05_05_2022__19:10:07\n","Epoch 4 of 5, Step: 7300 of 13750, Training loss: 0.0905729, Training accuracy: 0.9735959, Time: 05_05_2022__19:10:28\n","Epoch 4 of 5, Step: 7400 of 13750, Training loss: 0.0903710, Training accuracy: 0.9736824, Time: 05_05_2022__19:10:49\n","Epoch 4 of 5, Step: 7500 of 13750, Training loss: 0.0902707, Training accuracy: 0.9737333, Time: 05_05_2022__19:11:10\n","Epoch 4 of 5, Step: 7600 of 13750, Training loss: 0.0904551, Training accuracy: 0.9735855, Time: 05_05_2022__19:11:30\n","Epoch 4 of 5, Step: 7700 of 13750, Training loss: 0.0900688, Training accuracy: 0.9737013, Time: 05_05_2022__19:11:51\n","Epoch 4 of 5, Step: 7800 of 13750, Training loss: 0.0899459, Training accuracy: 0.9737500, Time: 05_05_2022__19:12:12\n","Epoch 4 of 5, Step: 7900 of 13750, Training loss: 0.0903243, Training accuracy: 0.9736709, Time: 05_05_2022__19:12:33\n","Epoch 4 of 5, Step: 8000 of 13750, Training loss: 0.0900753, Training accuracy: 0.9737187, Time: 05_05_2022__19:12:54\n","Epoch 4 of 5, Step: 8100 of 13750, Training loss: 0.0897248, Training accuracy: 0.9738889, Time: 05_05_2022__19:13:15\n","Epoch 4 of 5, Step: 8200 of 13750, Training loss: 0.0894708, Training accuracy: 0.9740244, Time: 05_05_2022__19:13:36\n","Epoch 4 of 5, Step: 8300 of 13750, Training loss: 0.0901631, Training accuracy: 0.9739759, Time: 05_05_2022__19:13:57\n","Epoch 4 of 5, Step: 8400 of 13750, Training loss: 0.0902823, Training accuracy: 0.9738988, Time: 05_05_2022__19:14:18\n","Epoch 4 of 5, Step: 8500 of 13750, Training loss: 0.0900109, Training accuracy: 0.9740000, Time: 05_05_2022__19:14:38\n","Epoch 4 of 5, Step: 8600 of 13750, Training loss: 0.0900650, Training accuracy: 0.9740407, Time: 05_05_2022__19:14:59\n","Epoch 4 of 5, Step: 8700 of 13750, Training loss: 0.0897734, Training accuracy: 0.9741667, Time: 05_05_2022__19:15:20\n","Epoch 4 of 5, Step: 8800 of 13750, Training loss: 0.0900902, Training accuracy: 0.9740909, Time: 05_05_2022__19:15:41\n","Epoch 4 of 5, Step: 8900 of 13750, Training loss: 0.0895696, Training accuracy: 0.9743258, Time: 05_05_2022__19:16:02\n","Epoch 4 of 5, Step: 9000 of 13750, Training loss: 0.0896679, Training accuracy: 0.9743611, Time: 05_05_2022__19:16:23\n","Epoch 4 of 5, Step: 9100 of 13750, Training loss: 0.0898021, Training accuracy: 0.9742857, Time: 05_05_2022__19:16:44\n","Epoch 4 of 5, Step: 9200 of 13750, Training loss: 0.0897626, Training accuracy: 0.9743207, Time: 05_05_2022__19:17:05\n","Epoch 4 of 5, Step: 9300 of 13750, Training loss: 0.0896686, Training accuracy: 0.9743280, Time: 05_05_2022__19:17:26\n","Epoch 4 of 5, Step: 9400 of 13750, Training loss: 0.0899179, Training accuracy: 0.9741755, Time: 05_05_2022__19:17:46\n","Epoch 4 of 5, Step: 9500 of 13750, Training loss: 0.0898303, Training accuracy: 0.9741842, Time: 05_05_2022__19:18:07\n","Epoch 4 of 5, Step: 9600 of 13750, Training loss: 0.0898710, Training accuracy: 0.9741146, Time: 05_05_2022__19:18:28\n","Epoch 4 of 5, Step: 9700 of 13750, Training loss: 0.0896237, Training accuracy: 0.9741495, Time: 05_05_2022__19:18:49\n","Epoch 4 of 5, Step: 9800 of 13750, Training loss: 0.0896112, Training accuracy: 0.9742347, Time: 05_05_2022__19:19:10\n","Epoch 4 of 5, Step: 9900 of 13750, Training loss: 0.0891727, Training accuracy: 0.9743687, Time: 05_05_2022__19:19:31\n","Epoch 4 of 5, Step: 10000 of 13750, Training loss: 0.0891204, Training accuracy: 0.9743250, Time: 05_05_2022__19:19:52\n","Epoch 4 of 5, Step: 10100 of 13750, Training loss: 0.0894580, Training accuracy: 0.9743564, Time: 05_05_2022__19:20:13\n","Epoch 4 of 5, Step: 10200 of 13750, Training loss: 0.0894194, Training accuracy: 0.9743627, Time: 05_05_2022__19:20:34\n","Epoch 4 of 5, Step: 10300 of 13750, Training loss: 0.0891095, Training accuracy: 0.9744660, Time: 05_05_2022__19:20:55\n","Epoch 4 of 5, Step: 10400 of 13750, Training loss: 0.0889513, Training accuracy: 0.9745192, Time: 05_05_2022__19:21:15\n","Epoch 4 of 5, Step: 10500 of 13750, Training loss: 0.0887223, Training accuracy: 0.9745952, Time: 05_05_2022__19:21:36\n","Epoch 4 of 5, Step: 10600 of 13750, Training loss: 0.0885924, Training accuracy: 0.9746462, Time: 05_05_2022__19:21:57\n","Epoch 4 of 5, Step: 10700 of 13750, Training loss: 0.0885962, Training accuracy: 0.9746262, Time: 05_05_2022__19:22:18\n","Epoch 4 of 5, Step: 10800 of 13750, Training loss: 0.0886996, Training accuracy: 0.9745139, Time: 05_05_2022__19:22:39\n","Epoch 4 of 5, Step: 10900 of 13750, Training loss: 0.0886421, Training accuracy: 0.9744725, Time: 05_05_2022__19:23:00\n","Epoch 4 of 5, Step: 11000 of 13750, Training loss: 0.0883659, Training accuracy: 0.9745909, Time: 05_05_2022__19:23:21\n","Epoch 4 of 5, Step: 11100 of 13750, Training loss: 0.0881285, Training accuracy: 0.9746396, Time: 05_05_2022__19:23:42\n","Epoch 4 of 5, Step: 11200 of 13750, Training loss: 0.0880989, Training accuracy: 0.9747098, Time: 05_05_2022__19:24:03\n","Epoch 4 of 5, Step: 11300 of 13750, Training loss: 0.0878185, Training accuracy: 0.9747788, Time: 05_05_2022__19:24:24\n","Epoch 4 of 5, Step: 11400 of 13750, Training loss: 0.0876855, Training accuracy: 0.9748465, Time: 05_05_2022__19:24:44\n","Epoch 4 of 5, Step: 11500 of 13750, Training loss: 0.0878680, Training accuracy: 0.9747391, Time: 05_05_2022__19:25:05\n","Epoch 4 of 5, Step: 11600 of 13750, Training loss: 0.0877508, Training accuracy: 0.9747629, Time: 05_05_2022__19:25:26\n","Epoch 4 of 5, Step: 11700 of 13750, Training loss: 0.0875724, Training accuracy: 0.9748291, Time: 05_05_2022__19:25:47\n","Epoch 4 of 5, Step: 11800 of 13750, Training loss: 0.0875419, Training accuracy: 0.9748517, Time: 05_05_2022__19:26:08\n","Epoch 4 of 5, Step: 11900 of 13750, Training loss: 0.0874628, Training accuracy: 0.9749160, Time: 05_05_2022__19:26:29\n","Epoch 4 of 5, Step: 12000 of 13750, Training loss: 0.0873352, Training accuracy: 0.9749375, Time: 05_05_2022__19:26:50\n","Epoch 4 of 5, Step: 12100 of 13750, Training loss: 0.0873188, Training accuracy: 0.9750000, Time: 05_05_2022__19:27:11\n","Epoch 4 of 5, Step: 12200 of 13750, Training loss: 0.0876632, Training accuracy: 0.9749385, Time: 05_05_2022__19:27:32\n","Epoch 4 of 5, Step: 12300 of 13750, Training loss: 0.0874230, Training accuracy: 0.9750203, Time: 05_05_2022__19:27:53\n","Epoch 4 of 5, Step: 12400 of 13750, Training loss: 0.0873629, Training accuracy: 0.9750605, Time: 05_05_2022__19:28:13\n","Epoch 4 of 5, Step: 12500 of 13750, Training loss: 0.0873390, Training accuracy: 0.9750200, Time: 05_05_2022__19:28:34\n","Epoch 4 of 5, Step: 12600 of 13750, Training loss: 0.0871764, Training accuracy: 0.9750397, Time: 05_05_2022__19:28:55\n","Epoch 4 of 5, Step: 12700 of 13750, Training loss: 0.0870388, Training accuracy: 0.9750394, Time: 05_05_2022__19:29:16\n","Epoch 4 of 5, Step: 12800 of 13750, Training loss: 0.0869205, Training accuracy: 0.9750586, Time: 05_05_2022__19:29:37\n","Epoch 4 of 5, Step: 12900 of 13750, Training loss: 0.0872325, Training accuracy: 0.9749806, Time: 05_05_2022__19:29:58\n","Epoch 4 of 5, Step: 13000 of 13750, Training loss: 0.0869963, Training accuracy: 0.9750192, Time: 05_05_2022__19:30:19\n","Epoch 4 of 5, Step: 13100 of 13750, Training loss: 0.0872112, Training accuracy: 0.9750191, Time: 05_05_2022__19:30:40\n","Epoch 4 of 5, Step: 13200 of 13750, Training loss: 0.0870159, Training accuracy: 0.9750379, Time: 05_05_2022__19:31:01\n","Epoch 4 of 5, Step: 13300 of 13750, Training loss: 0.0869974, Training accuracy: 0.9750376, Time: 05_05_2022__19:31:21\n","Epoch 4 of 5, Step: 13400 of 13750, Training loss: 0.0870491, Training accuracy: 0.9750560, Time: 05_05_2022__19:31:42\n","Epoch 4 of 5, Step: 13500 of 13750, Training loss: 0.0868972, Training accuracy: 0.9750741, Time: 05_05_2022__19:32:03\n","Epoch 4 of 5, Step: 13600 of 13750, Training loss: 0.0867786, Training accuracy: 0.9751103, Time: 05_05_2022__19:32:24\n","Epoch 4 of 5, Step: 13700 of 13750, Training loss: 0.0866063, Training accuracy: 0.9751642, Time: 05_05_2022__19:32:45\n","Epoch 4 of 5, Average training loss: 0.0866376, Average training accuracy: 0.9751455, Time: 05_05_2022__19:32:56\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00919d8ee5f44d1c850841009b6e53aa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0537884, Validation accuracy: 0.9850000, Time: 05_05_2022__19:33:01 | Loss decreased from 0.0606125 to 0.0543212 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0516034, Validation accuracy: 0.9837500, Time: 05_05_2022__19:33:08 | Loss decreased from 0.0543212 to 0.0518466 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.0531756, Validation accuracy: 0.9850000, Time: 05_05_2022__19:33:16\n","Step: 400 of 1250, Validation loss: 0.0509578, Validation accuracy: 0.9850000, Time: 05_05_2022__19:33:21 | Loss decreased from 0.0518466 to 0.0509555 .... Saving the model\n","Step: 500 of 1250, Validation loss: 0.0476153, Validation accuracy: 0.9860000, Time: 05_05_2022__19:33:28 | Loss decreased from 0.0509555 to 0.0476742 .... Saving the model\n","Step: 600 of 1250, Validation loss: 0.0454457, Validation accuracy: 0.9875000, Time: 05_05_2022__19:33:35 | Loss decreased from 0.0476742 to 0.0455144 .... Saving the model\n","Step: 700 of 1250, Validation loss: 0.0439982, Validation accuracy: 0.9871429, Time: 05_05_2022__19:33:43 | Loss decreased from 0.0455144 to 0.0434792 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0442130, Validation accuracy: 0.9868750, Time: 05_05_2022__19:33:50\n","Step: 900 of 1250, Validation loss: 0.0477674, Validation accuracy: 0.9861111, Time: 05_05_2022__19:33:56\n","Step: 1000 of 1250, Validation loss: 0.0504233, Validation accuracy: 0.9855000, Time: 05_05_2022__19:34:01\n","Step: 1100 of 1250, Validation loss: 0.0491081, Validation accuracy: 0.9861364, Time: 05_05_2022__19:34:06\n","Step: 1200 of 1250, Validation loss: 0.0494396, Validation accuracy: 0.9854167, Time: 05_05_2022__19:34:11\n","Average validation loss: 0.0503562, Average validation accuracy: 0.9848000, Time: 05_05_2022__19:34:14\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"110d6216f4b2491a9f2145e5751824d4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 13750, Training loss: 0.0615173, Training accuracy: 0.9800000, Time: 05_05_2022__19:34:35\n","Epoch 5 of 5, Step: 200 of 13750, Training loss: 0.0571309, Training accuracy: 0.9837500, Time: 05_05_2022__19:34:55\n","Epoch 5 of 5, Step: 300 of 13750, Training loss: 0.0654072, Training accuracy: 0.9816667, Time: 05_05_2022__19:35:16\n","Epoch 5 of 5, Step: 400 of 13750, Training loss: 0.0679216, Training accuracy: 0.9812500, Time: 05_05_2022__19:35:37\n","Epoch 5 of 5, Step: 500 of 13750, Training loss: 0.0737339, Training accuracy: 0.9785000, Time: 05_05_2022__19:35:58\n","Epoch 5 of 5, Step: 600 of 13750, Training loss: 0.0742796, Training accuracy: 0.9783333, Time: 05_05_2022__19:36:19\n","Epoch 5 of 5, Step: 700 of 13750, Training loss: 0.0774515, Training accuracy: 0.9785714, Time: 05_05_2022__19:36:40\n","Epoch 5 of 5, Step: 800 of 13750, Training loss: 0.0749762, Training accuracy: 0.9790625, Time: 05_05_2022__19:37:01\n","Epoch 5 of 5, Step: 900 of 13750, Training loss: 0.0760559, Training accuracy: 0.9786111, Time: 05_05_2022__19:37:22\n","Epoch 5 of 5, Step: 1000 of 13750, Training loss: 0.0754405, Training accuracy: 0.9790000, Time: 05_05_2022__19:37:43\n","Epoch 5 of 5, Step: 1100 of 13750, Training loss: 0.0770462, Training accuracy: 0.9781818, Time: 05_05_2022__19:38:04\n","Epoch 5 of 5, Step: 1200 of 13750, Training loss: 0.0758752, Training accuracy: 0.9783333, Time: 05_05_2022__19:38:24\n","Epoch 5 of 5, Step: 1300 of 13750, Training loss: 0.0760203, Training accuracy: 0.9782692, Time: 05_05_2022__19:38:45\n","Epoch 5 of 5, Step: 1400 of 13750, Training loss: 0.0745112, Training accuracy: 0.9783929, Time: 05_05_2022__19:39:06\n","Epoch 5 of 5, Step: 1500 of 13750, Training loss: 0.0755992, Training accuracy: 0.9776667, Time: 05_05_2022__19:39:27\n","Epoch 5 of 5, Step: 1600 of 13750, Training loss: 0.0758644, Training accuracy: 0.9776563, Time: 05_05_2022__19:39:48\n","Epoch 5 of 5, Step: 1700 of 13750, Training loss: 0.0745393, Training accuracy: 0.9780882, Time: 05_05_2022__19:40:09\n","Epoch 5 of 5, Step: 1800 of 13750, Training loss: 0.0736465, Training accuracy: 0.9787500, Time: 05_05_2022__19:40:30\n","Epoch 5 of 5, Step: 1900 of 13750, Training loss: 0.0737952, Training accuracy: 0.9788158, Time: 05_05_2022__19:40:51\n","Epoch 5 of 5, Step: 2000 of 13750, Training loss: 0.0729854, Training accuracy: 0.9792500, Time: 05_05_2022__19:41:12\n","Epoch 5 of 5, Step: 2100 of 13750, Training loss: 0.0715693, Training accuracy: 0.9794048, Time: 05_05_2022__19:41:33\n","Epoch 5 of 5, Step: 2200 of 13750, Training loss: 0.0711690, Training accuracy: 0.9794318, Time: 05_05_2022__19:41:54\n","Epoch 5 of 5, Step: 2300 of 13750, Training loss: 0.0716981, Training accuracy: 0.9793478, Time: 05_05_2022__19:42:14\n","Epoch 5 of 5, Step: 2400 of 13750, Training loss: 0.0736384, Training accuracy: 0.9791667, Time: 05_05_2022__19:42:35\n","Epoch 5 of 5, Step: 2500 of 13750, Training loss: 0.0733767, Training accuracy: 0.9789000, Time: 05_05_2022__19:42:56\n","Epoch 5 of 5, Step: 2600 of 13750, Training loss: 0.0750230, Training accuracy: 0.9784615, Time: 05_05_2022__19:43:17\n","Epoch 5 of 5, Step: 2700 of 13750, Training loss: 0.0748544, Training accuracy: 0.9786111, Time: 05_05_2022__19:43:38\n","Epoch 5 of 5, Step: 2800 of 13750, Training loss: 0.0749499, Training accuracy: 0.9785714, Time: 05_05_2022__19:43:59\n","Epoch 5 of 5, Step: 2900 of 13750, Training loss: 0.0754915, Training accuracy: 0.9781897, Time: 05_05_2022__19:44:20\n","Epoch 5 of 5, Step: 3000 of 13750, Training loss: 0.0750735, Training accuracy: 0.9783333, Time: 05_05_2022__19:44:41\n","Epoch 5 of 5, Step: 3100 of 13750, Training loss: 0.0756291, Training accuracy: 0.9781452, Time: 05_05_2022__19:45:02\n","Epoch 5 of 5, Step: 3200 of 13750, Training loss: 0.0748825, Training accuracy: 0.9785938, Time: 05_05_2022__19:45:23\n","Epoch 5 of 5, Step: 3300 of 13750, Training loss: 0.0744238, Training accuracy: 0.9788636, Time: 05_05_2022__19:45:43\n","Epoch 5 of 5, Step: 3400 of 13750, Training loss: 0.0745531, Training accuracy: 0.9786765, Time: 05_05_2022__19:46:04\n","Epoch 5 of 5, Step: 3500 of 13750, Training loss: 0.0744984, Training accuracy: 0.9785714, Time: 05_05_2022__19:46:25\n","Epoch 5 of 5, Step: 3600 of 13750, Training loss: 0.0741220, Training accuracy: 0.9785417, Time: 05_05_2022__19:46:46\n","Epoch 5 of 5, Step: 3700 of 13750, Training loss: 0.0740978, Training accuracy: 0.9785811, Time: 05_05_2022__19:47:07\n","Epoch 5 of 5, Step: 3800 of 13750, Training loss: 0.0739012, Training accuracy: 0.9785526, Time: 05_05_2022__19:47:28\n","Epoch 5 of 5, Step: 3900 of 13750, Training loss: 0.0741564, Training accuracy: 0.9785897, Time: 05_05_2022__19:47:49\n","Epoch 5 of 5, Step: 4000 of 13750, Training loss: 0.0744540, Training accuracy: 0.9786250, Time: 05_05_2022__19:48:10\n","Epoch 5 of 5, Step: 4100 of 13750, Training loss: 0.0745690, Training accuracy: 0.9784756, Time: 05_05_2022__19:48:31\n","Epoch 5 of 5, Step: 4200 of 13750, Training loss: 0.0759518, Training accuracy: 0.9780952, Time: 05_05_2022__19:48:52\n","Epoch 5 of 5, Step: 4300 of 13750, Training loss: 0.0761981, Training accuracy: 0.9779651, Time: 05_05_2022__19:49:12\n","Epoch 5 of 5, Step: 4400 of 13750, Training loss: 0.0765156, Training accuracy: 0.9778977, Time: 05_05_2022__19:49:33\n","Epoch 5 of 5, Step: 4500 of 13750, Training loss: 0.0760177, Training accuracy: 0.9781111, Time: 05_05_2022__19:49:54\n","Epoch 5 of 5, Step: 4600 of 13750, Training loss: 0.0755419, Training accuracy: 0.9782065, Time: 05_05_2022__19:50:15\n","Epoch 5 of 5, Step: 4700 of 13750, Training loss: 0.0755486, Training accuracy: 0.9780319, Time: 05_05_2022__19:50:36\n","Epoch 5 of 5, Step: 4800 of 13750, Training loss: 0.0759259, Training accuracy: 0.9780729, Time: 05_05_2022__19:50:57\n","Epoch 5 of 5, Step: 4900 of 13750, Training loss: 0.0759841, Training accuracy: 0.9780102, Time: 05_05_2022__19:51:18\n","Epoch 5 of 5, Step: 5000 of 13750, Training loss: 0.0759021, Training accuracy: 0.9780500, Time: 05_05_2022__19:51:39\n","Epoch 5 of 5, Step: 5100 of 13750, Training loss: 0.0756002, Training accuracy: 0.9779412, Time: 05_05_2022__19:52:00\n","Epoch 5 of 5, Step: 5200 of 13750, Training loss: 0.0757281, Training accuracy: 0.9779327, Time: 05_05_2022__19:52:20\n","Epoch 5 of 5, Step: 5300 of 13750, Training loss: 0.0760421, Training accuracy: 0.9779245, Time: 05_05_2022__19:52:41\n","Epoch 5 of 5, Step: 5400 of 13750, Training loss: 0.0758105, Training accuracy: 0.9781481, Time: 05_05_2022__19:53:02\n","Epoch 5 of 5, Step: 5500 of 13750, Training loss: 0.0755848, Training accuracy: 0.9783182, Time: 05_05_2022__19:53:23\n","Epoch 5 of 5, Step: 5600 of 13750, Training loss: 0.0758032, Training accuracy: 0.9781696, Time: 05_05_2022__19:53:44\n","Epoch 5 of 5, Step: 5700 of 13750, Training loss: 0.0764662, Training accuracy: 0.9778947, Time: 05_05_2022__19:54:05\n","Epoch 5 of 5, Step: 5800 of 13750, Training loss: 0.0764841, Training accuracy: 0.9778448, Time: 05_05_2022__19:54:26\n","Epoch 5 of 5, Step: 5900 of 13750, Training loss: 0.0762145, Training accuracy: 0.9778390, Time: 05_05_2022__19:54:47\n","Epoch 5 of 5, Step: 6000 of 13750, Training loss: 0.0767064, Training accuracy: 0.9775417, Time: 05_05_2022__19:55:08\n","Epoch 5 of 5, Step: 6100 of 13750, Training loss: 0.0765108, Training accuracy: 0.9776639, Time: 05_05_2022__19:55:29\n","Epoch 5 of 5, Step: 6200 of 13750, Training loss: 0.0765692, Training accuracy: 0.9777016, Time: 05_05_2022__19:55:49\n","Epoch 5 of 5, Step: 6300 of 13750, Training loss: 0.0767294, Training accuracy: 0.9776190, Time: 05_05_2022__19:56:10\n","Epoch 5 of 5, Step: 6400 of 13750, Training loss: 0.0768943, Training accuracy: 0.9775781, Time: 05_05_2022__19:56:31\n","Epoch 5 of 5, Step: 6500 of 13750, Training loss: 0.0774579, Training accuracy: 0.9775000, Time: 05_05_2022__19:56:52\n","Epoch 5 of 5, Step: 6600 of 13750, Training loss: 0.0770664, Training accuracy: 0.9776515, Time: 05_05_2022__19:57:13\n","Epoch 5 of 5, Step: 6700 of 13750, Training loss: 0.0767646, Training accuracy: 0.9776866, Time: 05_05_2022__19:57:34\n","Epoch 5 of 5, Step: 6800 of 13750, Training loss: 0.0765785, Training accuracy: 0.9776838, Time: 05_05_2022__19:57:55\n","Epoch 5 of 5, Step: 6900 of 13750, Training loss: 0.0765591, Training accuracy: 0.9776812, Time: 05_05_2022__19:58:16\n","Epoch 5 of 5, Step: 7000 of 13750, Training loss: 0.0766816, Training accuracy: 0.9776786, Time: 05_05_2022__19:58:37\n","Epoch 5 of 5, Step: 7100 of 13750, Training loss: 0.0766668, Training accuracy: 0.9777465, Time: 05_05_2022__19:58:58\n","Epoch 5 of 5, Step: 7200 of 13750, Training loss: 0.0764805, Training accuracy: 0.9777083, Time: 05_05_2022__19:59:18\n","Epoch 5 of 5, Step: 7300 of 13750, Training loss: 0.0762541, Training accuracy: 0.9777055, Time: 05_05_2022__19:59:39\n","Epoch 5 of 5, Step: 7400 of 13750, Training loss: 0.0760657, Training accuracy: 0.9778378, Time: 05_05_2022__20:00:00\n","Epoch 5 of 5, Step: 7500 of 13750, Training loss: 0.0761298, Training accuracy: 0.9778667, Time: 05_05_2022__20:00:21\n","Epoch 5 of 5, Step: 7600 of 13750, Training loss: 0.0763205, Training accuracy: 0.9777303, Time: 05_05_2022__20:00:42\n","Epoch 5 of 5, Step: 7700 of 13750, Training loss: 0.0760724, Training accuracy: 0.9777597, Time: 05_05_2022__20:01:03\n","Epoch 5 of 5, Step: 7800 of 13750, Training loss: 0.0759150, Training accuracy: 0.9778205, Time: 05_05_2022__20:01:24\n","Epoch 5 of 5, Step: 7900 of 13750, Training loss: 0.0758829, Training accuracy: 0.9779114, Time: 05_05_2022__20:01:45\n","Epoch 5 of 5, Step: 8000 of 13750, Training loss: 0.0760165, Training accuracy: 0.9778125, Time: 05_05_2022__20:02:06\n","Epoch 5 of 5, Step: 8100 of 13750, Training loss: 0.0757169, Training accuracy: 0.9778395, Time: 05_05_2022__20:02:27\n","Epoch 5 of 5, Step: 8200 of 13750, Training loss: 0.0755106, Training accuracy: 0.9778354, Time: 05_05_2022__20:02:47\n","Epoch 5 of 5, Step: 8300 of 13750, Training loss: 0.0763696, Training accuracy: 0.9775904, Time: 05_05_2022__20:03:08\n","Epoch 5 of 5, Step: 8400 of 13750, Training loss: 0.0764511, Training accuracy: 0.9775298, Time: 05_05_2022__20:03:29\n","Epoch 5 of 5, Step: 8500 of 13750, Training loss: 0.0763571, Training accuracy: 0.9776176, Time: 05_05_2022__20:03:50\n","Epoch 5 of 5, Step: 8600 of 13750, Training loss: 0.0763241, Training accuracy: 0.9776163, Time: 05_05_2022__20:04:11\n","Epoch 5 of 5, Step: 8700 of 13750, Training loss: 0.0760427, Training accuracy: 0.9777011, Time: 05_05_2022__20:04:32\n","Epoch 5 of 5, Step: 8800 of 13750, Training loss: 0.0763721, Training accuracy: 0.9776420, Time: 05_05_2022__20:04:53\n","Epoch 5 of 5, Step: 8900 of 13750, Training loss: 0.0760080, Training accuracy: 0.9778090, Time: 05_05_2022__20:05:14\n","Epoch 5 of 5, Step: 9000 of 13750, Training loss: 0.0758808, Training accuracy: 0.9778611, Time: 05_05_2022__20:05:35\n","Epoch 5 of 5, Step: 9100 of 13750, Training loss: 0.0758047, Training accuracy: 0.9778846, Time: 05_05_2022__20:05:56\n","Epoch 5 of 5, Step: 9200 of 13750, Training loss: 0.0759298, Training accuracy: 0.9777989, Time: 05_05_2022__20:06:17\n","Epoch 5 of 5, Step: 9300 of 13750, Training loss: 0.0757864, Training accuracy: 0.9777957, Time: 05_05_2022__20:06:38\n","Epoch 5 of 5, Step: 9400 of 13750, Training loss: 0.0759758, Training accuracy: 0.9777128, Time: 05_05_2022__20:06:58\n","Epoch 5 of 5, Step: 9500 of 13750, Training loss: 0.0758954, Training accuracy: 0.9777632, Time: 05_05_2022__20:07:19\n","Epoch 5 of 5, Step: 9600 of 13750, Training loss: 0.0761610, Training accuracy: 0.9776042, Time: 05_05_2022__20:07:40\n","Epoch 5 of 5, Step: 9700 of 13750, Training loss: 0.0759639, Training accuracy: 0.9776289, Time: 05_05_2022__20:08:01\n","Epoch 5 of 5, Step: 9800 of 13750, Training loss: 0.0759989, Training accuracy: 0.9776020, Time: 05_05_2022__20:08:22\n","Epoch 5 of 5, Step: 9900 of 13750, Training loss: 0.0756210, Training accuracy: 0.9777273, Time: 05_05_2022__20:08:43\n","Epoch 5 of 5, Step: 10000 of 13750, Training loss: 0.0755058, Training accuracy: 0.9777750, Time: 05_05_2022__20:09:04\n","Epoch 5 of 5, Step: 10100 of 13750, Training loss: 0.0759693, Training accuracy: 0.9776733, Time: 05_05_2022__20:09:25\n","Epoch 5 of 5, Step: 10200 of 13750, Training loss: 0.0759101, Training accuracy: 0.9777451, Time: 05_05_2022__20:09:46\n","Epoch 5 of 5, Step: 10300 of 13750, Training loss: 0.0754645, Training accuracy: 0.9779612, Time: 05_05_2022__20:10:07\n","Epoch 5 of 5, Step: 10400 of 13750, Training loss: 0.0753532, Training accuracy: 0.9779808, Time: 05_05_2022__20:10:28\n","Epoch 5 of 5, Step: 10500 of 13750, Training loss: 0.0752826, Training accuracy: 0.9780238, Time: 05_05_2022__20:10:48\n","Epoch 5 of 5, Step: 10600 of 13750, Training loss: 0.0753463, Training accuracy: 0.9780425, Time: 05_05_2022__20:11:09\n","Epoch 5 of 5, Step: 10700 of 13750, Training loss: 0.0753024, Training accuracy: 0.9779907, Time: 05_05_2022__20:11:30\n","Epoch 5 of 5, Step: 10800 of 13750, Training loss: 0.0752506, Training accuracy: 0.9779630, Time: 05_05_2022__20:11:51\n","Epoch 5 of 5, Step: 10900 of 13750, Training loss: 0.0752990, Training accuracy: 0.9779128, Time: 05_05_2022__20:12:12\n","Epoch 5 of 5, Step: 11000 of 13750, Training loss: 0.0751201, Training accuracy: 0.9780000, Time: 05_05_2022__20:12:33\n","Epoch 5 of 5, Step: 11100 of 13750, Training loss: 0.0750495, Training accuracy: 0.9779730, Time: 05_05_2022__20:12:54\n","Epoch 5 of 5, Step: 11200 of 13750, Training loss: 0.0748515, Training accuracy: 0.9780357, Time: 05_05_2022__20:13:15\n","Epoch 5 of 5, Step: 11300 of 13750, Training loss: 0.0747743, Training accuracy: 0.9780752, Time: 05_05_2022__20:13:36\n","Epoch 5 of 5, Step: 11400 of 13750, Training loss: 0.0746306, Training accuracy: 0.9781140, Time: 05_05_2022__20:13:57\n","Epoch 5 of 5, Step: 11500 of 13750, Training loss: 0.0746184, Training accuracy: 0.9780870, Time: 05_05_2022__20:14:17\n","Epoch 5 of 5, Step: 11600 of 13750, Training loss: 0.0745480, Training accuracy: 0.9781034, Time: 05_05_2022__20:14:38\n","Epoch 5 of 5, Step: 11700 of 13750, Training loss: 0.0744022, Training accuracy: 0.9780983, Time: 05_05_2022__20:14:59\n","Epoch 5 of 5, Step: 11800 of 13750, Training loss: 0.0744309, Training accuracy: 0.9780508, Time: 05_05_2022__20:15:20\n","Epoch 5 of 5, Step: 11900 of 13750, Training loss: 0.0744447, Training accuracy: 0.9781092, Time: 05_05_2022__20:15:41\n","Epoch 5 of 5, Step: 12000 of 13750, Training loss: 0.0743897, Training accuracy: 0.9781250, Time: 05_05_2022__20:16:02\n","Epoch 5 of 5, Step: 12100 of 13750, Training loss: 0.0743295, Training accuracy: 0.9780992, Time: 05_05_2022__20:16:23\n","Epoch 5 of 5, Step: 12200 of 13750, Training loss: 0.0743105, Training accuracy: 0.9780738, Time: 05_05_2022__20:16:44\n","Epoch 5 of 5, Step: 12300 of 13750, Training loss: 0.0740604, Training accuracy: 0.9781707, Time: 05_05_2022__20:17:05\n","Epoch 5 of 5, Step: 12400 of 13750, Training loss: 0.0739458, Training accuracy: 0.9782258, Time: 05_05_2022__20:17:26\n","Epoch 5 of 5, Step: 12500 of 13750, Training loss: 0.0738721, Training accuracy: 0.9782600, Time: 05_05_2022__20:17:47\n","Epoch 5 of 5, Step: 12600 of 13750, Training loss: 0.0735947, Training accuracy: 0.9783532, Time: 05_05_2022__20:18:07\n","Epoch 5 of 5, Step: 12700 of 13750, Training loss: 0.0735559, Training accuracy: 0.9783661, Time: 05_05_2022__20:18:28\n","Epoch 5 of 5, Step: 12800 of 13750, Training loss: 0.0734757, Training accuracy: 0.9784180, Time: 05_05_2022__20:18:49\n","Epoch 5 of 5, Step: 12900 of 13750, Training loss: 0.0736246, Training accuracy: 0.9783721, Time: 05_05_2022__20:19:10\n","Epoch 5 of 5, Step: 13000 of 13750, Training loss: 0.0734821, Training accuracy: 0.9784038, Time: 05_05_2022__20:19:31\n","Epoch 5 of 5, Step: 13100 of 13750, Training loss: 0.0736339, Training accuracy: 0.9782824, Time: 05_05_2022__20:19:52\n","Epoch 5 of 5, Step: 13200 of 13750, Training loss: 0.0734660, Training accuracy: 0.9783523, Time: 05_05_2022__20:20:13\n","Epoch 5 of 5, Step: 13300 of 13750, Training loss: 0.0734030, Training accuracy: 0.9783647, Time: 05_05_2022__20:20:34\n","Epoch 5 of 5, Step: 13400 of 13750, Training loss: 0.0735053, Training accuracy: 0.9783582, Time: 05_05_2022__20:20:55\n","Epoch 5 of 5, Step: 13500 of 13750, Training loss: 0.0734254, Training accuracy: 0.9783519, Time: 05_05_2022__20:21:16\n","Epoch 5 of 5, Step: 13600 of 13750, Training loss: 0.0734879, Training accuracy: 0.9783272, Time: 05_05_2022__20:21:37\n","Epoch 5 of 5, Step: 13700 of 13750, Training loss: 0.0733367, Training accuracy: 0.9783759, Time: 05_05_2022__20:21:58\n","Epoch 5 of 5, Average training loss: 0.0733173, Average training accuracy: 0.9784000, Time: 05_05_2022__20:22:08\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"429c92391fef42ad882703ba721bef85"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0351618, Validation accuracy: 0.9925000, Time: 05_05_2022__20:22:13 | Loss decreased from 0.0434792 to 0.0355055 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0441949, Validation accuracy: 0.9875000, Time: 05_05_2022__20:22:20\n","Step: 300 of 1250, Validation loss: 0.0446493, Validation accuracy: 0.9875000, Time: 05_05_2022__20:22:26\n","Step: 400 of 1250, Validation loss: 0.0440267, Validation accuracy: 0.9881250, Time: 05_05_2022__20:22:31\n","Step: 500 of 1250, Validation loss: 0.0435478, Validation accuracy: 0.9890000, Time: 05_05_2022__20:22:36\n","Step: 600 of 1250, Validation loss: 0.0431799, Validation accuracy: 0.9887500, Time: 05_05_2022__20:22:41\n","Step: 700 of 1250, Validation loss: 0.0424826, Validation accuracy: 0.9882143, Time: 05_05_2022__20:22:46\n","Step: 800 of 1250, Validation loss: 0.0425034, Validation accuracy: 0.9878125, Time: 05_05_2022__20:22:52\n","Step: 900 of 1250, Validation loss: 0.0433579, Validation accuracy: 0.9872222, Time: 05_05_2022__20:22:57\n","Step: 1000 of 1250, Validation loss: 0.0453447, Validation accuracy: 0.9860000, Time: 05_05_2022__20:23:02\n","Step: 1100 of 1250, Validation loss: 0.0444311, Validation accuracy: 0.9863636, Time: 05_05_2022__20:23:07\n","Step: 1200 of 1250, Validation loss: 0.0444797, Validation accuracy: 0.9862500, Time: 05_05_2022__20:23:12\n","Average validation loss: 0.0460538, Average validation accuracy: 0.9860000, Time: 05_05_2022__20:23:15\n","###################### Testing vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6b9a42d3d5a43f8b7337342b73df3e9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.9925000, Time: 05_05_2022__20:23:24\n","Step: 200 of 2500, Test accuracy: 0.9837500, Time: 05_05_2022__20:23:30\n","Step: 300 of 2500, Test accuracy: 0.9800000, Time: 05_05_2022__20:23:36\n","Step: 400 of 2500, Test accuracy: 0.9800000, Time: 05_05_2022__20:23:41\n","Step: 500 of 2500, Test accuracy: 0.9800000, Time: 05_05_2022__20:23:46\n","Step: 600 of 2500, Test accuracy: 0.9795833, Time: 05_05_2022__20:23:51\n","Step: 700 of 2500, Test accuracy: 0.9810714, Time: 05_05_2022__20:23:57\n","Step: 800 of 2500, Test accuracy: 0.9812500, Time: 05_05_2022__20:24:02\n","Step: 900 of 2500, Test accuracy: 0.9822222, Time: 05_05_2022__20:24:08\n","Step: 1000 of 2500, Test accuracy: 0.9820000, Time: 05_05_2022__20:24:13\n","Step: 1100 of 2500, Test accuracy: 0.9822727, Time: 05_05_2022__20:24:19\n","Step: 1200 of 2500, Test accuracy: 0.9820833, Time: 05_05_2022__20:24:24\n","Step: 1300 of 2500, Test accuracy: 0.9825000, Time: 05_05_2022__20:24:30\n","Step: 1400 of 2500, Test accuracy: 0.9837500, Time: 05_05_2022__20:24:35\n","Step: 1500 of 2500, Test accuracy: 0.9843333, Time: 05_05_2022__20:24:40\n","Step: 1600 of 2500, Test accuracy: 0.9851562, Time: 05_05_2022__20:24:46\n","Step: 1700 of 2500, Test accuracy: 0.9847059, Time: 05_05_2022__20:24:51\n","Step: 1800 of 2500, Test accuracy: 0.9854167, Time: 05_05_2022__20:24:57\n","Step: 1900 of 2500, Test accuracy: 0.9857895, Time: 05_05_2022__20:25:02\n","Step: 2000 of 2500, Test accuracy: 0.9862500, Time: 05_05_2022__20:25:07\n","Step: 2100 of 2500, Test accuracy: 0.9866667, Time: 05_05_2022__20:25:12\n","Step: 2200 of 2500, Test accuracy: 0.9871591, Time: 05_05_2022__20:25:18\n","Step: 2300 of 2500, Test accuracy: 0.9872826, Time: 05_05_2022__20:25:23\n","Step: 2400 of 2500, Test accuracy: 0.9877083, Time: 05_05_2022__20:25:28\n","Step: 2500 of 2500, Test accuracy: 0.9871000, Time: 05_05_2022__20:25:33\n","Average testing accuracy: 0.9871000, Time: 05_05_2022__20:25:33\n","###################### Training vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fccd5aacbd584eb288d237792c0aeda2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 13750, Training loss: 2.3954718, Training accuracy: 0.1175000, Time: 05_05_2022__20:25:56\n","Epoch 1 of 5, Step: 200 of 13750, Training loss: 2.3313121, Training accuracy: 0.1600000, Time: 05_05_2022__20:26:17\n","Epoch 1 of 5, Step: 300 of 13750, Training loss: 2.3094716, Training accuracy: 0.1683333, Time: 05_05_2022__20:26:38\n","Epoch 1 of 5, Step: 400 of 13750, Training loss: 2.2583872, Training accuracy: 0.1943750, Time: 05_05_2022__20:26:59\n","Epoch 1 of 5, Step: 500 of 13750, Training loss: 2.2147329, Training accuracy: 0.2205000, Time: 05_05_2022__20:27:20\n","Epoch 1 of 5, Step: 600 of 13750, Training loss: 2.1674597, Training accuracy: 0.2445833, Time: 05_05_2022__20:27:41\n","Epoch 1 of 5, Step: 700 of 13750, Training loss: 2.1175520, Training accuracy: 0.2671429, Time: 05_05_2022__20:28:02\n","Epoch 1 of 5, Step: 800 of 13750, Training loss: 2.0669014, Training accuracy: 0.2940625, Time: 05_05_2022__20:28:23\n","Epoch 1 of 5, Step: 900 of 13750, Training loss: 2.0191266, Training accuracy: 0.3138889, Time: 05_05_2022__20:28:44\n","Epoch 1 of 5, Step: 1000 of 13750, Training loss: 1.9673083, Training accuracy: 0.3372500, Time: 05_05_2022__20:29:05\n","Epoch 1 of 5, Step: 1100 of 13750, Training loss: 1.9195898, Training accuracy: 0.3579545, Time: 05_05_2022__20:29:26\n","Epoch 1 of 5, Step: 1200 of 13750, Training loss: 1.8677774, Training accuracy: 0.3814583, Time: 05_05_2022__20:29:47\n","Epoch 1 of 5, Step: 1300 of 13750, Training loss: 1.8175375, Training accuracy: 0.4030769, Time: 05_05_2022__20:30:08\n","Epoch 1 of 5, Step: 1400 of 13750, Training loss: 1.7709451, Training accuracy: 0.4228571, Time: 05_05_2022__20:30:28\n","Epoch 1 of 5, Step: 1500 of 13750, Training loss: 1.7244701, Training accuracy: 0.4410000, Time: 05_05_2022__20:30:49\n","Epoch 1 of 5, Step: 1600 of 13750, Training loss: 1.6814933, Training accuracy: 0.4579687, Time: 05_05_2022__20:31:10\n","Epoch 1 of 5, Step: 1700 of 13750, Training loss: 1.6398646, Training accuracy: 0.4735294, Time: 05_05_2022__20:31:31\n","Epoch 1 of 5, Step: 1800 of 13750, Training loss: 1.5964448, Training accuracy: 0.4897222, Time: 05_05_2022__20:31:52\n","Epoch 1 of 5, Step: 1900 of 13750, Training loss: 1.5573095, Training accuracy: 0.5042105, Time: 05_05_2022__20:32:13\n","Epoch 1 of 5, Step: 2000 of 13750, Training loss: 1.5178719, Training accuracy: 0.5190000, Time: 05_05_2022__20:32:34\n","Epoch 1 of 5, Step: 2100 of 13750, Training loss: 1.4806336, Training accuracy: 0.5326190, Time: 05_05_2022__20:32:55\n","Epoch 1 of 5, Step: 2200 of 13750, Training loss: 1.4447599, Training accuracy: 0.5454545, Time: 05_05_2022__20:33:16\n","Epoch 1 of 5, Step: 2300 of 13750, Training loss: 1.4110288, Training accuracy: 0.5578261, Time: 05_05_2022__20:33:37\n","Epoch 1 of 5, Step: 2400 of 13750, Training loss: 1.3783865, Training accuracy: 0.5696875, Time: 05_05_2022__20:33:58\n","Epoch 1 of 5, Step: 2500 of 13750, Training loss: 1.3503823, Training accuracy: 0.5798000, Time: 05_05_2022__20:34:19\n","Epoch 1 of 5, Step: 2600 of 13750, Training loss: 1.3237749, Training accuracy: 0.5889423, Time: 05_05_2022__20:34:40\n","Epoch 1 of 5, Step: 2700 of 13750, Training loss: 1.2956680, Training accuracy: 0.5989815, Time: 05_05_2022__20:35:01\n","Epoch 1 of 5, Step: 2800 of 13750, Training loss: 1.2693417, Training accuracy: 0.6077679, Time: 05_05_2022__20:35:21\n","Epoch 1 of 5, Step: 2900 of 13750, Training loss: 1.2440138, Training accuracy: 0.6165517, Time: 05_05_2022__20:35:42\n","Epoch 1 of 5, Step: 3000 of 13750, Training loss: 1.2179999, Training accuracy: 0.6254167, Time: 05_05_2022__20:36:03\n","Epoch 1 of 5, Step: 3100 of 13750, Training loss: 1.1957966, Training accuracy: 0.6320968, Time: 05_05_2022__20:36:24\n","Epoch 1 of 5, Step: 3200 of 13750, Training loss: 1.1732750, Training accuracy: 0.6394531, Time: 05_05_2022__20:36:45\n","Epoch 1 of 5, Step: 3300 of 13750, Training loss: 1.1505496, Training accuracy: 0.6473485, Time: 05_05_2022__20:37:06\n","Epoch 1 of 5, Step: 3400 of 13750, Training loss: 1.1307761, Training accuracy: 0.6536765, Time: 05_05_2022__20:37:27\n","Epoch 1 of 5, Step: 3500 of 13750, Training loss: 1.1114026, Training accuracy: 0.6600714, Time: 05_05_2022__20:37:48\n","Epoch 1 of 5, Step: 3600 of 13750, Training loss: 1.0926922, Training accuracy: 0.6662500, Time: 05_05_2022__20:38:09\n","Epoch 1 of 5, Step: 3700 of 13750, Training loss: 1.0752126, Training accuracy: 0.6721622, Time: 05_05_2022__20:38:30\n","Epoch 1 of 5, Step: 3800 of 13750, Training loss: 1.0579398, Training accuracy: 0.6779605, Time: 05_05_2022__20:38:51\n","Epoch 1 of 5, Step: 3900 of 13750, Training loss: 1.0418302, Training accuracy: 0.6832051, Time: 05_05_2022__20:39:12\n","Epoch 1 of 5, Step: 4000 of 13750, Training loss: 1.0258664, Training accuracy: 0.6883750, Time: 05_05_2022__20:39:33\n","Epoch 1 of 5, Step: 4100 of 13750, Training loss: 1.0098131, Training accuracy: 0.6932317, Time: 05_05_2022__20:39:53\n","Epoch 1 of 5, Step: 4200 of 13750, Training loss: 0.9953277, Training accuracy: 0.6981548, Time: 05_05_2022__20:40:14\n","Epoch 1 of 5, Step: 4300 of 13750, Training loss: 0.9811228, Training accuracy: 0.7029070, Time: 05_05_2022__20:40:35\n","Epoch 1 of 5, Step: 4400 of 13750, Training loss: 0.9667498, Training accuracy: 0.7076705, Time: 05_05_2022__20:40:56\n","Epoch 1 of 5, Step: 4500 of 13750, Training loss: 0.9525273, Training accuracy: 0.7122778, Time: 05_05_2022__20:41:17\n","Epoch 1 of 5, Step: 4600 of 13750, Training loss: 0.9379335, Training accuracy: 0.7171196, Time: 05_05_2022__20:41:38\n","Epoch 1 of 5, Step: 4700 of 13750, Training loss: 0.9254148, Training accuracy: 0.7209043, Time: 05_05_2022__20:41:59\n","Epoch 1 of 5, Step: 4800 of 13750, Training loss: 0.9132471, Training accuracy: 0.7246354, Time: 05_05_2022__20:42:20\n","Epoch 1 of 5, Step: 4900 of 13750, Training loss: 0.9017109, Training accuracy: 0.7284694, Time: 05_05_2022__20:42:41\n","Epoch 1 of 5, Step: 5000 of 13750, Training loss: 0.8900171, Training accuracy: 0.7321000, Time: 05_05_2022__20:43:02\n","Epoch 1 of 5, Step: 5100 of 13750, Training loss: 0.8781390, Training accuracy: 0.7360294, Time: 05_05_2022__20:43:23\n","Epoch 1 of 5, Step: 5200 of 13750, Training loss: 0.8665080, Training accuracy: 0.7393750, Time: 05_05_2022__20:43:44\n","Epoch 1 of 5, Step: 5300 of 13750, Training loss: 0.8562455, Training accuracy: 0.7424528, Time: 05_05_2022__20:44:04\n","Epoch 1 of 5, Step: 5400 of 13750, Training loss: 0.8454480, Training accuracy: 0.7458796, Time: 05_05_2022__20:44:25\n","Epoch 1 of 5, Step: 5500 of 13750, Training loss: 0.8345800, Training accuracy: 0.7495000, Time: 05_05_2022__20:44:46\n","Epoch 1 of 5, Step: 5600 of 13750, Training loss: 0.8253344, Training accuracy: 0.7524107, Time: 05_05_2022__20:45:07\n","Epoch 1 of 5, Step: 5700 of 13750, Training loss: 0.8165076, Training accuracy: 0.7552193, Time: 05_05_2022__20:45:28\n","Epoch 1 of 5, Step: 5800 of 13750, Training loss: 0.8066393, Training accuracy: 0.7584052, Time: 05_05_2022__20:45:49\n","Epoch 1 of 5, Step: 5900 of 13750, Training loss: 0.7976779, Training accuracy: 0.7613136, Time: 05_05_2022__20:46:10\n","Epoch 1 of 5, Step: 6000 of 13750, Training loss: 0.7902057, Training accuracy: 0.7637500, Time: 05_05_2022__20:46:31\n","Epoch 1 of 5, Step: 6100 of 13750, Training loss: 0.7813790, Training accuracy: 0.7665164, Time: 05_05_2022__20:46:52\n","Epoch 1 of 5, Step: 6200 of 13750, Training loss: 0.7737569, Training accuracy: 0.7688710, Time: 05_05_2022__20:47:13\n","Epoch 1 of 5, Step: 6300 of 13750, Training loss: 0.7661405, Training accuracy: 0.7712698, Time: 05_05_2022__20:47:34\n","Epoch 1 of 5, Step: 6400 of 13750, Training loss: 0.7581219, Training accuracy: 0.7733203, Time: 05_05_2022__20:47:55\n","Epoch 1 of 5, Step: 6500 of 13750, Training loss: 0.7503484, Training accuracy: 0.7758077, Time: 05_05_2022__20:48:15\n","Epoch 1 of 5, Step: 6600 of 13750, Training loss: 0.7424505, Training accuracy: 0.7782576, Time: 05_05_2022__20:48:36\n","Epoch 1 of 5, Step: 6700 of 13750, Training loss: 0.7344749, Training accuracy: 0.7807090, Time: 05_05_2022__20:48:57\n","Epoch 1 of 5, Step: 6800 of 13750, Training loss: 0.7267036, Training accuracy: 0.7830147, Time: 05_05_2022__20:49:18\n","Epoch 1 of 5, Step: 6900 of 13750, Training loss: 0.7194263, Training accuracy: 0.7852536, Time: 05_05_2022__20:49:39\n","Epoch 1 of 5, Step: 7000 of 13750, Training loss: 0.7124776, Training accuracy: 0.7875000, Time: 05_05_2022__20:50:00\n","Epoch 1 of 5, Step: 7100 of 13750, Training loss: 0.7063359, Training accuracy: 0.7894014, Time: 05_05_2022__20:50:21\n","Epoch 1 of 5, Step: 7200 of 13750, Training loss: 0.6996080, Training accuracy: 0.7915625, Time: 05_05_2022__20:50:42\n","Epoch 1 of 5, Step: 7300 of 13750, Training loss: 0.6931003, Training accuracy: 0.7935959, Time: 05_05_2022__20:51:03\n","Epoch 1 of 5, Step: 7400 of 13750, Training loss: 0.6867651, Training accuracy: 0.7955405, Time: 05_05_2022__20:51:24\n","Epoch 1 of 5, Step: 7500 of 13750, Training loss: 0.6807948, Training accuracy: 0.7973333, Time: 05_05_2022__20:51:45\n","Epoch 1 of 5, Step: 7600 of 13750, Training loss: 0.6747943, Training accuracy: 0.7992105, Time: 05_05_2022__20:52:06\n","Epoch 1 of 5, Step: 7700 of 13750, Training loss: 0.6684537, Training accuracy: 0.8011039, Time: 05_05_2022__20:52:26\n","Epoch 1 of 5, Step: 7800 of 13750, Training loss: 0.6629427, Training accuracy: 0.8025962, Time: 05_05_2022__20:52:47\n","Epoch 1 of 5, Step: 7900 of 13750, Training loss: 0.6578592, Training accuracy: 0.8040823, Time: 05_05_2022__20:53:08\n","Epoch 1 of 5, Step: 8000 of 13750, Training loss: 0.6523665, Training accuracy: 0.8057188, Time: 05_05_2022__20:53:29\n","Epoch 1 of 5, Step: 8100 of 13750, Training loss: 0.6465180, Training accuracy: 0.8074383, Time: 05_05_2022__20:53:50\n","Epoch 1 of 5, Step: 8200 of 13750, Training loss: 0.6411883, Training accuracy: 0.8089329, Time: 05_05_2022__20:54:11\n","Epoch 1 of 5, Step: 8300 of 13750, Training loss: 0.6363750, Training accuracy: 0.8105120, Time: 05_05_2022__20:54:32\n","Epoch 1 of 5, Step: 8400 of 13750, Training loss: 0.6318439, Training accuracy: 0.8119048, Time: 05_05_2022__20:54:53\n","Epoch 1 of 5, Step: 8500 of 13750, Training loss: 0.6265537, Training accuracy: 0.8136176, Time: 05_05_2022__20:55:14\n","Epoch 1 of 5, Step: 8600 of 13750, Training loss: 0.6217789, Training accuracy: 0.8149709, Time: 05_05_2022__20:55:35\n","Epoch 1 of 5, Step: 8700 of 13750, Training loss: 0.6173226, Training accuracy: 0.8163506, Time: 05_05_2022__20:55:56\n","Epoch 1 of 5, Step: 8800 of 13750, Training loss: 0.6129438, Training accuracy: 0.8177273, Time: 05_05_2022__20:56:17\n","Epoch 1 of 5, Step: 8900 of 13750, Training loss: 0.6079798, Training accuracy: 0.8192416, Time: 05_05_2022__20:56:37\n","Epoch 1 of 5, Step: 9000 of 13750, Training loss: 0.6035159, Training accuracy: 0.8205833, Time: 05_05_2022__20:56:58\n","Epoch 1 of 5, Step: 9100 of 13750, Training loss: 0.5988241, Training accuracy: 0.8221429, Time: 05_05_2022__20:57:19\n","Epoch 1 of 5, Step: 9200 of 13750, Training loss: 0.5948521, Training accuracy: 0.8233696, Time: 05_05_2022__20:57:40\n","Epoch 1 of 5, Step: 9300 of 13750, Training loss: 0.5905194, Training accuracy: 0.8247043, Time: 05_05_2022__20:58:01\n","Epoch 1 of 5, Step: 9400 of 13750, Training loss: 0.5864655, Training accuracy: 0.8258777, Time: 05_05_2022__20:58:22\n","Epoch 1 of 5, Step: 9500 of 13750, Training loss: 0.5823027, Training accuracy: 0.8272105, Time: 05_05_2022__20:58:43\n","Epoch 1 of 5, Step: 9600 of 13750, Training loss: 0.5782401, Training accuracy: 0.8284375, Time: 05_05_2022__20:59:04\n","Epoch 1 of 5, Step: 9700 of 13750, Training loss: 0.5737982, Training accuracy: 0.8297680, Time: 05_05_2022__20:59:25\n","Epoch 1 of 5, Step: 9800 of 13750, Training loss: 0.5697046, Training accuracy: 0.8309694, Time: 05_05_2022__20:59:46\n","Epoch 1 of 5, Step: 9900 of 13750, Training loss: 0.5655981, Training accuracy: 0.8322475, Time: 05_05_2022__21:00:07\n","Epoch 1 of 5, Step: 10000 of 13750, Training loss: 0.5615352, Training accuracy: 0.8334000, Time: 05_05_2022__21:00:28\n","Epoch 1 of 5, Step: 10100 of 13750, Training loss: 0.5580446, Training accuracy: 0.8344802, Time: 05_05_2022__21:00:49\n","Epoch 1 of 5, Step: 10200 of 13750, Training loss: 0.5542656, Training accuracy: 0.8355882, Time: 05_05_2022__21:01:10\n","Epoch 1 of 5, Step: 10300 of 13750, Training loss: 0.5505141, Training accuracy: 0.8367476, Time: 05_05_2022__21:01:30\n","Epoch 1 of 5, Step: 10400 of 13750, Training loss: 0.5471254, Training accuracy: 0.8377644, Time: 05_05_2022__21:01:51\n","Epoch 1 of 5, Step: 10500 of 13750, Training loss: 0.5433828, Training accuracy: 0.8389048, Time: 05_05_2022__21:02:12\n","Epoch 1 of 5, Step: 10600 of 13750, Training loss: 0.5399088, Training accuracy: 0.8398821, Time: 05_05_2022__21:02:33\n","Epoch 1 of 5, Step: 10700 of 13750, Training loss: 0.5364127, Training accuracy: 0.8409346, Time: 05_05_2022__21:02:54\n","Epoch 1 of 5, Step: 10800 of 13750, Training loss: 0.5333821, Training accuracy: 0.8418056, Time: 05_05_2022__21:03:15\n","Epoch 1 of 5, Step: 10900 of 13750, Training loss: 0.5299336, Training accuracy: 0.8428211, Time: 05_05_2022__21:03:36\n","Epoch 1 of 5, Step: 11000 of 13750, Training loss: 0.5263518, Training accuracy: 0.8438636, Time: 05_05_2022__21:03:57\n","Epoch 1 of 5, Step: 11100 of 13750, Training loss: 0.5232481, Training accuracy: 0.8447523, Time: 05_05_2022__21:04:18\n","Epoch 1 of 5, Step: 11200 of 13750, Training loss: 0.5200853, Training accuracy: 0.8456473, Time: 05_05_2022__21:04:39\n","Epoch 1 of 5, Step: 11300 of 13750, Training loss: 0.5166342, Training accuracy: 0.8467478, Time: 05_05_2022__21:05:00\n","Epoch 1 of 5, Step: 11400 of 13750, Training loss: 0.5135027, Training accuracy: 0.8476754, Time: 05_05_2022__21:05:21\n","Epoch 1 of 5, Step: 11500 of 13750, Training loss: 0.5107807, Training accuracy: 0.8485870, Time: 05_05_2022__21:05:41\n","Epoch 1 of 5, Step: 11600 of 13750, Training loss: 0.5077197, Training accuracy: 0.8495259, Time: 05_05_2022__21:06:02\n","Epoch 1 of 5, Step: 11700 of 13750, Training loss: 0.5046267, Training accuracy: 0.8504060, Time: 05_05_2022__21:06:23\n","Epoch 1 of 5, Step: 11800 of 13750, Training loss: 0.5017289, Training accuracy: 0.8512288, Time: 05_05_2022__21:06:44\n","Epoch 1 of 5, Step: 11900 of 13750, Training loss: 0.4989695, Training accuracy: 0.8520378, Time: 05_05_2022__21:07:05\n","Epoch 1 of 5, Step: 12000 of 13750, Training loss: 0.4962739, Training accuracy: 0.8527917, Time: 05_05_2022__21:07:26\n","Epoch 1 of 5, Step: 12100 of 13750, Training loss: 0.4936530, Training accuracy: 0.8535331, Time: 05_05_2022__21:07:47\n","Epoch 1 of 5, Step: 12200 of 13750, Training loss: 0.4911109, Training accuracy: 0.8542828, Time: 05_05_2022__21:08:08\n","Epoch 1 of 5, Step: 12300 of 13750, Training loss: 0.4883308, Training accuracy: 0.8550610, Time: 05_05_2022__21:08:29\n","Epoch 1 of 5, Step: 12400 of 13750, Training loss: 0.4854927, Training accuracy: 0.8559073, Time: 05_05_2022__21:08:50\n","Epoch 1 of 5, Step: 12500 of 13750, Training loss: 0.4830584, Training accuracy: 0.8566000, Time: 05_05_2022__21:09:11\n","Epoch 1 of 5, Step: 12600 of 13750, Training loss: 0.4801675, Training accuracy: 0.8574603, Time: 05_05_2022__21:09:32\n","Epoch 1 of 5, Step: 12700 of 13750, Training loss: 0.4774579, Training accuracy: 0.8583071, Time: 05_05_2022__21:09:53\n","Epoch 1 of 5, Step: 12800 of 13750, Training loss: 0.4749228, Training accuracy: 0.8591016, Time: 05_05_2022__21:10:13\n","Epoch 1 of 5, Step: 12900 of 13750, Training loss: 0.4725534, Training accuracy: 0.8598643, Time: 05_05_2022__21:10:34\n","Epoch 1 of 5, Step: 13000 of 13750, Training loss: 0.4702140, Training accuracy: 0.8605385, Time: 05_05_2022__21:10:55\n","Epoch 1 of 5, Step: 13100 of 13750, Training loss: 0.4682600, Training accuracy: 0.8611260, Time: 05_05_2022__21:11:16\n","Epoch 1 of 5, Step: 13200 of 13750, Training loss: 0.4656747, Training accuracy: 0.8619318, Time: 05_05_2022__21:11:37\n","Epoch 1 of 5, Step: 13300 of 13750, Training loss: 0.4634364, Training accuracy: 0.8626504, Time: 05_05_2022__21:11:58\n","Epoch 1 of 5, Step: 13400 of 13750, Training loss: 0.4609531, Training accuracy: 0.8633769, Time: 05_05_2022__21:12:19\n","Epoch 1 of 5, Step: 13500 of 13750, Training loss: 0.4586250, Training accuracy: 0.8640741, Time: 05_05_2022__21:12:40\n","Epoch 1 of 5, Step: 13600 of 13750, Training loss: 0.4563066, Training accuracy: 0.8647610, Time: 05_05_2022__21:13:01\n","Epoch 1 of 5, Step: 13700 of 13750, Training loss: 0.4539063, Training accuracy: 0.8655109, Time: 05_05_2022__21:13:22\n","Epoch 1 of 5, Average training loss: 0.4527440, Average training accuracy: 0.8658182, Time: 05_05_2022__21:13:32\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d74cbd27fd7f41aa9c659f4423faff82"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.1021350, Validation accuracy: 0.9650000, Time: 05_05_2022__21:13:37 | Loss decreased from inf to 0.1029910 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.1002796, Validation accuracy: 0.9650000, Time: 05_05_2022__21:13:45 | Loss decreased from 0.1029910 to 0.1007397 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.1078603, Validation accuracy: 0.9658333, Time: 05_05_2022__21:13:53\n","Step: 400 of 1250, Validation loss: 0.1017644, Validation accuracy: 0.9687500, Time: 05_05_2022__21:13:58\n","Step: 500 of 1250, Validation loss: 0.1010803, Validation accuracy: 0.9685000, Time: 05_05_2022__21:14:03\n","Step: 600 of 1250, Validation loss: 0.0963086, Validation accuracy: 0.9704167, Time: 05_05_2022__21:14:09 | Loss decreased from 0.1007397 to 0.0964344 .... Saving the model\n","Step: 700 of 1250, Validation loss: 0.0911790, Validation accuracy: 0.9714286, Time: 05_05_2022__21:14:16 | Loss decreased from 0.0964344 to 0.0899116 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0940983, Validation accuracy: 0.9709375, Time: 05_05_2022__21:14:24\n","Step: 900 of 1250, Validation loss: 0.0978374, Validation accuracy: 0.9708333, Time: 05_05_2022__21:14:29\n","Step: 1000 of 1250, Validation loss: 0.1021896, Validation accuracy: 0.9702500, Time: 05_05_2022__21:14:35\n","Step: 1100 of 1250, Validation loss: 0.0993811, Validation accuracy: 0.9715909, Time: 05_05_2022__21:14:40\n","Step: 1200 of 1250, Validation loss: 0.0973701, Validation accuracy: 0.9722917, Time: 05_05_2022__21:14:45\n","Average validation loss: 0.0976152, Average validation accuracy: 0.9720000, Time: 05_05_2022__21:14:48\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9960b9457fd5437084eba4b28666c5e6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 13750, Training loss: 0.1239935, Training accuracy: 0.9675000, Time: 05_05_2022__21:15:09\n","Epoch 2 of 5, Step: 200 of 13750, Training loss: 0.1213805, Training accuracy: 0.9725000, Time: 05_05_2022__21:15:30\n","Epoch 2 of 5, Step: 300 of 13750, Training loss: 0.1306103, Training accuracy: 0.9700000, Time: 05_05_2022__21:15:51\n","Epoch 2 of 5, Step: 400 of 13750, Training loss: 0.1331042, Training accuracy: 0.9675000, Time: 05_05_2022__21:16:12\n","Epoch 2 of 5, Step: 500 of 13750, Training loss: 0.1323460, Training accuracy: 0.9640000, Time: 05_05_2022__21:16:33\n","Epoch 2 of 5, Step: 600 of 13750, Training loss: 0.1316402, Training accuracy: 0.9625000, Time: 05_05_2022__21:16:53\n","Epoch 2 of 5, Step: 700 of 13750, Training loss: 0.1345888, Training accuracy: 0.9614286, Time: 05_05_2022__21:17:14\n","Epoch 2 of 5, Step: 800 of 13750, Training loss: 0.1349005, Training accuracy: 0.9609375, Time: 05_05_2022__21:17:35\n","Epoch 2 of 5, Step: 900 of 13750, Training loss: 0.1346393, Training accuracy: 0.9611111, Time: 05_05_2022__21:17:56\n","Epoch 2 of 5, Step: 1000 of 13750, Training loss: 0.1338367, Training accuracy: 0.9615000, Time: 05_05_2022__21:18:17\n","Epoch 2 of 5, Step: 1100 of 13750, Training loss: 0.1354317, Training accuracy: 0.9604545, Time: 05_05_2022__21:18:38\n","Epoch 2 of 5, Step: 1200 of 13750, Training loss: 0.1366687, Training accuracy: 0.9606250, Time: 05_05_2022__21:18:59\n","Epoch 2 of 5, Step: 1300 of 13750, Training loss: 0.1348338, Training accuracy: 0.9603846, Time: 05_05_2022__21:19:20\n","Epoch 2 of 5, Step: 1400 of 13750, Training loss: 0.1334786, Training accuracy: 0.9603571, Time: 05_05_2022__21:19:41\n","Epoch 2 of 5, Step: 1500 of 13750, Training loss: 0.1329091, Training accuracy: 0.9606667, Time: 05_05_2022__21:20:02\n","Epoch 2 of 5, Step: 1600 of 13750, Training loss: 0.1342188, Training accuracy: 0.9606250, Time: 05_05_2022__21:20:23\n","Epoch 2 of 5, Step: 1700 of 13750, Training loss: 0.1345343, Training accuracy: 0.9604412, Time: 05_05_2022__21:20:44\n","Epoch 2 of 5, Step: 1800 of 13750, Training loss: 0.1330740, Training accuracy: 0.9611111, Time: 05_05_2022__21:21:05\n","Epoch 2 of 5, Step: 1900 of 13750, Training loss: 0.1329257, Training accuracy: 0.9610526, Time: 05_05_2022__21:21:26\n","Epoch 2 of 5, Step: 2000 of 13750, Training loss: 0.1314229, Training accuracy: 0.9613750, Time: 05_05_2022__21:21:47\n","Epoch 2 of 5, Step: 2100 of 13750, Training loss: 0.1304162, Training accuracy: 0.9614286, Time: 05_05_2022__21:22:08\n","Epoch 2 of 5, Step: 2200 of 13750, Training loss: 0.1301369, Training accuracy: 0.9611364, Time: 05_05_2022__21:22:29\n","Epoch 2 of 5, Step: 2300 of 13750, Training loss: 0.1294880, Training accuracy: 0.9616304, Time: 05_05_2022__21:22:50\n","Epoch 2 of 5, Step: 2400 of 13750, Training loss: 0.1309993, Training accuracy: 0.9610417, Time: 05_05_2022__21:23:11\n","Epoch 2 of 5, Step: 2500 of 13750, Training loss: 0.1309259, Training accuracy: 0.9610000, Time: 05_05_2022__21:23:32\n","Epoch 2 of 5, Step: 2600 of 13750, Training loss: 0.1326160, Training accuracy: 0.9608654, Time: 05_05_2022__21:23:52\n","Epoch 2 of 5, Step: 2700 of 13750, Training loss: 0.1319847, Training accuracy: 0.9611111, Time: 05_05_2022__21:24:13\n","Epoch 2 of 5, Step: 2800 of 13750, Training loss: 0.1328152, Training accuracy: 0.9610714, Time: 05_05_2022__21:24:34\n","Epoch 2 of 5, Step: 2900 of 13750, Training loss: 0.1332212, Training accuracy: 0.9611207, Time: 05_05_2022__21:24:55\n","Epoch 2 of 5, Step: 3000 of 13750, Training loss: 0.1323402, Training accuracy: 0.9614167, Time: 05_05_2022__21:25:16\n","Epoch 2 of 5, Step: 3100 of 13750, Training loss: 0.1320453, Training accuracy: 0.9612903, Time: 05_05_2022__21:25:37\n","Epoch 2 of 5, Step: 3200 of 13750, Training loss: 0.1308608, Training accuracy: 0.9617187, Time: 05_05_2022__21:25:58\n","Epoch 2 of 5, Step: 3300 of 13750, Training loss: 0.1301309, Training accuracy: 0.9615909, Time: 05_05_2022__21:26:19\n","Epoch 2 of 5, Step: 3400 of 13750, Training loss: 0.1296465, Training accuracy: 0.9615441, Time: 05_05_2022__21:26:40\n","Epoch 2 of 5, Step: 3500 of 13750, Training loss: 0.1292002, Training accuracy: 0.9616429, Time: 05_05_2022__21:27:01\n","Epoch 2 of 5, Step: 3600 of 13750, Training loss: 0.1289364, Training accuracy: 0.9617361, Time: 05_05_2022__21:27:22\n","Epoch 2 of 5, Step: 3700 of 13750, Training loss: 0.1294839, Training accuracy: 0.9614865, Time: 05_05_2022__21:27:43\n","Epoch 2 of 5, Step: 3800 of 13750, Training loss: 0.1289853, Training accuracy: 0.9617763, Time: 05_05_2022__21:28:04\n","Epoch 2 of 5, Step: 3900 of 13750, Training loss: 0.1289987, Training accuracy: 0.9617949, Time: 05_05_2022__21:28:25\n","Epoch 2 of 5, Step: 4000 of 13750, Training loss: 0.1290021, Training accuracy: 0.9616875, Time: 05_05_2022__21:28:46\n","Epoch 2 of 5, Step: 4100 of 13750, Training loss: 0.1286672, Training accuracy: 0.9618293, Time: 05_05_2022__21:29:07\n","Epoch 2 of 5, Step: 4200 of 13750, Training loss: 0.1295314, Training accuracy: 0.9616071, Time: 05_05_2022__21:29:28\n","Epoch 2 of 5, Step: 4300 of 13750, Training loss: 0.1290243, Training accuracy: 0.9617442, Time: 05_05_2022__21:29:49\n","Epoch 2 of 5, Step: 4400 of 13750, Training loss: 0.1284880, Training accuracy: 0.9621023, Time: 05_05_2022__21:30:10\n","Epoch 2 of 5, Step: 4500 of 13750, Training loss: 0.1276661, Training accuracy: 0.9622222, Time: 05_05_2022__21:30:31\n","Epoch 2 of 5, Step: 4600 of 13750, Training loss: 0.1266349, Training accuracy: 0.9626087, Time: 05_05_2022__21:30:52\n","Epoch 2 of 5, Step: 4700 of 13750, Training loss: 0.1264674, Training accuracy: 0.9625532, Time: 05_05_2022__21:31:13\n","Epoch 2 of 5, Step: 4800 of 13750, Training loss: 0.1269365, Training accuracy: 0.9622917, Time: 05_05_2022__21:31:34\n","Epoch 2 of 5, Step: 4900 of 13750, Training loss: 0.1267542, Training accuracy: 0.9621939, Time: 05_05_2022__21:31:55\n","Epoch 2 of 5, Step: 5000 of 13750, Training loss: 0.1263458, Training accuracy: 0.9623500, Time: 05_05_2022__21:32:16\n","Epoch 2 of 5, Step: 5100 of 13750, Training loss: 0.1255242, Training accuracy: 0.9626471, Time: 05_05_2022__21:32:37\n","Epoch 2 of 5, Step: 5200 of 13750, Training loss: 0.1253530, Training accuracy: 0.9625962, Time: 05_05_2022__21:32:58\n","Epoch 2 of 5, Step: 5300 of 13750, Training loss: 0.1253672, Training accuracy: 0.9625943, Time: 05_05_2022__21:33:19\n","Epoch 2 of 5, Step: 5400 of 13750, Training loss: 0.1249742, Training accuracy: 0.9627315, Time: 05_05_2022__21:33:40\n","Epoch 2 of 5, Step: 5500 of 13750, Training loss: 0.1245918, Training accuracy: 0.9629091, Time: 05_05_2022__21:34:00\n","Epoch 2 of 5, Step: 5600 of 13750, Training loss: 0.1253750, Training accuracy: 0.9627232, Time: 05_05_2022__21:34:21\n","Epoch 2 of 5, Step: 5700 of 13750, Training loss: 0.1256472, Training accuracy: 0.9627193, Time: 05_05_2022__21:34:42\n","Epoch 2 of 5, Step: 5800 of 13750, Training loss: 0.1249072, Training accuracy: 0.9628879, Time: 05_05_2022__21:35:03\n","Epoch 2 of 5, Step: 5900 of 13750, Training loss: 0.1241012, Training accuracy: 0.9631780, Time: 05_05_2022__21:35:24\n","Epoch 2 of 5, Step: 6000 of 13750, Training loss: 0.1240983, Training accuracy: 0.9630833, Time: 05_05_2022__21:35:45\n","Epoch 2 of 5, Step: 6100 of 13750, Training loss: 0.1233009, Training accuracy: 0.9633197, Time: 05_05_2022__21:36:06\n","Epoch 2 of 5, Step: 6200 of 13750, Training loss: 0.1235447, Training accuracy: 0.9632258, Time: 05_05_2022__21:36:27\n","Epoch 2 of 5, Step: 6300 of 13750, Training loss: 0.1238013, Training accuracy: 0.9632143, Time: 05_05_2022__21:36:48\n","Epoch 2 of 5, Step: 6400 of 13750, Training loss: 0.1235177, Training accuracy: 0.9631250, Time: 05_05_2022__21:37:09\n","Epoch 2 of 5, Step: 6500 of 13750, Training loss: 0.1236737, Training accuracy: 0.9631923, Time: 05_05_2022__21:37:30\n","Epoch 2 of 5, Step: 6600 of 13750, Training loss: 0.1232500, Training accuracy: 0.9634091, Time: 05_05_2022__21:37:51\n","Epoch 2 of 5, Step: 6700 of 13750, Training loss: 0.1228905, Training accuracy: 0.9635821, Time: 05_05_2022__21:38:12\n","Epoch 2 of 5, Step: 6800 of 13750, Training loss: 0.1223342, Training accuracy: 0.9637500, Time: 05_05_2022__21:38:33\n","Epoch 2 of 5, Step: 6900 of 13750, Training loss: 0.1221271, Training accuracy: 0.9638406, Time: 05_05_2022__21:38:54\n","Epoch 2 of 5, Step: 7000 of 13750, Training loss: 0.1222363, Training accuracy: 0.9638571, Time: 05_05_2022__21:39:15\n","Epoch 2 of 5, Step: 7100 of 13750, Training loss: 0.1219499, Training accuracy: 0.9640141, Time: 05_05_2022__21:39:36\n","Epoch 2 of 5, Step: 7200 of 13750, Training loss: 0.1216636, Training accuracy: 0.9641319, Time: 05_05_2022__21:39:57\n","Epoch 2 of 5, Step: 7300 of 13750, Training loss: 0.1210466, Training accuracy: 0.9642808, Time: 05_05_2022__21:40:18\n","Epoch 2 of 5, Step: 7400 of 13750, Training loss: 0.1207639, Training accuracy: 0.9644257, Time: 05_05_2022__21:40:39\n","Epoch 2 of 5, Step: 7500 of 13750, Training loss: 0.1206071, Training accuracy: 0.9646333, Time: 05_05_2022__21:41:00\n","Epoch 2 of 5, Step: 7600 of 13750, Training loss: 0.1205952, Training accuracy: 0.9646053, Time: 05_05_2022__21:41:21\n","Epoch 2 of 5, Step: 7700 of 13750, Training loss: 0.1200192, Training accuracy: 0.9647078, Time: 05_05_2022__21:41:42\n","Epoch 2 of 5, Step: 7800 of 13750, Training loss: 0.1200579, Training accuracy: 0.9646154, Time: 05_05_2022__21:42:03\n","Epoch 2 of 5, Step: 7900 of 13750, Training loss: 0.1200359, Training accuracy: 0.9645570, Time: 05_05_2022__21:42:24\n","Epoch 2 of 5, Step: 8000 of 13750, Training loss: 0.1201186, Training accuracy: 0.9645000, Time: 05_05_2022__21:42:44\n","Epoch 2 of 5, Step: 8100 of 13750, Training loss: 0.1194801, Training accuracy: 0.9647531, Time: 05_05_2022__21:43:05\n","Epoch 2 of 5, Step: 8200 of 13750, Training loss: 0.1191433, Training accuracy: 0.9648171, Time: 05_05_2022__21:43:26\n","Epoch 2 of 5, Step: 8300 of 13750, Training loss: 0.1198363, Training accuracy: 0.9645181, Time: 05_05_2022__21:43:47\n","Epoch 2 of 5, Step: 8400 of 13750, Training loss: 0.1196913, Training accuracy: 0.9646131, Time: 05_05_2022__21:44:08\n","Epoch 2 of 5, Step: 8500 of 13750, Training loss: 0.1193674, Training accuracy: 0.9647353, Time: 05_05_2022__21:44:29\n","Epoch 2 of 5, Step: 8600 of 13750, Training loss: 0.1190171, Training accuracy: 0.9648837, Time: 05_05_2022__21:44:50\n","Epoch 2 of 5, Step: 8700 of 13750, Training loss: 0.1186352, Training accuracy: 0.9650000, Time: 05_05_2022__21:45:11\n","Epoch 2 of 5, Step: 8800 of 13750, Training loss: 0.1189349, Training accuracy: 0.9649432, Time: 05_05_2022__21:45:32\n","Epoch 2 of 5, Step: 8900 of 13750, Training loss: 0.1185344, Training accuracy: 0.9650281, Time: 05_05_2022__21:45:53\n","Epoch 2 of 5, Step: 9000 of 13750, Training loss: 0.1184103, Training accuracy: 0.9649722, Time: 05_05_2022__21:46:14\n","Epoch 2 of 5, Step: 9100 of 13750, Training loss: 0.1184315, Training accuracy: 0.9649451, Time: 05_05_2022__21:46:35\n","Epoch 2 of 5, Step: 9200 of 13750, Training loss: 0.1186802, Training accuracy: 0.9647826, Time: 05_05_2022__21:46:56\n","Epoch 2 of 5, Step: 9300 of 13750, Training loss: 0.1184576, Training accuracy: 0.9648925, Time: 05_05_2022__21:47:17\n","Epoch 2 of 5, Step: 9400 of 13750, Training loss: 0.1184194, Training accuracy: 0.9648670, Time: 05_05_2022__21:47:38\n","Epoch 2 of 5, Step: 9500 of 13750, Training loss: 0.1181855, Training accuracy: 0.9648947, Time: 05_05_2022__21:47:59\n","Epoch 2 of 5, Step: 9600 of 13750, Training loss: 0.1180284, Training accuracy: 0.9648698, Time: 05_05_2022__21:48:20\n","Epoch 2 of 5, Step: 9700 of 13750, Training loss: 0.1176632, Training accuracy: 0.9649227, Time: 05_05_2022__21:48:41\n","Epoch 2 of 5, Step: 9800 of 13750, Training loss: 0.1177171, Training accuracy: 0.9649235, Time: 05_05_2022__21:49:02\n","Epoch 2 of 5, Step: 9900 of 13750, Training loss: 0.1173975, Training accuracy: 0.9649747, Time: 05_05_2022__21:49:23\n","Epoch 2 of 5, Step: 10000 of 13750, Training loss: 0.1169798, Training accuracy: 0.9651250, Time: 05_05_2022__21:49:44\n","Epoch 2 of 5, Step: 10100 of 13750, Training loss: 0.1170772, Training accuracy: 0.9651485, Time: 05_05_2022__21:50:05\n","Epoch 2 of 5, Step: 10200 of 13750, Training loss: 0.1166849, Training accuracy: 0.9653431, Time: 05_05_2022__21:50:26\n","Epoch 2 of 5, Step: 10300 of 13750, Training loss: 0.1162768, Training accuracy: 0.9654854, Time: 05_05_2022__21:50:47\n","Epoch 2 of 5, Step: 10400 of 13750, Training loss: 0.1159892, Training accuracy: 0.9655769, Time: 05_05_2022__21:51:08\n","Epoch 2 of 5, Step: 10500 of 13750, Training loss: 0.1158615, Training accuracy: 0.9655476, Time: 05_05_2022__21:51:28\n","Epoch 2 of 5, Step: 10600 of 13750, Training loss: 0.1156466, Training accuracy: 0.9657075, Time: 05_05_2022__21:51:49\n","Epoch 2 of 5, Step: 10700 of 13750, Training loss: 0.1156253, Training accuracy: 0.9656542, Time: 05_05_2022__21:52:10\n","Epoch 2 of 5, Step: 10800 of 13750, Training loss: 0.1155298, Training accuracy: 0.9657176, Time: 05_05_2022__21:52:31\n","Epoch 2 of 5, Step: 10900 of 13750, Training loss: 0.1154295, Training accuracy: 0.9657339, Time: 05_05_2022__21:52:52\n","Epoch 2 of 5, Step: 11000 of 13750, Training loss: 0.1150362, Training accuracy: 0.9659318, Time: 05_05_2022__21:53:13\n","Epoch 2 of 5, Step: 11100 of 13750, Training loss: 0.1148900, Training accuracy: 0.9659009, Time: 05_05_2022__21:53:34\n","Epoch 2 of 5, Step: 11200 of 13750, Training loss: 0.1145011, Training accuracy: 0.9660268, Time: 05_05_2022__21:53:55\n","Epoch 2 of 5, Step: 11300 of 13750, Training loss: 0.1144289, Training accuracy: 0.9659956, Time: 05_05_2022__21:54:16\n","Epoch 2 of 5, Step: 11400 of 13750, Training loss: 0.1141016, Training accuracy: 0.9660965, Time: 05_05_2022__21:54:37\n","Epoch 2 of 5, Step: 11500 of 13750, Training loss: 0.1142385, Training accuracy: 0.9660652, Time: 05_05_2022__21:54:58\n","Epoch 2 of 5, Step: 11600 of 13750, Training loss: 0.1140300, Training accuracy: 0.9661853, Time: 05_05_2022__21:55:19\n","Epoch 2 of 5, Step: 11700 of 13750, Training loss: 0.1136210, Training accuracy: 0.9662393, Time: 05_05_2022__21:55:40\n","Epoch 2 of 5, Step: 11800 of 13750, Training loss: 0.1135685, Training accuracy: 0.9661653, Time: 05_05_2022__21:56:01\n","Epoch 2 of 5, Step: 11900 of 13750, Training loss: 0.1134726, Training accuracy: 0.9661134, Time: 05_05_2022__21:56:22\n","Epoch 2 of 5, Step: 12000 of 13750, Training loss: 0.1130837, Training accuracy: 0.9662292, Time: 05_05_2022__21:56:43\n","Epoch 2 of 5, Step: 12100 of 13750, Training loss: 0.1129112, Training accuracy: 0.9662190, Time: 05_05_2022__21:57:04\n","Epoch 2 of 5, Step: 12200 of 13750, Training loss: 0.1129159, Training accuracy: 0.9661885, Time: 05_05_2022__21:57:25\n","Epoch 2 of 5, Step: 12300 of 13750, Training loss: 0.1124945, Training accuracy: 0.9663008, Time: 05_05_2022__21:57:46\n","Epoch 2 of 5, Step: 12400 of 13750, Training loss: 0.1122193, Training accuracy: 0.9663911, Time: 05_05_2022__21:58:07\n","Epoch 2 of 5, Step: 12500 of 13750, Training loss: 0.1121136, Training accuracy: 0.9664400, Time: 05_05_2022__21:58:28\n","Epoch 2 of 5, Step: 12600 of 13750, Training loss: 0.1116901, Training accuracy: 0.9666270, Time: 05_05_2022__21:58:49\n","Epoch 2 of 5, Step: 12700 of 13750, Training loss: 0.1115040, Training accuracy: 0.9666732, Time: 05_05_2022__21:59:10\n","Epoch 2 of 5, Step: 12800 of 13750, Training loss: 0.1113164, Training accuracy: 0.9667383, Time: 05_05_2022__21:59:31\n","Epoch 2 of 5, Step: 12900 of 13750, Training loss: 0.1114209, Training accuracy: 0.9667442, Time: 05_05_2022__21:59:51\n","Epoch 2 of 5, Step: 13000 of 13750, Training loss: 0.1112815, Training accuracy: 0.9667885, Time: 05_05_2022__22:00:12\n","Epoch 2 of 5, Step: 13100 of 13750, Training loss: 0.1114593, Training accuracy: 0.9667939, Time: 05_05_2022__22:00:33\n","Epoch 2 of 5, Step: 13200 of 13750, Training loss: 0.1112348, Training accuracy: 0.9668561, Time: 05_05_2022__22:00:54\n","Epoch 2 of 5, Step: 13300 of 13750, Training loss: 0.1111719, Training accuracy: 0.9668609, Time: 05_05_2022__22:01:15\n","Epoch 2 of 5, Step: 13400 of 13750, Training loss: 0.1111435, Training accuracy: 0.9668470, Time: 05_05_2022__22:01:36\n","Epoch 2 of 5, Step: 13500 of 13750, Training loss: 0.1108427, Training accuracy: 0.9669259, Time: 05_05_2022__22:01:57\n","Epoch 2 of 5, Step: 13600 of 13750, Training loss: 0.1106583, Training accuracy: 0.9669853, Time: 05_05_2022__22:02:18\n","Epoch 2 of 5, Step: 13700 of 13750, Training loss: 0.1103870, Training accuracy: 0.9670438, Time: 05_05_2022__22:02:39\n","Epoch 2 of 5, Average training loss: 0.1103444, Average training accuracy: 0.9670182, Time: 05_05_2022__22:02:50\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86fa20f1f0974fdba512e0a768291444"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0644488, Validation accuracy: 0.9800000, Time: 05_05_2022__22:02:55 | Loss decreased from 0.0899116 to 0.0650840 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0617933, Validation accuracy: 0.9812500, Time: 05_05_2022__22:03:02 | Loss decreased from 0.0650840 to 0.0620826 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.0638434, Validation accuracy: 0.9816667, Time: 05_05_2022__22:03:10\n","Step: 400 of 1250, Validation loss: 0.0612177, Validation accuracy: 0.9825000, Time: 05_05_2022__22:03:15 | Loss decreased from 0.0620826 to 0.0612157 .... Saving the model\n","Step: 500 of 1250, Validation loss: 0.0602691, Validation accuracy: 0.9815000, Time: 05_05_2022__22:03:23 | Loss decreased from 0.0612157 to 0.0603374 .... Saving the model\n","Step: 600 of 1250, Validation loss: 0.0584138, Validation accuracy: 0.9825000, Time: 05_05_2022__22:03:30 | Loss decreased from 0.0603374 to 0.0584907 .... Saving the model\n","Step: 700 of 1250, Validation loss: 0.0554407, Validation accuracy: 0.9825000, Time: 05_05_2022__22:03:38 | Loss decreased from 0.0584907 to 0.0544811 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0568677, Validation accuracy: 0.9825000, Time: 05_05_2022__22:03:45\n","Step: 900 of 1250, Validation loss: 0.0575243, Validation accuracy: 0.9822222, Time: 05_05_2022__22:03:51\n","Step: 1000 of 1250, Validation loss: 0.0593074, Validation accuracy: 0.9820000, Time: 05_05_2022__22:03:56\n","Step: 1100 of 1250, Validation loss: 0.0572256, Validation accuracy: 0.9831818, Time: 05_05_2022__22:04:01\n","Step: 1200 of 1250, Validation loss: 0.0574589, Validation accuracy: 0.9827083, Time: 05_05_2022__22:04:07\n","Average validation loss: 0.0576995, Average validation accuracy: 0.9828000, Time: 05_05_2022__22:04:09\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb42e8d2b2154066a0fcf44324ba7ee7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 13750, Training loss: 0.0638712, Training accuracy: 0.9800000, Time: 05_05_2022__22:04:30\n","Epoch 3 of 5, Step: 200 of 13750, Training loss: 0.0647181, Training accuracy: 0.9787500, Time: 05_05_2022__22:04:51\n","Epoch 3 of 5, Step: 300 of 13750, Training loss: 0.0751066, Training accuracy: 0.9750000, Time: 05_05_2022__22:05:12\n","Epoch 3 of 5, Step: 400 of 13750, Training loss: 0.0776349, Training accuracy: 0.9743750, Time: 05_05_2022__22:05:33\n","Epoch 3 of 5, Step: 500 of 13750, Training loss: 0.0804146, Training accuracy: 0.9730000, Time: 05_05_2022__22:05:54\n","Epoch 3 of 5, Step: 600 of 13750, Training loss: 0.0853864, Training accuracy: 0.9720833, Time: 05_05_2022__22:06:15\n","Epoch 3 of 5, Step: 700 of 13750, Training loss: 0.0867448, Training accuracy: 0.9714286, Time: 05_05_2022__22:06:36\n","Epoch 3 of 5, Step: 800 of 13750, Training loss: 0.0866528, Training accuracy: 0.9718750, Time: 05_05_2022__22:06:57\n","Epoch 3 of 5, Step: 900 of 13750, Training loss: 0.0894833, Training accuracy: 0.9713889, Time: 05_05_2022__22:07:18\n","Epoch 3 of 5, Step: 1000 of 13750, Training loss: 0.0901414, Training accuracy: 0.9710000, Time: 05_05_2022__22:07:39\n","Epoch 3 of 5, Step: 1100 of 13750, Training loss: 0.0920410, Training accuracy: 0.9700000, Time: 05_05_2022__22:08:00\n","Epoch 3 of 5, Step: 1200 of 13750, Training loss: 0.0923064, Training accuracy: 0.9704167, Time: 05_05_2022__22:08:21\n","Epoch 3 of 5, Step: 1300 of 13750, Training loss: 0.0908481, Training accuracy: 0.9717308, Time: 05_05_2022__22:08:42\n","Epoch 3 of 5, Step: 1400 of 13750, Training loss: 0.0902693, Training accuracy: 0.9721429, Time: 05_05_2022__22:09:03\n","Epoch 3 of 5, Step: 1500 of 13750, Training loss: 0.0921130, Training accuracy: 0.9711667, Time: 05_05_2022__22:09:24\n","Epoch 3 of 5, Step: 1600 of 13750, Training loss: 0.0923333, Training accuracy: 0.9709375, Time: 05_05_2022__22:09:45\n","Epoch 3 of 5, Step: 1700 of 13750, Training loss: 0.0910029, Training accuracy: 0.9714706, Time: 05_05_2022__22:10:06\n","Epoch 3 of 5, Step: 1800 of 13750, Training loss: 0.0910884, Training accuracy: 0.9718056, Time: 05_05_2022__22:10:27\n","Epoch 3 of 5, Step: 1900 of 13750, Training loss: 0.0905402, Training accuracy: 0.9719737, Time: 05_05_2022__22:10:48\n","Epoch 3 of 5, Step: 2000 of 13750, Training loss: 0.0887199, Training accuracy: 0.9723750, Time: 05_05_2022__22:11:09\n","Epoch 3 of 5, Step: 2100 of 13750, Training loss: 0.0873311, Training accuracy: 0.9729762, Time: 05_05_2022__22:11:30\n","Epoch 3 of 5, Step: 2200 of 13750, Training loss: 0.0866748, Training accuracy: 0.9732955, Time: 05_05_2022__22:11:51\n","Epoch 3 of 5, Step: 2300 of 13750, Training loss: 0.0860011, Training accuracy: 0.9738043, Time: 05_05_2022__22:12:12\n","Epoch 3 of 5, Step: 2400 of 13750, Training loss: 0.0872708, Training accuracy: 0.9737500, Time: 05_05_2022__22:12:33\n","Epoch 3 of 5, Step: 2500 of 13750, Training loss: 0.0862702, Training accuracy: 0.9741000, Time: 05_05_2022__22:12:54\n","Epoch 3 of 5, Step: 2600 of 13750, Training loss: 0.0874819, Training accuracy: 0.9734615, Time: 05_05_2022__22:13:15\n","Epoch 3 of 5, Step: 2700 of 13750, Training loss: 0.0870521, Training accuracy: 0.9735185, Time: 05_05_2022__22:13:36\n","Epoch 3 of 5, Step: 2800 of 13750, Training loss: 0.0872825, Training accuracy: 0.9733929, Time: 05_05_2022__22:13:56\n","Epoch 3 of 5, Step: 2900 of 13750, Training loss: 0.0879590, Training accuracy: 0.9730172, Time: 05_05_2022__22:14:17\n","Epoch 3 of 5, Step: 3000 of 13750, Training loss: 0.0869204, Training accuracy: 0.9733333, Time: 05_05_2022__22:14:38\n","Epoch 3 of 5, Step: 3100 of 13750, Training loss: 0.0873957, Training accuracy: 0.9733065, Time: 05_05_2022__22:14:59\n","Epoch 3 of 5, Step: 3200 of 13750, Training loss: 0.0869725, Training accuracy: 0.9733594, Time: 05_05_2022__22:15:20\n","Epoch 3 of 5, Step: 3300 of 13750, Training loss: 0.0869453, Training accuracy: 0.9731818, Time: 05_05_2022__22:15:41\n","Epoch 3 of 5, Step: 3400 of 13750, Training loss: 0.0862360, Training accuracy: 0.9735294, Time: 05_05_2022__22:16:02\n","Epoch 3 of 5, Step: 3500 of 13750, Training loss: 0.0860592, Training accuracy: 0.9736429, Time: 05_05_2022__22:16:23\n","Epoch 3 of 5, Step: 3600 of 13750, Training loss: 0.0852666, Training accuracy: 0.9739583, Time: 05_05_2022__22:16:44\n","Epoch 3 of 5, Step: 3700 of 13750, Training loss: 0.0853518, Training accuracy: 0.9739865, Time: 05_05_2022__22:17:05\n","Epoch 3 of 5, Step: 3800 of 13750, Training loss: 0.0859226, Training accuracy: 0.9736842, Time: 05_05_2022__22:17:26\n","Epoch 3 of 5, Step: 3900 of 13750, Training loss: 0.0867283, Training accuracy: 0.9735897, Time: 05_05_2022__22:17:47\n","Epoch 3 of 5, Step: 4000 of 13750, Training loss: 0.0865706, Training accuracy: 0.9736250, Time: 05_05_2022__22:18:08\n","Epoch 3 of 5, Step: 4100 of 13750, Training loss: 0.0864348, Training accuracy: 0.9737195, Time: 05_05_2022__22:18:29\n","Epoch 3 of 5, Step: 4200 of 13750, Training loss: 0.0880942, Training accuracy: 0.9733333, Time: 05_05_2022__22:18:50\n","Epoch 3 of 5, Step: 4300 of 13750, Training loss: 0.0882833, Training accuracy: 0.9731977, Time: 05_05_2022__22:19:11\n","Epoch 3 of 5, Step: 4400 of 13750, Training loss: 0.0880791, Training accuracy: 0.9732386, Time: 05_05_2022__22:19:32\n","Epoch 3 of 5, Step: 4500 of 13750, Training loss: 0.0872678, Training accuracy: 0.9733889, Time: 05_05_2022__22:19:53\n","Epoch 3 of 5, Step: 4600 of 13750, Training loss: 0.0865011, Training accuracy: 0.9736413, Time: 05_05_2022__22:20:14\n","Epoch 3 of 5, Step: 4700 of 13750, Training loss: 0.0870254, Training accuracy: 0.9733511, Time: 05_05_2022__22:20:35\n","Epoch 3 of 5, Step: 4800 of 13750, Training loss: 0.0871360, Training accuracy: 0.9733854, Time: 05_05_2022__22:20:56\n","Epoch 3 of 5, Step: 4900 of 13750, Training loss: 0.0878697, Training accuracy: 0.9732143, Time: 05_05_2022__22:21:17\n","Epoch 3 of 5, Step: 5000 of 13750, Training loss: 0.0874143, Training accuracy: 0.9734500, Time: 05_05_2022__22:21:38\n","Epoch 3 of 5, Step: 5100 of 13750, Training loss: 0.0868510, Training accuracy: 0.9735294, Time: 05_05_2022__22:21:59\n","Epoch 3 of 5, Step: 5200 of 13750, Training loss: 0.0867602, Training accuracy: 0.9735096, Time: 05_05_2022__22:22:20\n","Epoch 3 of 5, Step: 5300 of 13750, Training loss: 0.0870948, Training accuracy: 0.9734434, Time: 05_05_2022__22:22:41\n","Epoch 3 of 5, Step: 5400 of 13750, Training loss: 0.0870550, Training accuracy: 0.9735648, Time: 05_05_2022__22:23:02\n","Epoch 3 of 5, Step: 5500 of 13750, Training loss: 0.0867113, Training accuracy: 0.9737273, Time: 05_05_2022__22:23:23\n","Epoch 3 of 5, Step: 5600 of 13750, Training loss: 0.0871421, Training accuracy: 0.9735268, Time: 05_05_2022__22:23:44\n","Epoch 3 of 5, Step: 5700 of 13750, Training loss: 0.0872593, Training accuracy: 0.9733333, Time: 05_05_2022__22:24:05\n","Epoch 3 of 5, Step: 5800 of 13750, Training loss: 0.0868152, Training accuracy: 0.9733621, Time: 05_05_2022__22:24:26\n","Epoch 3 of 5, Step: 5900 of 13750, Training loss: 0.0864464, Training accuracy: 0.9735169, Time: 05_05_2022__22:24:47\n","Epoch 3 of 5, Step: 6000 of 13750, Training loss: 0.0873436, Training accuracy: 0.9732917, Time: 05_05_2022__22:25:08\n","Epoch 3 of 5, Step: 6100 of 13750, Training loss: 0.0869882, Training accuracy: 0.9734836, Time: 05_05_2022__22:25:29\n","Epoch 3 of 5, Step: 6200 of 13750, Training loss: 0.0869657, Training accuracy: 0.9733065, Time: 05_05_2022__22:25:50\n","Epoch 3 of 5, Step: 6300 of 13750, Training loss: 0.0873563, Training accuracy: 0.9731746, Time: 05_05_2022__22:26:11\n","Epoch 3 of 5, Step: 6400 of 13750, Training loss: 0.0870169, Training accuracy: 0.9733594, Time: 05_05_2022__22:26:32\n","Epoch 3 of 5, Step: 6500 of 13750, Training loss: 0.0873512, Training accuracy: 0.9731154, Time: 05_05_2022__22:26:53\n","Epoch 3 of 5, Step: 6600 of 13750, Training loss: 0.0870925, Training accuracy: 0.9731439, Time: 05_05_2022__22:27:14\n","Epoch 3 of 5, Step: 6700 of 13750, Training loss: 0.0864990, Training accuracy: 0.9732836, Time: 05_05_2022__22:27:35\n","Epoch 3 of 5, Step: 6800 of 13750, Training loss: 0.0859887, Training accuracy: 0.9734191, Time: 05_05_2022__22:27:56\n","Epoch 3 of 5, Step: 6900 of 13750, Training loss: 0.0856751, Training accuracy: 0.9734783, Time: 05_05_2022__22:28:17\n","Epoch 3 of 5, Step: 7000 of 13750, Training loss: 0.0855084, Training accuracy: 0.9735000, Time: 05_05_2022__22:28:38\n","Epoch 3 of 5, Step: 7100 of 13750, Training loss: 0.0854659, Training accuracy: 0.9735563, Time: 05_05_2022__22:28:59\n","Epoch 3 of 5, Step: 7200 of 13750, Training loss: 0.0854843, Training accuracy: 0.9735069, Time: 05_05_2022__22:29:20\n","Epoch 3 of 5, Step: 7300 of 13750, Training loss: 0.0850003, Training accuracy: 0.9736986, Time: 05_05_2022__22:29:41\n","Epoch 3 of 5, Step: 7400 of 13750, Training loss: 0.0849869, Training accuracy: 0.9737500, Time: 05_05_2022__22:30:02\n","Epoch 3 of 5, Step: 7500 of 13750, Training loss: 0.0848918, Training accuracy: 0.9739333, Time: 05_05_2022__22:30:23\n","Epoch 3 of 5, Step: 7600 of 13750, Training loss: 0.0852127, Training accuracy: 0.9738158, Time: 05_05_2022__22:30:44\n","Epoch 3 of 5, Step: 7700 of 13750, Training loss: 0.0848074, Training accuracy: 0.9739935, Time: 05_05_2022__22:31:05\n","Epoch 3 of 5, Step: 7800 of 13750, Training loss: 0.0846021, Training accuracy: 0.9741026, Time: 05_05_2022__22:31:25\n","Epoch 3 of 5, Step: 7900 of 13750, Training loss: 0.0845644, Training accuracy: 0.9740506, Time: 05_05_2022__22:31:46\n","Epoch 3 of 5, Step: 8000 of 13750, Training loss: 0.0843906, Training accuracy: 0.9740313, Time: 05_05_2022__22:32:07\n","Epoch 3 of 5, Step: 8100 of 13750, Training loss: 0.0839155, Training accuracy: 0.9742284, Time: 05_05_2022__22:32:28\n","Epoch 3 of 5, Step: 8200 of 13750, Training loss: 0.0835737, Training accuracy: 0.9743902, Time: 05_05_2022__22:32:49\n","Epoch 3 of 5, Step: 8300 of 13750, Training loss: 0.0844261, Training accuracy: 0.9741566, Time: 05_05_2022__22:33:10\n","Epoch 3 of 5, Step: 8400 of 13750, Training loss: 0.0842716, Training accuracy: 0.9741369, Time: 05_05_2022__22:33:31\n","Epoch 3 of 5, Step: 8500 of 13750, Training loss: 0.0840877, Training accuracy: 0.9741765, Time: 05_05_2022__22:33:52\n","Epoch 3 of 5, Step: 8600 of 13750, Training loss: 0.0836911, Training accuracy: 0.9743895, Time: 05_05_2022__22:34:13\n","Epoch 3 of 5, Step: 8700 of 13750, Training loss: 0.0833906, Training accuracy: 0.9745115, Time: 05_05_2022__22:34:34\n","Epoch 3 of 5, Step: 8800 of 13750, Training loss: 0.0838654, Training accuracy: 0.9743750, Time: 05_05_2022__22:34:55\n","Epoch 3 of 5, Step: 8900 of 13750, Training loss: 0.0834852, Training accuracy: 0.9745506, Time: 05_05_2022__22:35:16\n","Epoch 3 of 5, Step: 9000 of 13750, Training loss: 0.0834855, Training accuracy: 0.9745833, Time: 05_05_2022__22:35:37\n","Epoch 3 of 5, Step: 9100 of 13750, Training loss: 0.0835422, Training accuracy: 0.9745604, Time: 05_05_2022__22:35:58\n","Epoch 3 of 5, Step: 9200 of 13750, Training loss: 0.0835208, Training accuracy: 0.9745652, Time: 05_05_2022__22:36:19\n","Epoch 3 of 5, Step: 9300 of 13750, Training loss: 0.0835289, Training accuracy: 0.9745161, Time: 05_05_2022__22:36:40\n","Epoch 3 of 5, Step: 9400 of 13750, Training loss: 0.0836878, Training accuracy: 0.9744681, Time: 05_05_2022__22:37:01\n","Epoch 3 of 5, Step: 9500 of 13750, Training loss: 0.0835995, Training accuracy: 0.9744737, Time: 05_05_2022__22:37:22\n","Epoch 3 of 5, Step: 9600 of 13750, Training loss: 0.0834610, Training accuracy: 0.9744271, Time: 05_05_2022__22:37:43\n","Epoch 3 of 5, Step: 9700 of 13750, Training loss: 0.0831251, Training accuracy: 0.9745361, Time: 05_05_2022__22:38:04\n","Epoch 3 of 5, Step: 9800 of 13750, Training loss: 0.0830311, Training accuracy: 0.9746173, Time: 05_05_2022__22:38:25\n","Epoch 3 of 5, Step: 9900 of 13750, Training loss: 0.0829126, Training accuracy: 0.9746465, Time: 05_05_2022__22:38:46\n","Epoch 3 of 5, Step: 10000 of 13750, Training loss: 0.0828866, Training accuracy: 0.9747000, Time: 05_05_2022__22:39:07\n","Epoch 3 of 5, Step: 10100 of 13750, Training loss: 0.0833626, Training accuracy: 0.9746782, Time: 05_05_2022__22:39:28\n","Epoch 3 of 5, Step: 10200 of 13750, Training loss: 0.0832765, Training accuracy: 0.9747549, Time: 05_05_2022__22:39:49\n","Epoch 3 of 5, Step: 10300 of 13750, Training loss: 0.0829189, Training accuracy: 0.9749029, Time: 05_05_2022__22:40:10\n","Epoch 3 of 5, Step: 10400 of 13750, Training loss: 0.0827921, Training accuracy: 0.9749519, Time: 05_05_2022__22:40:31\n","Epoch 3 of 5, Step: 10500 of 13750, Training loss: 0.0826783, Training accuracy: 0.9750000, Time: 05_05_2022__22:40:52\n","Epoch 3 of 5, Step: 10600 of 13750, Training loss: 0.0824850, Training accuracy: 0.9750943, Time: 05_05_2022__22:41:13\n","Epoch 3 of 5, Step: 10700 of 13750, Training loss: 0.0823363, Training accuracy: 0.9751402, Time: 05_05_2022__22:41:34\n","Epoch 3 of 5, Step: 10800 of 13750, Training loss: 0.0824485, Training accuracy: 0.9750694, Time: 05_05_2022__22:41:55\n","Epoch 3 of 5, Step: 10900 of 13750, Training loss: 0.0824612, Training accuracy: 0.9750459, Time: 05_05_2022__22:42:16\n","Epoch 3 of 5, Step: 11000 of 13750, Training loss: 0.0821722, Training accuracy: 0.9751591, Time: 05_05_2022__22:42:37\n","Epoch 3 of 5, Step: 11100 of 13750, Training loss: 0.0821812, Training accuracy: 0.9751802, Time: 05_05_2022__22:42:58\n","Epoch 3 of 5, Step: 11200 of 13750, Training loss: 0.0821071, Training accuracy: 0.9752009, Time: 05_05_2022__22:43:19\n","Epoch 3 of 5, Step: 11300 of 13750, Training loss: 0.0821173, Training accuracy: 0.9751327, Time: 05_05_2022__22:43:40\n","Epoch 3 of 5, Step: 11400 of 13750, Training loss: 0.0819669, Training accuracy: 0.9751754, Time: 05_05_2022__22:44:01\n","Epoch 3 of 5, Step: 11500 of 13750, Training loss: 0.0822310, Training accuracy: 0.9750870, Time: 05_05_2022__22:44:22\n","Epoch 3 of 5, Step: 11600 of 13750, Training loss: 0.0820954, Training accuracy: 0.9751078, Time: 05_05_2022__22:44:43\n","Epoch 3 of 5, Step: 11700 of 13750, Training loss: 0.0818714, Training accuracy: 0.9752137, Time: 05_05_2022__22:45:04\n","Epoch 3 of 5, Step: 11800 of 13750, Training loss: 0.0819899, Training accuracy: 0.9751483, Time: 05_05_2022__22:45:25\n","Epoch 3 of 5, Step: 11900 of 13750, Training loss: 0.0818043, Training accuracy: 0.9752731, Time: 05_05_2022__22:45:46\n","Epoch 3 of 5, Step: 12000 of 13750, Training loss: 0.0815645, Training accuracy: 0.9753542, Time: 05_05_2022__22:46:07\n","Epoch 3 of 5, Step: 12100 of 13750, Training loss: 0.0815512, Training accuracy: 0.9753512, Time: 05_05_2022__22:46:28\n","Epoch 3 of 5, Step: 12200 of 13750, Training loss: 0.0815682, Training accuracy: 0.9753689, Time: 05_05_2022__22:46:49\n","Epoch 3 of 5, Step: 12300 of 13750, Training loss: 0.0812670, Training accuracy: 0.9754675, Time: 05_05_2022__22:47:10\n","Epoch 3 of 5, Step: 12400 of 13750, Training loss: 0.0809771, Training accuracy: 0.9755645, Time: 05_05_2022__22:47:31\n","Epoch 3 of 5, Step: 12500 of 13750, Training loss: 0.0808357, Training accuracy: 0.9756200, Time: 05_05_2022__22:47:52\n","Epoch 3 of 5, Step: 12600 of 13750, Training loss: 0.0806566, Training accuracy: 0.9756548, Time: 05_05_2022__22:48:13\n","Epoch 3 of 5, Step: 12700 of 13750, Training loss: 0.0806622, Training accuracy: 0.9756102, Time: 05_05_2022__22:48:34\n","Epoch 3 of 5, Step: 12800 of 13750, Training loss: 0.0805431, Training accuracy: 0.9756250, Time: 05_05_2022__22:48:55\n","Epoch 3 of 5, Step: 12900 of 13750, Training loss: 0.0806349, Training accuracy: 0.9756202, Time: 05_05_2022__22:49:16\n","Epoch 3 of 5, Step: 13000 of 13750, Training loss: 0.0805401, Training accuracy: 0.9756731, Time: 05_05_2022__22:49:36\n","Epoch 3 of 5, Step: 13100 of 13750, Training loss: 0.0807436, Training accuracy: 0.9756489, Time: 05_05_2022__22:49:57\n","Epoch 3 of 5, Step: 13200 of 13750, Training loss: 0.0804773, Training accuracy: 0.9757008, Time: 05_05_2022__22:50:18\n","Epoch 3 of 5, Step: 13300 of 13750, Training loss: 0.0803916, Training accuracy: 0.9757331, Time: 05_05_2022__22:50:39\n","Epoch 3 of 5, Step: 13400 of 13750, Training loss: 0.0802595, Training accuracy: 0.9758022, Time: 05_05_2022__22:51:00\n","Epoch 3 of 5, Step: 13500 of 13750, Training loss: 0.0802403, Training accuracy: 0.9758148, Time: 05_05_2022__22:51:21\n","Epoch 3 of 5, Step: 13600 of 13750, Training loss: 0.0801261, Training accuracy: 0.9758456, Time: 05_05_2022__22:51:42\n","Epoch 3 of 5, Step: 13700 of 13750, Training loss: 0.0801502, Training accuracy: 0.9758577, Time: 05_05_2022__22:52:03\n","Epoch 3 of 5, Average training loss: 0.0800883, Average training accuracy: 0.9758727, Time: 05_05_2022__22:52:14\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b73f037ebf40b4b157acc88d0153dc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0486348, Validation accuracy: 0.9875000, Time: 05_05_2022__22:52:19 | Loss decreased from 0.0544811 to 0.0490587 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0555593, Validation accuracy: 0.9800000, Time: 05_05_2022__22:52:27\n","Step: 300 of 1250, Validation loss: 0.0582568, Validation accuracy: 0.9800000, Time: 05_05_2022__22:52:32\n","Step: 400 of 1250, Validation loss: 0.0537836, Validation accuracy: 0.9806250, Time: 05_05_2022__22:52:37\n","Step: 500 of 1250, Validation loss: 0.0507051, Validation accuracy: 0.9815000, Time: 05_05_2022__22:52:42\n","Step: 600 of 1250, Validation loss: 0.0492212, Validation accuracy: 0.9825000, Time: 05_05_2022__22:52:48\n","Step: 700 of 1250, Validation loss: 0.0459764, Validation accuracy: 0.9835714, Time: 05_05_2022__22:52:53 | Loss decreased from 0.0490587 to 0.0455046 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0469702, Validation accuracy: 0.9843750, Time: 05_05_2022__22:53:00\n","Step: 900 of 1250, Validation loss: 0.0481120, Validation accuracy: 0.9844444, Time: 05_05_2022__22:53:06\n","Step: 1000 of 1250, Validation loss: 0.0500630, Validation accuracy: 0.9840000, Time: 05_05_2022__22:53:11\n","Step: 1100 of 1250, Validation loss: 0.0482660, Validation accuracy: 0.9847727, Time: 05_05_2022__22:53:16\n","Step: 1200 of 1250, Validation loss: 0.0484488, Validation accuracy: 0.9843750, Time: 05_05_2022__22:53:21\n","Average validation loss: 0.0491377, Average validation accuracy: 0.9842000, Time: 05_05_2022__22:53:24\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c71e3570e3284807a8f238fda34518b5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 13750, Training loss: 0.0687269, Training accuracy: 0.9850000, Time: 05_05_2022__22:53:45\n","Epoch 4 of 5, Step: 200 of 13750, Training loss: 0.0576374, Training accuracy: 0.9862500, Time: 05_05_2022__22:54:06\n","Epoch 4 of 5, Step: 300 of 13750, Training loss: 0.0660017, Training accuracy: 0.9841667, Time: 05_05_2022__22:54:27\n","Epoch 4 of 5, Step: 400 of 13750, Training loss: 0.0680734, Training accuracy: 0.9825000, Time: 05_05_2022__22:54:48\n","Epoch 4 of 5, Step: 500 of 13750, Training loss: 0.0674652, Training accuracy: 0.9805000, Time: 05_05_2022__22:55:09\n","Epoch 4 of 5, Step: 600 of 13750, Training loss: 0.0673409, Training accuracy: 0.9812500, Time: 05_05_2022__22:55:30\n","Epoch 4 of 5, Step: 700 of 13750, Training loss: 0.0691747, Training accuracy: 0.9800000, Time: 05_05_2022__22:55:51\n","Epoch 4 of 5, Step: 800 of 13750, Training loss: 0.0685796, Training accuracy: 0.9803125, Time: 05_05_2022__22:56:12\n","Epoch 4 of 5, Step: 900 of 13750, Training loss: 0.0697042, Training accuracy: 0.9800000, Time: 05_05_2022__22:56:33\n","Epoch 4 of 5, Step: 1000 of 13750, Training loss: 0.0694525, Training accuracy: 0.9805000, Time: 05_05_2022__22:56:54\n","Epoch 4 of 5, Step: 1100 of 13750, Training loss: 0.0728869, Training accuracy: 0.9788636, Time: 05_05_2022__22:57:15\n","Epoch 4 of 5, Step: 1200 of 13750, Training loss: 0.0723026, Training accuracy: 0.9787500, Time: 05_05_2022__22:57:36\n","Epoch 4 of 5, Step: 1300 of 13750, Training loss: 0.0713029, Training accuracy: 0.9790385, Time: 05_05_2022__22:57:57\n","Epoch 4 of 5, Step: 1400 of 13750, Training loss: 0.0719355, Training accuracy: 0.9787500, Time: 05_05_2022__22:58:18\n","Epoch 4 of 5, Step: 1500 of 13750, Training loss: 0.0714772, Training accuracy: 0.9790000, Time: 05_05_2022__22:58:38\n","Epoch 4 of 5, Step: 1600 of 13750, Training loss: 0.0716155, Training accuracy: 0.9789062, Time: 05_05_2022__22:58:59\n","Epoch 4 of 5, Step: 1700 of 13750, Training loss: 0.0713206, Training accuracy: 0.9791176, Time: 05_05_2022__22:59:20\n","Epoch 4 of 5, Step: 1800 of 13750, Training loss: 0.0715337, Training accuracy: 0.9790278, Time: 05_05_2022__22:59:41\n","Epoch 4 of 5, Step: 1900 of 13750, Training loss: 0.0715620, Training accuracy: 0.9793421, Time: 05_05_2022__23:00:02\n","Epoch 4 of 5, Step: 2000 of 13750, Training loss: 0.0710591, Training accuracy: 0.9792500, Time: 05_05_2022__23:00:23\n","Epoch 4 of 5, Step: 2100 of 13750, Training loss: 0.0695815, Training accuracy: 0.9797619, Time: 05_05_2022__23:00:44\n","Epoch 4 of 5, Step: 2200 of 13750, Training loss: 0.0685483, Training accuracy: 0.9800000, Time: 05_05_2022__23:01:05\n","Epoch 4 of 5, Step: 2300 of 13750, Training loss: 0.0670766, Training accuracy: 0.9805435, Time: 05_05_2022__23:01:26\n","Epoch 4 of 5, Step: 2400 of 13750, Training loss: 0.0675767, Training accuracy: 0.9807292, Time: 05_05_2022__23:01:47\n","Epoch 4 of 5, Step: 2500 of 13750, Training loss: 0.0670741, Training accuracy: 0.9810000, Time: 05_05_2022__23:02:08\n","Epoch 4 of 5, Step: 2600 of 13750, Training loss: 0.0679044, Training accuracy: 0.9807692, Time: 05_05_2022__23:02:29\n","Epoch 4 of 5, Step: 2700 of 13750, Training loss: 0.0677613, Training accuracy: 0.9804630, Time: 05_05_2022__23:02:50\n","Epoch 4 of 5, Step: 2800 of 13750, Training loss: 0.0683713, Training accuracy: 0.9801786, Time: 05_05_2022__23:03:11\n","Epoch 4 of 5, Step: 2900 of 13750, Training loss: 0.0681922, Training accuracy: 0.9802586, Time: 05_05_2022__23:03:32\n","Epoch 4 of 5, Step: 3000 of 13750, Training loss: 0.0677695, Training accuracy: 0.9805833, Time: 05_05_2022__23:03:53\n","Epoch 4 of 5, Step: 3100 of 13750, Training loss: 0.0676925, Training accuracy: 0.9804839, Time: 05_05_2022__23:04:14\n","Epoch 4 of 5, Step: 3200 of 13750, Training loss: 0.0672411, Training accuracy: 0.9807031, Time: 05_05_2022__23:04:35\n","Epoch 4 of 5, Step: 3300 of 13750, Training loss: 0.0668738, Training accuracy: 0.9808333, Time: 05_05_2022__23:04:56\n","Epoch 4 of 5, Step: 3400 of 13750, Training loss: 0.0666290, Training accuracy: 0.9808088, Time: 05_05_2022__23:05:17\n","Epoch 4 of 5, Step: 3500 of 13750, Training loss: 0.0668066, Training accuracy: 0.9808571, Time: 05_05_2022__23:05:38\n","Epoch 4 of 5, Step: 3600 of 13750, Training loss: 0.0661526, Training accuracy: 0.9811111, Time: 05_05_2022__23:05:59\n","Epoch 4 of 5, Step: 3700 of 13750, Training loss: 0.0666648, Training accuracy: 0.9809459, Time: 05_05_2022__23:06:20\n","Epoch 4 of 5, Step: 3800 of 13750, Training loss: 0.0663586, Training accuracy: 0.9810526, Time: 05_05_2022__23:06:41\n","Epoch 4 of 5, Step: 3900 of 13750, Training loss: 0.0669659, Training accuracy: 0.9806410, Time: 05_05_2022__23:07:02\n","Epoch 4 of 5, Step: 4000 of 13750, Training loss: 0.0668764, Training accuracy: 0.9805625, Time: 05_05_2022__23:07:23\n","Epoch 4 of 5, Step: 4100 of 13750, Training loss: 0.0669954, Training accuracy: 0.9806098, Time: 05_05_2022__23:07:44\n","Epoch 4 of 5, Step: 4200 of 13750, Training loss: 0.0683265, Training accuracy: 0.9801786, Time: 05_05_2022__23:08:04\n","Epoch 4 of 5, Step: 4300 of 13750, Training loss: 0.0685714, Training accuracy: 0.9801744, Time: 05_05_2022__23:08:25\n","Epoch 4 of 5, Step: 4400 of 13750, Training loss: 0.0685019, Training accuracy: 0.9802273, Time: 05_05_2022__23:08:46\n","Epoch 4 of 5, Step: 4500 of 13750, Training loss: 0.0679049, Training accuracy: 0.9804444, Time: 05_05_2022__23:09:07\n","Epoch 4 of 5, Step: 4600 of 13750, Training loss: 0.0675164, Training accuracy: 0.9805435, Time: 05_05_2022__23:09:28\n","Epoch 4 of 5, Step: 4700 of 13750, Training loss: 0.0677650, Training accuracy: 0.9804787, Time: 05_05_2022__23:09:49\n","Epoch 4 of 5, Step: 4800 of 13750, Training loss: 0.0679845, Training accuracy: 0.9804167, Time: 05_05_2022__23:10:10\n","Epoch 4 of 5, Step: 4900 of 13750, Training loss: 0.0684975, Training accuracy: 0.9802041, Time: 05_05_2022__23:10:31\n","Epoch 4 of 5, Step: 5000 of 13750, Training loss: 0.0677607, Training accuracy: 0.9805000, Time: 05_05_2022__23:10:52\n","Epoch 4 of 5, Step: 5100 of 13750, Training loss: 0.0672902, Training accuracy: 0.9805882, Time: 05_05_2022__23:11:13\n","Epoch 4 of 5, Step: 5200 of 13750, Training loss: 0.0679588, Training accuracy: 0.9804327, Time: 05_05_2022__23:11:34\n","Epoch 4 of 5, Step: 5300 of 13750, Training loss: 0.0682383, Training accuracy: 0.9801887, Time: 05_05_2022__23:11:55\n","Epoch 4 of 5, Step: 5400 of 13750, Training loss: 0.0682086, Training accuracy: 0.9802778, Time: 05_05_2022__23:12:16\n","Epoch 4 of 5, Step: 5500 of 13750, Training loss: 0.0681892, Training accuracy: 0.9802273, Time: 05_05_2022__23:12:37\n","Epoch 4 of 5, Step: 5600 of 13750, Training loss: 0.0685646, Training accuracy: 0.9800446, Time: 05_05_2022__23:12:58\n","Epoch 4 of 5, Step: 5700 of 13750, Training loss: 0.0685242, Training accuracy: 0.9800000, Time: 05_05_2022__23:13:19\n","Epoch 4 of 5, Step: 5800 of 13750, Training loss: 0.0678800, Training accuracy: 0.9801724, Time: 05_05_2022__23:13:40\n","Epoch 4 of 5, Step: 5900 of 13750, Training loss: 0.0674117, Training accuracy: 0.9803814, Time: 05_05_2022__23:14:01\n","Epoch 4 of 5, Step: 6000 of 13750, Training loss: 0.0675538, Training accuracy: 0.9802500, Time: 05_05_2022__23:14:22\n","Epoch 4 of 5, Step: 6100 of 13750, Training loss: 0.0670966, Training accuracy: 0.9804508, Time: 05_05_2022__23:14:43\n","Epoch 4 of 5, Step: 6200 of 13750, Training loss: 0.0672854, Training accuracy: 0.9804435, Time: 05_05_2022__23:15:04\n","Epoch 4 of 5, Step: 6300 of 13750, Training loss: 0.0673741, Training accuracy: 0.9804762, Time: 05_05_2022__23:15:25\n","Epoch 4 of 5, Step: 6400 of 13750, Training loss: 0.0674567, Training accuracy: 0.9803906, Time: 05_05_2022__23:15:46\n","Epoch 4 of 5, Step: 6500 of 13750, Training loss: 0.0681269, Training accuracy: 0.9803077, Time: 05_05_2022__23:16:07\n","Epoch 4 of 5, Step: 6600 of 13750, Training loss: 0.0675096, Training accuracy: 0.9805303, Time: 05_05_2022__23:16:28\n","Epoch 4 of 5, Step: 6700 of 13750, Training loss: 0.0673272, Training accuracy: 0.9804478, Time: 05_05_2022__23:16:49\n","Epoch 4 of 5, Step: 6800 of 13750, Training loss: 0.0669296, Training accuracy: 0.9805515, Time: 05_05_2022__23:17:10\n","Epoch 4 of 5, Step: 6900 of 13750, Training loss: 0.0667783, Training accuracy: 0.9806159, Time: 05_05_2022__23:17:31\n","Epoch 4 of 5, Step: 7000 of 13750, Training loss: 0.0665900, Training accuracy: 0.9807143, Time: 05_05_2022__23:17:52\n","Epoch 4 of 5, Step: 7100 of 13750, Training loss: 0.0667183, Training accuracy: 0.9807042, Time: 05_05_2022__23:18:12\n","Epoch 4 of 5, Step: 7200 of 13750, Training loss: 0.0666892, Training accuracy: 0.9806597, Time: 05_05_2022__23:18:33\n","Epoch 4 of 5, Step: 7300 of 13750, Training loss: 0.0664721, Training accuracy: 0.9807192, Time: 05_05_2022__23:18:54\n","Epoch 4 of 5, Step: 7400 of 13750, Training loss: 0.0660844, Training accuracy: 0.9808108, Time: 05_05_2022__23:19:15\n","Epoch 4 of 5, Step: 7500 of 13750, Training loss: 0.0660519, Training accuracy: 0.9808333, Time: 05_05_2022__23:19:36\n","Epoch 4 of 5, Step: 7600 of 13750, Training loss: 0.0662728, Training accuracy: 0.9806908, Time: 05_05_2022__23:19:57\n","Epoch 4 of 5, Step: 7700 of 13750, Training loss: 0.0660101, Training accuracy: 0.9807792, Time: 05_05_2022__23:20:18\n","Epoch 4 of 5, Step: 7800 of 13750, Training loss: 0.0660607, Training accuracy: 0.9808974, Time: 05_05_2022__23:20:39\n","Epoch 4 of 5, Step: 7900 of 13750, Training loss: 0.0665732, Training accuracy: 0.9806646, Time: 05_05_2022__23:21:00\n","Epoch 4 of 5, Step: 8000 of 13750, Training loss: 0.0662673, Training accuracy: 0.9807187, Time: 05_05_2022__23:21:21\n","Epoch 4 of 5, Step: 8100 of 13750, Training loss: 0.0660495, Training accuracy: 0.9808025, Time: 05_05_2022__23:21:42\n","Epoch 4 of 5, Step: 8200 of 13750, Training loss: 0.0657488, Training accuracy: 0.9809451, Time: 05_05_2022__23:22:03\n","Epoch 4 of 5, Step: 8300 of 13750, Training loss: 0.0665348, Training accuracy: 0.9807831, Time: 05_05_2022__23:22:24\n","Epoch 4 of 5, Step: 8400 of 13750, Training loss: 0.0666262, Training accuracy: 0.9807143, Time: 05_05_2022__23:22:45\n","Epoch 4 of 5, Step: 8500 of 13750, Training loss: 0.0664894, Training accuracy: 0.9807353, Time: 05_05_2022__23:23:06\n","Epoch 4 of 5, Step: 8600 of 13750, Training loss: 0.0665154, Training accuracy: 0.9807558, Time: 05_05_2022__23:23:27\n","Epoch 4 of 5, Step: 8700 of 13750, Training loss: 0.0662921, Training accuracy: 0.9808333, Time: 05_05_2022__23:23:48\n","Epoch 4 of 5, Step: 8800 of 13750, Training loss: 0.0666494, Training accuracy: 0.9807102, Time: 05_05_2022__23:24:09\n","Epoch 4 of 5, Step: 8900 of 13750, Training loss: 0.0662820, Training accuracy: 0.9808146, Time: 05_05_2022__23:24:30\n","Epoch 4 of 5, Step: 9000 of 13750, Training loss: 0.0663468, Training accuracy: 0.9807500, Time: 05_05_2022__23:24:51\n","Epoch 4 of 5, Step: 9100 of 13750, Training loss: 0.0664441, Training accuracy: 0.9806593, Time: 05_05_2022__23:25:12\n","Epoch 4 of 5, Step: 9200 of 13750, Training loss: 0.0663196, Training accuracy: 0.9806793, Time: 05_05_2022__23:25:33\n","Epoch 4 of 5, Step: 9300 of 13750, Training loss: 0.0662428, Training accuracy: 0.9806989, Time: 05_05_2022__23:25:54\n","Epoch 4 of 5, Step: 9400 of 13750, Training loss: 0.0664925, Training accuracy: 0.9806915, Time: 05_05_2022__23:26:15\n","Epoch 4 of 5, Step: 9500 of 13750, Training loss: 0.0664656, Training accuracy: 0.9806316, Time: 05_05_2022__23:26:36\n","Epoch 4 of 5, Step: 9600 of 13750, Training loss: 0.0664913, Training accuracy: 0.9806510, Time: 05_05_2022__23:26:57\n","Epoch 4 of 5, Step: 9700 of 13750, Training loss: 0.0662738, Training accuracy: 0.9806443, Time: 05_05_2022__23:27:18\n","Epoch 4 of 5, Step: 9800 of 13750, Training loss: 0.0663142, Training accuracy: 0.9806888, Time: 05_05_2022__23:27:39\n","Epoch 4 of 5, Step: 9900 of 13750, Training loss: 0.0659471, Training accuracy: 0.9808081, Time: 05_05_2022__23:28:00\n","Epoch 4 of 5, Step: 10000 of 13750, Training loss: 0.0659774, Training accuracy: 0.9807750, Time: 05_05_2022__23:28:21\n","Epoch 4 of 5, Step: 10100 of 13750, Training loss: 0.0663307, Training accuracy: 0.9807426, Time: 05_05_2022__23:28:42\n","Epoch 4 of 5, Step: 10200 of 13750, Training loss: 0.0663377, Training accuracy: 0.9806618, Time: 05_05_2022__23:29:03\n","Epoch 4 of 5, Step: 10300 of 13750, Training loss: 0.0662271, Training accuracy: 0.9806796, Time: 05_05_2022__23:29:24\n","Epoch 4 of 5, Step: 10400 of 13750, Training loss: 0.0660371, Training accuracy: 0.9807452, Time: 05_05_2022__23:29:45\n","Epoch 4 of 5, Step: 10500 of 13750, Training loss: 0.0658652, Training accuracy: 0.9808095, Time: 05_05_2022__23:30:06\n","Epoch 4 of 5, Step: 10600 of 13750, Training loss: 0.0657618, Training accuracy: 0.9808255, Time: 05_05_2022__23:30:27\n","Epoch 4 of 5, Step: 10700 of 13750, Training loss: 0.0657869, Training accuracy: 0.9807710, Time: 05_05_2022__23:30:48\n","Epoch 4 of 5, Step: 10800 of 13750, Training loss: 0.0656586, Training accuracy: 0.9807870, Time: 05_05_2022__23:31:09\n","Epoch 4 of 5, Step: 10900 of 13750, Training loss: 0.0655963, Training accuracy: 0.9807798, Time: 05_05_2022__23:31:30\n","Epoch 4 of 5, Step: 11000 of 13750, Training loss: 0.0653855, Training accuracy: 0.9808636, Time: 05_05_2022__23:31:51\n","Epoch 4 of 5, Step: 11100 of 13750, Training loss: 0.0652648, Training accuracy: 0.9809685, Time: 05_05_2022__23:32:12\n","Epoch 4 of 5, Step: 11200 of 13750, Training loss: 0.0652315, Training accuracy: 0.9810268, Time: 05_05_2022__23:32:32\n","Epoch 4 of 5, Step: 11300 of 13750, Training loss: 0.0650321, Training accuracy: 0.9810398, Time: 05_05_2022__23:32:53\n","Epoch 4 of 5, Step: 11400 of 13750, Training loss: 0.0649831, Training accuracy: 0.9810307, Time: 05_05_2022__23:33:14\n","Epoch 4 of 5, Step: 11500 of 13750, Training loss: 0.0651499, Training accuracy: 0.9810217, Time: 05_05_2022__23:33:35\n","Epoch 4 of 5, Step: 11600 of 13750, Training loss: 0.0649964, Training accuracy: 0.9810345, Time: 05_05_2022__23:33:56\n","Epoch 4 of 5, Step: 11700 of 13750, Training loss: 0.0648727, Training accuracy: 0.9810470, Time: 05_05_2022__23:34:17\n","Epoch 4 of 5, Step: 11800 of 13750, Training loss: 0.0649851, Training accuracy: 0.9809958, Time: 05_05_2022__23:34:38\n","Epoch 4 of 5, Step: 11900 of 13750, Training loss: 0.0648934, Training accuracy: 0.9809874, Time: 05_05_2022__23:34:59\n","Epoch 4 of 5, Step: 12000 of 13750, Training loss: 0.0647155, Training accuracy: 0.9810417, Time: 05_05_2022__23:35:20\n","Epoch 4 of 5, Step: 12100 of 13750, Training loss: 0.0647671, Training accuracy: 0.9810537, Time: 05_05_2022__23:35:41\n","Epoch 4 of 5, Step: 12200 of 13750, Training loss: 0.0650525, Training accuracy: 0.9809631, Time: 05_05_2022__23:36:02\n","Epoch 4 of 5, Step: 12300 of 13750, Training loss: 0.0648773, Training accuracy: 0.9810163, Time: 05_05_2022__23:36:23\n","Epoch 4 of 5, Step: 12400 of 13750, Training loss: 0.0647898, Training accuracy: 0.9810484, Time: 05_05_2022__23:36:44\n","Epoch 4 of 5, Step: 12500 of 13750, Training loss: 0.0647163, Training accuracy: 0.9810200, Time: 05_05_2022__23:37:05\n","Epoch 4 of 5, Step: 12600 of 13750, Training loss: 0.0644669, Training accuracy: 0.9811111, Time: 05_05_2022__23:37:26\n","Epoch 4 of 5, Step: 12700 of 13750, Training loss: 0.0643171, Training accuracy: 0.9811024, Time: 05_05_2022__23:37:47\n","Epoch 4 of 5, Step: 12800 of 13750, Training loss: 0.0641951, Training accuracy: 0.9811523, Time: 05_05_2022__23:38:08\n","Epoch 4 of 5, Step: 12900 of 13750, Training loss: 0.0644637, Training accuracy: 0.9810659, Time: 05_05_2022__23:38:29\n","Epoch 4 of 5, Step: 13000 of 13750, Training loss: 0.0642514, Training accuracy: 0.9810962, Time: 05_05_2022__23:38:50\n","Epoch 4 of 5, Step: 13100 of 13750, Training loss: 0.0645170, Training accuracy: 0.9810305, Time: 05_05_2022__23:39:11\n","Epoch 4 of 5, Step: 13200 of 13750, Training loss: 0.0643311, Training accuracy: 0.9810606, Time: 05_05_2022__23:39:32\n","Epoch 4 of 5, Step: 13300 of 13750, Training loss: 0.0643707, Training accuracy: 0.9810526, Time: 05_05_2022__23:39:53\n","Epoch 4 of 5, Step: 13400 of 13750, Training loss: 0.0644119, Training accuracy: 0.9810261, Time: 05_05_2022__23:40:14\n","Epoch 4 of 5, Step: 13500 of 13750, Training loss: 0.0642203, Training accuracy: 0.9810741, Time: 05_05_2022__23:40:35\n","Epoch 4 of 5, Step: 13600 of 13750, Training loss: 0.0641217, Training accuracy: 0.9811029, Time: 05_05_2022__23:40:56\n","Epoch 4 of 5, Step: 13700 of 13750, Training loss: 0.0639600, Training accuracy: 0.9811496, Time: 05_05_2022__23:41:17\n","Epoch 4 of 5, Average training loss: 0.0640221, Average training accuracy: 0.9811273, Time: 05_05_2022__23:41:27\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"352cb8b1dcf647788a2482fed75e5c94"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0363722, Validation accuracy: 0.9900000, Time: 05_05_2022__23:41:33 | Loss decreased from 0.0455046 to 0.0367298 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0372559, Validation accuracy: 0.9887500, Time: 05_05_2022__23:41:41\n","Step: 300 of 1250, Validation loss: 0.0372462, Validation accuracy: 0.9891667, Time: 05_05_2022__23:41:46\n","Step: 400 of 1250, Validation loss: 0.0343360, Validation accuracy: 0.9900000, Time: 05_05_2022__23:41:51 | Loss decreased from 0.0367298 to 0.0343421 .... Saving the model\n","Step: 500 of 1250, Validation loss: 0.0331723, Validation accuracy: 0.9895000, Time: 05_05_2022__23:41:59 | Loss decreased from 0.0343421 to 0.0331760 .... Saving the model\n","Step: 600 of 1250, Validation loss: 0.0329995, Validation accuracy: 0.9904167, Time: 05_05_2022__23:42:06 | Loss decreased from 0.0331760 to 0.0330512 .... Saving the model\n","Step: 700 of 1250, Validation loss: 0.0317883, Validation accuracy: 0.9900000, Time: 05_05_2022__23:42:14 | Loss decreased from 0.0330512 to 0.0311962 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0330352, Validation accuracy: 0.9900000, Time: 05_05_2022__23:42:21\n","Step: 900 of 1250, Validation loss: 0.0352391, Validation accuracy: 0.9891667, Time: 05_05_2022__23:42:27\n","Step: 1000 of 1250, Validation loss: 0.0372381, Validation accuracy: 0.9890000, Time: 05_05_2022__23:42:32\n","Step: 1100 of 1250, Validation loss: 0.0359347, Validation accuracy: 0.9895455, Time: 05_05_2022__23:42:37\n","Step: 1200 of 1250, Validation loss: 0.0363561, Validation accuracy: 0.9889583, Time: 05_05_2022__23:42:43\n","Average validation loss: 0.0374337, Average validation accuracy: 0.9886000, Time: 05_05_2022__23:42:45\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa401d14edc6455f8e9e111f51518915"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 13750, Training loss: 0.0489829, Training accuracy: 0.9875000, Time: 05_05_2022__23:43:06\n","Epoch 5 of 5, Step: 200 of 13750, Training loss: 0.0407157, Training accuracy: 0.9900000, Time: 05_05_2022__23:43:27\n","Epoch 5 of 5, Step: 300 of 13750, Training loss: 0.0487624, Training accuracy: 0.9875000, Time: 05_05_2022__23:43:48\n","Epoch 5 of 5, Step: 400 of 13750, Training loss: 0.0491469, Training accuracy: 0.9862500, Time: 05_05_2022__23:44:09\n","Epoch 5 of 5, Step: 500 of 13750, Training loss: 0.0539033, Training accuracy: 0.9830000, Time: 05_05_2022__23:44:30\n","Epoch 5 of 5, Step: 600 of 13750, Training loss: 0.0556712, Training accuracy: 0.9816667, Time: 05_05_2022__23:44:51\n","Epoch 5 of 5, Step: 700 of 13750, Training loss: 0.0575532, Training accuracy: 0.9810714, Time: 05_05_2022__23:45:12\n","Epoch 5 of 5, Step: 800 of 13750, Training loss: 0.0563502, Training accuracy: 0.9812500, Time: 05_05_2022__23:45:33\n","Epoch 5 of 5, Step: 900 of 13750, Training loss: 0.0579362, Training accuracy: 0.9805556, Time: 05_05_2022__23:45:54\n","Epoch 5 of 5, Step: 1000 of 13750, Training loss: 0.0579382, Training accuracy: 0.9805000, Time: 05_05_2022__23:46:15\n","Epoch 5 of 5, Step: 1100 of 13750, Training loss: 0.0600394, Training accuracy: 0.9800000, Time: 05_05_2022__23:46:36\n","Epoch 5 of 5, Step: 1200 of 13750, Training loss: 0.0591916, Training accuracy: 0.9802083, Time: 05_05_2022__23:46:57\n","Epoch 5 of 5, Step: 1300 of 13750, Training loss: 0.0580482, Training accuracy: 0.9809615, Time: 05_05_2022__23:47:18\n","Epoch 5 of 5, Step: 1400 of 13750, Training loss: 0.0569597, Training accuracy: 0.9812500, Time: 05_05_2022__23:47:39\n","Epoch 5 of 5, Step: 1500 of 13750, Training loss: 0.0573942, Training accuracy: 0.9806667, Time: 05_05_2022__23:48:00\n","Epoch 5 of 5, Step: 1600 of 13750, Training loss: 0.0576793, Training accuracy: 0.9810937, Time: 05_05_2022__23:48:21\n","Epoch 5 of 5, Step: 1700 of 13750, Training loss: 0.0568365, Training accuracy: 0.9814706, Time: 05_05_2022__23:48:42\n","Epoch 5 of 5, Step: 1800 of 13750, Training loss: 0.0563494, Training accuracy: 0.9820833, Time: 05_05_2022__23:49:03\n","Epoch 5 of 5, Step: 1900 of 13750, Training loss: 0.0568458, Training accuracy: 0.9817105, Time: 05_05_2022__23:49:24\n","Epoch 5 of 5, Step: 2000 of 13750, Training loss: 0.0559955, Training accuracy: 0.9815000, Time: 05_05_2022__23:49:45\n","Epoch 5 of 5, Step: 2100 of 13750, Training loss: 0.0549041, Training accuracy: 0.9820238, Time: 05_05_2022__23:50:06\n","Epoch 5 of 5, Step: 2200 of 13750, Training loss: 0.0540680, Training accuracy: 0.9823864, Time: 05_05_2022__23:50:27\n","Epoch 5 of 5, Step: 2300 of 13750, Training loss: 0.0542442, Training accuracy: 0.9826087, Time: 05_05_2022__23:50:48\n","Epoch 5 of 5, Step: 2400 of 13750, Training loss: 0.0560748, Training accuracy: 0.9825000, Time: 05_05_2022__23:51:09\n","Epoch 5 of 5, Step: 2500 of 13750, Training loss: 0.0555585, Training accuracy: 0.9824000, Time: 05_05_2022__23:51:30\n","Epoch 5 of 5, Step: 2600 of 13750, Training loss: 0.0566523, Training accuracy: 0.9821154, Time: 05_05_2022__23:51:51\n","Epoch 5 of 5, Step: 2700 of 13750, Training loss: 0.0561603, Training accuracy: 0.9825000, Time: 05_05_2022__23:52:12\n","Epoch 5 of 5, Step: 2800 of 13750, Training loss: 0.0564883, Training accuracy: 0.9825000, Time: 05_05_2022__23:52:33\n","Epoch 5 of 5, Step: 2900 of 13750, Training loss: 0.0566225, Training accuracy: 0.9821552, Time: 05_05_2022__23:52:54\n","Epoch 5 of 5, Step: 3000 of 13750, Training loss: 0.0566341, Training accuracy: 0.9820833, Time: 05_05_2022__23:53:15\n","Epoch 5 of 5, Step: 3100 of 13750, Training loss: 0.0568383, Training accuracy: 0.9820161, Time: 05_05_2022__23:53:36\n","Epoch 5 of 5, Step: 3200 of 13750, Training loss: 0.0560618, Training accuracy: 0.9823437, Time: 05_05_2022__23:53:57\n","Epoch 5 of 5, Step: 3300 of 13750, Training loss: 0.0557712, Training accuracy: 0.9825758, Time: 05_05_2022__23:54:18\n","Epoch 5 of 5, Step: 3400 of 13750, Training loss: 0.0557946, Training accuracy: 0.9826471, Time: 05_05_2022__23:54:39\n","Epoch 5 of 5, Step: 3500 of 13750, Training loss: 0.0555760, Training accuracy: 0.9827857, Time: 05_05_2022__23:55:00\n","Epoch 5 of 5, Step: 3600 of 13750, Training loss: 0.0551588, Training accuracy: 0.9827778, Time: 05_05_2022__23:55:21\n","Epoch 5 of 5, Step: 3700 of 13750, Training loss: 0.0548663, Training accuracy: 0.9829054, Time: 05_05_2022__23:55:42\n","Epoch 5 of 5, Step: 3800 of 13750, Training loss: 0.0547149, Training accuracy: 0.9828947, Time: 05_05_2022__23:56:03\n","Epoch 5 of 5, Step: 3900 of 13750, Training loss: 0.0549858, Training accuracy: 0.9828205, Time: 05_05_2022__23:56:24\n","Epoch 5 of 5, Step: 4000 of 13750, Training loss: 0.0550208, Training accuracy: 0.9826875, Time: 05_05_2022__23:56:45\n","Epoch 5 of 5, Step: 4100 of 13750, Training loss: 0.0550803, Training accuracy: 0.9826829, Time: 05_05_2022__23:57:06\n","Epoch 5 of 5, Step: 4200 of 13750, Training loss: 0.0562890, Training accuracy: 0.9823810, Time: 05_05_2022__23:57:27\n","Epoch 5 of 5, Step: 4300 of 13750, Training loss: 0.0566317, Training accuracy: 0.9822093, Time: 05_05_2022__23:57:48\n","Epoch 5 of 5, Step: 4400 of 13750, Training loss: 0.0569361, Training accuracy: 0.9820455, Time: 05_05_2022__23:58:09\n","Epoch 5 of 5, Step: 4500 of 13750, Training loss: 0.0564922, Training accuracy: 0.9821667, Time: 05_05_2022__23:58:30\n","Epoch 5 of 5, Step: 4600 of 13750, Training loss: 0.0561005, Training accuracy: 0.9822826, Time: 05_05_2022__23:58:51\n","Epoch 5 of 5, Step: 4700 of 13750, Training loss: 0.0559014, Training accuracy: 0.9823404, Time: 05_05_2022__23:59:12\n","Epoch 5 of 5, Step: 4800 of 13750, Training loss: 0.0560651, Training accuracy: 0.9824479, Time: 05_05_2022__23:59:33\n","Epoch 5 of 5, Step: 4900 of 13750, Training loss: 0.0560818, Training accuracy: 0.9825510, Time: 05_05_2022__23:59:54\n","Epoch 5 of 5, Step: 5000 of 13750, Training loss: 0.0558160, Training accuracy: 0.9825000, Time: 06_05_2022__00:00:15\n","Epoch 5 of 5, Step: 5100 of 13750, Training loss: 0.0554244, Training accuracy: 0.9825000, Time: 06_05_2022__00:00:36\n","Epoch 5 of 5, Step: 5200 of 13750, Training loss: 0.0557262, Training accuracy: 0.9825481, Time: 06_05_2022__00:00:57\n","Epoch 5 of 5, Step: 5300 of 13750, Training loss: 0.0561152, Training accuracy: 0.9824057, Time: 06_05_2022__00:01:18\n","Epoch 5 of 5, Step: 5400 of 13750, Training loss: 0.0560627, Training accuracy: 0.9825463, Time: 06_05_2022__00:01:39\n","Epoch 5 of 5, Step: 5500 of 13750, Training loss: 0.0560262, Training accuracy: 0.9825909, Time: 06_05_2022__00:02:00\n","Epoch 5 of 5, Step: 5600 of 13750, Training loss: 0.0563420, Training accuracy: 0.9824554, Time: 06_05_2022__00:02:21\n","Epoch 5 of 5, Step: 5700 of 13750, Training loss: 0.0567840, Training accuracy: 0.9822807, Time: 06_05_2022__00:02:42\n","Epoch 5 of 5, Step: 5800 of 13750, Training loss: 0.0568311, Training accuracy: 0.9821983, Time: 06_05_2022__00:03:03\n","Epoch 5 of 5, Step: 5900 of 13750, Training loss: 0.0565682, Training accuracy: 0.9822458, Time: 06_05_2022__00:03:24\n","Epoch 5 of 5, Step: 6000 of 13750, Training loss: 0.0568323, Training accuracy: 0.9820417, Time: 06_05_2022__00:03:45\n","Epoch 5 of 5, Step: 6100 of 13750, Training loss: 0.0566336, Training accuracy: 0.9820492, Time: 06_05_2022__00:04:06\n","Epoch 5 of 5, Step: 6200 of 13750, Training loss: 0.0566401, Training accuracy: 0.9819758, Time: 06_05_2022__00:04:27\n","Epoch 5 of 5, Step: 6300 of 13750, Training loss: 0.0566919, Training accuracy: 0.9820238, Time: 06_05_2022__00:04:48\n","Epoch 5 of 5, Step: 6400 of 13750, Training loss: 0.0567814, Training accuracy: 0.9820313, Time: 06_05_2022__00:05:09\n","Epoch 5 of 5, Step: 6500 of 13750, Training loss: 0.0573877, Training accuracy: 0.9819231, Time: 06_05_2022__00:05:30\n","Epoch 5 of 5, Step: 6600 of 13750, Training loss: 0.0570490, Training accuracy: 0.9820455, Time: 06_05_2022__00:05:51\n","Epoch 5 of 5, Step: 6700 of 13750, Training loss: 0.0568836, Training accuracy: 0.9820522, Time: 06_05_2022__00:06:12\n","Epoch 5 of 5, Step: 6800 of 13750, Training loss: 0.0566539, Training accuracy: 0.9820588, Time: 06_05_2022__00:06:33\n","Epoch 5 of 5, Step: 6900 of 13750, Training loss: 0.0565405, Training accuracy: 0.9820652, Time: 06_05_2022__00:06:54\n","Epoch 5 of 5, Step: 7000 of 13750, Training loss: 0.0567212, Training accuracy: 0.9820714, Time: 06_05_2022__00:07:15\n","Epoch 5 of 5, Step: 7100 of 13750, Training loss: 0.0566490, Training accuracy: 0.9820775, Time: 06_05_2022__00:07:36\n","Epoch 5 of 5, Step: 7200 of 13750, Training loss: 0.0564674, Training accuracy: 0.9820833, Time: 06_05_2022__00:07:57\n","Epoch 5 of 5, Step: 7300 of 13750, Training loss: 0.0562601, Training accuracy: 0.9821233, Time: 06_05_2022__00:08:18\n","Epoch 5 of 5, Step: 7400 of 13750, Training loss: 0.0559478, Training accuracy: 0.9822297, Time: 06_05_2022__00:08:39\n","Epoch 5 of 5, Step: 7500 of 13750, Training loss: 0.0559328, Training accuracy: 0.9823000, Time: 06_05_2022__00:09:00\n","Epoch 5 of 5, Step: 7600 of 13750, Training loss: 0.0559545, Training accuracy: 0.9822368, Time: 06_05_2022__00:09:21\n","Epoch 5 of 5, Step: 7700 of 13750, Training loss: 0.0557353, Training accuracy: 0.9822727, Time: 06_05_2022__00:09:42\n","Epoch 5 of 5, Step: 7800 of 13750, Training loss: 0.0556093, Training accuracy: 0.9823397, Time: 06_05_2022__00:10:03\n","Epoch 5 of 5, Step: 7900 of 13750, Training loss: 0.0555493, Training accuracy: 0.9824051, Time: 06_05_2022__00:10:24\n","Epoch 5 of 5, Step: 8000 of 13750, Training loss: 0.0556259, Training accuracy: 0.9823750, Time: 06_05_2022__00:10:45\n","Epoch 5 of 5, Step: 8100 of 13750, Training loss: 0.0554120, Training accuracy: 0.9824383, Time: 06_05_2022__00:11:06\n","Epoch 5 of 5, Step: 8200 of 13750, Training loss: 0.0552708, Training accuracy: 0.9824695, Time: 06_05_2022__00:11:27\n","Epoch 5 of 5, Step: 8300 of 13750, Training loss: 0.0562571, Training accuracy: 0.9821687, Time: 06_05_2022__00:11:48\n","Epoch 5 of 5, Step: 8400 of 13750, Training loss: 0.0560847, Training accuracy: 0.9822619, Time: 06_05_2022__00:12:09\n","Epoch 5 of 5, Step: 8500 of 13750, Training loss: 0.0559721, Training accuracy: 0.9823824, Time: 06_05_2022__00:12:30\n","Epoch 5 of 5, Step: 8600 of 13750, Training loss: 0.0557746, Training accuracy: 0.9824709, Time: 06_05_2022__00:12:51\n","Epoch 5 of 5, Step: 8700 of 13750, Training loss: 0.0555615, Training accuracy: 0.9824713, Time: 06_05_2022__00:13:12\n","Epoch 5 of 5, Step: 8800 of 13750, Training loss: 0.0559671, Training accuracy: 0.9823011, Time: 06_05_2022__00:13:33\n","Epoch 5 of 5, Step: 8900 of 13750, Training loss: 0.0557196, Training accuracy: 0.9823876, Time: 06_05_2022__00:13:54\n","Epoch 5 of 5, Step: 9000 of 13750, Training loss: 0.0556050, Training accuracy: 0.9824167, Time: 06_05_2022__00:14:15\n","Epoch 5 of 5, Step: 9100 of 13750, Training loss: 0.0555560, Training accuracy: 0.9823901, Time: 06_05_2022__00:14:36\n","Epoch 5 of 5, Step: 9200 of 13750, Training loss: 0.0556859, Training accuracy: 0.9823370, Time: 06_05_2022__00:14:57\n","Epoch 5 of 5, Step: 9300 of 13750, Training loss: 0.0555462, Training accuracy: 0.9823656, Time: 06_05_2022__00:15:18\n","Epoch 5 of 5, Step: 9400 of 13750, Training loss: 0.0558986, Training accuracy: 0.9823138, Time: 06_05_2022__00:15:39\n","Epoch 5 of 5, Step: 9500 of 13750, Training loss: 0.0558675, Training accuracy: 0.9823158, Time: 06_05_2022__00:16:00\n","Epoch 5 of 5, Step: 9600 of 13750, Training loss: 0.0559251, Training accuracy: 0.9822917, Time: 06_05_2022__00:16:21\n","Epoch 5 of 5, Step: 9700 of 13750, Training loss: 0.0556330, Training accuracy: 0.9823969, Time: 06_05_2022__00:16:42\n","Epoch 5 of 5, Step: 9800 of 13750, Training loss: 0.0557242, Training accuracy: 0.9823214, Time: 06_05_2022__00:17:03\n","Epoch 5 of 5, Step: 9900 of 13750, Training loss: 0.0554610, Training accuracy: 0.9824242, Time: 06_05_2022__00:17:24\n","Epoch 5 of 5, Step: 10000 of 13750, Training loss: 0.0554092, Training accuracy: 0.9824750, Time: 06_05_2022__00:17:45\n","Epoch 5 of 5, Step: 10100 of 13750, Training loss: 0.0558854, Training accuracy: 0.9823762, Time: 06_05_2022__00:18:06\n","Epoch 5 of 5, Step: 10200 of 13750, Training loss: 0.0559389, Training accuracy: 0.9824265, Time: 06_05_2022__00:18:27\n","Epoch 5 of 5, Step: 10300 of 13750, Training loss: 0.0556320, Training accuracy: 0.9825971, Time: 06_05_2022__00:18:48\n","Epoch 5 of 5, Step: 10400 of 13750, Training loss: 0.0555448, Training accuracy: 0.9826683, Time: 06_05_2022__00:19:09\n","Epoch 5 of 5, Step: 10500 of 13750, Training loss: 0.0554092, Training accuracy: 0.9827143, Time: 06_05_2022__00:19:30\n","Epoch 5 of 5, Step: 10600 of 13750, Training loss: 0.0555121, Training accuracy: 0.9826651, Time: 06_05_2022__00:19:51\n","Epoch 5 of 5, Step: 10700 of 13750, Training loss: 0.0554116, Training accuracy: 0.9827570, Time: 06_05_2022__00:20:12\n","Epoch 5 of 5, Step: 10800 of 13750, Training loss: 0.0553403, Training accuracy: 0.9827546, Time: 06_05_2022__00:20:33\n","Epoch 5 of 5, Step: 10900 of 13750, Training loss: 0.0553708, Training accuracy: 0.9826835, Time: 06_05_2022__00:20:54\n","Epoch 5 of 5, Step: 11000 of 13750, Training loss: 0.0551297, Training accuracy: 0.9827727, Time: 06_05_2022__00:21:15\n","Epoch 5 of 5, Step: 11100 of 13750, Training loss: 0.0550413, Training accuracy: 0.9828378, Time: 06_05_2022__00:21:36\n","Epoch 5 of 5, Step: 11200 of 13750, Training loss: 0.0548761, Training accuracy: 0.9829018, Time: 06_05_2022__00:21:57\n","Epoch 5 of 5, Step: 11300 of 13750, Training loss: 0.0549157, Training accuracy: 0.9829204, Time: 06_05_2022__00:22:18\n","Epoch 5 of 5, Step: 11400 of 13750, Training loss: 0.0547559, Training accuracy: 0.9829605, Time: 06_05_2022__00:22:39\n","Epoch 5 of 5, Step: 11500 of 13750, Training loss: 0.0547850, Training accuracy: 0.9829565, Time: 06_05_2022__00:23:00\n","Epoch 5 of 5, Step: 11600 of 13750, Training loss: 0.0546248, Training accuracy: 0.9830172, Time: 06_05_2022__00:23:21\n","Epoch 5 of 5, Step: 11700 of 13750, Training loss: 0.0544520, Training accuracy: 0.9830342, Time: 06_05_2022__00:23:42\n","Epoch 5 of 5, Step: 11800 of 13750, Training loss: 0.0545259, Training accuracy: 0.9830085, Time: 06_05_2022__00:24:03\n","Epoch 5 of 5, Step: 11900 of 13750, Training loss: 0.0544510, Training accuracy: 0.9830672, Time: 06_05_2022__00:24:24\n","Epoch 5 of 5, Step: 12000 of 13750, Training loss: 0.0543616, Training accuracy: 0.9830625, Time: 06_05_2022__00:24:45\n","Epoch 5 of 5, Step: 12100 of 13750, Training loss: 0.0543037, Training accuracy: 0.9830579, Time: 06_05_2022__00:25:06\n","Epoch 5 of 5, Step: 12200 of 13750, Training loss: 0.0544264, Training accuracy: 0.9830738, Time: 06_05_2022__00:25:28\n","Epoch 5 of 5, Step: 12300 of 13750, Training loss: 0.0542190, Training accuracy: 0.9831504, Time: 06_05_2022__00:25:49\n","Epoch 5 of 5, Step: 12400 of 13750, Training loss: 0.0541948, Training accuracy: 0.9831653, Time: 06_05_2022__00:26:10\n","Epoch 5 of 5, Step: 12500 of 13750, Training loss: 0.0541141, Training accuracy: 0.9831800, Time: 06_05_2022__00:26:31\n","Epoch 5 of 5, Step: 12600 of 13750, Training loss: 0.0539065, Training accuracy: 0.9832540, Time: 06_05_2022__00:26:52\n","Epoch 5 of 5, Step: 12700 of 13750, Training loss: 0.0539044, Training accuracy: 0.9832480, Time: 06_05_2022__00:27:13\n","Epoch 5 of 5, Step: 12800 of 13750, Training loss: 0.0538142, Training accuracy: 0.9832617, Time: 06_05_2022__00:27:34\n","Epoch 5 of 5, Step: 12900 of 13750, Training loss: 0.0538855, Training accuracy: 0.9832558, Time: 06_05_2022__00:27:55\n","Epoch 5 of 5, Step: 13000 of 13750, Training loss: 0.0537305, Training accuracy: 0.9833077, Time: 06_05_2022__00:28:16\n","Epoch 5 of 5, Step: 13100 of 13750, Training loss: 0.0538413, Training accuracy: 0.9832824, Time: 06_05_2022__00:28:37\n","Epoch 5 of 5, Step: 13200 of 13750, Training loss: 0.0537255, Training accuracy: 0.9833144, Time: 06_05_2022__00:28:58\n","Epoch 5 of 5, Step: 13300 of 13750, Training loss: 0.0537156, Training accuracy: 0.9833083, Time: 06_05_2022__00:29:19\n","Epoch 5 of 5, Step: 13400 of 13750, Training loss: 0.0537099, Training accuracy: 0.9833022, Time: 06_05_2022__00:29:41\n","Epoch 5 of 5, Step: 13500 of 13750, Training loss: 0.0536299, Training accuracy: 0.9832963, Time: 06_05_2022__00:30:02\n","Epoch 5 of 5, Step: 13600 of 13750, Training loss: 0.0537390, Training accuracy: 0.9832904, Time: 06_05_2022__00:30:23\n","Epoch 5 of 5, Step: 13700 of 13750, Training loss: 0.0536296, Training accuracy: 0.9833212, Time: 06_05_2022__00:30:44\n","Epoch 5 of 5, Average training loss: 0.0536421, Average training accuracy: 0.9833455, Time: 06_05_2022__00:30:54\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf54fbae7a394b988ea0a03a4735a462"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0283667, Validation accuracy: 0.9900000, Time: 06_05_2022__00:31:00 | Loss decreased from 0.0311962 to 0.0286449 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0361840, Validation accuracy: 0.9875000, Time: 06_05_2022__00:31:07\n","Step: 300 of 1250, Validation loss: 0.0354372, Validation accuracy: 0.9883333, Time: 06_05_2022__00:31:13\n","Step: 400 of 1250, Validation loss: 0.0348755, Validation accuracy: 0.9893750, Time: 06_05_2022__00:31:18\n","Step: 500 of 1250, Validation loss: 0.0343512, Validation accuracy: 0.9895000, Time: 06_05_2022__00:31:23\n","Step: 600 of 1250, Validation loss: 0.0349165, Validation accuracy: 0.9891667, Time: 06_05_2022__00:31:29\n","Step: 700 of 1250, Validation loss: 0.0335070, Validation accuracy: 0.9892857, Time: 06_05_2022__00:31:34\n","Step: 800 of 1250, Validation loss: 0.0338175, Validation accuracy: 0.9890625, Time: 06_05_2022__00:31:39\n","Step: 900 of 1250, Validation loss: 0.0339016, Validation accuracy: 0.9891667, Time: 06_05_2022__00:31:44\n","Step: 1000 of 1250, Validation loss: 0.0355523, Validation accuracy: 0.9887500, Time: 06_05_2022__00:31:49\n","Step: 1100 of 1250, Validation loss: 0.0343363, Validation accuracy: 0.9888636, Time: 06_05_2022__00:31:55\n","Step: 1200 of 1250, Validation loss: 0.0349663, Validation accuracy: 0.9883333, Time: 06_05_2022__00:32:00\n","Average validation loss: 0.0363127, Average validation accuracy: 0.9882000, Time: 06_05_2022__00:32:02\n","###################### Testing vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f369a7e6b73c4137b0b9e6a66fbaf953"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.9950000, Time: 06_05_2022__00:32:12\n","Step: 200 of 2500, Test accuracy: 0.9900000, Time: 06_05_2022__00:32:18\n","Step: 300 of 2500, Test accuracy: 0.9866667, Time: 06_05_2022__00:32:23\n","Step: 400 of 2500, Test accuracy: 0.9862500, Time: 06_05_2022__00:32:28\n","Step: 500 of 2500, Test accuracy: 0.9860000, Time: 06_05_2022__00:32:34\n","Step: 600 of 2500, Test accuracy: 0.9850000, Time: 06_05_2022__00:32:39\n","Step: 700 of 2500, Test accuracy: 0.9853571, Time: 06_05_2022__00:32:45\n","Step: 800 of 2500, Test accuracy: 0.9856250, Time: 06_05_2022__00:32:50\n","Step: 900 of 2500, Test accuracy: 0.9858333, Time: 06_05_2022__00:32:56\n","Step: 1000 of 2500, Test accuracy: 0.9852500, Time: 06_05_2022__00:33:02\n","Step: 1100 of 2500, Test accuracy: 0.9856818, Time: 06_05_2022__00:33:07\n","Step: 1200 of 2500, Test accuracy: 0.9852083, Time: 06_05_2022__00:33:12\n","Step: 1300 of 2500, Test accuracy: 0.9851923, Time: 06_05_2022__00:33:18\n","Step: 1400 of 2500, Test accuracy: 0.9862500, Time: 06_05_2022__00:33:23\n","Step: 1500 of 2500, Test accuracy: 0.9866667, Time: 06_05_2022__00:33:28\n","Step: 1600 of 2500, Test accuracy: 0.9875000, Time: 06_05_2022__00:33:34\n","Step: 1700 of 2500, Test accuracy: 0.9869118, Time: 06_05_2022__00:33:39\n","Step: 1800 of 2500, Test accuracy: 0.9876389, Time: 06_05_2022__00:33:45\n","Step: 1900 of 2500, Test accuracy: 0.9882895, Time: 06_05_2022__00:33:50\n","Step: 2000 of 2500, Test accuracy: 0.9883750, Time: 06_05_2022__00:33:55\n","Step: 2100 of 2500, Test accuracy: 0.9886905, Time: 06_05_2022__00:34:00\n","Step: 2200 of 2500, Test accuracy: 0.9889773, Time: 06_05_2022__00:34:06\n","Step: 2300 of 2500, Test accuracy: 0.9891304, Time: 06_05_2022__00:34:11\n","Step: 2400 of 2500, Test accuracy: 0.9894792, Time: 06_05_2022__00:34:16\n","Step: 2500 of 2500, Test accuracy: 0.9890000, Time: 06_05_2022__00:34:21\n","Average testing accuracy: 0.9890000, Time: 06_05_2022__00:34:21\n","###################### Training vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf9626f28084445bb3961033c6cde6ec"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 13750, Training loss: 2.2979337, Training accuracy: 0.1625000, Time: 06_05_2022__00:34:45\n","Epoch 1 of 5, Step: 200 of 13750, Training loss: 2.0947862, Training accuracy: 0.2625000, Time: 06_05_2022__00:35:06\n","Epoch 1 of 5, Step: 300 of 13750, Training loss: 1.9407942, Training accuracy: 0.3416667, Time: 06_05_2022__00:35:27\n","Epoch 1 of 5, Step: 400 of 13750, Training loss: 1.7594890, Training accuracy: 0.4137500, Time: 06_05_2022__00:35:48\n","Epoch 1 of 5, Step: 500 of 13750, Training loss: 1.5995156, Training accuracy: 0.4725000, Time: 06_05_2022__00:36:09\n","Epoch 1 of 5, Step: 600 of 13750, Training loss: 1.4655168, Training accuracy: 0.5195833, Time: 06_05_2022__00:36:30\n","Epoch 1 of 5, Step: 700 of 13750, Training loss: 1.3566319, Training accuracy: 0.5575000, Time: 06_05_2022__00:36:51\n","Epoch 1 of 5, Step: 800 of 13750, Training loss: 1.2570210, Training accuracy: 0.5925000, Time: 06_05_2022__00:37:12\n","Epoch 1 of 5, Step: 900 of 13750, Training loss: 1.1799924, Training accuracy: 0.6197222, Time: 06_05_2022__00:37:33\n","Epoch 1 of 5, Step: 1000 of 13750, Training loss: 1.1089113, Training accuracy: 0.6427500, Time: 06_05_2022__00:37:54\n","Epoch 1 of 5, Step: 1100 of 13750, Training loss: 1.0455427, Training accuracy: 0.6647727, Time: 06_05_2022__00:38:15\n","Epoch 1 of 5, Step: 1200 of 13750, Training loss: 0.9880446, Training accuracy: 0.6845833, Time: 06_05_2022__00:38:36\n","Epoch 1 of 5, Step: 1300 of 13750, Training loss: 0.9401646, Training accuracy: 0.6998077, Time: 06_05_2022__00:38:57\n","Epoch 1 of 5, Step: 1400 of 13750, Training loss: 0.8946108, Training accuracy: 0.7146429, Time: 06_05_2022__00:39:19\n","Epoch 1 of 5, Step: 1500 of 13750, Training loss: 0.8545508, Training accuracy: 0.7275000, Time: 06_05_2022__00:39:40\n","Epoch 1 of 5, Step: 1600 of 13750, Training loss: 0.8215229, Training accuracy: 0.7392188, Time: 06_05_2022__00:40:01\n","Epoch 1 of 5, Step: 1700 of 13750, Training loss: 0.7927433, Training accuracy: 0.7486765, Time: 06_05_2022__00:40:22\n","Epoch 1 of 5, Step: 1800 of 13750, Training loss: 0.7643192, Training accuracy: 0.7583333, Time: 06_05_2022__00:40:43\n","Epoch 1 of 5, Step: 1900 of 13750, Training loss: 0.7390968, Training accuracy: 0.7672368, Time: 06_05_2022__00:41:04\n","Epoch 1 of 5, Step: 2000 of 13750, Training loss: 0.7143832, Training accuracy: 0.7747500, Time: 06_05_2022__00:41:25\n","Epoch 1 of 5, Step: 2100 of 13750, Training loss: 0.6894160, Training accuracy: 0.7827381, Time: 06_05_2022__00:41:46\n","Epoch 1 of 5, Step: 2200 of 13750, Training loss: 0.6689378, Training accuracy: 0.7892045, Time: 06_05_2022__00:42:07\n","Epoch 1 of 5, Step: 2300 of 13750, Training loss: 0.6472594, Training accuracy: 0.7969565, Time: 06_05_2022__00:42:28\n","Epoch 1 of 5, Step: 2400 of 13750, Training loss: 0.6298985, Training accuracy: 0.8026042, Time: 06_05_2022__00:42:49\n","Epoch 1 of 5, Step: 2500 of 13750, Training loss: 0.6137867, Training accuracy: 0.8078000, Time: 06_05_2022__00:43:10\n","Epoch 1 of 5, Step: 2600 of 13750, Training loss: 0.5992919, Training accuracy: 0.8124038, Time: 06_05_2022__00:43:31\n","Epoch 1 of 5, Step: 2700 of 13750, Training loss: 0.5849943, Training accuracy: 0.8170370, Time: 06_05_2022__00:43:52\n","Epoch 1 of 5, Step: 2800 of 13750, Training loss: 0.5709815, Training accuracy: 0.8214286, Time: 06_05_2022__00:44:13\n","Epoch 1 of 5, Step: 2900 of 13750, Training loss: 0.5584281, Training accuracy: 0.8256897, Time: 06_05_2022__00:44:34\n","Epoch 1 of 5, Step: 3000 of 13750, Training loss: 0.5448471, Training accuracy: 0.8300000, Time: 06_05_2022__00:44:55\n","Epoch 1 of 5, Step: 3100 of 13750, Training loss: 0.5333899, Training accuracy: 0.8340323, Time: 06_05_2022__00:45:16\n","Epoch 1 of 5, Step: 3200 of 13750, Training loss: 0.5214555, Training accuracy: 0.8376562, Time: 06_05_2022__00:45:37\n","Epoch 1 of 5, Step: 3300 of 13750, Training loss: 0.5105982, Training accuracy: 0.8412121, Time: 06_05_2022__00:45:58\n","Epoch 1 of 5, Step: 3400 of 13750, Training loss: 0.5012763, Training accuracy: 0.8442647, Time: 06_05_2022__00:46:20\n","Epoch 1 of 5, Step: 3500 of 13750, Training loss: 0.4916179, Training accuracy: 0.8471429, Time: 06_05_2022__00:46:41\n","Epoch 1 of 5, Step: 3600 of 13750, Training loss: 0.4825795, Training accuracy: 0.8499306, Time: 06_05_2022__00:47:02\n","Epoch 1 of 5, Step: 3700 of 13750, Training loss: 0.4742583, Training accuracy: 0.8522973, Time: 06_05_2022__00:47:23\n","Epoch 1 of 5, Step: 3800 of 13750, Training loss: 0.4658159, Training accuracy: 0.8548026, Time: 06_05_2022__00:47:44\n","Epoch 1 of 5, Step: 3900 of 13750, Training loss: 0.4589592, Training accuracy: 0.8569872, Time: 06_05_2022__00:48:05\n","Epoch 1 of 5, Step: 4000 of 13750, Training loss: 0.4521704, Training accuracy: 0.8587500, Time: 06_05_2022__00:48:26\n","Epoch 1 of 5, Step: 4100 of 13750, Training loss: 0.4446476, Training accuracy: 0.8611585, Time: 06_05_2022__00:48:47\n","Epoch 1 of 5, Step: 4200 of 13750, Training loss: 0.4394056, Training accuracy: 0.8629167, Time: 06_05_2022__00:49:08\n","Epoch 1 of 5, Step: 4300 of 13750, Training loss: 0.4330473, Training accuracy: 0.8651163, Time: 06_05_2022__00:49:29\n","Epoch 1 of 5, Step: 4400 of 13750, Training loss: 0.4263266, Training accuracy: 0.8675000, Time: 06_05_2022__00:49:50\n","Epoch 1 of 5, Step: 4500 of 13750, Training loss: 0.4198287, Training accuracy: 0.8693889, Time: 06_05_2022__00:50:11\n","Epoch 1 of 5, Step: 4600 of 13750, Training loss: 0.4133338, Training accuracy: 0.8714674, Time: 06_05_2022__00:50:32\n","Epoch 1 of 5, Step: 4700 of 13750, Training loss: 0.4081611, Training accuracy: 0.8729787, Time: 06_05_2022__00:50:53\n","Epoch 1 of 5, Step: 4800 of 13750, Training loss: 0.4033100, Training accuracy: 0.8745833, Time: 06_05_2022__00:51:14\n","Epoch 1 of 5, Step: 4900 of 13750, Training loss: 0.3986608, Training accuracy: 0.8762755, Time: 06_05_2022__00:51:35\n","Epoch 1 of 5, Step: 5000 of 13750, Training loss: 0.3932698, Training accuracy: 0.8780500, Time: 06_05_2022__00:51:56\n","Epoch 1 of 5, Step: 5100 of 13750, Training loss: 0.3876954, Training accuracy: 0.8797549, Time: 06_05_2022__00:52:18\n","Epoch 1 of 5, Step: 5200 of 13750, Training loss: 0.3824596, Training accuracy: 0.8812981, Time: 06_05_2022__00:52:39\n","Epoch 1 of 5, Step: 5300 of 13750, Training loss: 0.3780987, Training accuracy: 0.8825472, Time: 06_05_2022__00:53:00\n","Epoch 1 of 5, Step: 5400 of 13750, Training loss: 0.3732946, Training accuracy: 0.8841204, Time: 06_05_2022__00:53:21\n","Epoch 1 of 5, Step: 5500 of 13750, Training loss: 0.3684518, Training accuracy: 0.8856818, Time: 06_05_2022__00:53:42\n","Epoch 1 of 5, Step: 5600 of 13750, Training loss: 0.3651972, Training accuracy: 0.8867411, Time: 06_05_2022__00:54:03\n","Epoch 1 of 5, Step: 5700 of 13750, Training loss: 0.3618131, Training accuracy: 0.8878509, Time: 06_05_2022__00:54:24\n","Epoch 1 of 5, Step: 5800 of 13750, Training loss: 0.3572699, Training accuracy: 0.8893103, Time: 06_05_2022__00:54:45\n","Epoch 1 of 5, Step: 5900 of 13750, Training loss: 0.3532622, Training accuracy: 0.8905085, Time: 06_05_2022__00:55:06\n","Epoch 1 of 5, Step: 6000 of 13750, Training loss: 0.3507245, Training accuracy: 0.8912083, Time: 06_05_2022__00:55:27\n","Epoch 1 of 5, Step: 6100 of 13750, Training loss: 0.3467563, Training accuracy: 0.8924180, Time: 06_05_2022__00:55:48\n","Epoch 1 of 5, Step: 6200 of 13750, Training loss: 0.3436920, Training accuracy: 0.8932258, Time: 06_05_2022__00:56:09\n","Epoch 1 of 5, Step: 6300 of 13750, Training loss: 0.3405853, Training accuracy: 0.8942460, Time: 06_05_2022__00:56:30\n","Epoch 1 of 5, Step: 6400 of 13750, Training loss: 0.3373386, Training accuracy: 0.8951953, Time: 06_05_2022__00:56:51\n","Epoch 1 of 5, Step: 6500 of 13750, Training loss: 0.3345573, Training accuracy: 0.8961538, Time: 06_05_2022__00:57:12\n","Epoch 1 of 5, Step: 6600 of 13750, Training loss: 0.3310133, Training accuracy: 0.8971591, Time: 06_05_2022__00:57:33\n","Epoch 1 of 5, Step: 6700 of 13750, Training loss: 0.3271914, Training accuracy: 0.8982836, Time: 06_05_2022__00:57:54\n","Epoch 1 of 5, Step: 6800 of 13750, Training loss: 0.3237451, Training accuracy: 0.8993382, Time: 06_05_2022__00:58:15\n","Epoch 1 of 5, Step: 6900 of 13750, Training loss: 0.3206341, Training accuracy: 0.9004710, Time: 06_05_2022__00:58:37\n","Epoch 1 of 5, Step: 7000 of 13750, Training loss: 0.3178601, Training accuracy: 0.9013929, Time: 06_05_2022__00:58:58\n","Epoch 1 of 5, Step: 7100 of 13750, Training loss: 0.3154573, Training accuracy: 0.9022535, Time: 06_05_2022__00:59:19\n","Epoch 1 of 5, Step: 7200 of 13750, Training loss: 0.3126773, Training accuracy: 0.9030903, Time: 06_05_2022__00:59:40\n","Epoch 1 of 5, Step: 7300 of 13750, Training loss: 0.3095464, Training accuracy: 0.9041438, Time: 06_05_2022__01:00:01\n","Epoch 1 of 5, Step: 7400 of 13750, Training loss: 0.3066748, Training accuracy: 0.9051014, Time: 06_05_2022__01:00:22\n","Epoch 1 of 5, Step: 7500 of 13750, Training loss: 0.3043479, Training accuracy: 0.9059667, Time: 06_05_2022__01:00:43\n","Epoch 1 of 5, Step: 7600 of 13750, Training loss: 0.3019096, Training accuracy: 0.9067763, Time: 06_05_2022__01:01:04\n","Epoch 1 of 5, Step: 7700 of 13750, Training loss: 0.2991945, Training accuracy: 0.9075974, Time: 06_05_2022__01:01:25\n","Epoch 1 of 5, Step: 7800 of 13750, Training loss: 0.2968583, Training accuracy: 0.9082692, Time: 06_05_2022__01:01:46\n","Epoch 1 of 5, Step: 7900 of 13750, Training loss: 0.2951314, Training accuracy: 0.9086392, Time: 06_05_2022__01:02:07\n","Epoch 1 of 5, Step: 8000 of 13750, Training loss: 0.2929452, Training accuracy: 0.9093125, Time: 06_05_2022__01:02:28\n","Epoch 1 of 5, Step: 8100 of 13750, Training loss: 0.2903052, Training accuracy: 0.9100926, Time: 06_05_2022__01:02:49\n","Epoch 1 of 5, Step: 8200 of 13750, Training loss: 0.2879551, Training accuracy: 0.9109451, Time: 06_05_2022__01:03:10\n","Epoch 1 of 5, Step: 8300 of 13750, Training loss: 0.2868016, Training accuracy: 0.9113855, Time: 06_05_2022__01:03:31\n","Epoch 1 of 5, Step: 8400 of 13750, Training loss: 0.2849813, Training accuracy: 0.9119643, Time: 06_05_2022__01:03:52\n","Epoch 1 of 5, Step: 8500 of 13750, Training loss: 0.2828016, Training accuracy: 0.9126176, Time: 06_05_2022__01:04:13\n","Epoch 1 of 5, Step: 8600 of 13750, Training loss: 0.2805826, Training accuracy: 0.9133721, Time: 06_05_2022__01:04:34\n","Epoch 1 of 5, Step: 8700 of 13750, Training loss: 0.2784638, Training accuracy: 0.9139943, Time: 06_05_2022__01:04:55\n","Epoch 1 of 5, Step: 8800 of 13750, Training loss: 0.2769182, Training accuracy: 0.9144602, Time: 06_05_2022__01:05:17\n","Epoch 1 of 5, Step: 8900 of 13750, Training loss: 0.2745078, Training accuracy: 0.9153090, Time: 06_05_2022__01:05:38\n","Epoch 1 of 5, Step: 9000 of 13750, Training loss: 0.2725293, Training accuracy: 0.9158333, Time: 06_05_2022__01:05:59\n","Epoch 1 of 5, Step: 9100 of 13750, Training loss: 0.2707217, Training accuracy: 0.9164011, Time: 06_05_2022__01:06:20\n","Epoch 1 of 5, Step: 9200 of 13750, Training loss: 0.2690766, Training accuracy: 0.9168207, Time: 06_05_2022__01:06:41\n","Epoch 1 of 5, Step: 9300 of 13750, Training loss: 0.2675540, Training accuracy: 0.9173118, Time: 06_05_2022__01:07:02\n","Epoch 1 of 5, Step: 9400 of 13750, Training loss: 0.2661158, Training accuracy: 0.9177394, Time: 06_05_2022__01:07:23\n","Epoch 1 of 5, Step: 9500 of 13750, Training loss: 0.2643781, Training accuracy: 0.9183684, Time: 06_05_2022__01:07:44\n","Epoch 1 of 5, Step: 9600 of 13750, Training loss: 0.2626630, Training accuracy: 0.9188542, Time: 06_05_2022__01:08:05\n","Epoch 1 of 5, Step: 9700 of 13750, Training loss: 0.2607011, Training accuracy: 0.9194588, Time: 06_05_2022__01:08:26\n","Epoch 1 of 5, Step: 9800 of 13750, Training loss: 0.2590608, Training accuracy: 0.9199235, Time: 06_05_2022__01:08:47\n","Epoch 1 of 5, Step: 9900 of 13750, Training loss: 0.2571648, Training accuracy: 0.9204798, Time: 06_05_2022__01:09:08\n","Epoch 1 of 5, Step: 10000 of 13750, Training loss: 0.2553363, Training accuracy: 0.9210500, Time: 06_05_2022__01:09:29\n","Epoch 1 of 5, Step: 10100 of 13750, Training loss: 0.2542985, Training accuracy: 0.9215347, Time: 06_05_2022__01:09:50\n","Epoch 1 of 5, Step: 10200 of 13750, Training loss: 0.2528401, Training accuracy: 0.9219118, Time: 06_05_2022__01:10:11\n","Epoch 1 of 5, Step: 10300 of 13750, Training loss: 0.2511653, Training accuracy: 0.9224757, Time: 06_05_2022__01:10:32\n","Epoch 1 of 5, Step: 10400 of 13750, Training loss: 0.2496485, Training accuracy: 0.9229327, Time: 06_05_2022__01:10:53\n","Epoch 1 of 5, Step: 10500 of 13750, Training loss: 0.2480674, Training accuracy: 0.9234524, Time: 06_05_2022__01:11:14\n","Epoch 1 of 5, Step: 10600 of 13750, Training loss: 0.2466218, Training accuracy: 0.9239858, Time: 06_05_2022__01:11:35\n","Epoch 1 of 5, Step: 10700 of 13750, Training loss: 0.2450306, Training accuracy: 0.9244626, Time: 06_05_2022__01:11:56\n","Epoch 1 of 5, Step: 10800 of 13750, Training loss: 0.2438514, Training accuracy: 0.9247685, Time: 06_05_2022__01:12:17\n","Epoch 1 of 5, Step: 10900 of 13750, Training loss: 0.2424286, Training accuracy: 0.9251835, Time: 06_05_2022__01:12:38\n","Epoch 1 of 5, Step: 11000 of 13750, Training loss: 0.2407642, Training accuracy: 0.9256818, Time: 06_05_2022__01:13:00\n","Epoch 1 of 5, Step: 11100 of 13750, Training loss: 0.2395400, Training accuracy: 0.9260135, Time: 06_05_2022__01:13:21\n","Epoch 1 of 5, Step: 11200 of 13750, Training loss: 0.2380798, Training accuracy: 0.9264732, Time: 06_05_2022__01:13:42\n","Epoch 1 of 5, Step: 11300 of 13750, Training loss: 0.2367590, Training accuracy: 0.9267920, Time: 06_05_2022__01:14:03\n","Epoch 1 of 5, Step: 11400 of 13750, Training loss: 0.2354568, Training accuracy: 0.9272149, Time: 06_05_2022__01:14:24\n","Epoch 1 of 5, Step: 11500 of 13750, Training loss: 0.2344350, Training accuracy: 0.9275217, Time: 06_05_2022__01:14:45\n","Epoch 1 of 5, Step: 11600 of 13750, Training loss: 0.2329623, Training accuracy: 0.9279741, Time: 06_05_2022__01:15:06\n","Epoch 1 of 5, Step: 11700 of 13750, Training loss: 0.2315667, Training accuracy: 0.9283761, Time: 06_05_2022__01:15:27\n","Epoch 1 of 5, Step: 11800 of 13750, Training loss: 0.2303166, Training accuracy: 0.9287712, Time: 06_05_2022__01:15:48\n","Epoch 1 of 5, Step: 11900 of 13750, Training loss: 0.2291043, Training accuracy: 0.9291387, Time: 06_05_2022__01:16:09\n","Epoch 1 of 5, Step: 12000 of 13750, Training loss: 0.2279771, Training accuracy: 0.9294792, Time: 06_05_2022__01:16:30\n","Epoch 1 of 5, Step: 12100 of 13750, Training loss: 0.2268094, Training accuracy: 0.9297934, Time: 06_05_2022__01:16:51\n","Epoch 1 of 5, Step: 12200 of 13750, Training loss: 0.2258379, Training accuracy: 0.9301025, Time: 06_05_2022__01:17:12\n","Epoch 1 of 5, Step: 12300 of 13750, Training loss: 0.2246085, Training accuracy: 0.9305081, Time: 06_05_2022__01:17:33\n","Epoch 1 of 5, Step: 12400 of 13750, Training loss: 0.2233829, Training accuracy: 0.9309073, Time: 06_05_2022__01:17:54\n","Epoch 1 of 5, Step: 12500 of 13750, Training loss: 0.2221965, Training accuracy: 0.9312600, Time: 06_05_2022__01:18:15\n","Epoch 1 of 5, Step: 12600 of 13750, Training loss: 0.2208281, Training accuracy: 0.9316468, Time: 06_05_2022__01:18:36\n","Epoch 1 of 5, Step: 12700 of 13750, Training loss: 0.2195752, Training accuracy: 0.9320276, Time: 06_05_2022__01:18:57\n","Epoch 1 of 5, Step: 12800 of 13750, Training loss: 0.2184539, Training accuracy: 0.9322852, Time: 06_05_2022__01:19:18\n","Epoch 1 of 5, Step: 12900 of 13750, Training loss: 0.2175843, Training accuracy: 0.9325969, Time: 06_05_2022__01:19:39\n","Epoch 1 of 5, Step: 13000 of 13750, Training loss: 0.2165396, Training accuracy: 0.9328269, Time: 06_05_2022__01:20:00\n","Epoch 1 of 5, Step: 13100 of 13750, Training loss: 0.2158366, Training accuracy: 0.9329962, Time: 06_05_2022__01:20:22\n","Epoch 1 of 5, Step: 13200 of 13750, Training loss: 0.2147600, Training accuracy: 0.9333523, Time: 06_05_2022__01:20:43\n","Epoch 1 of 5, Step: 13300 of 13750, Training loss: 0.2140531, Training accuracy: 0.9336090, Time: 06_05_2022__01:21:04\n","Epoch 1 of 5, Step: 13400 of 13750, Training loss: 0.2131116, Training accuracy: 0.9339739, Time: 06_05_2022__01:21:25\n","Epoch 1 of 5, Step: 13500 of 13750, Training loss: 0.2119461, Training accuracy: 0.9343148, Time: 06_05_2022__01:21:46\n","Epoch 1 of 5, Step: 13600 of 13750, Training loss: 0.2109810, Training accuracy: 0.9346507, Time: 06_05_2022__01:22:07\n","Epoch 1 of 5, Step: 13700 of 13750, Training loss: 0.2100496, Training accuracy: 0.9349270, Time: 06_05_2022__01:22:28\n","Epoch 1 of 5, Average training loss: 0.2095835, Average training accuracy: 0.9350909, Time: 06_05_2022__01:22:38\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21b86af3bfd44f4b8c145a745ae0b14c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0539644, Validation accuracy: 0.9825000, Time: 06_05_2022__01:22:44 | Loss decreased from inf to 0.0540506 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0564132, Validation accuracy: 0.9800000, Time: 06_05_2022__01:22:52\n","Step: 300 of 1250, Validation loss: 0.0585782, Validation accuracy: 0.9800000, Time: 06_05_2022__01:22:57\n","Step: 400 of 1250, Validation loss: 0.0550838, Validation accuracy: 0.9812500, Time: 06_05_2022__01:23:03\n","Step: 500 of 1250, Validation loss: 0.0539197, Validation accuracy: 0.9810000, Time: 06_05_2022__01:23:08 | Loss decreased from 0.0540506 to 0.0539901 .... Saving the model\n","Step: 600 of 1250, Validation loss: 0.0516296, Validation accuracy: 0.9820833, Time: 06_05_2022__01:23:16 | Loss decreased from 0.0539901 to 0.0516970 .... Saving the model\n","Step: 700 of 1250, Validation loss: 0.0479302, Validation accuracy: 0.9835714, Time: 06_05_2022__01:23:23 | Loss decreased from 0.0516970 to 0.0473342 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0500957, Validation accuracy: 0.9840625, Time: 06_05_2022__01:23:31\n","Step: 900 of 1250, Validation loss: 0.0504011, Validation accuracy: 0.9841667, Time: 06_05_2022__01:23:36\n","Step: 1000 of 1250, Validation loss: 0.0536579, Validation accuracy: 0.9830000, Time: 06_05_2022__01:23:41\n","Step: 1100 of 1250, Validation loss: 0.0521340, Validation accuracy: 0.9834091, Time: 06_05_2022__01:23:47\n","Step: 1200 of 1250, Validation loss: 0.0524611, Validation accuracy: 0.9831250, Time: 06_05_2022__01:23:52\n","Average validation loss: 0.0542379, Average validation accuracy: 0.9828000, Time: 06_05_2022__01:23:54\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ef027d6365447888677ab79a7a8b996"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 13750, Training loss: 0.0647342, Training accuracy: 0.9825000, Time: 06_05_2022__01:24:16\n","Epoch 2 of 5, Step: 200 of 13750, Training loss: 0.0624151, Training accuracy: 0.9800000, Time: 06_05_2022__01:24:37\n","Epoch 2 of 5, Step: 300 of 13750, Training loss: 0.0759318, Training accuracy: 0.9791667, Time: 06_05_2022__01:24:58\n","Epoch 2 of 5, Step: 400 of 13750, Training loss: 0.0769219, Training accuracy: 0.9768750, Time: 06_05_2022__01:25:19\n","Epoch 2 of 5, Step: 500 of 13750, Training loss: 0.0780763, Training accuracy: 0.9755000, Time: 06_05_2022__01:25:40\n","Epoch 2 of 5, Step: 600 of 13750, Training loss: 0.0737470, Training accuracy: 0.9770833, Time: 06_05_2022__01:26:01\n","Epoch 2 of 5, Step: 700 of 13750, Training loss: 0.0773076, Training accuracy: 0.9775000, Time: 06_05_2022__01:26:22\n","Epoch 2 of 5, Step: 800 of 13750, Training loss: 0.0779171, Training accuracy: 0.9768750, Time: 06_05_2022__01:26:43\n","Epoch 2 of 5, Step: 900 of 13750, Training loss: 0.0785790, Training accuracy: 0.9766667, Time: 06_05_2022__01:27:04\n","Epoch 2 of 5, Step: 1000 of 13750, Training loss: 0.0793285, Training accuracy: 0.9770000, Time: 06_05_2022__01:27:25\n","Epoch 2 of 5, Step: 1100 of 13750, Training loss: 0.0787415, Training accuracy: 0.9772727, Time: 06_05_2022__01:27:46\n","Epoch 2 of 5, Step: 1200 of 13750, Training loss: 0.0799772, Training accuracy: 0.9772917, Time: 06_05_2022__01:28:07\n","Epoch 2 of 5, Step: 1300 of 13750, Training loss: 0.0783774, Training accuracy: 0.9773077, Time: 06_05_2022__01:28:28\n","Epoch 2 of 5, Step: 1400 of 13750, Training loss: 0.0769449, Training accuracy: 0.9776786, Time: 06_05_2022__01:28:49\n","Epoch 2 of 5, Step: 1500 of 13750, Training loss: 0.0763816, Training accuracy: 0.9780000, Time: 06_05_2022__01:29:10\n","Epoch 2 of 5, Step: 1600 of 13750, Training loss: 0.0767799, Training accuracy: 0.9776563, Time: 06_05_2022__01:29:31\n","Epoch 2 of 5, Step: 1700 of 13750, Training loss: 0.0761757, Training accuracy: 0.9775000, Time: 06_05_2022__01:29:52\n","Epoch 2 of 5, Step: 1800 of 13750, Training loss: 0.0750546, Training accuracy: 0.9780556, Time: 06_05_2022__01:30:13\n","Epoch 2 of 5, Step: 1900 of 13750, Training loss: 0.0746049, Training accuracy: 0.9781579, Time: 06_05_2022__01:30:34\n","Epoch 2 of 5, Step: 2000 of 13750, Training loss: 0.0741928, Training accuracy: 0.9778750, Time: 06_05_2022__01:30:56\n","Epoch 2 of 5, Step: 2100 of 13750, Training loss: 0.0733918, Training accuracy: 0.9778571, Time: 06_05_2022__01:31:17\n","Epoch 2 of 5, Step: 2200 of 13750, Training loss: 0.0726887, Training accuracy: 0.9779545, Time: 06_05_2022__01:31:38\n","Epoch 2 of 5, Step: 2300 of 13750, Training loss: 0.0716725, Training accuracy: 0.9783696, Time: 06_05_2022__01:31:59\n","Epoch 2 of 5, Step: 2400 of 13750, Training loss: 0.0730976, Training accuracy: 0.9781250, Time: 06_05_2022__01:32:20\n","Epoch 2 of 5, Step: 2500 of 13750, Training loss: 0.0730691, Training accuracy: 0.9782000, Time: 06_05_2022__01:32:41\n","Epoch 2 of 5, Step: 2600 of 13750, Training loss: 0.0743721, Training accuracy: 0.9776923, Time: 06_05_2022__01:33:02\n","Epoch 2 of 5, Step: 2700 of 13750, Training loss: 0.0736767, Training accuracy: 0.9777778, Time: 06_05_2022__01:33:23\n","Epoch 2 of 5, Step: 2800 of 13750, Training loss: 0.0743890, Training accuracy: 0.9779464, Time: 06_05_2022__01:33:44\n","Epoch 2 of 5, Step: 2900 of 13750, Training loss: 0.0753340, Training accuracy: 0.9777586, Time: 06_05_2022__01:34:05\n","Epoch 2 of 5, Step: 3000 of 13750, Training loss: 0.0751837, Training accuracy: 0.9777500, Time: 06_05_2022__01:34:26\n","Epoch 2 of 5, Step: 3100 of 13750, Training loss: 0.0748943, Training accuracy: 0.9777419, Time: 06_05_2022__01:34:47\n","Epoch 2 of 5, Step: 3200 of 13750, Training loss: 0.0741032, Training accuracy: 0.9779688, Time: 06_05_2022__01:35:08\n","Epoch 2 of 5, Step: 3300 of 13750, Training loss: 0.0732772, Training accuracy: 0.9781818, Time: 06_05_2022__01:35:29\n","Epoch 2 of 5, Step: 3400 of 13750, Training loss: 0.0727362, Training accuracy: 0.9784559, Time: 06_05_2022__01:35:50\n","Epoch 2 of 5, Step: 3500 of 13750, Training loss: 0.0725823, Training accuracy: 0.9784286, Time: 06_05_2022__01:36:11\n","Epoch 2 of 5, Step: 3600 of 13750, Training loss: 0.0717870, Training accuracy: 0.9786806, Time: 06_05_2022__01:36:32\n","Epoch 2 of 5, Step: 3700 of 13750, Training loss: 0.0724340, Training accuracy: 0.9784459, Time: 06_05_2022__01:36:53\n","Epoch 2 of 5, Step: 3800 of 13750, Training loss: 0.0720394, Training accuracy: 0.9785526, Time: 06_05_2022__01:37:14\n","Epoch 2 of 5, Step: 3900 of 13750, Training loss: 0.0720726, Training accuracy: 0.9783333, Time: 06_05_2022__01:37:35\n","Epoch 2 of 5, Step: 4000 of 13750, Training loss: 0.0718375, Training accuracy: 0.9784375, Time: 06_05_2022__01:37:56\n","Epoch 2 of 5, Step: 4100 of 13750, Training loss: 0.0720839, Training accuracy: 0.9783537, Time: 06_05_2022__01:38:17\n","Epoch 2 of 5, Step: 4200 of 13750, Training loss: 0.0730076, Training accuracy: 0.9782143, Time: 06_05_2022__01:38:39\n","Epoch 2 of 5, Step: 4300 of 13750, Training loss: 0.0725081, Training accuracy: 0.9783721, Time: 06_05_2022__01:39:00\n","Epoch 2 of 5, Step: 4400 of 13750, Training loss: 0.0720834, Training accuracy: 0.9784659, Time: 06_05_2022__01:39:21\n","Epoch 2 of 5, Step: 4500 of 13750, Training loss: 0.0714853, Training accuracy: 0.9786111, Time: 06_05_2022__01:39:42\n","Epoch 2 of 5, Step: 4600 of 13750, Training loss: 0.0710441, Training accuracy: 0.9786957, Time: 06_05_2022__01:40:03\n","Epoch 2 of 5, Step: 4700 of 13750, Training loss: 0.0715034, Training accuracy: 0.9785106, Time: 06_05_2022__01:40:24\n","Epoch 2 of 5, Step: 4800 of 13750, Training loss: 0.0720243, Training accuracy: 0.9783854, Time: 06_05_2022__01:40:45\n","Epoch 2 of 5, Step: 4900 of 13750, Training loss: 0.0722933, Training accuracy: 0.9784694, Time: 06_05_2022__01:41:06\n","Epoch 2 of 5, Step: 5000 of 13750, Training loss: 0.0715817, Training accuracy: 0.9786500, Time: 06_05_2022__01:41:27\n","Epoch 2 of 5, Step: 5100 of 13750, Training loss: 0.0708528, Training accuracy: 0.9789216, Time: 06_05_2022__01:41:48\n","Epoch 2 of 5, Step: 5200 of 13750, Training loss: 0.0711480, Training accuracy: 0.9788462, Time: 06_05_2022__01:42:09\n","Epoch 2 of 5, Step: 5300 of 13750, Training loss: 0.0711163, Training accuracy: 0.9788208, Time: 06_05_2022__01:42:30\n","Epoch 2 of 5, Step: 5400 of 13750, Training loss: 0.0706865, Training accuracy: 0.9789352, Time: 06_05_2022__01:42:51\n","Epoch 2 of 5, Step: 5500 of 13750, Training loss: 0.0705593, Training accuracy: 0.9789545, Time: 06_05_2022__01:43:12\n","Epoch 2 of 5, Step: 5600 of 13750, Training loss: 0.0712070, Training accuracy: 0.9788393, Time: 06_05_2022__01:43:33\n","Epoch 2 of 5, Step: 5700 of 13750, Training loss: 0.0713702, Training accuracy: 0.9785965, Time: 06_05_2022__01:43:54\n","Epoch 2 of 5, Step: 5800 of 13750, Training loss: 0.0710213, Training accuracy: 0.9786638, Time: 06_05_2022__01:44:15\n","Epoch 2 of 5, Step: 5900 of 13750, Training loss: 0.0705519, Training accuracy: 0.9788136, Time: 06_05_2022__01:44:36\n","Epoch 2 of 5, Step: 6000 of 13750, Training loss: 0.0707766, Training accuracy: 0.9787500, Time: 06_05_2022__01:44:57\n","Epoch 2 of 5, Step: 6100 of 13750, Training loss: 0.0702690, Training accuracy: 0.9789344, Time: 06_05_2022__01:45:18\n","Epoch 2 of 5, Step: 6200 of 13750, Training loss: 0.0708203, Training accuracy: 0.9787097, Time: 06_05_2022__01:45:39\n","Epoch 2 of 5, Step: 6300 of 13750, Training loss: 0.0710174, Training accuracy: 0.9786905, Time: 06_05_2022__01:46:01\n","Epoch 2 of 5, Step: 6400 of 13750, Training loss: 0.0710982, Training accuracy: 0.9785547, Time: 06_05_2022__01:46:22\n","Epoch 2 of 5, Step: 6500 of 13750, Training loss: 0.0714303, Training accuracy: 0.9784615, Time: 06_05_2022__01:46:43\n","Epoch 2 of 5, Step: 6600 of 13750, Training loss: 0.0711476, Training accuracy: 0.9785985, Time: 06_05_2022__01:47:04\n","Epoch 2 of 5, Step: 6700 of 13750, Training loss: 0.0708631, Training accuracy: 0.9786567, Time: 06_05_2022__01:47:25\n","Epoch 2 of 5, Step: 6800 of 13750, Training loss: 0.0705411, Training accuracy: 0.9787500, Time: 06_05_2022__01:47:46\n","Epoch 2 of 5, Step: 6900 of 13750, Training loss: 0.0701571, Training accuracy: 0.9789130, Time: 06_05_2022__01:48:07\n","Epoch 2 of 5, Step: 7000 of 13750, Training loss: 0.0702022, Training accuracy: 0.9788571, Time: 06_05_2022__01:48:28\n","Epoch 2 of 5, Step: 7100 of 13750, Training loss: 0.0700602, Training accuracy: 0.9788732, Time: 06_05_2022__01:48:49\n","Epoch 2 of 5, Step: 7200 of 13750, Training loss: 0.0698489, Training accuracy: 0.9789236, Time: 06_05_2022__01:49:10\n","Epoch 2 of 5, Step: 7300 of 13750, Training loss: 0.0694076, Training accuracy: 0.9790411, Time: 06_05_2022__01:49:31\n","Epoch 2 of 5, Step: 7400 of 13750, Training loss: 0.0692862, Training accuracy: 0.9790541, Time: 06_05_2022__01:49:52\n","Epoch 2 of 5, Step: 7500 of 13750, Training loss: 0.0693703, Training accuracy: 0.9791667, Time: 06_05_2022__01:50:13\n","Epoch 2 of 5, Step: 7600 of 13750, Training loss: 0.0694407, Training accuracy: 0.9792434, Time: 06_05_2022__01:50:34\n","Epoch 2 of 5, Step: 7700 of 13750, Training loss: 0.0689206, Training accuracy: 0.9794481, Time: 06_05_2022__01:50:55\n","Epoch 2 of 5, Step: 7800 of 13750, Training loss: 0.0686975, Training accuracy: 0.9795513, Time: 06_05_2022__01:51:16\n","Epoch 2 of 5, Step: 7900 of 13750, Training loss: 0.0689880, Training accuracy: 0.9793671, Time: 06_05_2022__01:51:37\n","Epoch 2 of 5, Step: 8000 of 13750, Training loss: 0.0688441, Training accuracy: 0.9793125, Time: 06_05_2022__01:51:58\n","Epoch 2 of 5, Step: 8100 of 13750, Training loss: 0.0685455, Training accuracy: 0.9793827, Time: 06_05_2022__01:52:20\n","Epoch 2 of 5, Step: 8200 of 13750, Training loss: 0.0684031, Training accuracy: 0.9794207, Time: 06_05_2022__01:52:41\n","Epoch 2 of 5, Step: 8300 of 13750, Training loss: 0.0690616, Training accuracy: 0.9792470, Time: 06_05_2022__01:53:02\n","Epoch 2 of 5, Step: 8400 of 13750, Training loss: 0.0689778, Training accuracy: 0.9793155, Time: 06_05_2022__01:53:23\n","Epoch 2 of 5, Step: 8500 of 13750, Training loss: 0.0686724, Training accuracy: 0.9794118, Time: 06_05_2022__01:53:44\n","Epoch 2 of 5, Step: 8600 of 13750, Training loss: 0.0684943, Training accuracy: 0.9794477, Time: 06_05_2022__01:54:05\n","Epoch 2 of 5, Step: 8700 of 13750, Training loss: 0.0682159, Training accuracy: 0.9795115, Time: 06_05_2022__01:54:26\n","Epoch 2 of 5, Step: 8800 of 13750, Training loss: 0.0685401, Training accuracy: 0.9794034, Time: 06_05_2022__01:54:47\n","Epoch 2 of 5, Step: 8900 of 13750, Training loss: 0.0683711, Training accuracy: 0.9794382, Time: 06_05_2022__01:55:08\n","Epoch 2 of 5, Step: 9000 of 13750, Training loss: 0.0682312, Training accuracy: 0.9794167, Time: 06_05_2022__01:55:29\n","Epoch 2 of 5, Step: 9100 of 13750, Training loss: 0.0680512, Training accuracy: 0.9795055, Time: 06_05_2022__01:55:50\n","Epoch 2 of 5, Step: 9200 of 13750, Training loss: 0.0683064, Training accuracy: 0.9794293, Time: 06_05_2022__01:56:11\n","Epoch 2 of 5, Step: 9300 of 13750, Training loss: 0.0682622, Training accuracy: 0.9794086, Time: 06_05_2022__01:56:32\n","Epoch 2 of 5, Step: 9400 of 13750, Training loss: 0.0684350, Training accuracy: 0.9793351, Time: 06_05_2022__01:56:53\n","Epoch 2 of 5, Step: 9500 of 13750, Training loss: 0.0683748, Training accuracy: 0.9794211, Time: 06_05_2022__01:57:14\n","Epoch 2 of 5, Step: 9600 of 13750, Training loss: 0.0682932, Training accuracy: 0.9794010, Time: 06_05_2022__01:57:35\n","Epoch 2 of 5, Step: 9700 of 13750, Training loss: 0.0680559, Training accuracy: 0.9794330, Time: 06_05_2022__01:57:56\n","Epoch 2 of 5, Step: 9800 of 13750, Training loss: 0.0680771, Training accuracy: 0.9794133, Time: 06_05_2022__01:58:17\n","Epoch 2 of 5, Step: 9900 of 13750, Training loss: 0.0678641, Training accuracy: 0.9794444, Time: 06_05_2022__01:58:38\n","Epoch 2 of 5, Step: 10000 of 13750, Training loss: 0.0677584, Training accuracy: 0.9795250, Time: 06_05_2022__01:58:59\n","Epoch 2 of 5, Step: 10100 of 13750, Training loss: 0.0679895, Training accuracy: 0.9795297, Time: 06_05_2022__01:59:20\n","Epoch 2 of 5, Step: 10200 of 13750, Training loss: 0.0677681, Training accuracy: 0.9795833, Time: 06_05_2022__01:59:41\n","Epoch 2 of 5, Step: 10300 of 13750, Training loss: 0.0675478, Training accuracy: 0.9796117, Time: 06_05_2022__02:00:02\n","Epoch 2 of 5, Step: 10400 of 13750, Training loss: 0.0672965, Training accuracy: 0.9797115, Time: 06_05_2022__02:00:23\n","Epoch 2 of 5, Step: 10500 of 13750, Training loss: 0.0671186, Training accuracy: 0.9797857, Time: 06_05_2022__02:00:44\n","Epoch 2 of 5, Step: 10600 of 13750, Training loss: 0.0670544, Training accuracy: 0.9797170, Time: 06_05_2022__02:01:05\n","Epoch 2 of 5, Step: 10700 of 13750, Training loss: 0.0669278, Training accuracy: 0.9797430, Time: 06_05_2022__02:01:26\n","Epoch 2 of 5, Step: 10800 of 13750, Training loss: 0.0666748, Training accuracy: 0.9798148, Time: 06_05_2022__02:01:47\n","Epoch 2 of 5, Step: 10900 of 13750, Training loss: 0.0666803, Training accuracy: 0.9798165, Time: 06_05_2022__02:02:09\n","Epoch 2 of 5, Step: 11000 of 13750, Training loss: 0.0663587, Training accuracy: 0.9799318, Time: 06_05_2022__02:02:30\n","Epoch 2 of 5, Step: 11100 of 13750, Training loss: 0.0662197, Training accuracy: 0.9799099, Time: 06_05_2022__02:02:51\n","Epoch 2 of 5, Step: 11200 of 13750, Training loss: 0.0659033, Training accuracy: 0.9800000, Time: 06_05_2022__02:03:12\n","Epoch 2 of 5, Step: 11300 of 13750, Training loss: 0.0659519, Training accuracy: 0.9799336, Time: 06_05_2022__02:03:33\n","Epoch 2 of 5, Step: 11400 of 13750, Training loss: 0.0659178, Training accuracy: 0.9799561, Time: 06_05_2022__02:03:54\n","Epoch 2 of 5, Step: 11500 of 13750, Training loss: 0.0661198, Training accuracy: 0.9799565, Time: 06_05_2022__02:04:15\n","Epoch 2 of 5, Step: 11600 of 13750, Training loss: 0.0659663, Training accuracy: 0.9800000, Time: 06_05_2022__02:04:36\n","Epoch 2 of 5, Step: 11700 of 13750, Training loss: 0.0656136, Training accuracy: 0.9801068, Time: 06_05_2022__02:04:57\n","Epoch 2 of 5, Step: 11800 of 13750, Training loss: 0.0655865, Training accuracy: 0.9800636, Time: 06_05_2022__02:05:18\n","Epoch 2 of 5, Step: 11900 of 13750, Training loss: 0.0654134, Training accuracy: 0.9801050, Time: 06_05_2022__02:05:39\n","Epoch 2 of 5, Step: 12000 of 13750, Training loss: 0.0652130, Training accuracy: 0.9801458, Time: 06_05_2022__02:06:00\n","Epoch 2 of 5, Step: 12100 of 13750, Training loss: 0.0649963, Training accuracy: 0.9802273, Time: 06_05_2022__02:06:21\n","Epoch 2 of 5, Step: 12200 of 13750, Training loss: 0.0650203, Training accuracy: 0.9802049, Time: 06_05_2022__02:06:42\n","Epoch 2 of 5, Step: 12300 of 13750, Training loss: 0.0647379, Training accuracy: 0.9802846, Time: 06_05_2022__02:07:03\n","Epoch 2 of 5, Step: 12400 of 13750, Training loss: 0.0647061, Training accuracy: 0.9803024, Time: 06_05_2022__02:07:24\n","Epoch 2 of 5, Step: 12500 of 13750, Training loss: 0.0645916, Training accuracy: 0.9803200, Time: 06_05_2022__02:07:45\n","Epoch 2 of 5, Step: 12600 of 13750, Training loss: 0.0642711, Training accuracy: 0.9804167, Time: 06_05_2022__02:08:06\n","Epoch 2 of 5, Step: 12700 of 13750, Training loss: 0.0641581, Training accuracy: 0.9804134, Time: 06_05_2022__02:08:27\n","Epoch 2 of 5, Step: 12800 of 13750, Training loss: 0.0640442, Training accuracy: 0.9804492, Time: 06_05_2022__02:08:48\n","Epoch 2 of 5, Step: 12900 of 13750, Training loss: 0.0641663, Training accuracy: 0.9803876, Time: 06_05_2022__02:09:09\n","Epoch 2 of 5, Step: 13000 of 13750, Training loss: 0.0639725, Training accuracy: 0.9804423, Time: 06_05_2022__02:09:30\n","Epoch 2 of 5, Step: 13100 of 13750, Training loss: 0.0640650, Training accuracy: 0.9804008, Time: 06_05_2022__02:09:51\n","Epoch 2 of 5, Step: 13200 of 13750, Training loss: 0.0638881, Training accuracy: 0.9804356, Time: 06_05_2022__02:10:12\n","Epoch 2 of 5, Step: 13300 of 13750, Training loss: 0.0639023, Training accuracy: 0.9804511, Time: 06_05_2022__02:10:33\n","Epoch 2 of 5, Step: 13400 of 13750, Training loss: 0.0638800, Training accuracy: 0.9804851, Time: 06_05_2022__02:10:54\n","Epoch 2 of 5, Step: 13500 of 13750, Training loss: 0.0636969, Training accuracy: 0.9805185, Time: 06_05_2022__02:11:15\n","Epoch 2 of 5, Step: 13600 of 13750, Training loss: 0.0636740, Training accuracy: 0.9805147, Time: 06_05_2022__02:11:36\n","Epoch 2 of 5, Step: 13700 of 13750, Training loss: 0.0634737, Training accuracy: 0.9805474, Time: 06_05_2022__02:11:57\n","Epoch 2 of 5, Average training loss: 0.0635230, Average training accuracy: 0.9805273, Time: 06_05_2022__02:12:07\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"436839a265974a1e9502a6878135f239"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0431037, Validation accuracy: 0.9850000, Time: 06_05_2022__02:12:13 | Loss decreased from 0.0473342 to 0.0435256 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0437442, Validation accuracy: 0.9875000, Time: 06_05_2022__02:12:20\n","Step: 300 of 1250, Validation loss: 0.0410906, Validation accuracy: 0.9875000, Time: 06_05_2022__02:12:25 | Loss decreased from 0.0435256 to 0.0412246 .... Saving the model\n","Step: 400 of 1250, Validation loss: 0.0385945, Validation accuracy: 0.9881250, Time: 06_05_2022__02:12:33 | Loss decreased from 0.0412246 to 0.0386509 .... Saving the model\n","Step: 500 of 1250, Validation loss: 0.0353544, Validation accuracy: 0.9890000, Time: 06_05_2022__02:12:40 | Loss decreased from 0.0386509 to 0.0354177 .... Saving the model\n","Step: 600 of 1250, Validation loss: 0.0354935, Validation accuracy: 0.9887500, Time: 06_05_2022__02:12:48\n","Step: 700 of 1250, Validation loss: 0.0327079, Validation accuracy: 0.9896429, Time: 06_05_2022__02:12:53 | Loss decreased from 0.0354177 to 0.0321768 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0341122, Validation accuracy: 0.9890625, Time: 06_05_2022__02:13:01\n","Step: 900 of 1250, Validation loss: 0.0330230, Validation accuracy: 0.9891667, Time: 06_05_2022__02:13:06\n","Step: 1000 of 1250, Validation loss: 0.0341724, Validation accuracy: 0.9892500, Time: 06_05_2022__02:13:11\n","Step: 1100 of 1250, Validation loss: 0.0337291, Validation accuracy: 0.9895455, Time: 06_05_2022__02:13:16\n","Step: 1200 of 1250, Validation loss: 0.0347029, Validation accuracy: 0.9893750, Time: 06_05_2022__02:13:22\n","Average validation loss: 0.0359837, Average validation accuracy: 0.9890000, Time: 06_05_2022__02:13:24\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7071817d29934e84bd0cd2d2ecb08a91"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 13750, Training loss: 0.0317062, Training accuracy: 0.9900000, Time: 06_05_2022__02:13:45\n","Epoch 3 of 5, Step: 200 of 13750, Training loss: 0.0328701, Training accuracy: 0.9887500, Time: 06_05_2022__02:14:06\n","Epoch 3 of 5, Step: 300 of 13750, Training loss: 0.0383970, Training accuracy: 0.9883333, Time: 06_05_2022__02:14:27\n","Epoch 3 of 5, Step: 400 of 13750, Training loss: 0.0404356, Training accuracy: 0.9868750, Time: 06_05_2022__02:14:48\n","Epoch 3 of 5, Step: 500 of 13750, Training loss: 0.0410229, Training accuracy: 0.9855000, Time: 06_05_2022__02:15:09\n","Epoch 3 of 5, Step: 600 of 13750, Training loss: 0.0460957, Training accuracy: 0.9850000, Time: 06_05_2022__02:15:30\n","Epoch 3 of 5, Step: 700 of 13750, Training loss: 0.0476679, Training accuracy: 0.9850000, Time: 06_05_2022__02:15:51\n","Epoch 3 of 5, Step: 800 of 13750, Training loss: 0.0483555, Training accuracy: 0.9850000, Time: 06_05_2022__02:16:12\n","Epoch 3 of 5, Step: 900 of 13750, Training loss: 0.0538607, Training accuracy: 0.9833333, Time: 06_05_2022__02:16:33\n","Epoch 3 of 5, Step: 1000 of 13750, Training loss: 0.0549289, Training accuracy: 0.9830000, Time: 06_05_2022__02:16:54\n","Epoch 3 of 5, Step: 1100 of 13750, Training loss: 0.0566524, Training accuracy: 0.9818182, Time: 06_05_2022__02:17:15\n","Epoch 3 of 5, Step: 1200 of 13750, Training loss: 0.0582518, Training accuracy: 0.9818750, Time: 06_05_2022__02:17:36\n","Epoch 3 of 5, Step: 1300 of 13750, Training loss: 0.0571598, Training accuracy: 0.9823077, Time: 06_05_2022__02:17:57\n","Epoch 3 of 5, Step: 1400 of 13750, Training loss: 0.0558506, Training accuracy: 0.9826786, Time: 06_05_2022__02:18:18\n","Epoch 3 of 5, Step: 1500 of 13750, Training loss: 0.0566398, Training accuracy: 0.9818333, Time: 06_05_2022__02:18:39\n","Epoch 3 of 5, Step: 1600 of 13750, Training loss: 0.0569696, Training accuracy: 0.9817187, Time: 06_05_2022__02:19:00\n","Epoch 3 of 5, Step: 1700 of 13750, Training loss: 0.0554891, Training accuracy: 0.9820588, Time: 06_05_2022__02:19:21\n","Epoch 3 of 5, Step: 1800 of 13750, Training loss: 0.0560600, Training accuracy: 0.9822222, Time: 06_05_2022__02:19:42\n","Epoch 3 of 5, Step: 1900 of 13750, Training loss: 0.0556014, Training accuracy: 0.9821053, Time: 06_05_2022__02:20:03\n","Epoch 3 of 5, Step: 2000 of 13750, Training loss: 0.0543461, Training accuracy: 0.9826250, Time: 06_05_2022__02:20:24\n","Epoch 3 of 5, Step: 2100 of 13750, Training loss: 0.0531622, Training accuracy: 0.9829762, Time: 06_05_2022__02:20:45\n","Epoch 3 of 5, Step: 2200 of 13750, Training loss: 0.0526592, Training accuracy: 0.9832955, Time: 06_05_2022__02:21:06\n","Epoch 3 of 5, Step: 2300 of 13750, Training loss: 0.0519855, Training accuracy: 0.9832609, Time: 06_05_2022__02:21:27\n","Epoch 3 of 5, Step: 2400 of 13750, Training loss: 0.0535672, Training accuracy: 0.9833333, Time: 06_05_2022__02:21:48\n","Epoch 3 of 5, Step: 2500 of 13750, Training loss: 0.0526089, Training accuracy: 0.9837000, Time: 06_05_2022__02:22:09\n","Epoch 3 of 5, Step: 2600 of 13750, Training loss: 0.0540142, Training accuracy: 0.9832692, Time: 06_05_2022__02:22:30\n","Epoch 3 of 5, Step: 2700 of 13750, Training loss: 0.0538756, Training accuracy: 0.9831481, Time: 06_05_2022__02:22:51\n","Epoch 3 of 5, Step: 2800 of 13750, Training loss: 0.0535592, Training accuracy: 0.9832143, Time: 06_05_2022__02:23:12\n","Epoch 3 of 5, Step: 2900 of 13750, Training loss: 0.0537147, Training accuracy: 0.9831897, Time: 06_05_2022__02:23:33\n","Epoch 3 of 5, Step: 3000 of 13750, Training loss: 0.0528377, Training accuracy: 0.9834167, Time: 06_05_2022__02:23:54\n","Epoch 3 of 5, Step: 3100 of 13750, Training loss: 0.0531943, Training accuracy: 0.9832258, Time: 06_05_2022__02:24:15\n","Epoch 3 of 5, Step: 3200 of 13750, Training loss: 0.0526579, Training accuracy: 0.9833594, Time: 06_05_2022__02:24:36\n","Epoch 3 of 5, Step: 3300 of 13750, Training loss: 0.0520471, Training accuracy: 0.9835606, Time: 06_05_2022__02:24:57\n","Epoch 3 of 5, Step: 3400 of 13750, Training loss: 0.0514684, Training accuracy: 0.9837500, Time: 06_05_2022__02:25:18\n","Epoch 3 of 5, Step: 3500 of 13750, Training loss: 0.0514758, Training accuracy: 0.9837857, Time: 06_05_2022__02:25:38\n","Epoch 3 of 5, Step: 3600 of 13750, Training loss: 0.0507035, Training accuracy: 0.9840972, Time: 06_05_2022__02:25:59\n","Epoch 3 of 5, Step: 3700 of 13750, Training loss: 0.0506795, Training accuracy: 0.9840541, Time: 06_05_2022__02:26:20\n","Epoch 3 of 5, Step: 3800 of 13750, Training loss: 0.0503946, Training accuracy: 0.9842105, Time: 06_05_2022__02:26:41\n","Epoch 3 of 5, Step: 3900 of 13750, Training loss: 0.0511275, Training accuracy: 0.9840385, Time: 06_05_2022__02:27:02\n","Epoch 3 of 5, Step: 4000 of 13750, Training loss: 0.0509947, Training accuracy: 0.9840000, Time: 06_05_2022__02:27:23\n","Epoch 3 of 5, Step: 4100 of 13750, Training loss: 0.0509888, Training accuracy: 0.9838415, Time: 06_05_2022__02:27:44\n","Epoch 3 of 5, Step: 4200 of 13750, Training loss: 0.0524437, Training accuracy: 0.9833333, Time: 06_05_2022__02:28:05\n","Epoch 3 of 5, Step: 4300 of 13750, Training loss: 0.0523685, Training accuracy: 0.9832558, Time: 06_05_2022__02:28:26\n","Epoch 3 of 5, Step: 4400 of 13750, Training loss: 0.0523261, Training accuracy: 0.9832386, Time: 06_05_2022__02:28:47\n","Epoch 3 of 5, Step: 4500 of 13750, Training loss: 0.0516504, Training accuracy: 0.9834444, Time: 06_05_2022__02:29:08\n","Epoch 3 of 5, Step: 4600 of 13750, Training loss: 0.0512875, Training accuracy: 0.9835326, Time: 06_05_2022__02:29:29\n","Epoch 3 of 5, Step: 4700 of 13750, Training loss: 0.0514181, Training accuracy: 0.9834574, Time: 06_05_2022__02:29:50\n","Epoch 3 of 5, Step: 4800 of 13750, Training loss: 0.0517949, Training accuracy: 0.9833854, Time: 06_05_2022__02:30:11\n","Epoch 3 of 5, Step: 4900 of 13750, Training loss: 0.0525612, Training accuracy: 0.9831633, Time: 06_05_2022__02:30:32\n","Epoch 3 of 5, Step: 5000 of 13750, Training loss: 0.0523114, Training accuracy: 0.9833000, Time: 06_05_2022__02:30:53\n","Epoch 3 of 5, Step: 5100 of 13750, Training loss: 0.0519488, Training accuracy: 0.9834314, Time: 06_05_2022__02:31:14\n","Epoch 3 of 5, Step: 5200 of 13750, Training loss: 0.0523856, Training accuracy: 0.9833173, Time: 06_05_2022__02:31:35\n","Epoch 3 of 5, Step: 5300 of 13750, Training loss: 0.0526952, Training accuracy: 0.9832075, Time: 06_05_2022__02:31:55\n","Epoch 3 of 5, Step: 5400 of 13750, Training loss: 0.0528078, Training accuracy: 0.9831481, Time: 06_05_2022__02:32:16\n","Epoch 3 of 5, Step: 5500 of 13750, Training loss: 0.0525740, Training accuracy: 0.9832273, Time: 06_05_2022__02:32:37\n","Epoch 3 of 5, Step: 5600 of 13750, Training loss: 0.0527826, Training accuracy: 0.9832143, Time: 06_05_2022__02:32:58\n","Epoch 3 of 5, Step: 5700 of 13750, Training loss: 0.0526315, Training accuracy: 0.9832018, Time: 06_05_2022__02:33:19\n","Epoch 3 of 5, Step: 5800 of 13750, Training loss: 0.0522049, Training accuracy: 0.9834052, Time: 06_05_2022__02:33:40\n","Epoch 3 of 5, Step: 5900 of 13750, Training loss: 0.0519211, Training accuracy: 0.9834746, Time: 06_05_2022__02:34:01\n","Epoch 3 of 5, Step: 6000 of 13750, Training loss: 0.0521258, Training accuracy: 0.9835000, Time: 06_05_2022__02:34:22\n","Epoch 3 of 5, Step: 6100 of 13750, Training loss: 0.0517821, Training accuracy: 0.9836475, Time: 06_05_2022__02:34:43\n","Epoch 3 of 5, Step: 6200 of 13750, Training loss: 0.0517917, Training accuracy: 0.9836290, Time: 06_05_2022__02:35:04\n","Epoch 3 of 5, Step: 6300 of 13750, Training loss: 0.0517703, Training accuracy: 0.9835317, Time: 06_05_2022__02:35:25\n","Epoch 3 of 5, Step: 6400 of 13750, Training loss: 0.0517421, Training accuracy: 0.9835547, Time: 06_05_2022__02:35:46\n","Epoch 3 of 5, Step: 6500 of 13750, Training loss: 0.0520899, Training accuracy: 0.9835000, Time: 06_05_2022__02:36:07\n","Epoch 3 of 5, Step: 6600 of 13750, Training loss: 0.0519761, Training accuracy: 0.9835606, Time: 06_05_2022__02:36:28\n","Epoch 3 of 5, Step: 6700 of 13750, Training loss: 0.0515386, Training accuracy: 0.9837313, Time: 06_05_2022__02:36:49\n","Epoch 3 of 5, Step: 6800 of 13750, Training loss: 0.0511006, Training accuracy: 0.9838971, Time: 06_05_2022__02:37:10\n","Epoch 3 of 5, Step: 6900 of 13750, Training loss: 0.0509309, Training accuracy: 0.9840217, Time: 06_05_2022__02:37:31\n","Epoch 3 of 5, Step: 7000 of 13750, Training loss: 0.0509956, Training accuracy: 0.9840000, Time: 06_05_2022__02:37:52\n","Epoch 3 of 5, Step: 7100 of 13750, Training loss: 0.0511713, Training accuracy: 0.9839437, Time: 06_05_2022__02:38:13\n","Epoch 3 of 5, Step: 7200 of 13750, Training loss: 0.0510793, Training accuracy: 0.9838889, Time: 06_05_2022__02:38:34\n","Epoch 3 of 5, Step: 7300 of 13750, Training loss: 0.0506697, Training accuracy: 0.9840068, Time: 06_05_2022__02:38:55\n","Epoch 3 of 5, Step: 7400 of 13750, Training loss: 0.0505622, Training accuracy: 0.9840203, Time: 06_05_2022__02:39:16\n","Epoch 3 of 5, Step: 7500 of 13750, Training loss: 0.0504566, Training accuracy: 0.9841667, Time: 06_05_2022__02:39:37\n","Epoch 3 of 5, Step: 7600 of 13750, Training loss: 0.0506185, Training accuracy: 0.9841118, Time: 06_05_2022__02:39:58\n","Epoch 3 of 5, Step: 7700 of 13750, Training loss: 0.0503478, Training accuracy: 0.9842208, Time: 06_05_2022__02:40:19\n","Epoch 3 of 5, Step: 7800 of 13750, Training loss: 0.0502633, Training accuracy: 0.9842628, Time: 06_05_2022__02:40:40\n","Epoch 3 of 5, Step: 7900 of 13750, Training loss: 0.0502854, Training accuracy: 0.9841772, Time: 06_05_2022__02:41:01\n","Epoch 3 of 5, Step: 8000 of 13750, Training loss: 0.0502743, Training accuracy: 0.9841562, Time: 06_05_2022__02:41:22\n","Epoch 3 of 5, Step: 8100 of 13750, Training loss: 0.0499472, Training accuracy: 0.9843210, Time: 06_05_2022__02:41:43\n","Epoch 3 of 5, Step: 8200 of 13750, Training loss: 0.0496487, Training accuracy: 0.9844512, Time: 06_05_2022__02:42:04\n","Epoch 3 of 5, Step: 8300 of 13750, Training loss: 0.0503981, Training accuracy: 0.9843072, Time: 06_05_2022__02:42:25\n","Epoch 3 of 5, Step: 8400 of 13750, Training loss: 0.0503299, Training accuracy: 0.9842560, Time: 06_05_2022__02:42:46\n","Epoch 3 of 5, Step: 8500 of 13750, Training loss: 0.0501415, Training accuracy: 0.9843235, Time: 06_05_2022__02:43:07\n","Epoch 3 of 5, Step: 8600 of 13750, Training loss: 0.0498612, Training accuracy: 0.9844477, Time: 06_05_2022__02:43:28\n","Epoch 3 of 5, Step: 8700 of 13750, Training loss: 0.0496308, Training accuracy: 0.9844828, Time: 06_05_2022__02:43:49\n","Epoch 3 of 5, Step: 8800 of 13750, Training loss: 0.0500668, Training accuracy: 0.9844034, Time: 06_05_2022__02:44:10\n","Epoch 3 of 5, Step: 8900 of 13750, Training loss: 0.0497891, Training accuracy: 0.9845225, Time: 06_05_2022__02:44:30\n","Epoch 3 of 5, Step: 9000 of 13750, Training loss: 0.0499019, Training accuracy: 0.9843889, Time: 06_05_2022__02:44:51\n","Epoch 3 of 5, Step: 9100 of 13750, Training loss: 0.0499003, Training accuracy: 0.9843681, Time: 06_05_2022__02:45:12\n","Epoch 3 of 5, Step: 9200 of 13750, Training loss: 0.0499242, Training accuracy: 0.9843207, Time: 06_05_2022__02:45:33\n","Epoch 3 of 5, Step: 9300 of 13750, Training loss: 0.0499206, Training accuracy: 0.9842742, Time: 06_05_2022__02:45:54\n","Epoch 3 of 5, Step: 9400 of 13750, Training loss: 0.0501980, Training accuracy: 0.9842553, Time: 06_05_2022__02:46:15\n","Epoch 3 of 5, Step: 9500 of 13750, Training loss: 0.0502162, Training accuracy: 0.9842368, Time: 06_05_2022__02:46:36\n","Epoch 3 of 5, Step: 9600 of 13750, Training loss: 0.0502608, Training accuracy: 0.9841146, Time: 06_05_2022__02:46:57\n","Epoch 3 of 5, Step: 9700 of 13750, Training loss: 0.0501723, Training accuracy: 0.9841237, Time: 06_05_2022__02:47:18\n","Epoch 3 of 5, Step: 9800 of 13750, Training loss: 0.0500474, Training accuracy: 0.9842092, Time: 06_05_2022__02:47:39\n","Epoch 3 of 5, Step: 9900 of 13750, Training loss: 0.0498829, Training accuracy: 0.9842424, Time: 06_05_2022__02:48:00\n","Epoch 3 of 5, Step: 10000 of 13750, Training loss: 0.0498857, Training accuracy: 0.9842250, Time: 06_05_2022__02:48:21\n","Epoch 3 of 5, Step: 10100 of 13750, Training loss: 0.0504020, Training accuracy: 0.9841832, Time: 06_05_2022__02:48:42\n","Epoch 3 of 5, Step: 10200 of 13750, Training loss: 0.0502128, Training accuracy: 0.9842402, Time: 06_05_2022__02:49:03\n","Epoch 3 of 5, Step: 10300 of 13750, Training loss: 0.0499982, Training accuracy: 0.9843204, Time: 06_05_2022__02:49:24\n","Epoch 3 of 5, Step: 10400 of 13750, Training loss: 0.0498485, Training accuracy: 0.9843990, Time: 06_05_2022__02:49:45\n","Epoch 3 of 5, Step: 10500 of 13750, Training loss: 0.0496661, Training accuracy: 0.9844762, Time: 06_05_2022__02:50:06\n","Epoch 3 of 5, Step: 10600 of 13750, Training loss: 0.0495956, Training accuracy: 0.9845047, Time: 06_05_2022__02:50:27\n","Epoch 3 of 5, Step: 10700 of 13750, Training loss: 0.0494731, Training accuracy: 0.9845327, Time: 06_05_2022__02:50:48\n","Epoch 3 of 5, Step: 10800 of 13750, Training loss: 0.0494772, Training accuracy: 0.9844907, Time: 06_05_2022__02:51:09\n","Epoch 3 of 5, Step: 10900 of 13750, Training loss: 0.0495393, Training accuracy: 0.9844037, Time: 06_05_2022__02:51:30\n","Epoch 3 of 5, Step: 11000 of 13750, Training loss: 0.0492198, Training accuracy: 0.9845227, Time: 06_05_2022__02:51:51\n","Epoch 3 of 5, Step: 11100 of 13750, Training loss: 0.0491539, Training accuracy: 0.9845721, Time: 06_05_2022__02:52:12\n","Epoch 3 of 5, Step: 11200 of 13750, Training loss: 0.0491583, Training accuracy: 0.9846205, Time: 06_05_2022__02:52:33\n","Epoch 3 of 5, Step: 11300 of 13750, Training loss: 0.0492132, Training accuracy: 0.9846018, Time: 06_05_2022__02:52:54\n","Epoch 3 of 5, Step: 11400 of 13750, Training loss: 0.0490475, Training accuracy: 0.9846272, Time: 06_05_2022__02:53:15\n","Epoch 3 of 5, Step: 11500 of 13750, Training loss: 0.0491411, Training accuracy: 0.9846304, Time: 06_05_2022__02:53:36\n","Epoch 3 of 5, Step: 11600 of 13750, Training loss: 0.0489952, Training accuracy: 0.9846983, Time: 06_05_2022__02:53:57\n","Epoch 3 of 5, Step: 11700 of 13750, Training loss: 0.0487380, Training accuracy: 0.9848077, Time: 06_05_2022__02:54:18\n","Epoch 3 of 5, Step: 11800 of 13750, Training loss: 0.0488568, Training accuracy: 0.9847246, Time: 06_05_2022__02:54:39\n","Epoch 3 of 5, Step: 11900 of 13750, Training loss: 0.0487400, Training accuracy: 0.9847269, Time: 06_05_2022__02:55:00\n","Epoch 3 of 5, Step: 12000 of 13750, Training loss: 0.0485819, Training accuracy: 0.9847500, Time: 06_05_2022__02:55:21\n","Epoch 3 of 5, Step: 12100 of 13750, Training loss: 0.0484384, Training accuracy: 0.9848140, Time: 06_05_2022__02:55:42\n","Epoch 3 of 5, Step: 12200 of 13750, Training loss: 0.0484934, Training accuracy: 0.9848156, Time: 06_05_2022__02:56:03\n","Epoch 3 of 5, Step: 12300 of 13750, Training loss: 0.0482099, Training accuracy: 0.9849187, Time: 06_05_2022__02:56:24\n","Epoch 3 of 5, Step: 12400 of 13750, Training loss: 0.0480669, Training accuracy: 0.9849798, Time: 06_05_2022__02:56:45\n","Epoch 3 of 5, Step: 12500 of 13750, Training loss: 0.0479590, Training accuracy: 0.9850400, Time: 06_05_2022__02:57:06\n","Epoch 3 of 5, Step: 12600 of 13750, Training loss: 0.0478494, Training accuracy: 0.9850794, Time: 06_05_2022__02:57:27\n","Epoch 3 of 5, Step: 12700 of 13750, Training loss: 0.0477202, Training accuracy: 0.9851181, Time: 06_05_2022__02:57:48\n","Epoch 3 of 5, Step: 12800 of 13750, Training loss: 0.0475486, Training accuracy: 0.9851562, Time: 06_05_2022__02:58:09\n","Epoch 3 of 5, Step: 12900 of 13750, Training loss: 0.0475777, Training accuracy: 0.9851357, Time: 06_05_2022__02:58:29\n","Epoch 3 of 5, Step: 13000 of 13750, Training loss: 0.0474794, Training accuracy: 0.9851731, Time: 06_05_2022__02:58:50\n","Epoch 3 of 5, Step: 13100 of 13750, Training loss: 0.0475683, Training accuracy: 0.9851145, Time: 06_05_2022__02:59:11\n","Epoch 3 of 5, Step: 13200 of 13750, Training loss: 0.0473169, Training accuracy: 0.9852083, Time: 06_05_2022__02:59:32\n","Epoch 3 of 5, Step: 13300 of 13750, Training loss: 0.0471785, Training accuracy: 0.9852632, Time: 06_05_2022__02:59:53\n","Epoch 3 of 5, Step: 13400 of 13750, Training loss: 0.0471408, Training accuracy: 0.9852985, Time: 06_05_2022__03:00:14\n","Epoch 3 of 5, Step: 13500 of 13750, Training loss: 0.0469789, Training accuracy: 0.9853704, Time: 06_05_2022__03:00:35\n","Epoch 3 of 5, Step: 13600 of 13750, Training loss: 0.0468845, Training accuracy: 0.9853860, Time: 06_05_2022__03:00:56\n","Epoch 3 of 5, Step: 13700 of 13750, Training loss: 0.0467860, Training accuracy: 0.9854015, Time: 06_05_2022__03:01:17\n","Epoch 3 of 5, Average training loss: 0.0468712, Average training accuracy: 0.9854000, Time: 06_05_2022__03:01:28\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5d7a7f04a15496eba8ddcb0aa8a6329"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0349523, Validation accuracy: 0.9900000, Time: 06_05_2022__03:01:33\n","Step: 200 of 1250, Validation loss: 0.0371123, Validation accuracy: 0.9900000, Time: 06_05_2022__03:01:38\n","Step: 300 of 1250, Validation loss: 0.0362188, Validation accuracy: 0.9908333, Time: 06_05_2022__03:01:43\n","Step: 400 of 1250, Validation loss: 0.0329186, Validation accuracy: 0.9900000, Time: 06_05_2022__03:01:49\n","Step: 500 of 1250, Validation loss: 0.0303096, Validation accuracy: 0.9900000, Time: 06_05_2022__03:01:54 | Loss decreased from 0.0321768 to 0.0303633 .... Saving the model\n","Step: 600 of 1250, Validation loss: 0.0317716, Validation accuracy: 0.9891667, Time: 06_05_2022__03:02:01\n","Step: 700 of 1250, Validation loss: 0.0292433, Validation accuracy: 0.9900000, Time: 06_05_2022__03:02:06 | Loss decreased from 0.0303633 to 0.0288204 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0305526, Validation accuracy: 0.9896875, Time: 06_05_2022__03:02:14\n","Step: 900 of 1250, Validation loss: 0.0300198, Validation accuracy: 0.9897222, Time: 06_05_2022__03:02:19\n","Step: 1000 of 1250, Validation loss: 0.0313154, Validation accuracy: 0.9897500, Time: 06_05_2022__03:02:24\n","Step: 1100 of 1250, Validation loss: 0.0305458, Validation accuracy: 0.9902273, Time: 06_05_2022__03:02:29\n","Step: 1200 of 1250, Validation loss: 0.0324857, Validation accuracy: 0.9902083, Time: 06_05_2022__03:02:35\n","Average validation loss: 0.0341145, Average validation accuracy: 0.9900000, Time: 06_05_2022__03:02:37\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39e4b2397adf49ec95df6258c70e6acf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 13750, Training loss: 0.0292952, Training accuracy: 0.9900000, Time: 06_05_2022__03:02:59\n","Epoch 4 of 5, Step: 200 of 13750, Training loss: 0.0327401, Training accuracy: 0.9887500, Time: 06_05_2022__03:03:20\n","Epoch 4 of 5, Step: 300 of 13750, Training loss: 0.0429878, Training accuracy: 0.9875000, Time: 06_05_2022__03:03:40\n","Epoch 4 of 5, Step: 400 of 13750, Training loss: 0.0439412, Training accuracy: 0.9856250, Time: 06_05_2022__03:04:01\n","Epoch 4 of 5, Step: 500 of 13750, Training loss: 0.0444888, Training accuracy: 0.9855000, Time: 06_05_2022__03:04:22\n","Epoch 4 of 5, Step: 600 of 13750, Training loss: 0.0469350, Training accuracy: 0.9850000, Time: 06_05_2022__03:04:43\n","Epoch 4 of 5, Step: 700 of 13750, Training loss: 0.0467108, Training accuracy: 0.9853571, Time: 06_05_2022__03:05:04\n","Epoch 4 of 5, Step: 800 of 13750, Training loss: 0.0453689, Training accuracy: 0.9856250, Time: 06_05_2022__03:05:25\n","Epoch 4 of 5, Step: 900 of 13750, Training loss: 0.0456763, Training accuracy: 0.9855556, Time: 06_05_2022__03:05:46\n","Epoch 4 of 5, Step: 1000 of 13750, Training loss: 0.0460702, Training accuracy: 0.9852500, Time: 06_05_2022__03:06:07\n","Epoch 4 of 5, Step: 1100 of 13750, Training loss: 0.0482657, Training accuracy: 0.9843182, Time: 06_05_2022__03:06:28\n","Epoch 4 of 5, Step: 1200 of 13750, Training loss: 0.0476355, Training accuracy: 0.9850000, Time: 06_05_2022__03:06:49\n","Epoch 4 of 5, Step: 1300 of 13750, Training loss: 0.0457881, Training accuracy: 0.9857692, Time: 06_05_2022__03:07:10\n","Epoch 4 of 5, Step: 1400 of 13750, Training loss: 0.0460622, Training accuracy: 0.9858929, Time: 06_05_2022__03:07:31\n","Epoch 4 of 5, Step: 1500 of 13750, Training loss: 0.0446952, Training accuracy: 0.9861667, Time: 06_05_2022__03:07:52\n","Epoch 4 of 5, Step: 1600 of 13750, Training loss: 0.0451206, Training accuracy: 0.9860937, Time: 06_05_2022__03:08:13\n","Epoch 4 of 5, Step: 1700 of 13750, Training loss: 0.0452584, Training accuracy: 0.9860294, Time: 06_05_2022__03:08:34\n","Epoch 4 of 5, Step: 1800 of 13750, Training loss: 0.0451521, Training accuracy: 0.9861111, Time: 06_05_2022__03:08:55\n","Epoch 4 of 5, Step: 1900 of 13750, Training loss: 0.0455850, Training accuracy: 0.9861842, Time: 06_05_2022__03:09:16\n","Epoch 4 of 5, Step: 2000 of 13750, Training loss: 0.0449392, Training accuracy: 0.9861250, Time: 06_05_2022__03:09:37\n","Epoch 4 of 5, Step: 2100 of 13750, Training loss: 0.0441345, Training accuracy: 0.9865476, Time: 06_05_2022__03:09:58\n","Epoch 4 of 5, Step: 2200 of 13750, Training loss: 0.0432135, Training accuracy: 0.9869318, Time: 06_05_2022__03:10:19\n","Epoch 4 of 5, Step: 2300 of 13750, Training loss: 0.0417687, Training accuracy: 0.9875000, Time: 06_05_2022__03:10:40\n","Epoch 4 of 5, Step: 2400 of 13750, Training loss: 0.0425843, Training accuracy: 0.9875000, Time: 06_05_2022__03:11:01\n","Epoch 4 of 5, Step: 2500 of 13750, Training loss: 0.0418509, Training accuracy: 0.9877000, Time: 06_05_2022__03:11:22\n","Epoch 4 of 5, Step: 2600 of 13750, Training loss: 0.0423620, Training accuracy: 0.9875962, Time: 06_05_2022__03:11:43\n","Epoch 4 of 5, Step: 2700 of 13750, Training loss: 0.0421125, Training accuracy: 0.9875926, Time: 06_05_2022__03:12:04\n","Epoch 4 of 5, Step: 2800 of 13750, Training loss: 0.0421675, Training accuracy: 0.9871429, Time: 06_05_2022__03:12:25\n","Epoch 4 of 5, Step: 2900 of 13750, Training loss: 0.0424195, Training accuracy: 0.9870690, Time: 06_05_2022__03:12:46\n","Epoch 4 of 5, Step: 3000 of 13750, Training loss: 0.0422647, Training accuracy: 0.9871667, Time: 06_05_2022__03:13:07\n","Epoch 4 of 5, Step: 3100 of 13750, Training loss: 0.0424780, Training accuracy: 0.9870161, Time: 06_05_2022__03:13:28\n","Epoch 4 of 5, Step: 3200 of 13750, Training loss: 0.0422229, Training accuracy: 0.9871094, Time: 06_05_2022__03:13:49\n","Epoch 4 of 5, Step: 3300 of 13750, Training loss: 0.0417178, Training accuracy: 0.9874242, Time: 06_05_2022__03:14:10\n","Epoch 4 of 5, Step: 3400 of 13750, Training loss: 0.0411653, Training accuracy: 0.9876471, Time: 06_05_2022__03:14:31\n","Epoch 4 of 5, Step: 3500 of 13750, Training loss: 0.0413108, Training accuracy: 0.9876429, Time: 06_05_2022__03:14:52\n","Epoch 4 of 5, Step: 3600 of 13750, Training loss: 0.0407100, Training accuracy: 0.9878472, Time: 06_05_2022__03:15:13\n","Epoch 4 of 5, Step: 3700 of 13750, Training loss: 0.0408273, Training accuracy: 0.9876351, Time: 06_05_2022__03:15:34\n","Epoch 4 of 5, Step: 3800 of 13750, Training loss: 0.0404429, Training accuracy: 0.9876316, Time: 06_05_2022__03:15:55\n","Epoch 4 of 5, Step: 3900 of 13750, Training loss: 0.0409853, Training accuracy: 0.9874359, Time: 06_05_2022__03:16:16\n","Epoch 4 of 5, Step: 4000 of 13750, Training loss: 0.0406295, Training accuracy: 0.9875625, Time: 06_05_2022__03:16:36\n","Epoch 4 of 5, Step: 4100 of 13750, Training loss: 0.0413494, Training accuracy: 0.9873780, Time: 06_05_2022__03:16:57\n","Epoch 4 of 5, Step: 4200 of 13750, Training loss: 0.0425094, Training accuracy: 0.9870833, Time: 06_05_2022__03:17:18\n","Epoch 4 of 5, Step: 4300 of 13750, Training loss: 0.0424351, Training accuracy: 0.9869767, Time: 06_05_2022__03:17:39\n","Epoch 4 of 5, Step: 4400 of 13750, Training loss: 0.0422195, Training accuracy: 0.9870455, Time: 06_05_2022__03:18:00\n","Epoch 4 of 5, Step: 4500 of 13750, Training loss: 0.0418437, Training accuracy: 0.9871111, Time: 06_05_2022__03:18:21\n","Epoch 4 of 5, Step: 4600 of 13750, Training loss: 0.0416878, Training accuracy: 0.9871196, Time: 06_05_2022__03:18:42\n","Epoch 4 of 5, Step: 4700 of 13750, Training loss: 0.0418112, Training accuracy: 0.9871809, Time: 06_05_2022__03:19:03\n","Epoch 4 of 5, Step: 4800 of 13750, Training loss: 0.0418990, Training accuracy: 0.9871354, Time: 06_05_2022__03:19:24\n","Epoch 4 of 5, Step: 4900 of 13750, Training loss: 0.0424893, Training accuracy: 0.9869388, Time: 06_05_2022__03:19:45\n","Epoch 4 of 5, Step: 5000 of 13750, Training loss: 0.0421359, Training accuracy: 0.9870000, Time: 06_05_2022__03:20:06\n","Epoch 4 of 5, Step: 5100 of 13750, Training loss: 0.0418249, Training accuracy: 0.9871569, Time: 06_05_2022__03:20:27\n","Epoch 4 of 5, Step: 5200 of 13750, Training loss: 0.0423818, Training accuracy: 0.9870192, Time: 06_05_2022__03:20:48\n","Epoch 4 of 5, Step: 5300 of 13750, Training loss: 0.0425689, Training accuracy: 0.9869811, Time: 06_05_2022__03:21:09\n","Epoch 4 of 5, Step: 5400 of 13750, Training loss: 0.0424520, Training accuracy: 0.9870370, Time: 06_05_2022__03:21:30\n","Epoch 4 of 5, Step: 5500 of 13750, Training loss: 0.0422586, Training accuracy: 0.9870455, Time: 06_05_2022__03:21:51\n","Epoch 4 of 5, Step: 5600 of 13750, Training loss: 0.0424491, Training accuracy: 0.9870536, Time: 06_05_2022__03:22:12\n","Epoch 4 of 5, Step: 5700 of 13750, Training loss: 0.0423016, Training accuracy: 0.9871491, Time: 06_05_2022__03:22:33\n","Epoch 4 of 5, Step: 5800 of 13750, Training loss: 0.0418694, Training accuracy: 0.9872414, Time: 06_05_2022__03:22:54\n","Epoch 4 of 5, Step: 5900 of 13750, Training loss: 0.0414687, Training accuracy: 0.9873729, Time: 06_05_2022__03:23:15\n","Epoch 4 of 5, Step: 6000 of 13750, Training loss: 0.0414297, Training accuracy: 0.9875000, Time: 06_05_2022__03:23:36\n","Epoch 4 of 5, Step: 6100 of 13750, Training loss: 0.0410329, Training accuracy: 0.9876230, Time: 06_05_2022__03:23:57\n","Epoch 4 of 5, Step: 6200 of 13750, Training loss: 0.0412167, Training accuracy: 0.9875403, Time: 06_05_2022__03:24:18\n","Epoch 4 of 5, Step: 6300 of 13750, Training loss: 0.0413489, Training accuracy: 0.9875397, Time: 06_05_2022__03:24:39\n","Epoch 4 of 5, Step: 6400 of 13750, Training loss: 0.0415938, Training accuracy: 0.9875000, Time: 06_05_2022__03:25:00\n","Epoch 4 of 5, Step: 6500 of 13750, Training loss: 0.0424235, Training accuracy: 0.9873846, Time: 06_05_2022__03:25:21\n","Epoch 4 of 5, Step: 6600 of 13750, Training loss: 0.0419891, Training accuracy: 0.9875000, Time: 06_05_2022__03:25:42\n","Epoch 4 of 5, Step: 6700 of 13750, Training loss: 0.0417961, Training accuracy: 0.9875373, Time: 06_05_2022__03:26:03\n","Epoch 4 of 5, Step: 6800 of 13750, Training loss: 0.0415193, Training accuracy: 0.9876471, Time: 06_05_2022__03:26:24\n","Epoch 4 of 5, Step: 6900 of 13750, Training loss: 0.0413786, Training accuracy: 0.9876449, Time: 06_05_2022__03:26:45\n","Epoch 4 of 5, Step: 7000 of 13750, Training loss: 0.0411985, Training accuracy: 0.9877500, Time: 06_05_2022__03:27:06\n","Epoch 4 of 5, Step: 7100 of 13750, Training loss: 0.0412692, Training accuracy: 0.9876761, Time: 06_05_2022__03:27:27\n","Epoch 4 of 5, Step: 7200 of 13750, Training loss: 0.0414696, Training accuracy: 0.9875694, Time: 06_05_2022__03:27:48\n","Epoch 4 of 5, Step: 7300 of 13750, Training loss: 0.0412929, Training accuracy: 0.9876027, Time: 06_05_2022__03:28:09\n","Epoch 4 of 5, Step: 7400 of 13750, Training loss: 0.0411121, Training accuracy: 0.9875676, Time: 06_05_2022__03:28:30\n","Epoch 4 of 5, Step: 7500 of 13750, Training loss: 0.0408917, Training accuracy: 0.9876667, Time: 06_05_2022__03:28:51\n","Epoch 4 of 5, Step: 7600 of 13750, Training loss: 0.0412591, Training accuracy: 0.9876316, Time: 06_05_2022__03:29:12\n","Epoch 4 of 5, Step: 7700 of 13750, Training loss: 0.0409403, Training accuracy: 0.9877273, Time: 06_05_2022__03:29:33\n","Epoch 4 of 5, Step: 7800 of 13750, Training loss: 0.0410070, Training accuracy: 0.9876282, Time: 06_05_2022__03:29:54\n","Epoch 4 of 5, Step: 7900 of 13750, Training loss: 0.0413852, Training accuracy: 0.9874684, Time: 06_05_2022__03:30:15\n","Epoch 4 of 5, Step: 8000 of 13750, Training loss: 0.0411936, Training accuracy: 0.9875312, Time: 06_05_2022__03:30:36\n","Epoch 4 of 5, Step: 8100 of 13750, Training loss: 0.0410584, Training accuracy: 0.9875309, Time: 06_05_2022__03:30:57\n","Epoch 4 of 5, Step: 8200 of 13750, Training loss: 0.0408627, Training accuracy: 0.9875610, Time: 06_05_2022__03:31:18\n","Epoch 4 of 5, Step: 8300 of 13750, Training loss: 0.0417715, Training accuracy: 0.9873494, Time: 06_05_2022__03:31:39\n","Epoch 4 of 5, Step: 8400 of 13750, Training loss: 0.0416694, Training accuracy: 0.9873214, Time: 06_05_2022__03:32:00\n","Epoch 4 of 5, Step: 8500 of 13750, Training loss: 0.0415404, Training accuracy: 0.9874118, Time: 06_05_2022__03:32:20\n","Epoch 4 of 5, Step: 8600 of 13750, Training loss: 0.0414268, Training accuracy: 0.9874419, Time: 06_05_2022__03:32:41\n","Epoch 4 of 5, Step: 8700 of 13750, Training loss: 0.0412273, Training accuracy: 0.9875287, Time: 06_05_2022__03:33:02\n","Epoch 4 of 5, Step: 8800 of 13750, Training loss: 0.0414283, Training accuracy: 0.9874432, Time: 06_05_2022__03:33:23\n","Epoch 4 of 5, Step: 8900 of 13750, Training loss: 0.0410788, Training accuracy: 0.9875843, Time: 06_05_2022__03:33:44\n","Epoch 4 of 5, Step: 9000 of 13750, Training loss: 0.0410282, Training accuracy: 0.9876111, Time: 06_05_2022__03:34:05\n","Epoch 4 of 5, Step: 9100 of 13750, Training loss: 0.0410065, Training accuracy: 0.9876099, Time: 06_05_2022__03:34:26\n","Epoch 4 of 5, Step: 9200 of 13750, Training loss: 0.0411829, Training accuracy: 0.9876087, Time: 06_05_2022__03:34:47\n","Epoch 4 of 5, Step: 9300 of 13750, Training loss: 0.0410162, Training accuracy: 0.9876075, Time: 06_05_2022__03:35:08\n","Epoch 4 of 5, Step: 9400 of 13750, Training loss: 0.0413784, Training accuracy: 0.9875266, Time: 06_05_2022__03:35:29\n","Epoch 4 of 5, Step: 9500 of 13750, Training loss: 0.0415129, Training accuracy: 0.9874211, Time: 06_05_2022__03:35:50\n","Epoch 4 of 5, Step: 9600 of 13750, Training loss: 0.0414990, Training accuracy: 0.9873437, Time: 06_05_2022__03:36:11\n","Epoch 4 of 5, Step: 9700 of 13750, Training loss: 0.0412831, Training accuracy: 0.9874485, Time: 06_05_2022__03:36:32\n","Epoch 4 of 5, Step: 9800 of 13750, Training loss: 0.0413381, Training accuracy: 0.9874235, Time: 06_05_2022__03:36:53\n","Epoch 4 of 5, Step: 9900 of 13750, Training loss: 0.0410582, Training accuracy: 0.9875000, Time: 06_05_2022__03:37:14\n","Epoch 4 of 5, Step: 10000 of 13750, Training loss: 0.0410244, Training accuracy: 0.9875500, Time: 06_05_2022__03:37:35\n","Epoch 4 of 5, Step: 10100 of 13750, Training loss: 0.0414695, Training accuracy: 0.9874752, Time: 06_05_2022__03:37:56\n","Epoch 4 of 5, Step: 10200 of 13750, Training loss: 0.0414073, Training accuracy: 0.9874265, Time: 06_05_2022__03:38:17\n","Epoch 4 of 5, Step: 10300 of 13750, Training loss: 0.0412962, Training accuracy: 0.9874515, Time: 06_05_2022__03:38:38\n","Epoch 4 of 5, Step: 10400 of 13750, Training loss: 0.0410958, Training accuracy: 0.9875481, Time: 06_05_2022__03:38:59\n","Epoch 4 of 5, Step: 10500 of 13750, Training loss: 0.0409500, Training accuracy: 0.9875952, Time: 06_05_2022__03:39:20\n","Epoch 4 of 5, Step: 10600 of 13750, Training loss: 0.0407695, Training accuracy: 0.9876415, Time: 06_05_2022__03:39:41\n","Epoch 4 of 5, Step: 10700 of 13750, Training loss: 0.0407117, Training accuracy: 0.9876636, Time: 06_05_2022__03:40:02\n","Epoch 4 of 5, Step: 10800 of 13750, Training loss: 0.0406372, Training accuracy: 0.9876852, Time: 06_05_2022__03:40:23\n","Epoch 4 of 5, Step: 10900 of 13750, Training loss: 0.0405749, Training accuracy: 0.9876835, Time: 06_05_2022__03:40:44\n","Epoch 4 of 5, Step: 11000 of 13750, Training loss: 0.0403969, Training accuracy: 0.9877273, Time: 06_05_2022__03:41:05\n","Epoch 4 of 5, Step: 11100 of 13750, Training loss: 0.0403658, Training accuracy: 0.9876802, Time: 06_05_2022__03:41:26\n","Epoch 4 of 5, Step: 11200 of 13750, Training loss: 0.0404169, Training accuracy: 0.9877009, Time: 06_05_2022__03:41:47\n","Epoch 4 of 5, Step: 11300 of 13750, Training loss: 0.0402972, Training accuracy: 0.9877212, Time: 06_05_2022__03:42:08\n","Epoch 4 of 5, Step: 11400 of 13750, Training loss: 0.0402131, Training accuracy: 0.9877412, Time: 06_05_2022__03:42:29\n","Epoch 4 of 5, Step: 11500 of 13750, Training loss: 0.0402698, Training accuracy: 0.9877174, Time: 06_05_2022__03:42:50\n","Epoch 4 of 5, Step: 11600 of 13750, Training loss: 0.0400549, Training accuracy: 0.9878017, Time: 06_05_2022__03:43:11\n","Epoch 4 of 5, Step: 11700 of 13750, Training loss: 0.0399443, Training accuracy: 0.9878205, Time: 06_05_2022__03:43:32\n","Epoch 4 of 5, Step: 11800 of 13750, Training loss: 0.0400338, Training accuracy: 0.9877542, Time: 06_05_2022__03:43:53\n","Epoch 4 of 5, Step: 11900 of 13750, Training loss: 0.0399949, Training accuracy: 0.9877311, Time: 06_05_2022__03:44:14\n","Epoch 4 of 5, Step: 12000 of 13750, Training loss: 0.0399293, Training accuracy: 0.9877500, Time: 06_05_2022__03:44:35\n","Epoch 4 of 5, Step: 12100 of 13750, Training loss: 0.0399599, Training accuracy: 0.9877066, Time: 06_05_2022__03:44:56\n","Epoch 4 of 5, Step: 12200 of 13750, Training loss: 0.0400782, Training accuracy: 0.9876639, Time: 06_05_2022__03:45:17\n","Epoch 4 of 5, Step: 12300 of 13750, Training loss: 0.0398514, Training accuracy: 0.9877236, Time: 06_05_2022__03:45:38\n","Epoch 4 of 5, Step: 12400 of 13750, Training loss: 0.0397655, Training accuracy: 0.9877823, Time: 06_05_2022__03:45:59\n","Epoch 4 of 5, Step: 12500 of 13750, Training loss: 0.0395870, Training accuracy: 0.9878200, Time: 06_05_2022__03:46:20\n","Epoch 4 of 5, Step: 12600 of 13750, Training loss: 0.0394147, Training accuracy: 0.9878571, Time: 06_05_2022__03:46:41\n","Epoch 4 of 5, Step: 12700 of 13750, Training loss: 0.0392712, Training accuracy: 0.9879134, Time: 06_05_2022__03:47:02\n","Epoch 4 of 5, Step: 12800 of 13750, Training loss: 0.0391572, Training accuracy: 0.9879492, Time: 06_05_2022__03:47:23\n","Epoch 4 of 5, Step: 12900 of 13750, Training loss: 0.0394463, Training accuracy: 0.9878488, Time: 06_05_2022__03:47:43\n","Epoch 4 of 5, Step: 13000 of 13750, Training loss: 0.0393082, Training accuracy: 0.9879038, Time: 06_05_2022__03:48:04\n","Epoch 4 of 5, Step: 13100 of 13750, Training loss: 0.0394680, Training accuracy: 0.9879198, Time: 06_05_2022__03:48:25\n","Epoch 4 of 5, Step: 13200 of 13750, Training loss: 0.0393095, Training accuracy: 0.9879545, Time: 06_05_2022__03:48:46\n","Epoch 4 of 5, Step: 13300 of 13750, Training loss: 0.0392118, Training accuracy: 0.9879887, Time: 06_05_2022__03:49:07\n","Epoch 4 of 5, Step: 13400 of 13750, Training loss: 0.0391645, Training accuracy: 0.9880037, Time: 06_05_2022__03:49:28\n","Epoch 4 of 5, Step: 13500 of 13750, Training loss: 0.0390923, Training accuracy: 0.9880185, Time: 06_05_2022__03:49:49\n","Epoch 4 of 5, Step: 13600 of 13750, Training loss: 0.0389839, Training accuracy: 0.9880331, Time: 06_05_2022__03:50:10\n","Epoch 4 of 5, Step: 13700 of 13750, Training loss: 0.0389046, Training accuracy: 0.9880474, Time: 06_05_2022__03:50:31\n","Epoch 4 of 5, Average training loss: 0.0390430, Average training accuracy: 0.9880000, Time: 06_05_2022__03:50:42\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f54df648e49841b3acd5839ba8b9ac43"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0199600, Validation accuracy: 0.9950000, Time: 06_05_2022__03:50:47 | Loss decreased from 0.0288204 to 0.0201379 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.0250509, Validation accuracy: 0.9950000, Time: 06_05_2022__03:50:55\n","Step: 300 of 1250, Validation loss: 0.0222759, Validation accuracy: 0.9941667, Time: 06_05_2022__03:51:00\n","Step: 400 of 1250, Validation loss: 0.0195852, Validation accuracy: 0.9950000, Time: 06_05_2022__03:51:05 | Loss decreased from 0.0201379 to 0.0196118 .... Saving the model\n","Step: 500 of 1250, Validation loss: 0.0189496, Validation accuracy: 0.9945000, Time: 06_05_2022__03:51:13 | Loss decreased from 0.0196118 to 0.0189737 .... Saving the model\n","Step: 600 of 1250, Validation loss: 0.0201357, Validation accuracy: 0.9933333, Time: 06_05_2022__03:51:20\n","Step: 700 of 1250, Validation loss: 0.0189570, Validation accuracy: 0.9935714, Time: 06_05_2022__03:51:25 | Loss decreased from 0.0189737 to 0.0184442 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.0193718, Validation accuracy: 0.9931250, Time: 06_05_2022__03:51:33\n","Step: 900 of 1250, Validation loss: 0.0198392, Validation accuracy: 0.9930556, Time: 06_05_2022__03:51:38\n","Step: 1000 of 1250, Validation loss: 0.0216900, Validation accuracy: 0.9930000, Time: 06_05_2022__03:51:43\n","Step: 1100 of 1250, Validation loss: 0.0214988, Validation accuracy: 0.9929545, Time: 06_05_2022__03:51:49\n","Step: 1200 of 1250, Validation loss: 0.0230581, Validation accuracy: 0.9925000, Time: 06_05_2022__03:51:54\n","Average validation loss: 0.0241286, Average validation accuracy: 0.9922000, Time: 06_05_2022__03:51:57\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8198d3f4dc6e4a2c8f12fc51ff718eb6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 13750, Training loss: 0.0250769, Training accuracy: 0.9925000, Time: 06_05_2022__03:52:18\n","Epoch 5 of 5, Step: 200 of 13750, Training loss: 0.0242340, Training accuracy: 0.9937500, Time: 06_05_2022__03:52:39\n","Epoch 5 of 5, Step: 300 of 13750, Training loss: 0.0289075, Training accuracy: 0.9925000, Time: 06_05_2022__03:52:59\n","Epoch 5 of 5, Step: 400 of 13750, Training loss: 0.0299597, Training accuracy: 0.9925000, Time: 06_05_2022__03:53:20\n","Epoch 5 of 5, Step: 500 of 13750, Training loss: 0.0349087, Training accuracy: 0.9910000, Time: 06_05_2022__03:53:41\n","Epoch 5 of 5, Step: 600 of 13750, Training loss: 0.0362736, Training accuracy: 0.9900000, Time: 06_05_2022__03:54:02\n","Epoch 5 of 5, Step: 700 of 13750, Training loss: 0.0381775, Training accuracy: 0.9892857, Time: 06_05_2022__03:54:23\n","Epoch 5 of 5, Step: 800 of 13750, Training loss: 0.0373144, Training accuracy: 0.9890625, Time: 06_05_2022__03:54:44\n","Epoch 5 of 5, Step: 900 of 13750, Training loss: 0.0388775, Training accuracy: 0.9886111, Time: 06_05_2022__03:55:05\n","Epoch 5 of 5, Step: 1000 of 13750, Training loss: 0.0383973, Training accuracy: 0.9887500, Time: 06_05_2022__03:55:26\n","Epoch 5 of 5, Step: 1100 of 13750, Training loss: 0.0401106, Training accuracy: 0.9879545, Time: 06_05_2022__03:55:47\n","Epoch 5 of 5, Step: 1200 of 13750, Training loss: 0.0392881, Training accuracy: 0.9879167, Time: 06_05_2022__03:56:08\n","Epoch 5 of 5, Step: 1300 of 13750, Training loss: 0.0379438, Training accuracy: 0.9880769, Time: 06_05_2022__03:56:29\n","Epoch 5 of 5, Step: 1400 of 13750, Training loss: 0.0371824, Training accuracy: 0.9880357, Time: 06_05_2022__03:56:50\n","Epoch 5 of 5, Step: 1500 of 13750, Training loss: 0.0370991, Training accuracy: 0.9878333, Time: 06_05_2022__03:57:11\n","Epoch 5 of 5, Step: 1600 of 13750, Training loss: 0.0370944, Training accuracy: 0.9881250, Time: 06_05_2022__03:57:32\n","Epoch 5 of 5, Step: 1700 of 13750, Training loss: 0.0366531, Training accuracy: 0.9885294, Time: 06_05_2022__03:57:53\n","Epoch 5 of 5, Step: 1800 of 13750, Training loss: 0.0369319, Training accuracy: 0.9887500, Time: 06_05_2022__03:58:14\n","Epoch 5 of 5, Step: 1900 of 13750, Training loss: 0.0369498, Training accuracy: 0.9886842, Time: 06_05_2022__03:58:35\n","Epoch 5 of 5, Step: 2000 of 13750, Training loss: 0.0363007, Training accuracy: 0.9890000, Time: 06_05_2022__03:58:56\n","Epoch 5 of 5, Step: 2100 of 13750, Training loss: 0.0358950, Training accuracy: 0.9891667, Time: 06_05_2022__03:59:17\n","Epoch 5 of 5, Step: 2200 of 13750, Training loss: 0.0356767, Training accuracy: 0.9893182, Time: 06_05_2022__03:59:38\n","Epoch 5 of 5, Step: 2300 of 13750, Training loss: 0.0354246, Training accuracy: 0.9893478, Time: 06_05_2022__03:59:59\n","Epoch 5 of 5, Step: 2400 of 13750, Training loss: 0.0371498, Training accuracy: 0.9893750, Time: 06_05_2022__04:00:20\n","Epoch 5 of 5, Step: 2500 of 13750, Training loss: 0.0366849, Training accuracy: 0.9895000, Time: 06_05_2022__04:00:41\n","Epoch 5 of 5, Step: 2600 of 13750, Training loss: 0.0375480, Training accuracy: 0.9890385, Time: 06_05_2022__04:01:02\n","Epoch 5 of 5, Step: 2700 of 13750, Training loss: 0.0371816, Training accuracy: 0.9892593, Time: 06_05_2022__04:01:23\n","Epoch 5 of 5, Step: 2800 of 13750, Training loss: 0.0369850, Training accuracy: 0.9894643, Time: 06_05_2022__04:01:44\n","Epoch 5 of 5, Step: 2900 of 13750, Training loss: 0.0370813, Training accuracy: 0.9893966, Time: 06_05_2022__04:02:05\n","Epoch 5 of 5, Step: 3000 of 13750, Training loss: 0.0367260, Training accuracy: 0.9895000, Time: 06_05_2022__04:02:26\n","Epoch 5 of 5, Step: 3100 of 13750, Training loss: 0.0370081, Training accuracy: 0.9893548, Time: 06_05_2022__04:02:47\n","Epoch 5 of 5, Step: 3200 of 13750, Training loss: 0.0362845, Training accuracy: 0.9896094, Time: 06_05_2022__04:03:08\n","Epoch 5 of 5, Step: 3300 of 13750, Training loss: 0.0357462, Training accuracy: 0.9896970, Time: 06_05_2022__04:03:29\n","Epoch 5 of 5, Step: 3400 of 13750, Training loss: 0.0356493, Training accuracy: 0.9897794, Time: 06_05_2022__04:03:50\n","Epoch 5 of 5, Step: 3500 of 13750, Training loss: 0.0353680, Training accuracy: 0.9898571, Time: 06_05_2022__04:04:11\n","Epoch 5 of 5, Step: 3600 of 13750, Training loss: 0.0350715, Training accuracy: 0.9899306, Time: 06_05_2022__04:04:32\n","Epoch 5 of 5, Step: 3700 of 13750, Training loss: 0.0350272, Training accuracy: 0.9899324, Time: 06_05_2022__04:04:53\n","Epoch 5 of 5, Step: 3800 of 13750, Training loss: 0.0344459, Training accuracy: 0.9901974, Time: 06_05_2022__04:05:14\n","Epoch 5 of 5, Step: 3900 of 13750, Training loss: 0.0343407, Training accuracy: 0.9903205, Time: 06_05_2022__04:05:35\n","Epoch 5 of 5, Step: 4000 of 13750, Training loss: 0.0340524, Training accuracy: 0.9903750, Time: 06_05_2022__04:05:56\n","Epoch 5 of 5, Step: 4100 of 13750, Training loss: 0.0348214, Training accuracy: 0.9901220, Time: 06_05_2022__04:06:17\n","Epoch 5 of 5, Step: 4200 of 13750, Training loss: 0.0353318, Training accuracy: 0.9900000, Time: 06_05_2022__04:06:38\n","Epoch 5 of 5, Step: 4300 of 13750, Training loss: 0.0354277, Training accuracy: 0.9898837, Time: 06_05_2022__04:06:59\n","Epoch 5 of 5, Step: 4400 of 13750, Training loss: 0.0354583, Training accuracy: 0.9899432, Time: 06_05_2022__04:07:20\n","Epoch 5 of 5, Step: 4500 of 13750, Training loss: 0.0351172, Training accuracy: 0.9900556, Time: 06_05_2022__04:07:41\n","Epoch 5 of 5, Step: 4600 of 13750, Training loss: 0.0349260, Training accuracy: 0.9900543, Time: 06_05_2022__04:08:02\n","Epoch 5 of 5, Step: 4700 of 13750, Training loss: 0.0346436, Training accuracy: 0.9901596, Time: 06_05_2022__04:08:23\n","Epoch 5 of 5, Step: 4800 of 13750, Training loss: 0.0347162, Training accuracy: 0.9901562, Time: 06_05_2022__04:08:44\n","Epoch 5 of 5, Step: 4900 of 13750, Training loss: 0.0347499, Training accuracy: 0.9902551, Time: 06_05_2022__04:09:05\n","Epoch 5 of 5, Step: 5000 of 13750, Training loss: 0.0345627, Training accuracy: 0.9902500, Time: 06_05_2022__04:09:26\n","Epoch 5 of 5, Step: 5100 of 13750, Training loss: 0.0342183, Training accuracy: 0.9902941, Time: 06_05_2022__04:09:47\n","Epoch 5 of 5, Step: 5200 of 13750, Training loss: 0.0344963, Training accuracy: 0.9902404, Time: 06_05_2022__04:10:08\n","Epoch 5 of 5, Step: 5300 of 13750, Training loss: 0.0347843, Training accuracy: 0.9900943, Time: 06_05_2022__04:10:29\n","Epoch 5 of 5, Step: 5400 of 13750, Training loss: 0.0347125, Training accuracy: 0.9901389, Time: 06_05_2022__04:10:50\n","Epoch 5 of 5, Step: 5500 of 13750, Training loss: 0.0347478, Training accuracy: 0.9899545, Time: 06_05_2022__04:11:11\n","Epoch 5 of 5, Step: 5600 of 13750, Training loss: 0.0348760, Training accuracy: 0.9898661, Time: 06_05_2022__04:11:32\n","Epoch 5 of 5, Step: 5700 of 13750, Training loss: 0.0349448, Training accuracy: 0.9899123, Time: 06_05_2022__04:11:53\n","Epoch 5 of 5, Step: 5800 of 13750, Training loss: 0.0348403, Training accuracy: 0.9897845, Time: 06_05_2022__04:12:14\n","Epoch 5 of 5, Step: 5900 of 13750, Training loss: 0.0348628, Training accuracy: 0.9896610, Time: 06_05_2022__04:12:34\n","Epoch 5 of 5, Step: 6000 of 13750, Training loss: 0.0350628, Training accuracy: 0.9895833, Time: 06_05_2022__04:12:55\n","Epoch 5 of 5, Step: 6100 of 13750, Training loss: 0.0348611, Training accuracy: 0.9896311, Time: 06_05_2022__04:13:16\n","Epoch 5 of 5, Step: 6200 of 13750, Training loss: 0.0350332, Training accuracy: 0.9895565, Time: 06_05_2022__04:13:37\n","Epoch 5 of 5, Step: 6300 of 13750, Training loss: 0.0352013, Training accuracy: 0.9895238, Time: 06_05_2022__04:13:58\n","Epoch 5 of 5, Step: 6400 of 13750, Training loss: 0.0353706, Training accuracy: 0.9894531, Time: 06_05_2022__04:14:19\n","Epoch 5 of 5, Step: 6500 of 13750, Training loss: 0.0359037, Training accuracy: 0.9893077, Time: 06_05_2022__04:14:40\n","Epoch 5 of 5, Step: 6600 of 13750, Training loss: 0.0356897, Training accuracy: 0.9893182, Time: 06_05_2022__04:15:01\n","Epoch 5 of 5, Step: 6700 of 13750, Training loss: 0.0354387, Training accuracy: 0.9894030, Time: 06_05_2022__04:15:22\n","Epoch 5 of 5, Step: 6800 of 13750, Training loss: 0.0351501, Training accuracy: 0.9894853, Time: 06_05_2022__04:15:43\n","Epoch 5 of 5, Step: 6900 of 13750, Training loss: 0.0349385, Training accuracy: 0.9895290, Time: 06_05_2022__04:16:04\n","Epoch 5 of 5, Step: 7000 of 13750, Training loss: 0.0350338, Training accuracy: 0.9895357, Time: 06_05_2022__04:16:25\n","Epoch 5 of 5, Step: 7100 of 13750, Training loss: 0.0349835, Training accuracy: 0.9895070, Time: 06_05_2022__04:16:46\n","Epoch 5 of 5, Step: 7200 of 13750, Training loss: 0.0348995, Training accuracy: 0.9895139, Time: 06_05_2022__04:17:07\n","Epoch 5 of 5, Step: 7300 of 13750, Training loss: 0.0347217, Training accuracy: 0.9895548, Time: 06_05_2022__04:17:28\n","Epoch 5 of 5, Step: 7400 of 13750, Training loss: 0.0345790, Training accuracy: 0.9895946, Time: 06_05_2022__04:17:49\n","Epoch 5 of 5, Step: 7500 of 13750, Training loss: 0.0344718, Training accuracy: 0.9896000, Time: 06_05_2022__04:18:10\n","Epoch 5 of 5, Step: 7600 of 13750, Training loss: 0.0344668, Training accuracy: 0.9895724, Time: 06_05_2022__04:18:31\n","Epoch 5 of 5, Step: 7700 of 13750, Training loss: 0.0342571, Training accuracy: 0.9896429, Time: 06_05_2022__04:18:52\n","Epoch 5 of 5, Step: 7800 of 13750, Training loss: 0.0341132, Training accuracy: 0.9896795, Time: 06_05_2022__04:19:13\n","Epoch 5 of 5, Step: 7900 of 13750, Training loss: 0.0340614, Training accuracy: 0.9896835, Time: 06_05_2022__04:19:34\n","Epoch 5 of 5, Step: 8000 of 13750, Training loss: 0.0339401, Training accuracy: 0.9897500, Time: 06_05_2022__04:19:55\n","Epoch 5 of 5, Step: 8100 of 13750, Training loss: 0.0337691, Training accuracy: 0.9898148, Time: 06_05_2022__04:20:16\n","Epoch 5 of 5, Step: 8200 of 13750, Training loss: 0.0336254, Training accuracy: 0.9898476, Time: 06_05_2022__04:20:37\n","Epoch 5 of 5, Step: 8300 of 13750, Training loss: 0.0342690, Training accuracy: 0.9896687, Time: 06_05_2022__04:20:58\n","Epoch 5 of 5, Step: 8400 of 13750, Training loss: 0.0340749, Training accuracy: 0.9897321, Time: 06_05_2022__04:21:19\n","Epoch 5 of 5, Step: 8500 of 13750, Training loss: 0.0339707, Training accuracy: 0.9897647, Time: 06_05_2022__04:21:40\n","Epoch 5 of 5, Step: 8600 of 13750, Training loss: 0.0338936, Training accuracy: 0.9898256, Time: 06_05_2022__04:22:01\n","Epoch 5 of 5, Step: 8700 of 13750, Training loss: 0.0336699, Training accuracy: 0.9899138, Time: 06_05_2022__04:22:22\n","Epoch 5 of 5, Step: 8800 of 13750, Training loss: 0.0337700, Training accuracy: 0.9898295, Time: 06_05_2022__04:22:43\n","Epoch 5 of 5, Step: 8900 of 13750, Training loss: 0.0335673, Training accuracy: 0.9898876, Time: 06_05_2022__04:23:04\n","Epoch 5 of 5, Step: 9000 of 13750, Training loss: 0.0334186, Training accuracy: 0.9899167, Time: 06_05_2022__04:23:25\n","Epoch 5 of 5, Step: 9100 of 13750, Training loss: 0.0333040, Training accuracy: 0.9899451, Time: 06_05_2022__04:23:46\n","Epoch 5 of 5, Step: 9200 of 13750, Training loss: 0.0336323, Training accuracy: 0.9898370, Time: 06_05_2022__04:24:07\n","Epoch 5 of 5, Step: 9300 of 13750, Training loss: 0.0335615, Training accuracy: 0.9898387, Time: 06_05_2022__04:24:28\n","Epoch 5 of 5, Step: 9400 of 13750, Training loss: 0.0337966, Training accuracy: 0.9897606, Time: 06_05_2022__04:24:49\n","Epoch 5 of 5, Step: 9500 of 13750, Training loss: 0.0340284, Training accuracy: 0.9897632, Time: 06_05_2022__04:25:10\n","Epoch 5 of 5, Step: 9600 of 13750, Training loss: 0.0340658, Training accuracy: 0.9897135, Time: 06_05_2022__04:25:31\n","Epoch 5 of 5, Step: 9700 of 13750, Training loss: 0.0338352, Training accuracy: 0.9897938, Time: 06_05_2022__04:25:52\n","Epoch 5 of 5, Step: 9800 of 13750, Training loss: 0.0338192, Training accuracy: 0.9898469, Time: 06_05_2022__04:26:13\n","Epoch 5 of 5, Step: 9900 of 13750, Training loss: 0.0335899, Training accuracy: 0.9898990, Time: 06_05_2022__04:26:34\n","Epoch 5 of 5, Step: 10000 of 13750, Training loss: 0.0336692, Training accuracy: 0.9898750, Time: 06_05_2022__04:26:55\n","Epoch 5 of 5, Step: 10100 of 13750, Training loss: 0.0341496, Training accuracy: 0.9898515, Time: 06_05_2022__04:27:16\n","Epoch 5 of 5, Step: 10200 of 13750, Training loss: 0.0340349, Training accuracy: 0.9898775, Time: 06_05_2022__04:27:37\n","Epoch 5 of 5, Step: 10300 of 13750, Training loss: 0.0338082, Training accuracy: 0.9899757, Time: 06_05_2022__04:27:58\n","Epoch 5 of 5, Step: 10400 of 13750, Training loss: 0.0337264, Training accuracy: 0.9900240, Time: 06_05_2022__04:28:19\n","Epoch 5 of 5, Step: 10500 of 13750, Training loss: 0.0336923, Training accuracy: 0.9900714, Time: 06_05_2022__04:28:40\n","Epoch 5 of 5, Step: 10600 of 13750, Training loss: 0.0336493, Training accuracy: 0.9900708, Time: 06_05_2022__04:29:01\n","Epoch 5 of 5, Step: 10700 of 13750, Training loss: 0.0336831, Training accuracy: 0.9900935, Time: 06_05_2022__04:29:22\n","Epoch 5 of 5, Step: 10800 of 13750, Training loss: 0.0334885, Training accuracy: 0.9901620, Time: 06_05_2022__04:29:43\n","Epoch 5 of 5, Step: 10900 of 13750, Training loss: 0.0334950, Training accuracy: 0.9901376, Time: 06_05_2022__04:30:04\n","Epoch 5 of 5, Step: 11000 of 13750, Training loss: 0.0333309, Training accuracy: 0.9901818, Time: 06_05_2022__04:30:25\n","Epoch 5 of 5, Step: 11100 of 13750, Training loss: 0.0332458, Training accuracy: 0.9901802, Time: 06_05_2022__04:30:46\n","Epoch 5 of 5, Step: 11200 of 13750, Training loss: 0.0331208, Training accuracy: 0.9902232, Time: 06_05_2022__04:31:07\n","Epoch 5 of 5, Step: 11300 of 13750, Training loss: 0.0330852, Training accuracy: 0.9902434, Time: 06_05_2022__04:31:28\n","Epoch 5 of 5, Step: 11400 of 13750, Training loss: 0.0329262, Training accuracy: 0.9903070, Time: 06_05_2022__04:31:49\n","Epoch 5 of 5, Step: 11500 of 13750, Training loss: 0.0329227, Training accuracy: 0.9903478, Time: 06_05_2022__04:32:10\n","Epoch 5 of 5, Step: 11600 of 13750, Training loss: 0.0327537, Training accuracy: 0.9903879, Time: 06_05_2022__04:32:31\n","Epoch 5 of 5, Step: 11700 of 13750, Training loss: 0.0326665, Training accuracy: 0.9904060, Time: 06_05_2022__04:32:52\n","Epoch 5 of 5, Step: 11800 of 13750, Training loss: 0.0326354, Training accuracy: 0.9903814, Time: 06_05_2022__04:33:13\n","Epoch 5 of 5, Step: 11900 of 13750, Training loss: 0.0327098, Training accuracy: 0.9903782, Time: 06_05_2022__04:33:34\n","Epoch 5 of 5, Step: 12000 of 13750, Training loss: 0.0326216, Training accuracy: 0.9903958, Time: 06_05_2022__04:33:55\n","Epoch 5 of 5, Step: 12100 of 13750, Training loss: 0.0326186, Training accuracy: 0.9903926, Time: 06_05_2022__04:34:16\n","Epoch 5 of 5, Step: 12200 of 13750, Training loss: 0.0327337, Training accuracy: 0.9903689, Time: 06_05_2022__04:34:37\n","Epoch 5 of 5, Step: 12300 of 13750, Training loss: 0.0325068, Training accuracy: 0.9904472, Time: 06_05_2022__04:34:58\n","Epoch 5 of 5, Step: 12400 of 13750, Training loss: 0.0324980, Training accuracy: 0.9904637, Time: 06_05_2022__04:35:19\n","Epoch 5 of 5, Step: 12500 of 13750, Training loss: 0.0323957, Training accuracy: 0.9904800, Time: 06_05_2022__04:35:40\n","Epoch 5 of 5, Step: 12600 of 13750, Training loss: 0.0323371, Training accuracy: 0.9904960, Time: 06_05_2022__04:36:01\n","Epoch 5 of 5, Step: 12700 of 13750, Training loss: 0.0323034, Training accuracy: 0.9904921, Time: 06_05_2022__04:36:22\n","Epoch 5 of 5, Step: 12800 of 13750, Training loss: 0.0321698, Training accuracy: 0.9905273, Time: 06_05_2022__04:36:42\n","Epoch 5 of 5, Step: 12900 of 13750, Training loss: 0.0322173, Training accuracy: 0.9905039, Time: 06_05_2022__04:37:03\n","Epoch 5 of 5, Step: 13000 of 13750, Training loss: 0.0320940, Training accuracy: 0.9905000, Time: 06_05_2022__04:37:24\n","Epoch 5 of 5, Step: 13100 of 13750, Training loss: 0.0320767, Training accuracy: 0.9904962, Time: 06_05_2022__04:37:45\n","Epoch 5 of 5, Step: 13200 of 13750, Training loss: 0.0320294, Training accuracy: 0.9904735, Time: 06_05_2022__04:38:06\n","Epoch 5 of 5, Step: 13300 of 13750, Training loss: 0.0320975, Training accuracy: 0.9904323, Time: 06_05_2022__04:38:27\n","Epoch 5 of 5, Step: 13400 of 13750, Training loss: 0.0320657, Training accuracy: 0.9904104, Time: 06_05_2022__04:38:48\n","Epoch 5 of 5, Step: 13500 of 13750, Training loss: 0.0320140, Training accuracy: 0.9904074, Time: 06_05_2022__04:39:09\n","Epoch 5 of 5, Step: 13600 of 13750, Training loss: 0.0320348, Training accuracy: 0.9903860, Time: 06_05_2022__04:39:30\n","Epoch 5 of 5, Step: 13700 of 13750, Training loss: 0.0319625, Training accuracy: 0.9904015, Time: 06_05_2022__04:39:51\n","Epoch 5 of 5, Average training loss: 0.0321166, Average training accuracy: 0.9903636, Time: 06_05_2022__04:40:02\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f8973bd3b64492e96f4c0d2258b2678"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.0207729, Validation accuracy: 0.9975000, Time: 06_05_2022__04:40:07\n","Step: 200 of 1250, Validation loss: 0.0265786, Validation accuracy: 0.9962500, Time: 06_05_2022__04:40:12\n","Step: 300 of 1250, Validation loss: 0.0226001, Validation accuracy: 0.9958333, Time: 06_05_2022__04:40:17\n","Step: 400 of 1250, Validation loss: 0.0206480, Validation accuracy: 0.9962500, Time: 06_05_2022__04:40:23\n","Step: 500 of 1250, Validation loss: 0.0197850, Validation accuracy: 0.9955000, Time: 06_05_2022__04:40:28\n","Step: 600 of 1250, Validation loss: 0.0226442, Validation accuracy: 0.9945833, Time: 06_05_2022__04:40:33\n","Step: 700 of 1250, Validation loss: 0.0208190, Validation accuracy: 0.9946429, Time: 06_05_2022__04:40:38\n","Step: 800 of 1250, Validation loss: 0.0200930, Validation accuracy: 0.9943750, Time: 06_05_2022__04:40:43\n","Step: 900 of 1250, Validation loss: 0.0189474, Validation accuracy: 0.9947222, Time: 06_05_2022__04:40:49\n","Step: 1000 of 1250, Validation loss: 0.0203403, Validation accuracy: 0.9942500, Time: 06_05_2022__04:40:54\n","Step: 1100 of 1250, Validation loss: 0.0195093, Validation accuracy: 0.9945455, Time: 06_05_2022__04:40:59\n","Step: 1200 of 1250, Validation loss: 0.0208785, Validation accuracy: 0.9941667, Time: 06_05_2022__04:41:04\n","Average validation loss: 0.0233239, Average validation accuracy: 0.9934000, Time: 06_05_2022__04:41:07\n","###################### Testing vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0046e09c5d0746e1b45ce72057f0f3bc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.9900000, Time: 06_05_2022__04:41:16\n","Step: 200 of 2500, Test accuracy: 0.9887500, Time: 06_05_2022__04:41:22\n","Step: 300 of 2500, Test accuracy: 0.9875000, Time: 06_05_2022__04:41:27\n","Step: 400 of 2500, Test accuracy: 0.9862500, Time: 06_05_2022__04:41:33\n","Step: 500 of 2500, Test accuracy: 0.9870000, Time: 06_05_2022__04:41:38\n","Step: 600 of 2500, Test accuracy: 0.9858333, Time: 06_05_2022__04:41:43\n","Step: 700 of 2500, Test accuracy: 0.9864286, Time: 06_05_2022__04:41:48\n","Step: 800 of 2500, Test accuracy: 0.9859375, Time: 06_05_2022__04:41:54\n","Step: 900 of 2500, Test accuracy: 0.9861111, Time: 06_05_2022__04:41:59\n","Step: 1000 of 2500, Test accuracy: 0.9867500, Time: 06_05_2022__04:42:05\n","Step: 1100 of 2500, Test accuracy: 0.9877273, Time: 06_05_2022__04:42:10\n","Step: 1200 of 2500, Test accuracy: 0.9872917, Time: 06_05_2022__04:42:15\n","Step: 1300 of 2500, Test accuracy: 0.9875000, Time: 06_05_2022__04:42:21\n","Step: 1400 of 2500, Test accuracy: 0.9882143, Time: 06_05_2022__04:42:26\n","Step: 1500 of 2500, Test accuracy: 0.9883333, Time: 06_05_2022__04:42:31\n","Step: 1600 of 2500, Test accuracy: 0.9890625, Time: 06_05_2022__04:42:37\n","Step: 1700 of 2500, Test accuracy: 0.9889706, Time: 06_05_2022__04:42:42\n","Step: 1800 of 2500, Test accuracy: 0.9895833, Time: 06_05_2022__04:42:47\n","Step: 1900 of 2500, Test accuracy: 0.9901316, Time: 06_05_2022__04:42:52\n","Step: 2000 of 2500, Test accuracy: 0.9906250, Time: 06_05_2022__04:42:57\n","Step: 2100 of 2500, Test accuracy: 0.9909524, Time: 06_05_2022__04:43:03\n","Step: 2200 of 2500, Test accuracy: 0.9911364, Time: 06_05_2022__04:43:08\n","Step: 2300 of 2500, Test accuracy: 0.9910870, Time: 06_05_2022__04:43:13\n","Step: 2400 of 2500, Test accuracy: 0.9913542, Time: 06_05_2022__04:43:18\n","Step: 2500 of 2500, Test accuracy: 0.9912000, Time: 06_05_2022__04:43:24\n","Average testing accuracy: 0.9912000, Time: 06_05_2022__04:43:24\n","time: 16h 20min 2s (started: 2022-05-05 12:23:21 +00:00)\n"]}],"source":["#-- Parameters\n","epochs = 5\n","\n","for learning_rate in [0.1, 0.01, 0.001, 0.0001]:\n","  for mom in [0, 0.3, 0.6, 0.9]:\n","    #-- Freeze the randomness\n","    seed()\n","    model = vgg19_bn(pretrained=False)\n","    model_name = 'vgg19_batch_norm'\n","\n","    lr = learning_rate\n","    momentum = mom\n","    parameters = 'SGD, lr_{}, momentum_{}'.format(lr, momentum)\n","\n","    #-- Initiating a tensorboard writer that contains all logs for training, validation, and testing\n","    tb_writer = SummaryWriter('./models/MNIST/runs', filename_suffix='_'+model_name+'_'+parameters)\n","\n","    #-- Create the model's critrion loss function and a optimization function \n","    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","\n","    #-- Train and valiate the model\n","    model, model_save_path = model_train(model, model_name, lr, momentum, optimizer, epochs, tb_writer, parameters)\n","\n","    #-- Load the best saved model for testing\n","    model.load_state_dict(torch.load(model_save_path))\n","    model.to(device)\n","\n","    #-- Set the model mode to evaluation to prepare for testing\n","    model.eval()\n","    model_test(model, model_name, tb_writer, parameters) \n","\n","    #-- Close the Tensoboard writer\n","    tb_writer.close()\n","\n","    #-- Delete the model\n","    del model"]},{"cell_type":"markdown","id":"usJp3lvO_Dog","metadata":{"id":"usJp3lvO_Dog"},"source":["# Loading and Spliting CIFAR Data"]},{"cell_type":"code","execution_count":null,"id":"k_-npzax_Dog","metadata":{"id":"k_-npzax_Dog","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651882960351,"user_tz":-60,"elapsed":10724,"user":{"displayName":"Ziyad Moraished","userId":"09734916932076943331"}},"outputId":"a7f42e27-fafb-4548-8685-803d6883d0b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Number of Samples in Training Dataset:  45000\n","Number of Samples in Validation Dataset:  5000\n","Number of Samples in Testing Dataset:  10000\n","time: 10.5 s (started: 2022-05-07 00:22:29 +00:00)\n"]}],"source":["#-- Freeze the randomness\n","seed()\n","\n","#-- Prepare GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#-- Create data, train, and test directories\n","data_dir  = './datasets/CIFAR'\n","train_dir = os.path.join(data_dir, 'train')\n","test_dir  = os.path.join(data_dir, 'test')\n","\n","#-- Create directories for models and outputs\n","model_dir  = './models/CIFAR'\n","output_dir = '/content/drive/MyDrive/DL and CV/outputs/CIFAR'\n","Path(output_dir).mkdir(parents=True, exist_ok=True)\n","\n","trans = transforms.Compose([transforms.Resize(224), #-- VGG model requires this image shape\n","                              transforms.RandomRotation(15), #-- images augmentation to challenge the model\n","                              transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #-- Values normalization\n","\n","#-- Download CIFAR10 training data, and splitting it to training and validation\n","train_data = datasets.CIFAR10(root=train_dir, train=True, download=True, transform=trans)\n","\n","#-- Split the training data to training and validation datasets.\n","train_indices, val_indices = train_test_split(list(range(len(train_data.targets))), test_size=5000, stratify=train_data.targets, random_state=0)\n","train = torch.utils.data.Subset(train_data, train_indices)\n","val = torch.utils.data.Subset(train_data, val_indices)\n","\n","#-- Download CIFAR10 test data\n","test = datasets.CIFAR10(root=test_dir, train=False, download=True, transform=trans)\n","\n","#-- Setting training batch size:\n","batch_size = 4\n","\n","#-- Build the training, validation, and test data loaders\n","train_loader = DataLoader(dataset=train, batch_size=batch_size, shuffle=False)  \n","val_loader   = DataLoader(dataset=val,   batch_size=batch_size, shuffle=False)  \n","test_loader  = DataLoader(dataset=test,  batch_size=batch_size, shuffle=False) \n","\n","print(\"Number of Samples in Training Dataset: \",   len(train))\n","print(\"Number of Samples in Validation Dataset: \", len(val))\n","print(\"Number of Samples in Testing Dataset: \",    len(test))"]},{"cell_type":"markdown","id":"bp_TbEn2_Doi","metadata":{"id":"bp_TbEn2_Doi"},"source":["# CIFAR Main"]},{"cell_type":"markdown","source":["## Part 1"],"metadata":{"id":"I9ZwUhPULSmw"},"id":"I9ZwUhPULSmw"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e180a5b5ad094bdf92855b5270be0b88","d2b411167afc425fb70c7385d4212d57","50589997a7254d32888cca0b2795a05f","4c3efe558cef4d2fa4e7e6fd8a42d764","a0ee25f3f0d544d8a2f28a7413882382","30ffb17859d345c0a4670d51241e3aba","40ad6005004046f4b07040636995dd16","607923ddbf5a4c8f9ab80b596e3d2055","129b64f1ce2145c0b9c704f8119d64d1","7f02206f8e6045bf9929ea84b0499471","9109a2cdd21d4c60b559cbaa1e4a96bb","c63cde3814a04790bdec4231faadc6b8","58b5656400db43b0bba71b5199faaf2e","d6d8c84f446741c29dabe5cda4cf8ebf","0bf89b6a1bc04095b0caa3f09532ad35","3a9415dba4d14ed1bfefbaf4a507b783","031073c33c254f45ac1d335bb268a803","3b27a59fb58d4d50b9dfa04118e9975a","a689167daf464398b49b77e2ad90fe9e","43d54a131a5b49179fb205b318f9b67a","39d926e6b81247489e98b1926d7ce6ac","2dd88af8eaf848cba2d4b47d044a9e93","0615131857f14dae90a74631983f1f18","195023fb25d54d1e9bea00647e3091f3","5dcd91aa9c874325a9f7a4fa33e28175","b9cddd0057fa4078a2baf9eda1c1eb07","9bfd8d4b4f704eefaeb262a759cd758b","4b38515e7c1a4560b3eeac5c01464d25","5a6d322d1f1143d68f2746c49ede921d","c006043d93b142549684438054a6b1c1","91f299cc2120442c9b61d1b6875f0d66","43cf8d74586b4fb1a921c056839cee34","46758440697248f7b3a468034aaa046c","160c08a76130446f95feb06a6998b6c5","db3e5d09d8d042c2a6ce004c5453ff62","ef42427c31a8455585e5cead527a83eb","111a334adaba44399f3dd174c823421e","995568eed4e54a7ca0e4d1b7c1e6f663","42d5f0d0af4f40d7bc3047948be7acb1","aca464686e4f4649865c4b4a330978fe","fbef4865534244d688f0cc19683233a0","8bd1c784dc4c4b948ab6c8140ed2ac8f","23adfd8f65d844e28b2522db7463b1ea","2b2687c47a2946d7a92653d7219b4e94","6618959cd0ca4e35b2eb4bf7ed1181cc","794d8996148a48ecaca45e4ba5bc9a8a","fd6075fbb15945d1835b0226c7c5bfed","d8efafa42db44703af471b30bfc8c73d","3b9ff9ec31b0461998a47b7c4bb1b627","f699fccf25204d26a462be5a358cfae9","17aaa73fe9054336871f9c54d1dc6f2d","167eb11990a746bf98fe0c9f279505e2","08e30a3757aa4e62ae9dab521bf348c3","efd29a17cfea409abbcda3acb5ed1c38","335c0112301a4ec294c75d98d96d91a2","41a8a0d9d8704760a0f3ca79be005b37","14f228de4bdc439797e3af87d216ccad","a349046f4ed44041acc43a2e44514c6a","3a667f6e8036406d9a20d908eaf723d1","23548ba087f0446ebf7e165f8429472c","596b634dcc5d42dc915228a8f1f58b3d","d097c3bfa5c241828f9b2070c5f5b061","24956ae1383a435183a81f6cacdc78d9","0d2bfd1a3758417b920d38970976c47b","644858e16e28470a86e74040d363cfbb","aa2dd2529bb84c13a134299f5ce61eff","eac89e0900804c02bc408652a0498449","cc55b62675cf4865bbdb061302dcf815","d38680d409fb4fa4a398a6535e07b384","0ca707f50eeb49ff84bb8b35591586bc","27b031ea2b1546d59f9b4976e1c8313e","e4d5aa63a6844d4baf67250487583f06","d6e7f4b95d354dff8784671a8ed2db90","6435516ff0604545a8806cd3afdbf7ff","82b7ebf30d1244ff91e39e3ccd9f41ae","bfdf3bf035424d1bab5ac98cbcd26f26","7f5c485538cc43f7b4684f727daf9050","2321405a822b40ecb897a06c7d442255","ce95c6207a414b45bee325146b3160ad","473ac0ae0fc44aa68ae23b8440b5a039","eb3a54a8d2e94672b9101764213b09a9","6957d20e2cba4f319c00c91243b8363f","dff508f706c0439096af68f742cbd646","22507c391c8c47abb0e85019da49344f","8af29145863d4a6888e7c15dec79f530","f7d127e7560b445db5f133bc4983f983","e4884a5bde4342c1b4c652945cb93c51","35fdcc9f9ec84171835ab0c2300c1ceb","dd718da822db4af08781b58991fc5ad9","2c67d1ba578948e3bfa34a7be64f6f3f","0bedfcfeabee4ab2a5377a41806da443","d1cdd2a0eca4428fb032df34b71131b3","469925429f144a5582ebbe4fcbaae950","8c674bc45fbb4ffe8833e7e011dcf990","993d17cc52154e75b436b43f2fcc9ce7","d4a4d02d287649a0b99d9889f2775ddd","8d91e1c6a7694ebe9ec7a2e0e3f8d197","eb753fe0422c4c4193af78de01e21572","ef99c8c31a764df98de7093adf6c6b8c","cba68c496cdf460a830204432d07c94e","427dfdb3dc8148269483b52a40c9d559","6db9f83235fe4b9aa731f868f0a3868a","645db10b4a114dceb20481d84e8766a9","e3434ddcd1a8411796fb2cb152f2d8e5","e5705d0f029a4126b99820d43b6afbe1","0a1b7738163d4bb98d95cd4a453d5d54","855e566de1224a06b3d305fedfe1b814","2b827e119d5f4c61a9d46d1ef7020578","b262493dadc14e8eb64cd9560ee10d8f","c702911d97a1440db2902fdf84f568a1","c71a97e2f3c84c73a6dec545dd454c48","e9eeebcaaa1d46e5867c5f86f467e405","62a9739f3bac4785b20ff390e81ddfc6","14f2028d11824e2d8e4d141a59451034","806653e78b3847bbb9350a1b09282c2f","f0313af337a647e0a8090e05bdaab041","9127257bb0934828a093e3537df37113","f3f7029f3c804304b227ef2bb4ab8be4","a625ac1eb4064fc393bd567e660a0cec","f4d06ff24c5c4717871587c4c8618f5e","9219d2abd8af46429d2ed4c13853d3c0","af0aa3b381ab4c25b1d91be80b7c9fd4","7a5e97ce06dd4ed39629bf5e50828f97","71d73973bdce445f9b5f22dcff967ea6","b46961d3453443c9abb84aa37573d537","63f595159dab49adb3dfff04cb0af978","ff2ae82c6a004d7f9510cf1983f8c7e6","a4daabc05c9649d4b9cb254936e3f891","b1806c8d3c3e46e4ba8896c86814214a","a2d4d7c3a4c5478e8abb08693f13a13a","1277025b57754e999595dea4eb5268b1","9195d73d71534c2d98b7985a36441c1a","7da26a14fe6345c7aa1eea98045a7647","1bb5fdfe327f45e4a5526fac2082293e","1fc6e32536eb4102b5d5d9683a53212f","d949517d9ec248b38db5631263e717a7","88195d474e924898a960520f455e99e4","609637eda2154c138aea3fb88b355eca","53b185b58e9f41fabbcd067b14ead3bb","5ee04300d3a44de5b65148c3db13e849","eb8760c91f24437daf3876bc60fd60ae","2100595d91fc423691c1d3287dbe82eb","6ab22477a5874573925892f1d7691103","2455c8f80d25403eb09eb2a35073ad04","a875a82f1095437485ea7d2d52b856dd","eb761613fd8a442e8b4c27ac735ce94e","af2abe32bb4045dcb2acaadf7aff25df","563edde506a446f88a2f6d468d603046","7b03c12d4ac34bd28f561989a4f57bab","01bcf20f06dc47ba9964e33ae69b436f","4ab82042a2b6496f9f4ed8a1c971dcf0","78aee733fe5747ebb2cfab51be9f9d72","aa979dd975874d109a7d2fd1604058b8","9d1bef1f9e3546d2b321802e18ea9cc0","8a8f714e0d6a43b19690ec2ad6cc7e3b","1a172ebc147f4da68b16bfe41c5210d7","b591519cc8324bad836b6a58543dcafa","667b7853307e4d58a77d98382d9622a3","c8e27ff3f30f43d680bf0fbd96d03278","9c44b7cecdde4ef5963d622e32ef8ed4","b56e94b69876457fa0e18bc595bc44ed","0e8c0a7059584208bc18c0f0d81925c3","4dab16ebe00e477ab82f67b49b32cc92","45c836b44cc74b2099a0742fddab5ccf","05533943864c47d18a3eec493180ea03","d3f081f4ea7e4e7bac5183f2dc42799f","afc4e90f26bc4ae9a8576e72b5e87186","95969a3655484d78a7eb6308ff228859","70cdb2de1b374ad1a9cdef6a1294dc1c","9415876e57d349478a437c442cc55010","9322e76c41014325891ea975910a6939","2217fbe269bc44c183e802890768daac","1d3da1e5273d440a999fe6704c518551","7c25ce7c9adb4e6eaa5ddc2d817e4a27","16c91286de204fcba8b0fdeeec21be7d","77d75115b910471b930ecad8a16b1fcf","ec7fd73e6bdc432ea5388cdd1d4d25e6","afb61593573a432da21011e109eb7c85","5d138a81d7eb40dba58586f65062c735","159de70099774297873aca26ca75449e","ea71ba2b4f954237863455f98cd0db98","29546901285048e9b984f2b41f0c4c2e","6bc656229a3142a5b0ec7c8935642501","6befe754516146f5ad7ebad3be1444fb","2793a3727c9e4d6bb298fb13866c2d16","04141569e26c41d18979ed3af7c34b73","cd2137f27239401dba30a0fcb2d8e822","d9add8ecac0c47ec8fc8965caecc7465","29b12b670c7b4dca9d18fe758e6a4ca4","5eecf3b40adb4846980e1cbdaad805be","c11b6c6dc5f442d8affa7177d4a3e302","32f5dddbfea84ceaa71ed81745d5294c","8085f389b44448cebfe2502ffdef3904","556b40fa0cd3464a86dbed637a22dcc0","22ff7b5e55a34690bf8c0ff6991a1244","de833e5f1fb64e009127368508a022f2","fd06f84bcbcc4f698ac25f1e8128ee44","a34c87d616e040e7a163a91e549dd0b4","2529595687b140feb0ae747cdac411a1","72d87b4c0d6e43bb99c897e94b846322","e8695a85f5bd4eebbe202cc619ad148e","51e194a5873c4726926fb604612826d5","303f1d7312d548adb401d8b36b9bb2c6","8853af83288b4d33b0486e89e9cbe9de","49aa5b656b604963b1bcbb1b14213747","e386493553f54b60b677b6f9c7ba33c5","8d1104b78a8945348737db4003814097","cf1c03af553b4617acad01b1015cd792","befa3196a4214f20b0198456767d41aa","85314b5733e44913a56654e4d9b68b13","fe4739b95c3c4c2486b7ac96910c6f7a","ab0a9752ee0a4d37bcd0cce62695146a","d6cf2e4c82b2475f8d733a2dabcd669f","bdaeccc333694ffd8734de8bc0807489","eec83080ddcf456c9f93268ded1ad0e3","b95fee5473894ad4ace49c8ff9f556d3","a50db90f793c4a2986aa4f72a9c109c9","61ebe781e4994c95af013140b88cbf9d","9e941da14f4c4dbfb5602d90f3a1f652","075e8075c8234945a934b7e19de79764","66d5feae3aec4c5499b4fb44e2504aa5","0ed89107186d4d17b90aa7d4cb90c976","149e9df12b46407b96d04472341e6406","0f861af9c0654e90ac3795b3fe91c3a5","a28bbb631b42494b9b62023babf58d88","038aab078257498790fa1805caad70c3","ae0b8789619644e8bcd38f09e6d39e46","5d8ab241ef6d430dad3ccb49e84d6bbc","ddc4c28eb3374162b1f99b48a782bb85","fea5c86955264bb18b1eb896376d0daf","3d4fe98c8c9e4c639bd836d650d9a08d","ecd2aef1af904626baed5589e8fbbc82","29d3c38bfe0846e888b71778e82f6786","a9cc15333c2a4eeb970879a2ff199764","b22c17c86c9a434aac9f860285c2a3f9","47ea5321f29447d9bf2bed15e7582734","a08825c6770b48a796532b50ae5ed955","38e6bab97bed49d5a89174a9dbad7ae8","ae64789266b847f29e78d16b5a802e6d","7d69782c5bd74fac8cda2d7405467ab0","f714f8f376ef4452b2abae828c491a02","eb36d0867d5e4a0e8ba17139dd0579e2","c1047f6cbdef4002975523daf4af41bf","59ede637fc7c4604b18e7132eb67f7f5","757baec32f9a4fbcb55424ae658009d3","49ab8f508ae3486097db351118299a2f","2598585fea1740b3b11fd63b4c7f732d","45f63edd668341b8bcc9b0447beb18ed","7492241efa29444aa79edda34da93a44","a8a3a807e28445ca99e66cbeb4432615","90b0298280b444ebbf7b67999f3ff7e7","88f5b076f96b452b8e4fe67afef727e7","be0709d55b714c8bb20fb973fb64e5ee","86d1ea1a000b47a3b901a7d6390e5361","16927b962e8e455f89bf628c4efa1487","7ddc4ec2110347568184c20b6c10727a","1d3a7c89b2e6409f9ba198862f4baafa","38641a24597a44c781be8b45ac116493","a6a7ad3fabe3440096aab10648dce6bd","14da47e6e16d4ffd95e711c84f701f01","c8841c82e65e483f9a33ebc11b9b58af","360d376c52d0460889734babaf7bdcc0","218de708e76049738c064e5b4b8e34c5","534d487c9e3349009209b2d2f88f314a","9775c7bea58c4469a2f69c1a9b410e9f","9488697197ac4500bd9c1ec91e9b673d","7073e01701594f24b14d57de5b7ac75b","31bc9d1f6d434165a94c0dd23c1b4eaf","1267bbebca284ffbbb6dc59063ef41f4","325ac04b68484b8d9dfb5c4d4bf5d546","d1c89d3b392d42778ff75bb0073ed39f","3dc18efc5a9a40a98debbed7ba5b5116","364571af3006426a8af6965912b1a067","0379eb38242a4c278deaac43c0cb284f","6828d3b7a580450e8bbd727150989d08"]},"outputId":"bfebef70-cfae-4359-9710-9e8f5f254e9a","id":"T8zoxXiCJkKV"},"outputs":[{"output_type":"stream","name":"stdout","text":["###################### Training vgg19_batch_norm SGD, lr_0.1, momentum_0 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e180a5b5ad094bdf92855b5270be0b88"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 6.4188341, Training accuracy: 0.1075000, Time: 06_05_2022__04:44:02\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 4.4110913, Training accuracy: 0.1137500, Time: 06_05_2022__04:44:22\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 3.7270829, Training accuracy: 0.1091667, Time: 06_05_2022__04:44:41\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 3.3741683, Training accuracy: 0.1093750, Time: 06_05_2022__04:45:01\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 3.1603608, Training accuracy: 0.1140000, Time: 06_05_2022__04:45:21\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 3.0190351, Training accuracy: 0.1166667, Time: 06_05_2022__04:45:40\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.9169597, Training accuracy: 0.1214286, Time: 06_05_2022__04:46:00\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.8394547, Training accuracy: 0.1218750, Time: 06_05_2022__04:46:20\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.7802101, Training accuracy: 0.1213889, Time: 06_05_2022__04:46:39\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.7338393, Training accuracy: 0.1187500, Time: 06_05_2022__04:46:59\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.6951684, Training accuracy: 0.1177273, Time: 06_05_2022__04:47:19\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.6626160, Training accuracy: 0.1179167, Time: 06_05_2022__04:47:38\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.6348437, Training accuracy: 0.1180769, Time: 06_05_2022__04:47:58\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.6105758, Training accuracy: 0.1192857, Time: 06_05_2022__04:48:17\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.5909551, Training accuracy: 0.1191667, Time: 06_05_2022__04:48:37\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.5722583, Training accuracy: 0.1196875, Time: 06_05_2022__04:48:57\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.5565311, Training accuracy: 0.1185294, Time: 06_05_2022__04:49:16\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.5426639, Training accuracy: 0.1187500, Time: 06_05_2022__04:49:36\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.5301951, Training accuracy: 0.1182895, Time: 06_05_2022__04:49:56\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.5191333, Training accuracy: 0.1185000, Time: 06_05_2022__04:50:15\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.5077560, Training accuracy: 0.1200000, Time: 06_05_2022__04:50:35\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.4973129, Training accuracy: 0.1198864, Time: 06_05_2022__04:50:55\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.4882629, Training accuracy: 0.1197826, Time: 06_05_2022__04:51:14\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.4807401, Training accuracy: 0.1205208, Time: 06_05_2022__04:51:34\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.4730617, Training accuracy: 0.1210000, Time: 06_05_2022__04:51:54\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.4655407, Training accuracy: 0.1212500, Time: 06_05_2022__04:52:13\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.4590639, Training accuracy: 0.1212037, Time: 06_05_2022__04:52:33\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.4533445, Training accuracy: 0.1213393, Time: 06_05_2022__04:52:52\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.4472608, Training accuracy: 0.1210345, Time: 06_05_2022__04:53:12\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.4417988, Training accuracy: 0.1207500, Time: 06_05_2022__04:53:32\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.4363159, Training accuracy: 0.1212903, Time: 06_05_2022__04:53:51\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.4312407, Training accuracy: 0.1217188, Time: 06_05_2022__04:54:11\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.4265745, Training accuracy: 0.1221970, Time: 06_05_2022__04:54:31\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.4226282, Training accuracy: 0.1219118, Time: 06_05_2022__04:54:50\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.4187425, Training accuracy: 0.1215714, Time: 06_05_2022__04:55:10\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.4145580, Training accuracy: 0.1225000, Time: 06_05_2022__04:55:30\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.4103586, Training accuracy: 0.1235811, Time: 06_05_2022__04:55:49\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.4069649, Training accuracy: 0.1235526, Time: 06_05_2022__04:56:09\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.4030910, Training accuracy: 0.1239744, Time: 06_05_2022__04:56:29\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.4001742, Training accuracy: 0.1239375, Time: 06_05_2022__04:56:48\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.3969275, Training accuracy: 0.1244512, Time: 06_05_2022__04:57:08\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.3937013, Training accuracy: 0.1253571, Time: 06_05_2022__04:57:28\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.3909671, Training accuracy: 0.1254651, Time: 06_05_2022__04:57:47\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.3881903, Training accuracy: 0.1260795, Time: 06_05_2022__04:58:07\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.3847271, Training accuracy: 0.1263889, Time: 06_05_2022__04:58:27\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.3818077, Training accuracy: 0.1269565, Time: 06_05_2022__04:58:46\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.3787894, Training accuracy: 0.1270213, Time: 06_05_2022__04:59:06\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 2.3764980, Training accuracy: 0.1271354, Time: 06_05_2022__04:59:26\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 2.3742186, Training accuracy: 0.1277041, Time: 06_05_2022__04:59:45\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 2.3726010, Training accuracy: 0.1276000, Time: 06_05_2022__05:00:05\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 2.3700910, Training accuracy: 0.1282353, Time: 06_05_2022__05:00:25\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 2.3681375, Training accuracy: 0.1285577, Time: 06_05_2022__05:00:44\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 2.3661982, Training accuracy: 0.1286321, Time: 06_05_2022__05:01:04\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 2.3638720, Training accuracy: 0.1293519, Time: 06_05_2022__05:01:24\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 2.3615796, Training accuracy: 0.1299545, Time: 06_05_2022__05:01:43\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 2.3593993, Training accuracy: 0.1304911, Time: 06_05_2022__05:02:03\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 2.3577339, Training accuracy: 0.1307895, Time: 06_05_2022__05:02:22\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 2.3554635, Training accuracy: 0.1316810, Time: 06_05_2022__05:02:42\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 2.3528405, Training accuracy: 0.1325847, Time: 06_05_2022__05:03:02\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 2.3507958, Training accuracy: 0.1333333, Time: 06_05_2022__05:03:21\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 2.3487320, Training accuracy: 0.1337295, Time: 06_05_2022__05:03:41\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 2.3467769, Training accuracy: 0.1342339, Time: 06_05_2022__05:04:01\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 2.3442444, Training accuracy: 0.1351984, Time: 06_05_2022__05:04:20\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 2.3418679, Training accuracy: 0.1357812, Time: 06_05_2022__05:04:40\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 2.3381605, Training accuracy: 0.1371923, Time: 06_05_2022__05:05:00\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 2.3360965, Training accuracy: 0.1385606, Time: 06_05_2022__05:05:19\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 2.3333486, Training accuracy: 0.1397015, Time: 06_05_2022__05:05:39\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 2.3310706, Training accuracy: 0.1404044, Time: 06_05_2022__05:05:59\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 2.3281235, Training accuracy: 0.1409420, Time: 06_05_2022__05:06:18\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 2.3254600, Training accuracy: 0.1419643, Time: 06_05_2022__05:06:38\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 2.3225266, Training accuracy: 0.1431690, Time: 06_05_2022__05:06:58\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 2.3192704, Training accuracy: 0.1445139, Time: 06_05_2022__05:07:17\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 2.3162867, Training accuracy: 0.1457534, Time: 06_05_2022__05:07:37\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 2.3139840, Training accuracy: 0.1463851, Time: 06_05_2022__05:07:57\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 2.3112894, Training accuracy: 0.1474333, Time: 06_05_2022__05:08:16\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 2.3085724, Training accuracy: 0.1483224, Time: 06_05_2022__05:08:36\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 2.3058711, Training accuracy: 0.1492857, Time: 06_05_2022__05:08:56\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 2.3029214, Training accuracy: 0.1504167, Time: 06_05_2022__05:09:15\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 2.3000934, Training accuracy: 0.1512342, Time: 06_05_2022__05:09:35\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 2.2975891, Training accuracy: 0.1523438, Time: 06_05_2022__05:09:54\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 2.2949433, Training accuracy: 0.1533951, Time: 06_05_2022__05:10:14\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 2.2916257, Training accuracy: 0.1547561, Time: 06_05_2022__05:10:34\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 2.2883996, Training accuracy: 0.1557831, Time: 06_05_2022__05:10:53\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 2.2853706, Training accuracy: 0.1567560, Time: 06_05_2022__05:11:13\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 2.2826325, Training accuracy: 0.1577353, Time: 06_05_2022__05:11:33\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 2.2799550, Training accuracy: 0.1588663, Time: 06_05_2022__05:11:52\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 2.2772351, Training accuracy: 0.1599138, Time: 06_05_2022__05:12:12\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 2.2736714, Training accuracy: 0.1617330, Time: 06_05_2022__05:12:32\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 2.2707332, Training accuracy: 0.1628090, Time: 06_05_2022__05:12:51\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 2.2681058, Training accuracy: 0.1630556, Time: 06_05_2022__05:13:11\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 2.2657113, Training accuracy: 0.1640659, Time: 06_05_2022__05:13:31\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 2.2627127, Training accuracy: 0.1652717, Time: 06_05_2022__05:13:50\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 2.2605116, Training accuracy: 0.1661022, Time: 06_05_2022__05:14:10\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 2.2581656, Training accuracy: 0.1673404, Time: 06_05_2022__05:14:30\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 2.2560648, Training accuracy: 0.1681579, Time: 06_05_2022__05:14:49\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 2.2528510, Training accuracy: 0.1694531, Time: 06_05_2022__05:15:09\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 2.2494257, Training accuracy: 0.1704381, Time: 06_05_2022__05:15:29\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 2.2462156, Training accuracy: 0.1720153, Time: 06_05_2022__05:15:48\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 2.2439504, Training accuracy: 0.1730556, Time: 06_05_2022__05:16:08\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 2.2414923, Training accuracy: 0.1743000, Time: 06_05_2022__05:16:28\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 2.2390846, Training accuracy: 0.1751980, Time: 06_05_2022__05:16:47\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 2.2363016, Training accuracy: 0.1762500, Time: 06_05_2022__05:17:07\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 2.2334557, Training accuracy: 0.1775243, Time: 06_05_2022__05:17:27\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 2.2307812, Training accuracy: 0.1785337, Time: 06_05_2022__05:17:46\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 2.2286563, Training accuracy: 0.1791429, Time: 06_05_2022__05:18:06\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 2.2258710, Training accuracy: 0.1798349, Time: 06_05_2022__05:18:26\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 2.2233441, Training accuracy: 0.1805374, Time: 06_05_2022__05:18:45\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 2.2204839, Training accuracy: 0.1818981, Time: 06_05_2022__05:19:05\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 2.2185738, Training accuracy: 0.1826376, Time: 06_05_2022__05:19:25\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 2.2165638, Training accuracy: 0.1834545, Time: 06_05_2022__05:19:44\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 2.2136314, Training accuracy: 0.1844369, Time: 06_05_2022__05:20:04\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 2.2111609, Training accuracy: 0.1853348, Time: 06_05_2022__05:20:24\n","Epoch 1 of 5, Average training loss: 2.2100975, Average training accuracy: 0.1856889, Time: 06_05_2022__05:20:33\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c63cde3814a04790bdec4231faadc6b8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.8017911, Validation accuracy: 0.3675000, Time: 06_05_2022__05:20:39 | Loss decreased from inf to 1.7981505 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.8153935, Validation accuracy: 0.3650000, Time: 06_05_2022__05:20:46\n","Step: 300 of 1250, Validation loss: 1.8108777, Validation accuracy: 0.3591667, Time: 06_05_2022__05:20:51\n","Step: 400 of 1250, Validation loss: 1.8137978, Validation accuracy: 0.3587500, Time: 06_05_2022__05:20:57\n","Step: 500 of 1250, Validation loss: 1.8246531, Validation accuracy: 0.3530000, Time: 06_05_2022__05:21:02\n","Step: 600 of 1250, Validation loss: 1.8255114, Validation accuracy: 0.3500000, Time: 06_05_2022__05:21:07\n","Step: 700 of 1250, Validation loss: 1.8291330, Validation accuracy: 0.3482143, Time: 06_05_2022__05:21:12\n","Step: 800 of 1250, Validation loss: 1.8273261, Validation accuracy: 0.3443750, Time: 06_05_2022__05:21:17\n","Step: 900 of 1250, Validation loss: 1.8280932, Validation accuracy: 0.3430556, Time: 06_05_2022__05:21:22\n","Step: 1000 of 1250, Validation loss: 1.8306202, Validation accuracy: 0.3405000, Time: 06_05_2022__05:21:28\n","Step: 1100 of 1250, Validation loss: 1.8310378, Validation accuracy: 0.3415909, Time: 06_05_2022__05:21:33\n","Step: 1200 of 1250, Validation loss: 1.8330614, Validation accuracy: 0.3400000, Time: 06_05_2022__05:21:38\n","Average validation loss: 1.8314733, Average validation accuracy: 0.3406000, Time: 06_05_2022__05:21:40\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0615131857f14dae90a74631983f1f18"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.8524756, Training accuracy: 0.3150000, Time: 06_05_2022__05:22:00\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.8867755, Training accuracy: 0.3150000, Time: 06_05_2022__05:22:20\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.9048923, Training accuracy: 0.3058333, Time: 06_05_2022__05:22:40\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.9047750, Training accuracy: 0.3037500, Time: 06_05_2022__05:22:59\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.8992196, Training accuracy: 0.3055000, Time: 06_05_2022__05:23:19\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.8953737, Training accuracy: 0.3070833, Time: 06_05_2022__05:23:39\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.8974476, Training accuracy: 0.3053571, Time: 06_05_2022__05:23:58\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.8921296, Training accuracy: 0.3050000, Time: 06_05_2022__05:24:18\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.8870040, Training accuracy: 0.3069444, Time: 06_05_2022__05:24:38\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.8821455, Training accuracy: 0.3117500, Time: 06_05_2022__05:24:57\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.8814781, Training accuracy: 0.3122727, Time: 06_05_2022__05:25:17\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.8764272, Training accuracy: 0.3127083, Time: 06_05_2022__05:25:37\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.8714791, Training accuracy: 0.3144231, Time: 06_05_2022__05:25:56\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.8658841, Training accuracy: 0.3167857, Time: 06_05_2022__05:26:16\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.8663340, Training accuracy: 0.3155000, Time: 06_05_2022__05:26:36\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.8667643, Training accuracy: 0.3143750, Time: 06_05_2022__05:26:55\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.8625964, Training accuracy: 0.3161765, Time: 06_05_2022__05:27:15\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.8583958, Training accuracy: 0.3193056, Time: 06_05_2022__05:27:35\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.8528291, Training accuracy: 0.3223684, Time: 06_05_2022__05:27:54\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.8498956, Training accuracy: 0.3230000, Time: 06_05_2022__05:28:14\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.8443189, Training accuracy: 0.3235714, Time: 06_05_2022__05:28:34\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.8423716, Training accuracy: 0.3253409, Time: 06_05_2022__05:28:54\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.8387329, Training accuracy: 0.3271739, Time: 06_05_2022__05:29:13\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.8346759, Training accuracy: 0.3273958, Time: 06_05_2022__05:29:33\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.8280371, Training accuracy: 0.3303000, Time: 06_05_2022__05:29:53\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.8251955, Training accuracy: 0.3316346, Time: 06_05_2022__05:30:12\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.8207455, Training accuracy: 0.3337037, Time: 06_05_2022__05:30:32\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.8176985, Training accuracy: 0.3346429, Time: 06_05_2022__05:30:52\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.8116873, Training accuracy: 0.3380172, Time: 06_05_2022__05:31:11\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.8099248, Training accuracy: 0.3385833, Time: 06_05_2022__05:31:31\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.8057780, Training accuracy: 0.3392742, Time: 06_05_2022__05:31:51\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.8012565, Training accuracy: 0.3410156, Time: 06_05_2022__05:32:10\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.7995533, Training accuracy: 0.3418939, Time: 06_05_2022__05:32:30\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.7979505, Training accuracy: 0.3425000, Time: 06_05_2022__05:32:50\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.7942708, Training accuracy: 0.3432857, Time: 06_05_2022__05:33:09\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.7933646, Training accuracy: 0.3426389, Time: 06_05_2022__05:33:29\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.7927257, Training accuracy: 0.3424324, Time: 06_05_2022__05:33:49\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.7901759, Training accuracy: 0.3443421, Time: 06_05_2022__05:34:08\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.7878622, Training accuracy: 0.3455128, Time: 06_05_2022__05:34:28\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.7860556, Training accuracy: 0.3463125, Time: 06_05_2022__05:34:48\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.7834899, Training accuracy: 0.3473171, Time: 06_05_2022__05:35:07\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.7789445, Training accuracy: 0.3488095, Time: 06_05_2022__05:35:27\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.7768221, Training accuracy: 0.3494767, Time: 06_05_2022__05:35:47\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.7727378, Training accuracy: 0.3503409, Time: 06_05_2022__05:36:07\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.7693228, Training accuracy: 0.3516667, Time: 06_05_2022__05:36:26\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.7675119, Training accuracy: 0.3530978, Time: 06_05_2022__05:36:46\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.7655437, Training accuracy: 0.3535106, Time: 06_05_2022__05:37:06\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.7644038, Training accuracy: 0.3546875, Time: 06_05_2022__05:37:25\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.7630758, Training accuracy: 0.3551020, Time: 06_05_2022__05:37:45\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.7615942, Training accuracy: 0.3561500, Time: 06_05_2022__05:38:05\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.7589797, Training accuracy: 0.3571569, Time: 06_05_2022__05:38:24\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.7574547, Training accuracy: 0.3579808, Time: 06_05_2022__05:38:44\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.7554424, Training accuracy: 0.3590094, Time: 06_05_2022__05:39:04\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.7536480, Training accuracy: 0.3604630, Time: 06_05_2022__05:39:23\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.7505760, Training accuracy: 0.3615455, Time: 06_05_2022__05:39:43\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.7481796, Training accuracy: 0.3624554, Time: 06_05_2022__05:40:03\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.7457666, Training accuracy: 0.3633772, Time: 06_05_2022__05:40:22\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.7436164, Training accuracy: 0.3641379, Time: 06_05_2022__05:40:42\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.7416892, Training accuracy: 0.3647881, Time: 06_05_2022__05:41:02\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.7394293, Training accuracy: 0.3650833, Time: 06_05_2022__05:41:22\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.7380081, Training accuracy: 0.3659426, Time: 06_05_2022__05:41:41\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.7355343, Training accuracy: 0.3669758, Time: 06_05_2022__05:42:01\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.7333129, Training accuracy: 0.3678571, Time: 06_05_2022__05:42:21\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.7311876, Training accuracy: 0.3685937, Time: 06_05_2022__05:42:40\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.7287602, Training accuracy: 0.3699615, Time: 06_05_2022__05:43:00\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.7266031, Training accuracy: 0.3707955, Time: 06_05_2022__05:43:20\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.7236864, Training accuracy: 0.3715672, Time: 06_05_2022__05:43:39\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.7221318, Training accuracy: 0.3724632, Time: 06_05_2022__05:43:59\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.7198906, Training accuracy: 0.3729348, Time: 06_05_2022__05:44:19\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.7176517, Training accuracy: 0.3737500, Time: 06_05_2022__05:44:38\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.7161320, Training accuracy: 0.3746479, Time: 06_05_2022__05:44:58\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.7130649, Training accuracy: 0.3758333, Time: 06_05_2022__05:45:18\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.7119747, Training accuracy: 0.3762329, Time: 06_05_2022__05:45:38\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.7102416, Training accuracy: 0.3765878, Time: 06_05_2022__05:45:57\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.7084395, Training accuracy: 0.3770000, Time: 06_05_2022__05:46:17\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.7060065, Training accuracy: 0.3778618, Time: 06_05_2022__05:46:37\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.7038576, Training accuracy: 0.3786688, Time: 06_05_2022__05:46:56\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.7013583, Training accuracy: 0.3799359, Time: 06_05_2022__05:47:16\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.6995555, Training accuracy: 0.3806962, Time: 06_05_2022__05:47:36\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.6982083, Training accuracy: 0.3812187, Time: 06_05_2022__05:47:55\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.6967806, Training accuracy: 0.3814815, Time: 06_05_2022__05:48:15\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.6950097, Training accuracy: 0.3823780, Time: 06_05_2022__05:48:35\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.6920261, Training accuracy: 0.3836145, Time: 06_05_2022__05:48:55\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.6908520, Training accuracy: 0.3841667, Time: 06_05_2022__05:49:14\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.6885876, Training accuracy: 0.3853235, Time: 06_05_2022__05:49:34\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.6867731, Training accuracy: 0.3859884, Time: 06_05_2022__05:49:54\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.6845715, Training accuracy: 0.3868678, Time: 06_05_2022__05:50:13\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.6815837, Training accuracy: 0.3880114, Time: 06_05_2022__05:50:33\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.6795469, Training accuracy: 0.3889326, Time: 06_05_2022__05:50:53\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.6777729, Training accuracy: 0.3899444, Time: 06_05_2022__05:51:13\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.6767711, Training accuracy: 0.3903297, Time: 06_05_2022__05:51:32\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.6744665, Training accuracy: 0.3913859, Time: 06_05_2022__05:51:52\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.6733364, Training accuracy: 0.3916667, Time: 06_05_2022__05:52:12\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.6713668, Training accuracy: 0.3922606, Time: 06_05_2022__05:52:31\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.6716002, Training accuracy: 0.3921842, Time: 06_05_2022__05:52:51\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.6691977, Training accuracy: 0.3928125, Time: 06_05_2022__05:53:11\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.6663988, Training accuracy: 0.3937371, Time: 06_05_2022__05:53:30\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.6638274, Training accuracy: 0.3944643, Time: 06_05_2022__05:53:50\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.6617373, Training accuracy: 0.3951263, Time: 06_05_2022__05:54:10\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.6603977, Training accuracy: 0.3960500, Time: 06_05_2022__05:54:30\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.6593034, Training accuracy: 0.3969059, Time: 06_05_2022__05:54:49\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.6570829, Training accuracy: 0.3977206, Time: 06_05_2022__05:55:09\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.6546004, Training accuracy: 0.3990777, Time: 06_05_2022__05:55:29\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.6530252, Training accuracy: 0.3996394, Time: 06_05_2022__05:55:48\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.6513919, Training accuracy: 0.4002381, Time: 06_05_2022__05:56:08\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.6496331, Training accuracy: 0.4006368, Time: 06_05_2022__05:56:28\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.6472586, Training accuracy: 0.4014019, Time: 06_05_2022__05:56:47\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.6450093, Training accuracy: 0.4024074, Time: 06_05_2022__05:57:07\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.6440171, Training accuracy: 0.4029358, Time: 06_05_2022__05:57:27\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.6419708, Training accuracy: 0.4037273, Time: 06_05_2022__05:57:47\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.6399692, Training accuracy: 0.4044144, Time: 06_05_2022__05:58:06\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.6381423, Training accuracy: 0.4052902, Time: 06_05_2022__05:58:26\n","Epoch 2 of 5, Average training loss: 1.6375970, Average training accuracy: 0.4055111, Time: 06_05_2022__05:58:36\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"160c08a76130446f95feb06a6998b6c5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.2838735, Validation accuracy: 0.5400000, Time: 06_05_2022__05:58:41 | Loss decreased from 1.7981505 to 1.2813759 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.3126419, Validation accuracy: 0.5287500, Time: 06_05_2022__05:58:48\n","Step: 300 of 1250, Validation loss: 1.3142326, Validation accuracy: 0.5283333, Time: 06_05_2022__05:58:54\n","Step: 400 of 1250, Validation loss: 1.3262543, Validation accuracy: 0.5287500, Time: 06_05_2022__05:58:59\n","Step: 500 of 1250, Validation loss: 1.3328381, Validation accuracy: 0.5295000, Time: 06_05_2022__05:59:04\n","Step: 600 of 1250, Validation loss: 1.3208599, Validation accuracy: 0.5341667, Time: 06_05_2022__05:59:09\n","Step: 700 of 1250, Validation loss: 1.3120231, Validation accuracy: 0.5364286, Time: 06_05_2022__05:59:14\n","Step: 800 of 1250, Validation loss: 1.3064576, Validation accuracy: 0.5384375, Time: 06_05_2022__05:59:19\n","Step: 900 of 1250, Validation loss: 1.3089622, Validation accuracy: 0.5386111, Time: 06_05_2022__05:59:25\n","Step: 1000 of 1250, Validation loss: 1.3145058, Validation accuracy: 0.5377500, Time: 06_05_2022__05:59:30\n","Step: 1100 of 1250, Validation loss: 1.3159784, Validation accuracy: 0.5397727, Time: 06_05_2022__05:59:35\n","Step: 1200 of 1250, Validation loss: 1.3198139, Validation accuracy: 0.5366667, Time: 06_05_2022__05:59:40\n","Average validation loss: 1.3184192, Average validation accuracy: 0.5378000, Time: 06_05_2022__05:59:43\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6618959cd0ca4e35b2eb4bf7ed1181cc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.3369995, Training accuracy: 0.5525000, Time: 06_05_2022__06:00:02\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.3892066, Training accuracy: 0.5062500, Time: 06_05_2022__06:00:22\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.4183027, Training accuracy: 0.4966667, Time: 06_05_2022__06:00:42\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.3925177, Training accuracy: 0.5031250, Time: 06_05_2022__06:01:01\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.3940112, Training accuracy: 0.4960000, Time: 06_05_2022__06:01:21\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.3828887, Training accuracy: 0.5016667, Time: 06_05_2022__06:01:41\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.3920036, Training accuracy: 0.5017857, Time: 06_05_2022__06:02:00\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.3950606, Training accuracy: 0.5025000, Time: 06_05_2022__06:02:20\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.3967347, Training accuracy: 0.4991667, Time: 06_05_2022__06:02:40\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.3965426, Training accuracy: 0.5005000, Time: 06_05_2022__06:03:00\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.3893398, Training accuracy: 0.5006818, Time: 06_05_2022__06:03:19\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.3903882, Training accuracy: 0.5012500, Time: 06_05_2022__06:03:39\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.3831283, Training accuracy: 0.5030769, Time: 06_05_2022__06:03:59\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.3809956, Training accuracy: 0.5046429, Time: 06_05_2022__06:04:18\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.3894300, Training accuracy: 0.5045000, Time: 06_05_2022__06:04:38\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.3872072, Training accuracy: 0.5050000, Time: 06_05_2022__06:04:58\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.3885767, Training accuracy: 0.5052941, Time: 06_05_2022__06:05:18\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.3861821, Training accuracy: 0.5058333, Time: 06_05_2022__06:05:37\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.3824205, Training accuracy: 0.5080263, Time: 06_05_2022__06:05:57\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.3828862, Training accuracy: 0.5091250, Time: 06_05_2022__06:06:17\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.3758540, Training accuracy: 0.5107143, Time: 06_05_2022__06:06:36\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.3732943, Training accuracy: 0.5118182, Time: 06_05_2022__06:06:56\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.3703587, Training accuracy: 0.5131522, Time: 06_05_2022__06:07:16\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.3667231, Training accuracy: 0.5137500, Time: 06_05_2022__06:07:36\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.3626817, Training accuracy: 0.5143000, Time: 06_05_2022__06:07:55\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.3589476, Training accuracy: 0.5174038, Time: 06_05_2022__06:08:15\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.3555089, Training accuracy: 0.5187963, Time: 06_05_2022__06:08:35\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.3534846, Training accuracy: 0.5193750, Time: 06_05_2022__06:08:54\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.3524914, Training accuracy: 0.5195690, Time: 06_05_2022__06:09:14\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.3533788, Training accuracy: 0.5193333, Time: 06_05_2022__06:09:34\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.3495657, Training accuracy: 0.5208065, Time: 06_05_2022__06:09:54\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.3457321, Training accuracy: 0.5223437, Time: 06_05_2022__06:10:13\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.3454644, Training accuracy: 0.5218182, Time: 06_05_2022__06:10:33\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.3441875, Training accuracy: 0.5225735, Time: 06_05_2022__06:10:53\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.3435453, Training accuracy: 0.5225000, Time: 06_05_2022__06:11:12\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.3431462, Training accuracy: 0.5220833, Time: 06_05_2022__06:11:32\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.3423947, Training accuracy: 0.5227027, Time: 06_05_2022__06:11:52\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.3403679, Training accuracy: 0.5236842, Time: 06_05_2022__06:12:12\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.3385097, Training accuracy: 0.5240385, Time: 06_05_2022__06:12:31\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.3366999, Training accuracy: 0.5245000, Time: 06_05_2022__06:12:51\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.3383727, Training accuracy: 0.5245732, Time: 06_05_2022__06:13:11\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.3357813, Training accuracy: 0.5261310, Time: 06_05_2022__06:13:30\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.3333457, Training accuracy: 0.5267442, Time: 06_05_2022__06:13:50\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.3325445, Training accuracy: 0.5272159, Time: 06_05_2022__06:14:10\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.3307788, Training accuracy: 0.5282778, Time: 06_05_2022__06:14:30\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.3299517, Training accuracy: 0.5288043, Time: 06_05_2022__06:14:49\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.3280231, Training accuracy: 0.5297340, Time: 06_05_2022__06:15:09\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.3257541, Training accuracy: 0.5308854, Time: 06_05_2022__06:15:29\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.3252867, Training accuracy: 0.5311224, Time: 06_05_2022__06:15:49\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.3240712, Training accuracy: 0.5320000, Time: 06_05_2022__06:16:08\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.3222803, Training accuracy: 0.5325980, Time: 06_05_2022__06:16:28\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.3222247, Training accuracy: 0.5330288, Time: 06_05_2022__06:16:48\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.3205224, Training accuracy: 0.5344340, Time: 06_05_2022__06:17:07\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.3184254, Training accuracy: 0.5352778, Time: 06_05_2022__06:17:27\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.3163170, Training accuracy: 0.5361818, Time: 06_05_2022__06:17:47\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.3156931, Training accuracy: 0.5364286, Time: 06_05_2022__06:18:07\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.3139890, Training accuracy: 0.5370175, Time: 06_05_2022__06:18:26\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.3129268, Training accuracy: 0.5372414, Time: 06_05_2022__06:18:46\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.3118611, Training accuracy: 0.5377119, Time: 06_05_2022__06:19:06\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.3106246, Training accuracy: 0.5380833, Time: 06_05_2022__06:19:26\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.3101395, Training accuracy: 0.5379918, Time: 06_05_2022__06:19:45\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.3078912, Training accuracy: 0.5388306, Time: 06_05_2022__06:20:05\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.3073035, Training accuracy: 0.5391270, Time: 06_05_2022__06:20:25\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.3061425, Training accuracy: 0.5399219, Time: 06_05_2022__06:20:45\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.3044598, Training accuracy: 0.5404615, Time: 06_05_2022__06:21:04\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.3034025, Training accuracy: 0.5411364, Time: 06_05_2022__06:21:24\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.3013196, Training accuracy: 0.5420149, Time: 06_05_2022__06:21:44\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.3008160, Training accuracy: 0.5419118, Time: 06_05_2022__06:22:03\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.2994404, Training accuracy: 0.5427174, Time: 06_05_2022__06:22:23\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.2977837, Training accuracy: 0.5433214, Time: 06_05_2022__06:22:43\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.2968961, Training accuracy: 0.5438028, Time: 06_05_2022__06:23:03\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.2947860, Training accuracy: 0.5445833, Time: 06_05_2022__06:23:22\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.2935229, Training accuracy: 0.5451712, Time: 06_05_2022__06:23:42\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.2922741, Training accuracy: 0.5454730, Time: 06_05_2022__06:24:02\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.2901730, Training accuracy: 0.5463000, Time: 06_05_2022__06:24:22\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.2887400, Training accuracy: 0.5472697, Time: 06_05_2022__06:24:41\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.2875556, Training accuracy: 0.5473052, Time: 06_05_2022__06:25:01\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.2849728, Training accuracy: 0.5481090, Time: 06_05_2022__06:25:21\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.2826469, Training accuracy: 0.5489557, Time: 06_05_2022__06:25:41\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.2811633, Training accuracy: 0.5495625, Time: 06_05_2022__06:26:00\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.2802970, Training accuracy: 0.5496605, Time: 06_05_2022__06:26:20\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.2801828, Training accuracy: 0.5499695, Time: 06_05_2022__06:26:40\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.2773263, Training accuracy: 0.5509639, Time: 06_05_2022__06:27:00\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.2769883, Training accuracy: 0.5513095, Time: 06_05_2022__06:27:19\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.2762032, Training accuracy: 0.5516471, Time: 06_05_2022__06:27:39\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.2746263, Training accuracy: 0.5522093, Time: 06_05_2022__06:27:59\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.2730259, Training accuracy: 0.5526437, Time: 06_05_2022__06:28:18\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.2699377, Training accuracy: 0.5537216, Time: 06_05_2022__06:28:38\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 1.2672667, Training accuracy: 0.5544944, Time: 06_05_2022__06:28:58\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 1.2645568, Training accuracy: 0.5555000, Time: 06_05_2022__06:29:18\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 1.2637069, Training accuracy: 0.5559890, Time: 06_05_2022__06:29:37\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 1.2619484, Training accuracy: 0.5565761, Time: 06_05_2022__06:29:57\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 1.2610035, Training accuracy: 0.5570699, Time: 06_05_2022__06:30:17\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 1.2597846, Training accuracy: 0.5575000, Time: 06_05_2022__06:30:37\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 1.2597155, Training accuracy: 0.5577105, Time: 06_05_2022__06:30:56\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 1.2572697, Training accuracy: 0.5586979, Time: 06_05_2022__06:31:16\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 1.2549323, Training accuracy: 0.5592784, Time: 06_05_2022__06:31:36\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 1.2530122, Training accuracy: 0.5599745, Time: 06_05_2022__06:31:56\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 1.2518716, Training accuracy: 0.5604040, Time: 06_05_2022__06:32:15\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 1.2509010, Training accuracy: 0.5607500, Time: 06_05_2022__06:32:35\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 1.2504582, Training accuracy: 0.5607921, Time: 06_05_2022__06:32:55\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 1.2487092, Training accuracy: 0.5613480, Time: 06_05_2022__06:33:15\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 1.2463721, Training accuracy: 0.5621845, Time: 06_05_2022__06:33:34\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 1.2450303, Training accuracy: 0.5625962, Time: 06_05_2022__06:33:54\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 1.2435192, Training accuracy: 0.5631429, Time: 06_05_2022__06:34:14\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 1.2421601, Training accuracy: 0.5638915, Time: 06_05_2022__06:34:33\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 1.2402970, Training accuracy: 0.5646495, Time: 06_05_2022__06:34:53\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 1.2392591, Training accuracy: 0.5650231, Time: 06_05_2022__06:35:13\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 1.2384031, Training accuracy: 0.5653440, Time: 06_05_2022__06:35:33\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 1.2371882, Training accuracy: 0.5659318, Time: 06_05_2022__06:35:52\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 1.2349890, Training accuracy: 0.5668018, Time: 06_05_2022__06:36:12\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 1.2337230, Training accuracy: 0.5672321, Time: 06_05_2022__06:36:32\n","Epoch 3 of 5, Average training loss: 1.2335966, Average training accuracy: 0.5672222, Time: 06_05_2022__06:36:42\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41a8a0d9d8704760a0f3ca79be005b37"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.9166435, Validation accuracy: 0.6850000, Time: 06_05_2022__06:36:47 | Loss decreased from 1.2813759 to 0.9144011 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.9501135, Validation accuracy: 0.6637500, Time: 06_05_2022__06:36:55\n","Step: 300 of 1250, Validation loss: 0.9623112, Validation accuracy: 0.6600000, Time: 06_05_2022__06:37:00\n","Step: 400 of 1250, Validation loss: 0.9747033, Validation accuracy: 0.6637500, Time: 06_05_2022__06:37:05\n","Step: 500 of 1250, Validation loss: 0.9949992, Validation accuracy: 0.6580000, Time: 06_05_2022__06:37:10\n","Step: 600 of 1250, Validation loss: 0.9813344, Validation accuracy: 0.6608333, Time: 06_05_2022__06:37:15\n","Step: 700 of 1250, Validation loss: 0.9740717, Validation accuracy: 0.6603571, Time: 06_05_2022__06:37:21\n","Step: 800 of 1250, Validation loss: 0.9601403, Validation accuracy: 0.6665625, Time: 06_05_2022__06:37:26\n","Step: 900 of 1250, Validation loss: 0.9634312, Validation accuracy: 0.6658333, Time: 06_05_2022__06:37:31\n","Step: 1000 of 1250, Validation loss: 0.9658157, Validation accuracy: 0.6637500, Time: 06_05_2022__06:37:36\n","Step: 1100 of 1250, Validation loss: 0.9691664, Validation accuracy: 0.6647727, Time: 06_05_2022__06:37:41\n","Step: 1200 of 1250, Validation loss: 0.9767792, Validation accuracy: 0.6616667, Time: 06_05_2022__06:37:46\n","Average validation loss: 0.9742367, Average validation accuracy: 0.6610000, Time: 06_05_2022__06:37:49\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eac89e0900804c02bc408652a0498449"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 0.9753030, Training accuracy: 0.6650000, Time: 06_05_2022__06:38:09\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 1.0066472, Training accuracy: 0.6437500, Time: 06_05_2022__06:38:29\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 1.0399117, Training accuracy: 0.6325000, Time: 06_05_2022__06:38:48\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 1.0343697, Training accuracy: 0.6331250, Time: 06_05_2022__06:39:08\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 1.0384630, Training accuracy: 0.6350000, Time: 06_05_2022__06:39:28\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 1.0397192, Training accuracy: 0.6337500, Time: 06_05_2022__06:39:48\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 1.0529996, Training accuracy: 0.6289286, Time: 06_05_2022__06:40:07\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 1.0487896, Training accuracy: 0.6337500, Time: 06_05_2022__06:40:27\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 1.0482687, Training accuracy: 0.6322222, Time: 06_05_2022__06:40:47\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 1.0399406, Training accuracy: 0.6350000, Time: 06_05_2022__06:41:07\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 1.0413190, Training accuracy: 0.6338636, Time: 06_05_2022__06:41:26\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 1.0404003, Training accuracy: 0.6343750, Time: 06_05_2022__06:41:46\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 1.0425468, Training accuracy: 0.6321154, Time: 06_05_2022__06:42:06\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 1.0473193, Training accuracy: 0.6312500, Time: 06_05_2022__06:42:26\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 1.0485856, Training accuracy: 0.6291667, Time: 06_05_2022__06:42:45\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 1.0452599, Training accuracy: 0.6298438, Time: 06_05_2022__06:43:05\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 1.0463767, Training accuracy: 0.6297059, Time: 06_05_2022__06:43:25\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 1.0525888, Training accuracy: 0.6286111, Time: 06_05_2022__06:43:45\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 1.0460683, Training accuracy: 0.6306579, Time: 06_05_2022__06:44:04\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 1.0475325, Training accuracy: 0.6297500, Time: 06_05_2022__06:44:24\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 1.0413313, Training accuracy: 0.6330952, Time: 06_05_2022__06:44:44\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 1.0388714, Training accuracy: 0.6343182, Time: 06_05_2022__06:45:04\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 1.0412306, Training accuracy: 0.6347826, Time: 06_05_2022__06:45:23\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 1.0373235, Training accuracy: 0.6348958, Time: 06_05_2022__06:45:43\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 1.0357682, Training accuracy: 0.6350000, Time: 06_05_2022__06:46:03\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 1.0350225, Training accuracy: 0.6355769, Time: 06_05_2022__06:46:23\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 1.0316592, Training accuracy: 0.6368519, Time: 06_05_2022__06:46:42\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 1.0280592, Training accuracy: 0.6383036, Time: 06_05_2022__06:47:02\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 1.0260682, Training accuracy: 0.6388793, Time: 06_05_2022__06:47:22\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 1.0281603, Training accuracy: 0.6385833, Time: 06_05_2022__06:47:42\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 1.0233891, Training accuracy: 0.6399194, Time: 06_05_2022__06:48:01\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 1.0207339, Training accuracy: 0.6414062, Time: 06_05_2022__06:48:21\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 1.0213638, Training accuracy: 0.6403788, Time: 06_05_2022__06:48:41\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 1.0201252, Training accuracy: 0.6408824, Time: 06_05_2022__06:49:01\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 1.0184724, Training accuracy: 0.6417857, Time: 06_05_2022__06:49:20\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 1.0184758, Training accuracy: 0.6413889, Time: 06_05_2022__06:49:40\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 1.0177945, Training accuracy: 0.6410135, Time: 06_05_2022__06:50:00\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 1.0164220, Training accuracy: 0.6411184, Time: 06_05_2022__06:50:20\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 1.0160144, Training accuracy: 0.6413462, Time: 06_05_2022__06:50:39\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 1.0143826, Training accuracy: 0.6417500, Time: 06_05_2022__06:50:59\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 1.0162998, Training accuracy: 0.6412805, Time: 06_05_2022__06:51:19\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 1.0129055, Training accuracy: 0.6425595, Time: 06_05_2022__06:51:39\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 1.0114163, Training accuracy: 0.6435465, Time: 06_05_2022__06:51:58\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 1.0106106, Training accuracy: 0.6436364, Time: 06_05_2022__06:52:18\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 1.0101476, Training accuracy: 0.6441667, Time: 06_05_2022__06:52:38\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 1.0098496, Training accuracy: 0.6442391, Time: 06_05_2022__06:52:58\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 1.0085165, Training accuracy: 0.6444681, Time: 06_05_2022__06:53:17\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 1.0078858, Training accuracy: 0.6446875, Time: 06_05_2022__06:53:37\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 1.0082010, Training accuracy: 0.6444898, Time: 06_05_2022__06:53:57\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 1.0071278, Training accuracy: 0.6448000, Time: 06_05_2022__06:54:17\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 1.0055542, Training accuracy: 0.6454902, Time: 06_05_2022__06:54:36\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 1.0064678, Training accuracy: 0.6448558, Time: 06_05_2022__06:54:56\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 1.0055246, Training accuracy: 0.6450472, Time: 06_05_2022__06:55:16\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 1.0053133, Training accuracy: 0.6453704, Time: 06_05_2022__06:55:36\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 1.0053595, Training accuracy: 0.6457273, Time: 06_05_2022__06:55:55\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 1.0041056, Training accuracy: 0.6461161, Time: 06_05_2022__06:56:15\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 1.0029180, Training accuracy: 0.6463158, Time: 06_05_2022__06:56:35\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 1.0032353, Training accuracy: 0.6461638, Time: 06_05_2022__06:56:55\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 1.0038201, Training accuracy: 0.6464407, Time: 06_05_2022__06:57:15\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 1.0029821, Training accuracy: 0.6470833, Time: 06_05_2022__06:57:34\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 1.0028705, Training accuracy: 0.6473770, Time: 06_05_2022__06:57:54\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 1.0011403, Training accuracy: 0.6480242, Time: 06_05_2022__06:58:14\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 1.0013168, Training accuracy: 0.6480159, Time: 06_05_2022__06:58:34\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 0.9998811, Training accuracy: 0.6483984, Time: 06_05_2022__06:58:53\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 0.9990078, Training accuracy: 0.6489231, Time: 06_05_2022__06:59:13\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 0.9978156, Training accuracy: 0.6492803, Time: 06_05_2022__06:59:33\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 0.9954892, Training accuracy: 0.6501119, Time: 06_05_2022__06:59:53\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 0.9955333, Training accuracy: 0.6500368, Time: 06_05_2022__07:00:12\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 0.9948128, Training accuracy: 0.6505797, Time: 06_05_2022__07:00:32\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 0.9927668, Training accuracy: 0.6516786, Time: 06_05_2022__07:00:52\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 0.9923466, Training accuracy: 0.6517254, Time: 06_05_2022__07:01:12\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 0.9911991, Training accuracy: 0.6520486, Time: 06_05_2022__07:01:31\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 0.9906376, Training accuracy: 0.6520890, Time: 06_05_2022__07:01:51\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 0.9900418, Training accuracy: 0.6522635, Time: 06_05_2022__07:02:11\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 0.9883856, Training accuracy: 0.6528000, Time: 06_05_2022__07:02:31\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 0.9865060, Training accuracy: 0.6536842, Time: 06_05_2022__07:02:50\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 0.9864882, Training accuracy: 0.6535065, Time: 06_05_2022__07:03:10\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 0.9853519, Training accuracy: 0.6538782, Time: 06_05_2022__07:03:30\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 0.9836078, Training accuracy: 0.6546519, Time: 06_05_2022__07:03:50\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 0.9827657, Training accuracy: 0.6547500, Time: 06_05_2022__07:04:09\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 0.9828931, Training accuracy: 0.6549383, Time: 06_05_2022__07:04:29\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 0.9828357, Training accuracy: 0.6551829, Time: 06_05_2022__07:04:49\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 0.9820403, Training accuracy: 0.6554217, Time: 06_05_2022__07:05:09\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 0.9824523, Training accuracy: 0.6550298, Time: 06_05_2022__07:05:28\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 0.9815927, Training accuracy: 0.6552353, Time: 06_05_2022__07:05:48\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 0.9808948, Training accuracy: 0.6555814, Time: 06_05_2022__07:06:08\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 0.9802017, Training accuracy: 0.6560057, Time: 06_05_2022__07:06:28\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 0.9790746, Training accuracy: 0.6565341, Time: 06_05_2022__07:06:47\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 0.9770425, Training accuracy: 0.6571067, Time: 06_05_2022__07:07:07\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 0.9760537, Training accuracy: 0.6575000, Time: 06_05_2022__07:07:27\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 0.9750850, Training accuracy: 0.6576923, Time: 06_05_2022__07:07:47\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 0.9737673, Training accuracy: 0.6579620, Time: 06_05_2022__07:08:06\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 0.9737847, Training accuracy: 0.6579839, Time: 06_05_2022__07:08:26\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 0.9734736, Training accuracy: 0.6578191, Time: 06_05_2022__07:08:46\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 0.9736324, Training accuracy: 0.6580000, Time: 06_05_2022__07:09:06\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 0.9721599, Training accuracy: 0.6583073, Time: 06_05_2022__07:09:26\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 0.9697759, Training accuracy: 0.6592784, Time: 06_05_2022__07:09:45\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 0.9685675, Training accuracy: 0.6597959, Time: 06_05_2022__07:10:05\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 0.9681111, Training accuracy: 0.6599495, Time: 06_05_2022__07:10:25\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 0.9678104, Training accuracy: 0.6603000, Time: 06_05_2022__07:10:45\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 0.9677036, Training accuracy: 0.6604208, Time: 06_05_2022__07:11:04\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 0.9667773, Training accuracy: 0.6607353, Time: 06_05_2022__07:11:24\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 0.9655554, Training accuracy: 0.6611650, Time: 06_05_2022__07:11:44\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 0.9644474, Training accuracy: 0.6614663, Time: 06_05_2022__07:12:04\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 0.9631424, Training accuracy: 0.6620238, Time: 06_05_2022__07:12:23\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 0.9624738, Training accuracy: 0.6624292, Time: 06_05_2022__07:12:43\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 0.9610344, Training accuracy: 0.6630140, Time: 06_05_2022__07:13:03\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 0.9608924, Training accuracy: 0.6631944, Time: 06_05_2022__07:13:23\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 0.9608925, Training accuracy: 0.6632110, Time: 06_05_2022__07:13:42\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 0.9599856, Training accuracy: 0.6634773, Time: 06_05_2022__07:14:02\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 0.9588514, Training accuracy: 0.6640766, Time: 06_05_2022__07:14:22\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 0.9581185, Training accuracy: 0.6643973, Time: 06_05_2022__07:14:42\n","Epoch 4 of 5, Average training loss: 0.9585010, Average training accuracy: 0.6643333, Time: 06_05_2022__07:14:52\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2321405a822b40ecb897a06c7d442255"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.7969939, Validation accuracy: 0.7150000, Time: 06_05_2022__07:14:57 | Loss decreased from 0.9144011 to 0.7973723 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.8037708, Validation accuracy: 0.7125000, Time: 06_05_2022__07:15:05\n","Step: 300 of 1250, Validation loss: 0.8342769, Validation accuracy: 0.7075000, Time: 06_05_2022__07:15:10\n","Step: 400 of 1250, Validation loss: 0.8274387, Validation accuracy: 0.7156250, Time: 06_05_2022__07:15:15\n","Step: 500 of 1250, Validation loss: 0.8373284, Validation accuracy: 0.7045000, Time: 06_05_2022__07:15:21\n","Step: 600 of 1250, Validation loss: 0.8202777, Validation accuracy: 0.7108333, Time: 06_05_2022__07:15:26\n","Step: 700 of 1250, Validation loss: 0.8143863, Validation accuracy: 0.7110714, Time: 06_05_2022__07:15:31\n","Step: 800 of 1250, Validation loss: 0.7998506, Validation accuracy: 0.7171875, Time: 06_05_2022__07:15:36\n","Step: 900 of 1250, Validation loss: 0.8064684, Validation accuracy: 0.7138889, Time: 06_05_2022__07:15:41\n","Step: 1000 of 1250, Validation loss: 0.8065930, Validation accuracy: 0.7150000, Time: 06_05_2022__07:15:46\n","Step: 1100 of 1250, Validation loss: 0.8063401, Validation accuracy: 0.7172727, Time: 06_05_2022__07:15:52\n","Step: 1200 of 1250, Validation loss: 0.8084990, Validation accuracy: 0.7160417, Time: 06_05_2022__07:15:57\n","Average validation loss: 0.8081206, Average validation accuracy: 0.7166000, Time: 06_05_2022__07:15:59\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd718da822db4af08781b58991fc5ad9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 0.7828265, Training accuracy: 0.7375000, Time: 06_05_2022__07:16:19\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 0.8078837, Training accuracy: 0.7300000, Time: 06_05_2022__07:16:39\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 0.8411597, Training accuracy: 0.7125000, Time: 06_05_2022__07:16:59\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 0.8230562, Training accuracy: 0.7168750, Time: 06_05_2022__07:17:18\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 0.8399950, Training accuracy: 0.7050000, Time: 06_05_2022__07:17:38\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 0.8363373, Training accuracy: 0.7091667, Time: 06_05_2022__07:17:58\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 0.8419514, Training accuracy: 0.7064286, Time: 06_05_2022__07:18:18\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 0.8304208, Training accuracy: 0.7090625, Time: 06_05_2022__07:18:38\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 0.8342554, Training accuracy: 0.7097222, Time: 06_05_2022__07:18:57\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 0.8273721, Training accuracy: 0.7112500, Time: 06_05_2022__07:19:17\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 0.8320709, Training accuracy: 0.7118182, Time: 06_05_2022__07:19:37\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 0.8370399, Training accuracy: 0.7089583, Time: 06_05_2022__07:19:57\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 0.8382015, Training accuracy: 0.7082692, Time: 06_05_2022__07:20:16\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 0.8398792, Training accuracy: 0.7091071, Time: 06_05_2022__07:20:36\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 0.8422992, Training accuracy: 0.7088333, Time: 06_05_2022__07:20:56\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 0.8377112, Training accuracy: 0.7103125, Time: 06_05_2022__07:21:16\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 0.8385874, Training accuracy: 0.7104412, Time: 06_05_2022__07:21:36\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 0.8446132, Training accuracy: 0.7077778, Time: 06_05_2022__07:21:56\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 0.8406771, Training accuracy: 0.7088158, Time: 06_05_2022__07:22:15\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 0.8405465, Training accuracy: 0.7085000, Time: 06_05_2022__07:22:35\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 0.8374367, Training accuracy: 0.7090476, Time: 06_05_2022__07:22:55\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 0.8336669, Training accuracy: 0.7102273, Time: 06_05_2022__07:23:15\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 0.8314202, Training accuracy: 0.7103261, Time: 06_05_2022__07:23:35\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 0.8307926, Training accuracy: 0.7100000, Time: 06_05_2022__07:23:54\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 0.8289424, Training accuracy: 0.7096000, Time: 06_05_2022__07:24:14\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 0.8277516, Training accuracy: 0.7096154, Time: 06_05_2022__07:24:34\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 0.8268426, Training accuracy: 0.7094444, Time: 06_05_2022__07:24:54\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 0.8251889, Training accuracy: 0.7098214, Time: 06_05_2022__07:25:13\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 0.8227521, Training accuracy: 0.7106897, Time: 06_05_2022__07:25:33\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 0.8217644, Training accuracy: 0.7107500, Time: 06_05_2022__07:25:53\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 0.8216094, Training accuracy: 0.7101613, Time: 06_05_2022__07:26:13\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 0.8175496, Training accuracy: 0.7115625, Time: 06_05_2022__07:26:32\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 0.8204247, Training accuracy: 0.7102273, Time: 06_05_2022__07:26:52\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 0.8190898, Training accuracy: 0.7111765, Time: 06_05_2022__07:27:12\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 0.8174141, Training accuracy: 0.7116429, Time: 06_05_2022__07:27:32\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 0.8186591, Training accuracy: 0.7111111, Time: 06_05_2022__07:27:52\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 0.8174896, Training accuracy: 0.7115541, Time: 06_05_2022__07:28:11\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 0.8150615, Training accuracy: 0.7121711, Time: 06_05_2022__07:28:31\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 0.8154282, Training accuracy: 0.7116667, Time: 06_05_2022__07:28:51\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 0.8134790, Training accuracy: 0.7118750, Time: 06_05_2022__07:29:11\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 0.8161236, Training accuracy: 0.7120122, Time: 06_05_2022__07:29:30\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 0.8145956, Training accuracy: 0.7126786, Time: 06_05_2022__07:29:50\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 0.8141017, Training accuracy: 0.7127326, Time: 06_05_2022__07:30:10\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 0.8129781, Training accuracy: 0.7135795, Time: 06_05_2022__07:30:30\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 0.8131662, Training accuracy: 0.7137222, Time: 06_05_2022__07:30:50\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 0.8129200, Training accuracy: 0.7138043, Time: 06_05_2022__07:31:09\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 0.8126100, Training accuracy: 0.7140957, Time: 06_05_2022__07:31:29\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 0.8127249, Training accuracy: 0.7138542, Time: 06_05_2022__07:31:49\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 0.8111899, Training accuracy: 0.7140306, Time: 06_05_2022__07:32:09\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 0.8112711, Training accuracy: 0.7138500, Time: 06_05_2022__07:32:29\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 0.8105102, Training accuracy: 0.7139706, Time: 06_05_2022__07:32:48\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 0.8104618, Training accuracy: 0.7139904, Time: 06_05_2022__07:33:08\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 0.8103499, Training accuracy: 0.7140094, Time: 06_05_2022__07:33:28\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 0.8100597, Training accuracy: 0.7142130, Time: 06_05_2022__07:33:48\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 0.8105128, Training accuracy: 0.7143182, Time: 06_05_2022__07:34:07\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 0.8092144, Training accuracy: 0.7151339, Time: 06_05_2022__07:34:27\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 0.8085565, Training accuracy: 0.7154825, Time: 06_05_2022__07:34:47\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 0.8085989, Training accuracy: 0.7152586, Time: 06_05_2022__07:35:07\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 0.8095594, Training accuracy: 0.7152966, Time: 06_05_2022__07:35:27\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 0.8099950, Training accuracy: 0.7152917, Time: 06_05_2022__07:35:46\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 0.8086525, Training accuracy: 0.7159426, Time: 06_05_2022__07:36:06\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 0.8073740, Training accuracy: 0.7161290, Time: 06_05_2022__07:36:26\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 0.8067620, Training accuracy: 0.7163889, Time: 06_05_2022__07:36:46\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 0.8070304, Training accuracy: 0.7163672, Time: 06_05_2022__07:37:06\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 0.8067592, Training accuracy: 0.7164615, Time: 06_05_2022__07:37:25\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 0.8059753, Training accuracy: 0.7168561, Time: 06_05_2022__07:37:45\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 0.8057262, Training accuracy: 0.7171269, Time: 06_05_2022__07:38:05\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 0.8063826, Training accuracy: 0.7168382, Time: 06_05_2022__07:38:25\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 0.8048451, Training accuracy: 0.7173551, Time: 06_05_2022__07:38:44\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 0.8040001, Training accuracy: 0.7176786, Time: 06_05_2022__07:39:04\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 0.8038145, Training accuracy: 0.7176761, Time: 06_05_2022__07:39:24\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 0.8019690, Training accuracy: 0.7182986, Time: 06_05_2022__07:39:44\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 0.8027126, Training accuracy: 0.7182192, Time: 06_05_2022__07:40:04\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 0.8012922, Training accuracy: 0.7188176, Time: 06_05_2022__07:40:23\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 0.8002074, Training accuracy: 0.7193333, Time: 06_05_2022__07:40:43\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 0.7985746, Training accuracy: 0.7199013, Time: 06_05_2022__07:41:03\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 0.7980900, Training accuracy: 0.7201299, Time: 06_05_2022__07:41:23\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 0.7975824, Training accuracy: 0.7203205, Time: 06_05_2022__07:41:43\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 0.7957603, Training accuracy: 0.7212658, Time: 06_05_2022__07:42:02\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 0.7954828, Training accuracy: 0.7215000, Time: 06_05_2022__07:42:22\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 0.7959285, Training accuracy: 0.7213272, Time: 06_05_2022__07:42:42\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 0.7966002, Training accuracy: 0.7212805, Time: 06_05_2022__07:43:02\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 0.7960636, Training accuracy: 0.7214157, Time: 06_05_2022__07:43:21\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 0.7966440, Training accuracy: 0.7212798, Time: 06_05_2022__07:43:41\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 0.7959655, Training accuracy: 0.7213529, Time: 06_05_2022__07:44:01\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 0.7950957, Training accuracy: 0.7215407, Time: 06_05_2022__07:44:21\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 0.7954883, Training accuracy: 0.7213218, Time: 06_05_2022__07:44:40\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 0.7935335, Training accuracy: 0.7223580, Time: 06_05_2022__07:45:00\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 0.7917559, Training accuracy: 0.7229775, Time: 06_05_2022__07:45:20\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 0.7909290, Training accuracy: 0.7234167, Time: 06_05_2022__07:45:40\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 0.7906107, Training accuracy: 0.7237088, Time: 06_05_2022__07:45:59\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 0.7895097, Training accuracy: 0.7241848, Time: 06_05_2022__07:46:19\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 0.7899097, Training accuracy: 0.7241935, Time: 06_05_2022__07:46:39\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 0.7897149, Training accuracy: 0.7244415, Time: 06_05_2022__07:46:59\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 0.7905995, Training accuracy: 0.7242105, Time: 06_05_2022__07:47:18\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 0.7901154, Training accuracy: 0.7244010, Time: 06_05_2022__07:47:38\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 0.7881069, Training accuracy: 0.7253866, Time: 06_05_2022__07:47:58\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 0.7865874, Training accuracy: 0.7258163, Time: 06_05_2022__07:48:18\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 0.7859716, Training accuracy: 0.7257071, Time: 06_05_2022__07:48:38\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 0.7858951, Training accuracy: 0.7259750, Time: 06_05_2022__07:48:57\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 0.7858573, Training accuracy: 0.7258663, Time: 06_05_2022__07:49:17\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 0.7856676, Training accuracy: 0.7259559, Time: 06_05_2022__07:49:37\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 0.7848010, Training accuracy: 0.7262621, Time: 06_05_2022__07:49:57\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 0.7843301, Training accuracy: 0.7266106, Time: 06_05_2022__07:50:16\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 0.7836066, Training accuracy: 0.7271667, Time: 06_05_2022__07:50:36\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 0.7830724, Training accuracy: 0.7272877, Time: 06_05_2022__07:50:56\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 0.7813213, Training accuracy: 0.7278271, Time: 06_05_2022__07:51:16\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 0.7811304, Training accuracy: 0.7278241, Time: 06_05_2022__07:51:36\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 0.7813408, Training accuracy: 0.7279817, Time: 06_05_2022__07:51:56\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 0.7809433, Training accuracy: 0.7279545, Time: 06_05_2022__07:52:15\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 0.7801785, Training accuracy: 0.7283784, Time: 06_05_2022__07:52:35\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 0.7796551, Training accuracy: 0.7285938, Time: 06_05_2022__07:52:55\n","Epoch 5 of 5, Average training loss: 0.7797993, Average training accuracy: 0.7284889, Time: 06_05_2022__07:53:05\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cba68c496cdf460a830204432d07c94e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.7220016, Validation accuracy: 0.7575000, Time: 06_05_2022__07:53:10 | Loss decreased from 0.7973723 to 0.7265385 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.7273611, Validation accuracy: 0.7512500, Time: 06_05_2022__07:53:17\n","Step: 300 of 1250, Validation loss: 0.7399369, Validation accuracy: 0.7466667, Time: 06_05_2022__07:53:23\n","Step: 400 of 1250, Validation loss: 0.7303898, Validation accuracy: 0.7537500, Time: 06_05_2022__07:53:28\n","Step: 500 of 1250, Validation loss: 0.7489315, Validation accuracy: 0.7500000, Time: 06_05_2022__07:53:33\n","Step: 600 of 1250, Validation loss: 0.7390730, Validation accuracy: 0.7495833, Time: 06_05_2022__07:53:38\n","Step: 700 of 1250, Validation loss: 0.7391697, Validation accuracy: 0.7517857, Time: 06_05_2022__07:53:43\n","Step: 800 of 1250, Validation loss: 0.7288703, Validation accuracy: 0.7521875, Time: 06_05_2022__07:53:49\n","Step: 900 of 1250, Validation loss: 0.7318458, Validation accuracy: 0.7538889, Time: 06_05_2022__07:53:54\n","Step: 1000 of 1250, Validation loss: 0.7316825, Validation accuracy: 0.7535000, Time: 06_05_2022__07:53:59\n","Step: 1100 of 1250, Validation loss: 0.7316321, Validation accuracy: 0.7543182, Time: 06_05_2022__07:54:04\n","Step: 1200 of 1250, Validation loss: 0.7379858, Validation accuracy: 0.7531250, Time: 06_05_2022__07:54:09\n","Average validation loss: 0.7366305, Average validation accuracy: 0.7530000, Time: 06_05_2022__07:54:12\n","###################### Testing vgg19_batch_norm SGD, lr_0.1, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c71a97e2f3c84c73a6dec545dd454c48"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.7550000, Time: 06_05_2022__07:54:30\n","Step: 200 of 2500, Test accuracy: 0.7475000, Time: 06_05_2022__07:54:36\n","Step: 300 of 2500, Test accuracy: 0.7533333, Time: 06_05_2022__07:54:41\n","Step: 400 of 2500, Test accuracy: 0.7525000, Time: 06_05_2022__07:54:46\n","Step: 500 of 2500, Test accuracy: 0.7405000, Time: 06_05_2022__07:54:51\n","Step: 600 of 2500, Test accuracy: 0.7391667, Time: 06_05_2022__07:54:57\n","Step: 700 of 2500, Test accuracy: 0.7396429, Time: 06_05_2022__07:55:02\n","Step: 800 of 2500, Test accuracy: 0.7465625, Time: 06_05_2022__07:55:07\n","Step: 900 of 2500, Test accuracy: 0.7436111, Time: 06_05_2022__07:55:13\n","Step: 1000 of 2500, Test accuracy: 0.7452500, Time: 06_05_2022__07:55:18\n","Step: 1100 of 2500, Test accuracy: 0.7475000, Time: 06_05_2022__07:55:23\n","Step: 1200 of 2500, Test accuracy: 0.7481250, Time: 06_05_2022__07:55:28\n","Step: 1300 of 2500, Test accuracy: 0.7513462, Time: 06_05_2022__07:55:33\n","Step: 1400 of 2500, Test accuracy: 0.7526786, Time: 06_05_2022__07:55:39\n","Step: 1500 of 2500, Test accuracy: 0.7521667, Time: 06_05_2022__07:55:44\n","Step: 1600 of 2500, Test accuracy: 0.7532813, Time: 06_05_2022__07:55:49\n","Step: 1700 of 2500, Test accuracy: 0.7529412, Time: 06_05_2022__07:55:54\n","Step: 1800 of 2500, Test accuracy: 0.7520833, Time: 06_05_2022__07:55:59\n","Step: 1900 of 2500, Test accuracy: 0.7526316, Time: 06_05_2022__07:56:05\n","Step: 2000 of 2500, Test accuracy: 0.7512500, Time: 06_05_2022__07:56:10\n","Step: 2100 of 2500, Test accuracy: 0.7504762, Time: 06_05_2022__07:56:15\n","Step: 2200 of 2500, Test accuracy: 0.7498864, Time: 06_05_2022__07:56:20\n","Step: 2300 of 2500, Test accuracy: 0.7514130, Time: 06_05_2022__07:56:25\n","Step: 2400 of 2500, Test accuracy: 0.7518750, Time: 06_05_2022__07:56:31\n","Step: 2500 of 2500, Test accuracy: 0.7504000, Time: 06_05_2022__07:56:36\n","Average testing accuracy: 0.7504000, Time: 06_05_2022__07:56:36\n","###################### Training vgg19_batch_norm SGD, lr_0.1, momentum_0.3 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af0aa3b381ab4c25b1d91be80b7c9fd4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 7.6194797, Training accuracy: 0.1000000, Time: 06_05_2022__07:56:59\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 4.9901232, Training accuracy: 0.1025000, Time: 06_05_2022__07:57:19\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 4.1011599, Training accuracy: 0.1025000, Time: 06_05_2022__07:57:40\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 3.6538819, Training accuracy: 0.1043750, Time: 06_05_2022__07:58:01\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 3.3812376, Training accuracy: 0.1095000, Time: 06_05_2022__07:58:22\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 3.2017860, Training accuracy: 0.1133333, Time: 06_05_2022__07:58:42\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 3.0718165, Training accuracy: 0.1171429, Time: 06_05_2022__07:59:03\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.9750640, Training accuracy: 0.1178125, Time: 06_05_2022__07:59:24\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.8973561, Training accuracy: 0.1205556, Time: 06_05_2022__07:59:45\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.8371559, Training accuracy: 0.1190000, Time: 06_05_2022__08:00:05\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.7873716, Training accuracy: 0.1193182, Time: 06_05_2022__08:00:26\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.7450238, Training accuracy: 0.1212500, Time: 06_05_2022__08:00:47\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.7092497, Training accuracy: 0.1232692, Time: 06_05_2022__08:01:08\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.6771428, Training accuracy: 0.1237500, Time: 06_05_2022__08:01:28\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.6516407, Training accuracy: 0.1260000, Time: 06_05_2022__08:01:49\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.6289814, Training accuracy: 0.1256250, Time: 06_05_2022__08:02:10\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.6085787, Training accuracy: 0.1258824, Time: 06_05_2022__08:02:30\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.5895238, Training accuracy: 0.1269444, Time: 06_05_2022__08:02:51\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.5731357, Training accuracy: 0.1278947, Time: 06_05_2022__08:03:12\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.5582593, Training accuracy: 0.1272500, Time: 06_05_2022__08:03:33\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.5442341, Training accuracy: 0.1296429, Time: 06_05_2022__08:03:53\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.5323115, Training accuracy: 0.1293182, Time: 06_05_2022__08:04:14\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.5201795, Training accuracy: 0.1315217, Time: 06_05_2022__08:04:35\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.5104093, Training accuracy: 0.1326042, Time: 06_05_2022__08:04:56\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.5003615, Training accuracy: 0.1336000, Time: 06_05_2022__08:05:16\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.4905211, Training accuracy: 0.1344231, Time: 06_05_2022__08:05:37\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.4824537, Training accuracy: 0.1337037, Time: 06_05_2022__08:05:58\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.4749868, Training accuracy: 0.1331250, Time: 06_05_2022__08:06:19\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.4679780, Training accuracy: 0.1331034, Time: 06_05_2022__08:06:39\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.4614455, Training accuracy: 0.1328333, Time: 06_05_2022__08:07:00\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.4532132, Training accuracy: 0.1345161, Time: 06_05_2022__08:07:21\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.4463637, Training accuracy: 0.1357031, Time: 06_05_2022__08:07:42\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.4408265, Training accuracy: 0.1365909, Time: 06_05_2022__08:08:02\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.4353385, Training accuracy: 0.1369853, Time: 06_05_2022__08:08:23\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.4297831, Training accuracy: 0.1366429, Time: 06_05_2022__08:08:44\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.4246985, Training accuracy: 0.1370833, Time: 06_05_2022__08:09:05\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.4197154, Training accuracy: 0.1379054, Time: 06_05_2022__08:09:26\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.4158202, Training accuracy: 0.1372368, Time: 06_05_2022__08:09:46\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.4114605, Training accuracy: 0.1374359, Time: 06_05_2022__08:10:07\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.4072999, Training accuracy: 0.1382500, Time: 06_05_2022__08:10:28\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.4031832, Training accuracy: 0.1384146, Time: 06_05_2022__08:10:49\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.3987711, Training accuracy: 0.1390476, Time: 06_05_2022__08:11:10\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.3953887, Training accuracy: 0.1393023, Time: 06_05_2022__08:11:30\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.3912202, Training accuracy: 0.1409659, Time: 06_05_2022__08:11:51\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.3872934, Training accuracy: 0.1414444, Time: 06_05_2022__08:12:12\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.3836508, Training accuracy: 0.1418478, Time: 06_05_2022__08:12:33\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.3793694, Training accuracy: 0.1421277, Time: 06_05_2022__08:12:54\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 2.3761376, Training accuracy: 0.1423958, Time: 06_05_2022__08:13:14\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 2.3734136, Training accuracy: 0.1426020, Time: 06_05_2022__08:13:35\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 2.3704069, Training accuracy: 0.1428000, Time: 06_05_2022__08:13:56\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 2.3667381, Training accuracy: 0.1439216, Time: 06_05_2022__08:14:17\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 2.3637699, Training accuracy: 0.1443269, Time: 06_05_2022__08:14:38\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 2.3610394, Training accuracy: 0.1449057, Time: 06_05_2022__08:14:58\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 2.3583086, Training accuracy: 0.1453704, Time: 06_05_2022__08:15:19\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 2.3550872, Training accuracy: 0.1461364, Time: 06_05_2022__08:15:40\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 2.3522819, Training accuracy: 0.1471429, Time: 06_05_2022__08:16:01\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 2.3500043, Training accuracy: 0.1476754, Time: 06_05_2022__08:16:22\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 2.3472343, Training accuracy: 0.1489655, Time: 06_05_2022__08:16:43\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 2.3442836, Training accuracy: 0.1499153, Time: 06_05_2022__08:17:03\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 2.3414383, Training accuracy: 0.1507083, Time: 06_05_2022__08:17:24\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 2.3392349, Training accuracy: 0.1510656, Time: 06_05_2022__08:17:45\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 2.3358607, Training accuracy: 0.1521371, Time: 06_05_2022__08:18:06\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 2.3327001, Training accuracy: 0.1530159, Time: 06_05_2022__08:18:27\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 2.3299271, Training accuracy: 0.1536719, Time: 06_05_2022__08:18:47\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 2.3252602, Training accuracy: 0.1550385, Time: 06_05_2022__08:19:08\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 2.3223597, Training accuracy: 0.1562879, Time: 06_05_2022__08:19:29\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 2.3189162, Training accuracy: 0.1568284, Time: 06_05_2022__08:19:50\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 2.3160920, Training accuracy: 0.1575000, Time: 06_05_2022__08:20:11\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 2.3134441, Training accuracy: 0.1580797, Time: 06_05_2022__08:20:31\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 2.3101318, Training accuracy: 0.1593214, Time: 06_05_2022__08:20:52\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 2.3074143, Training accuracy: 0.1604930, Time: 06_05_2022__08:21:13\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 2.3035401, Training accuracy: 0.1615972, Time: 06_05_2022__08:21:34\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 2.2995941, Training accuracy: 0.1630137, Time: 06_05_2022__08:21:55\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 2.2962497, Training accuracy: 0.1643243, Time: 06_05_2022__08:22:15\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 2.2931533, Training accuracy: 0.1651000, Time: 06_05_2022__08:22:36\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 2.2901963, Training accuracy: 0.1664145, Time: 06_05_2022__08:22:57\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 2.2867662, Training accuracy: 0.1678571, Time: 06_05_2022__08:23:18\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 2.2827930, Training accuracy: 0.1693269, Time: 06_05_2022__08:23:39\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 2.2793007, Training accuracy: 0.1703481, Time: 06_05_2022__08:23:59\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 2.2763816, Training accuracy: 0.1710937, Time: 06_05_2022__08:24:20\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 2.2728990, Training accuracy: 0.1723765, Time: 06_05_2022__08:24:41\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 2.2688136, Training accuracy: 0.1737195, Time: 06_05_2022__08:25:02\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 2.2647435, Training accuracy: 0.1748795, Time: 06_05_2022__08:25:23\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 2.2614147, Training accuracy: 0.1757440, Time: 06_05_2022__08:25:43\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 2.2585261, Training accuracy: 0.1766176, Time: 06_05_2022__08:26:04\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 2.2558472, Training accuracy: 0.1776744, Time: 06_05_2022__08:26:25\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 2.2524911, Training accuracy: 0.1785345, Time: 06_05_2022__08:26:46\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 2.2483802, Training accuracy: 0.1799716, Time: 06_05_2022__08:27:07\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 2.2451348, Training accuracy: 0.1810674, Time: 06_05_2022__08:27:27\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 2.2420092, Training accuracy: 0.1821111, Time: 06_05_2022__08:27:48\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 2.2395033, Training accuracy: 0.1829396, Time: 06_05_2022__08:28:09\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 2.2360730, Training accuracy: 0.1844837, Time: 06_05_2022__08:28:30\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 2.2334668, Training accuracy: 0.1852957, Time: 06_05_2022__08:28:50\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 2.2308002, Training accuracy: 0.1862234, Time: 06_05_2022__08:29:11\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 2.2286280, Training accuracy: 0.1869737, Time: 06_05_2022__08:29:32\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 2.2253786, Training accuracy: 0.1882292, Time: 06_05_2022__08:29:53\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 2.2220276, Training accuracy: 0.1894330, Time: 06_05_2022__08:30:14\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 2.2186882, Training accuracy: 0.1904847, Time: 06_05_2022__08:30:35\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 2.2162565, Training accuracy: 0.1916667, Time: 06_05_2022__08:30:55\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 2.2135503, Training accuracy: 0.1929000, Time: 06_05_2022__08:31:16\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 2.2105405, Training accuracy: 0.1942079, Time: 06_05_2022__08:31:37\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 2.2075888, Training accuracy: 0.1953186, Time: 06_05_2022__08:31:58\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 2.2050768, Training accuracy: 0.1962621, Time: 06_05_2022__08:32:19\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 2.2018254, Training accuracy: 0.1974038, Time: 06_05_2022__08:32:39\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 2.1988799, Training accuracy: 0.1982857, Time: 06_05_2022__08:33:00\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 2.1957557, Training accuracy: 0.1994104, Time: 06_05_2022__08:33:21\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 2.1927712, Training accuracy: 0.2006542, Time: 06_05_2022__08:33:42\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 2.1894784, Training accuracy: 0.2019213, Time: 06_05_2022__08:34:03\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 2.1875471, Training accuracy: 0.2026835, Time: 06_05_2022__08:34:24\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 2.1848727, Training accuracy: 0.2037500, Time: 06_05_2022__08:34:44\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 2.1814191, Training accuracy: 0.2050450, Time: 06_05_2022__08:35:05\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 2.1789278, Training accuracy: 0.2056696, Time: 06_05_2022__08:35:26\n","Epoch 1 of 5, Average training loss: 2.1778730, Average training accuracy: 0.2060667, Time: 06_05_2022__08:35:36\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7da26a14fe6345c7aa1eea98045a7647"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.7948123, Validation accuracy: 0.3475000, Time: 06_05_2022__08:35:42 | Loss decreased from inf to 1.7925866 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.7782865, Validation accuracy: 0.3587500, Time: 06_05_2022__08:35:49 | Loss decreased from 1.7925866 to 1.7784895 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.7748759, Validation accuracy: 0.3650000, Time: 06_05_2022__08:35:57 | Loss decreased from 1.7784895 to 1.7739319 .... Saving the model\n","Step: 400 of 1250, Validation loss: 1.7749744, Validation accuracy: 0.3537500, Time: 06_05_2022__08:36:04\n","Step: 500 of 1250, Validation loss: 1.7796865, Validation accuracy: 0.3600000, Time: 06_05_2022__08:36:10\n","Step: 600 of 1250, Validation loss: 1.7714130, Validation accuracy: 0.3658333, Time: 06_05_2022__08:36:15 | Loss decreased from 1.7739319 to 1.7716970 .... Saving the model\n","Step: 700 of 1250, Validation loss: 1.7699228, Validation accuracy: 0.3671429, Time: 06_05_2022__08:36:23 | Loss decreased from 1.7716970 to 1.7702247 .... Saving the model\n","Step: 800 of 1250, Validation loss: 1.7674942, Validation accuracy: 0.3706250, Time: 06_05_2022__08:36:30 | Loss decreased from 1.7702247 to 1.7681982 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.7685474, Validation accuracy: 0.3688889, Time: 06_05_2022__08:36:38\n","Step: 1000 of 1250, Validation loss: 1.7710520, Validation accuracy: 0.3672500, Time: 06_05_2022__08:36:43\n","Step: 1100 of 1250, Validation loss: 1.7719872, Validation accuracy: 0.3645455, Time: 06_05_2022__08:36:49\n","Step: 1200 of 1250, Validation loss: 1.7707370, Validation accuracy: 0.3625000, Time: 06_05_2022__08:36:54\n","Average validation loss: 1.7700437, Average validation accuracy: 0.3638000, Time: 06_05_2022__08:36:56\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2455c8f80d25403eb09eb2a35073ad04"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.7592084, Training accuracy: 0.3625000, Time: 06_05_2022__08:37:17\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.8033312, Training accuracy: 0.3450000, Time: 06_05_2022__08:37:38\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.8264709, Training accuracy: 0.3350000, Time: 06_05_2022__08:37:59\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.8429810, Training accuracy: 0.3387500, Time: 06_05_2022__08:38:20\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.8306818, Training accuracy: 0.3495000, Time: 06_05_2022__08:38:41\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.8271424, Training accuracy: 0.3500000, Time: 06_05_2022__08:39:01\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.8309678, Training accuracy: 0.3464286, Time: 06_05_2022__08:39:22\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.8245070, Training accuracy: 0.3446875, Time: 06_05_2022__08:39:43\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.8257157, Training accuracy: 0.3425000, Time: 06_05_2022__08:40:04\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.8155075, Training accuracy: 0.3477500, Time: 06_05_2022__08:40:24\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.8130230, Training accuracy: 0.3475000, Time: 06_05_2022__08:40:45\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.8134242, Training accuracy: 0.3439583, Time: 06_05_2022__08:41:06\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.8089642, Training accuracy: 0.3476923, Time: 06_05_2022__08:41:27\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.8062905, Training accuracy: 0.3480357, Time: 06_05_2022__08:41:48\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.8087768, Training accuracy: 0.3466667, Time: 06_05_2022__08:42:08\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.8076611, Training accuracy: 0.3464063, Time: 06_05_2022__08:42:29\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.8067285, Training accuracy: 0.3473529, Time: 06_05_2022__08:42:50\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.8023935, Training accuracy: 0.3470833, Time: 06_05_2022__08:43:11\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.7963698, Training accuracy: 0.3485526, Time: 06_05_2022__08:43:32\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.7953164, Training accuracy: 0.3487500, Time: 06_05_2022__08:43:52\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.7908501, Training accuracy: 0.3492857, Time: 06_05_2022__08:44:13\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.7888339, Training accuracy: 0.3492045, Time: 06_05_2022__08:44:34\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.7877763, Training accuracy: 0.3501087, Time: 06_05_2022__08:44:55\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.7851160, Training accuracy: 0.3505208, Time: 06_05_2022__08:45:16\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.7794455, Training accuracy: 0.3520000, Time: 06_05_2022__08:45:36\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.7762163, Training accuracy: 0.3538462, Time: 06_05_2022__08:45:57\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.7729542, Training accuracy: 0.3551852, Time: 06_05_2022__08:46:18\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.7727954, Training accuracy: 0.3558036, Time: 06_05_2022__08:46:39\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.7694275, Training accuracy: 0.3570690, Time: 06_05_2022__08:47:00\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.7679558, Training accuracy: 0.3580833, Time: 06_05_2022__08:47:20\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.7660336, Training accuracy: 0.3587903, Time: 06_05_2022__08:47:41\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.7619152, Training accuracy: 0.3611719, Time: 06_05_2022__08:48:02\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.7634021, Training accuracy: 0.3609848, Time: 06_05_2022__08:48:23\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.7626723, Training accuracy: 0.3605147, Time: 06_05_2022__08:48:44\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.7591927, Training accuracy: 0.3612857, Time: 06_05_2022__08:49:05\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.7587871, Training accuracy: 0.3612500, Time: 06_05_2022__08:49:25\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.7580780, Training accuracy: 0.3620946, Time: 06_05_2022__08:49:46\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.7555389, Training accuracy: 0.3632895, Time: 06_05_2022__08:50:07\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.7549986, Training accuracy: 0.3640385, Time: 06_05_2022__08:50:28\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.7527463, Training accuracy: 0.3644375, Time: 06_05_2022__08:50:48\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.7510894, Training accuracy: 0.3653659, Time: 06_05_2022__08:51:09\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.7471244, Training accuracy: 0.3668452, Time: 06_05_2022__08:51:30\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.7463222, Training accuracy: 0.3677907, Time: 06_05_2022__08:51:51\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.7427968, Training accuracy: 0.3689205, Time: 06_05_2022__08:52:12\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.7395214, Training accuracy: 0.3697778, Time: 06_05_2022__08:52:32\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.7379892, Training accuracy: 0.3707609, Time: 06_05_2022__08:52:53\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.7363585, Training accuracy: 0.3713830, Time: 06_05_2022__08:53:14\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.7354612, Training accuracy: 0.3715104, Time: 06_05_2022__08:53:35\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.7354362, Training accuracy: 0.3714286, Time: 06_05_2022__08:53:56\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.7352264, Training accuracy: 0.3719000, Time: 06_05_2022__08:54:17\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.7332780, Training accuracy: 0.3731863, Time: 06_05_2022__08:54:37\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.7332424, Training accuracy: 0.3738942, Time: 06_05_2022__08:54:58\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.7318114, Training accuracy: 0.3737264, Time: 06_05_2022__08:55:19\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.7311492, Training accuracy: 0.3747222, Time: 06_05_2022__08:55:40\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.7293515, Training accuracy: 0.3747273, Time: 06_05_2022__08:56:01\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.7287060, Training accuracy: 0.3746429, Time: 06_05_2022__08:56:21\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.7266192, Training accuracy: 0.3753947, Time: 06_05_2022__08:56:42\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.7255874, Training accuracy: 0.3753448, Time: 06_05_2022__08:57:03\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.7242460, Training accuracy: 0.3757627, Time: 06_05_2022__08:57:24\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.7223214, Training accuracy: 0.3763750, Time: 06_05_2022__08:57:45\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.7219640, Training accuracy: 0.3757787, Time: 06_05_2022__08:58:06\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.7203840, Training accuracy: 0.3762500, Time: 06_05_2022__08:58:26\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.7186348, Training accuracy: 0.3765873, Time: 06_05_2022__08:58:47\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.7171780, Training accuracy: 0.3767578, Time: 06_05_2022__08:59:08\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.7151392, Training accuracy: 0.3775000, Time: 06_05_2022__08:59:29\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.7139476, Training accuracy: 0.3774242, Time: 06_05_2022__08:59:50\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.7119608, Training accuracy: 0.3784701, Time: 06_05_2022__09:00:10\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.7114953, Training accuracy: 0.3788603, Time: 06_05_2022__09:00:31\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.7097180, Training accuracy: 0.3798188, Time: 06_05_2022__09:00:52\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.7072733, Training accuracy: 0.3807500, Time: 06_05_2022__09:01:13\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.7064221, Training accuracy: 0.3817606, Time: 06_05_2022__09:01:34\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.7045416, Training accuracy: 0.3824306, Time: 06_05_2022__09:01:54\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.7035757, Training accuracy: 0.3829452, Time: 06_05_2022__09:02:15\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.7027368, Training accuracy: 0.3833108, Time: 06_05_2022__09:02:36\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.7012196, Training accuracy: 0.3839667, Time: 06_05_2022__09:02:57\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.6997698, Training accuracy: 0.3846382, Time: 06_05_2022__09:03:18\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.6989966, Training accuracy: 0.3850974, Time: 06_05_2022__09:03:38\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.6970393, Training accuracy: 0.3858013, Time: 06_05_2022__09:03:59\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.6955278, Training accuracy: 0.3862975, Time: 06_05_2022__09:04:20\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.6946210, Training accuracy: 0.3865000, Time: 06_05_2022__09:04:41\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.6934683, Training accuracy: 0.3867593, Time: 06_05_2022__09:05:02\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.6928099, Training accuracy: 0.3871341, Time: 06_05_2022__09:05:23\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.6899833, Training accuracy: 0.3883735, Time: 06_05_2022__09:05:43\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.6890357, Training accuracy: 0.3888095, Time: 06_05_2022__09:06:04\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.6877869, Training accuracy: 0.3894706, Time: 06_05_2022__09:06:25\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.6866307, Training accuracy: 0.3897093, Time: 06_05_2022__09:06:46\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.6853012, Training accuracy: 0.3899425, Time: 06_05_2022__09:07:07\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.6829560, Training accuracy: 0.3909375, Time: 06_05_2022__09:07:28\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.6809392, Training accuracy: 0.3916573, Time: 06_05_2022__09:07:48\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.6800035, Training accuracy: 0.3916389, Time: 06_05_2022__09:08:09\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.6793056, Training accuracy: 0.3918407, Time: 06_05_2022__09:08:30\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.6767644, Training accuracy: 0.3930978, Time: 06_05_2022__09:08:51\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.6757782, Training accuracy: 0.3933602, Time: 06_05_2022__09:09:11\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.6749705, Training accuracy: 0.3936170, Time: 06_05_2022__09:09:32\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.6748797, Training accuracy: 0.3937895, Time: 06_05_2022__09:09:53\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.6725279, Training accuracy: 0.3945312, Time: 06_05_2022__09:10:14\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.6707764, Training accuracy: 0.3952320, Time: 06_05_2022__09:10:35\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.6688135, Training accuracy: 0.3959694, Time: 06_05_2022__09:10:56\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.6683492, Training accuracy: 0.3958838, Time: 06_05_2022__09:11:16\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.6677557, Training accuracy: 0.3963000, Time: 06_05_2022__09:11:37\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.6666708, Training accuracy: 0.3968812, Time: 06_05_2022__09:11:58\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.6654315, Training accuracy: 0.3976961, Time: 06_05_2022__09:12:19\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.6635601, Training accuracy: 0.3983495, Time: 06_05_2022__09:12:40\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.6630488, Training accuracy: 0.3986779, Time: 06_05_2022__09:13:01\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.6617654, Training accuracy: 0.3987381, Time: 06_05_2022__09:13:22\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.6603978, Training accuracy: 0.3993160, Time: 06_05_2022__09:13:42\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.6590320, Training accuracy: 0.3999533, Time: 06_05_2022__09:14:03\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.6575048, Training accuracy: 0.4004630, Time: 06_05_2022__09:14:24\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.6567438, Training accuracy: 0.4005046, Time: 06_05_2022__09:14:45\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.6551832, Training accuracy: 0.4011136, Time: 06_05_2022__09:15:06\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.6535700, Training accuracy: 0.4017117, Time: 06_05_2022__09:15:27\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.6526924, Training accuracy: 0.4019420, Time: 06_05_2022__09:15:47\n","Epoch 2 of 5, Average training loss: 1.6525160, Average training accuracy: 0.4019556, Time: 06_05_2022__09:15:58\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a8f714e0d6a43b19690ec2ad6cc7e3b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.3932915, Validation accuracy: 0.4800000, Time: 06_05_2022__09:16:03 | Loss decreased from 1.7681982 to 1.3905112 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.3892441, Validation accuracy: 0.4850000, Time: 06_05_2022__09:16:11 | Loss decreased from 1.3905112 to 1.3904071 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.4099667, Validation accuracy: 0.4866667, Time: 06_05_2022__09:16:18\n","Step: 400 of 1250, Validation loss: 1.4136975, Validation accuracy: 0.4881250, Time: 06_05_2022__09:16:23\n","Step: 500 of 1250, Validation loss: 1.4248140, Validation accuracy: 0.4850000, Time: 06_05_2022__09:16:29\n","Step: 600 of 1250, Validation loss: 1.4176440, Validation accuracy: 0.4916667, Time: 06_05_2022__09:16:34\n","Step: 700 of 1250, Validation loss: 1.4041484, Validation accuracy: 0.4950000, Time: 06_05_2022__09:16:39\n","Step: 800 of 1250, Validation loss: 1.3987543, Validation accuracy: 0.4946875, Time: 06_05_2022__09:16:44\n","Step: 900 of 1250, Validation loss: 1.3979488, Validation accuracy: 0.4966667, Time: 06_05_2022__09:16:50\n","Step: 1000 of 1250, Validation loss: 1.4047866, Validation accuracy: 0.4917500, Time: 06_05_2022__09:16:55\n","Step: 1100 of 1250, Validation loss: 1.4083932, Validation accuracy: 0.4904545, Time: 06_05_2022__09:17:00\n","Step: 1200 of 1250, Validation loss: 1.4106150, Validation accuracy: 0.4904167, Time: 06_05_2022__09:17:05\n","Average validation loss: 1.4082387, Average validation accuracy: 0.4904000, Time: 06_05_2022__09:17:08\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3f081f4ea7e4e7bac5183f2dc42799f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.4436949, Training accuracy: 0.4850000, Time: 06_05_2022__09:17:28\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.4797342, Training accuracy: 0.4687500, Time: 06_05_2022__09:17:49\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.5158064, Training accuracy: 0.4508333, Time: 06_05_2022__09:18:10\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.5144575, Training accuracy: 0.4493750, Time: 06_05_2022__09:18:31\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.5232106, Training accuracy: 0.4450000, Time: 06_05_2022__09:18:52\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.5179434, Training accuracy: 0.4479167, Time: 06_05_2022__09:19:13\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.5247113, Training accuracy: 0.4460714, Time: 06_05_2022__09:19:34\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.5147519, Training accuracy: 0.4459375, Time: 06_05_2022__09:19:54\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.5149997, Training accuracy: 0.4455556, Time: 06_05_2022__09:20:15\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.5106032, Training accuracy: 0.4497500, Time: 06_05_2022__09:20:36\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.5049910, Training accuracy: 0.4511364, Time: 06_05_2022__09:20:57\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.5058140, Training accuracy: 0.4506250, Time: 06_05_2022__09:21:18\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.5029720, Training accuracy: 0.4536538, Time: 06_05_2022__09:21:39\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.4994948, Training accuracy: 0.4539286, Time: 06_05_2022__09:21:59\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.5055450, Training accuracy: 0.4513333, Time: 06_05_2022__09:22:20\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.5034408, Training accuracy: 0.4526562, Time: 06_05_2022__09:22:41\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.4997454, Training accuracy: 0.4539706, Time: 06_05_2022__09:23:02\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.4964182, Training accuracy: 0.4550000, Time: 06_05_2022__09:23:23\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.4925059, Training accuracy: 0.4573684, Time: 06_05_2022__09:23:44\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.4915621, Training accuracy: 0.4567500, Time: 06_05_2022__09:24:04\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.4870987, Training accuracy: 0.4595238, Time: 06_05_2022__09:24:25\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.4858227, Training accuracy: 0.4613636, Time: 06_05_2022__09:24:46\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.4845593, Training accuracy: 0.4623913, Time: 06_05_2022__09:25:07\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.4824959, Training accuracy: 0.4622917, Time: 06_05_2022__09:25:28\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.4820426, Training accuracy: 0.4629000, Time: 06_05_2022__09:25:49\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.4808239, Training accuracy: 0.4634615, Time: 06_05_2022__09:26:09\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.4788710, Training accuracy: 0.4637037, Time: 06_05_2022__09:26:30\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.4768212, Training accuracy: 0.4644643, Time: 06_05_2022__09:26:51\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.4761759, Training accuracy: 0.4654310, Time: 06_05_2022__09:27:12\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.4731509, Training accuracy: 0.4670000, Time: 06_05_2022__09:27:33\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.4715157, Training accuracy: 0.4678226, Time: 06_05_2022__09:27:54\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.4671726, Training accuracy: 0.4690625, Time: 06_05_2022__09:28:14\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.4674932, Training accuracy: 0.4678030, Time: 06_05_2022__09:28:35\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.4689729, Training accuracy: 0.4675735, Time: 06_05_2022__09:28:56\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.4671481, Training accuracy: 0.4673571, Time: 06_05_2022__09:29:17\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.4672280, Training accuracy: 0.4671528, Time: 06_05_2022__09:29:38\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.4666105, Training accuracy: 0.4668919, Time: 06_05_2022__09:29:59\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.4645322, Training accuracy: 0.4671711, Time: 06_05_2022__09:30:19\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.4639858, Training accuracy: 0.4670513, Time: 06_05_2022__09:30:40\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.4623242, Training accuracy: 0.4679375, Time: 06_05_2022__09:31:01\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.4628247, Training accuracy: 0.4678049, Time: 06_05_2022__09:31:22\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.4604046, Training accuracy: 0.4693452, Time: 06_05_2022__09:31:43\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.4595196, Training accuracy: 0.4704070, Time: 06_05_2022__09:32:04\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.4580158, Training accuracy: 0.4713068, Time: 06_05_2022__09:32:25\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.4570375, Training accuracy: 0.4716111, Time: 06_05_2022__09:32:45\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.4559588, Training accuracy: 0.4727174, Time: 06_05_2022__09:33:06\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.4537996, Training accuracy: 0.4736702, Time: 06_05_2022__09:33:27\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.4530095, Training accuracy: 0.4747396, Time: 06_05_2022__09:33:48\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.4535621, Training accuracy: 0.4743878, Time: 06_05_2022__09:34:09\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.4529654, Training accuracy: 0.4750000, Time: 06_05_2022__09:34:30\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.4524631, Training accuracy: 0.4754902, Time: 06_05_2022__09:34:51\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.4526312, Training accuracy: 0.4758654, Time: 06_05_2022__09:35:12\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.4534514, Training accuracy: 0.4760377, Time: 06_05_2022__09:35:32\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.4529608, Training accuracy: 0.4761111, Time: 06_05_2022__09:35:53\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.4515062, Training accuracy: 0.4767273, Time: 06_05_2022__09:36:14\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.4514490, Training accuracy: 0.4766518, Time: 06_05_2022__09:36:35\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.4500653, Training accuracy: 0.4773684, Time: 06_05_2022__09:36:56\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.4498959, Training accuracy: 0.4773276, Time: 06_05_2022__09:37:17\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.4486590, Training accuracy: 0.4781356, Time: 06_05_2022__09:37:37\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.4469141, Training accuracy: 0.4787917, Time: 06_05_2022__09:37:58\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.4474207, Training accuracy: 0.4785656, Time: 06_05_2022__09:38:19\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.4448353, Training accuracy: 0.4793145, Time: 06_05_2022__09:38:40\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.4446525, Training accuracy: 0.4796825, Time: 06_05_2022__09:39:01\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.4433676, Training accuracy: 0.4803516, Time: 06_05_2022__09:39:22\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.4419489, Training accuracy: 0.4808846, Time: 06_05_2022__09:39:42\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.4407216, Training accuracy: 0.4811364, Time: 06_05_2022__09:40:03\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.4395420, Training accuracy: 0.4815299, Time: 06_05_2022__09:40:24\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.4391131, Training accuracy: 0.4820588, Time: 06_05_2022__09:40:45\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.4379712, Training accuracy: 0.4824638, Time: 06_05_2022__09:41:06\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.4363984, Training accuracy: 0.4833571, Time: 06_05_2022__09:41:27\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.4359374, Training accuracy: 0.4838380, Time: 06_05_2022__09:41:48\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.4346434, Training accuracy: 0.4843056, Time: 06_05_2022__09:42:08\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.4334954, Training accuracy: 0.4847260, Time: 06_05_2022__09:42:29\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.4331790, Training accuracy: 0.4848649, Time: 06_05_2022__09:42:50\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.4320476, Training accuracy: 0.4856000, Time: 06_05_2022__09:43:11\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.4308770, Training accuracy: 0.4857895, Time: 06_05_2022__09:43:32\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.4299401, Training accuracy: 0.4863312, Time: 06_05_2022__09:43:53\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.4280038, Training accuracy: 0.4868590, Time: 06_05_2022__09:44:14\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.4268943, Training accuracy: 0.4869937, Time: 06_05_2022__09:44:34\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.4250112, Training accuracy: 0.4876563, Time: 06_05_2022__09:44:55\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.4244953, Training accuracy: 0.4879630, Time: 06_05_2022__09:45:16\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.4240808, Training accuracy: 0.4880488, Time: 06_05_2022__09:45:37\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.4218258, Training accuracy: 0.4887651, Time: 06_05_2022__09:45:58\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.4223502, Training accuracy: 0.4887798, Time: 06_05_2022__09:46:19\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.4210088, Training accuracy: 0.4889412, Time: 06_05_2022__09:46:39\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.4207872, Training accuracy: 0.4893314, Time: 06_05_2022__09:47:00\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.4203960, Training accuracy: 0.4894253, Time: 06_05_2022__09:47:21\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.4191011, Training accuracy: 0.4902557, Time: 06_05_2022__09:47:42\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 1.4172912, Training accuracy: 0.4908708, Time: 06_05_2022__09:48:03\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 1.4156806, Training accuracy: 0.4915000, Time: 06_05_2022__09:48:24\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 1.4152861, Training accuracy: 0.4918681, Time: 06_05_2022__09:48:44\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 1.4141639, Training accuracy: 0.4924185, Time: 06_05_2022__09:49:05\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 1.4140664, Training accuracy: 0.4925806, Time: 06_05_2022__09:49:26\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 1.4137580, Training accuracy: 0.4923936, Time: 06_05_2022__09:49:47\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 1.4137536, Training accuracy: 0.4925789, Time: 06_05_2022__09:50:08\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 1.4116114, Training accuracy: 0.4936458, Time: 06_05_2022__09:50:29\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 1.4099373, Training accuracy: 0.4941753, Time: 06_05_2022__09:50:50\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 1.4082853, Training accuracy: 0.4949745, Time: 06_05_2022__09:51:11\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 1.4079935, Training accuracy: 0.4952525, Time: 06_05_2022__09:51:31\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 1.4070165, Training accuracy: 0.4959000, Time: 06_05_2022__09:51:52\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 1.4074025, Training accuracy: 0.4961881, Time: 06_05_2022__09:52:13\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 1.4056555, Training accuracy: 0.4970343, Time: 06_05_2022__09:52:34\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 1.4040842, Training accuracy: 0.4975728, Time: 06_05_2022__09:52:55\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 1.4032041, Training accuracy: 0.4978606, Time: 06_05_2022__09:53:16\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 1.4023812, Training accuracy: 0.4981905, Time: 06_05_2022__09:53:36\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 1.4008970, Training accuracy: 0.4988443, Time: 06_05_2022__09:53:57\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 1.3994449, Training accuracy: 0.4995093, Time: 06_05_2022__09:54:18\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 1.3978019, Training accuracy: 0.5000231, Time: 06_05_2022__09:54:39\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 1.3975531, Training accuracy: 0.5004128, Time: 06_05_2022__09:55:00\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 1.3965100, Training accuracy: 0.5008409, Time: 06_05_2022__09:55:21\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 1.3944630, Training accuracy: 0.5015090, Time: 06_05_2022__09:55:42\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 1.3935523, Training accuracy: 0.5017187, Time: 06_05_2022__09:56:02\n","Epoch 3 of 5, Average training loss: 1.3933062, Average training accuracy: 0.5018222, Time: 06_05_2022__09:56:13\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec7fd73e6bdc432ea5388cdd1d4d25e6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.1226123, Validation accuracy: 0.6000000, Time: 06_05_2022__09:56:18 | Loss decreased from 1.3904071 to 1.1171501 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.1473777, Validation accuracy: 0.5837500, Time: 06_05_2022__09:56:26\n","Step: 300 of 1250, Validation loss: 1.1571625, Validation accuracy: 0.5850000, Time: 06_05_2022__09:56:31\n","Step: 400 of 1250, Validation loss: 1.1583796, Validation accuracy: 0.5918750, Time: 06_05_2022__09:56:36\n","Step: 500 of 1250, Validation loss: 1.1833653, Validation accuracy: 0.5865000, Time: 06_05_2022__09:56:41\n","Step: 600 of 1250, Validation loss: 1.1727244, Validation accuracy: 0.5887500, Time: 06_05_2022__09:56:46\n","Step: 700 of 1250, Validation loss: 1.1676513, Validation accuracy: 0.5925000, Time: 06_05_2022__09:56:52\n","Step: 800 of 1250, Validation loss: 1.1600395, Validation accuracy: 0.5915625, Time: 06_05_2022__09:56:57\n","Step: 900 of 1250, Validation loss: 1.1639274, Validation accuracy: 0.5900000, Time: 06_05_2022__09:57:02\n","Step: 1000 of 1250, Validation loss: 1.1656491, Validation accuracy: 0.5867500, Time: 06_05_2022__09:57:07\n","Step: 1100 of 1250, Validation loss: 1.1641776, Validation accuracy: 0.5875000, Time: 06_05_2022__09:57:12\n","Step: 1200 of 1250, Validation loss: 1.1666230, Validation accuracy: 0.5868750, Time: 06_05_2022__09:57:18\n","Average validation loss: 1.1677591, Average validation accuracy: 0.5860000, Time: 06_05_2022__09:57:20\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9add8ecac0c47ec8fc8965caecc7465"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 1.2090465, Training accuracy: 0.5425000, Time: 06_05_2022__09:57:41\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 1.2602227, Training accuracy: 0.5375000, Time: 06_05_2022__09:58:02\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 1.2757623, Training accuracy: 0.5300000, Time: 06_05_2022__09:58:23\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 1.2585249, Training accuracy: 0.5475000, Time: 06_05_2022__09:58:44\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 1.2600351, Training accuracy: 0.5480000, Time: 06_05_2022__09:59:04\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 1.2550507, Training accuracy: 0.5495833, Time: 06_05_2022__09:59:25\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 1.2630180, Training accuracy: 0.5478571, Time: 06_05_2022__09:59:46\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 1.2574414, Training accuracy: 0.5493750, Time: 06_05_2022__10:00:07\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 1.2641609, Training accuracy: 0.5452778, Time: 06_05_2022__10:00:28\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 1.2616925, Training accuracy: 0.5477500, Time: 06_05_2022__10:00:49\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 1.2529252, Training accuracy: 0.5495455, Time: 06_05_2022__10:01:10\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 1.2586066, Training accuracy: 0.5475000, Time: 06_05_2022__10:01:31\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 1.2563504, Training accuracy: 0.5496154, Time: 06_05_2022__10:01:51\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 1.2549123, Training accuracy: 0.5533929, Time: 06_05_2022__10:02:12\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 1.2557739, Training accuracy: 0.5526667, Time: 06_05_2022__10:02:33\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 1.2533609, Training accuracy: 0.5540625, Time: 06_05_2022__10:02:54\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 1.2532957, Training accuracy: 0.5529412, Time: 06_05_2022__10:03:15\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 1.2533743, Training accuracy: 0.5543056, Time: 06_05_2022__10:03:36\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 1.2511922, Training accuracy: 0.5543421, Time: 06_05_2022__10:03:57\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 1.2515453, Training accuracy: 0.5536250, Time: 06_05_2022__10:04:18\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 1.2473433, Training accuracy: 0.5550000, Time: 06_05_2022__10:04:38\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 1.2427205, Training accuracy: 0.5573864, Time: 06_05_2022__10:04:59\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 1.2427412, Training accuracy: 0.5577174, Time: 06_05_2022__10:05:20\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 1.2402494, Training accuracy: 0.5571875, Time: 06_05_2022__10:05:41\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 1.2405009, Training accuracy: 0.5576000, Time: 06_05_2022__10:06:02\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 1.2390160, Training accuracy: 0.5581731, Time: 06_05_2022__10:06:23\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 1.2366517, Training accuracy: 0.5589815, Time: 06_05_2022__10:06:44\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 1.2367120, Training accuracy: 0.5586607, Time: 06_05_2022__10:07:04\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 1.2352569, Training accuracy: 0.5581897, Time: 06_05_2022__10:07:25\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 1.2356947, Training accuracy: 0.5582500, Time: 06_05_2022__10:07:46\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 1.2299304, Training accuracy: 0.5611290, Time: 06_05_2022__10:08:07\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 1.2255599, Training accuracy: 0.5632031, Time: 06_05_2022__10:08:28\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 1.2268354, Training accuracy: 0.5621212, Time: 06_05_2022__10:08:49\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 1.2265415, Training accuracy: 0.5627941, Time: 06_05_2022__10:09:10\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 1.2266001, Training accuracy: 0.5627857, Time: 06_05_2022__10:09:30\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 1.2277369, Training accuracy: 0.5615972, Time: 06_05_2022__10:09:51\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 1.2259935, Training accuracy: 0.5621622, Time: 06_05_2022__10:10:12\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 1.2242304, Training accuracy: 0.5630921, Time: 06_05_2022__10:10:33\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 1.2224037, Training accuracy: 0.5642308, Time: 06_05_2022__10:10:54\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 1.2205248, Training accuracy: 0.5643750, Time: 06_05_2022__10:11:15\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 1.2216490, Training accuracy: 0.5644512, Time: 06_05_2022__10:11:36\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 1.2188019, Training accuracy: 0.5656548, Time: 06_05_2022__10:11:56\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 1.2168180, Training accuracy: 0.5668605, Time: 06_05_2022__10:12:17\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 1.2158549, Training accuracy: 0.5671591, Time: 06_05_2022__10:12:38\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 1.2139066, Training accuracy: 0.5678889, Time: 06_05_2022__10:12:59\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 1.2138811, Training accuracy: 0.5683152, Time: 06_05_2022__10:13:20\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 1.2120907, Training accuracy: 0.5690957, Time: 06_05_2022__10:13:41\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 1.2114522, Training accuracy: 0.5697396, Time: 06_05_2022__10:14:02\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 1.2105195, Training accuracy: 0.5694388, Time: 06_05_2022__10:14:23\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 1.2101555, Training accuracy: 0.5701000, Time: 06_05_2022__10:14:43\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 1.2091514, Training accuracy: 0.5702941, Time: 06_05_2022__10:15:04\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 1.2089926, Training accuracy: 0.5699519, Time: 06_05_2022__10:15:25\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 1.2095327, Training accuracy: 0.5703302, Time: 06_05_2022__10:15:46\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 1.2092707, Training accuracy: 0.5708333, Time: 06_05_2022__10:16:07\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 1.2094315, Training accuracy: 0.5706818, Time: 06_05_2022__10:16:28\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 1.2086846, Training accuracy: 0.5708929, Time: 06_05_2022__10:16:48\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 1.2069405, Training accuracy: 0.5714474, Time: 06_05_2022__10:17:09\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 1.2063094, Training accuracy: 0.5715517, Time: 06_05_2022__10:17:30\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 1.2065274, Training accuracy: 0.5715254, Time: 06_05_2022__10:17:51\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 1.2061298, Training accuracy: 0.5712917, Time: 06_05_2022__10:18:12\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 1.2073276, Training accuracy: 0.5705738, Time: 06_05_2022__10:18:33\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 1.2060157, Training accuracy: 0.5708871, Time: 06_05_2022__10:18:53\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 1.2061536, Training accuracy: 0.5707143, Time: 06_05_2022__10:19:14\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 1.2043172, Training accuracy: 0.5714453, Time: 06_05_2022__10:19:35\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 1.2029268, Training accuracy: 0.5718077, Time: 06_05_2022__10:19:56\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 1.2013959, Training accuracy: 0.5724242, Time: 06_05_2022__10:20:17\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 1.2000367, Training accuracy: 0.5730597, Time: 06_05_2022__10:20:38\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 1.1996028, Training accuracy: 0.5730882, Time: 06_05_2022__10:20:58\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 1.1981927, Training accuracy: 0.5736594, Time: 06_05_2022__10:21:19\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 1.1960483, Training accuracy: 0.5746786, Time: 06_05_2022__10:21:40\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 1.1951757, Training accuracy: 0.5747535, Time: 06_05_2022__10:22:01\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 1.1932169, Training accuracy: 0.5755903, Time: 06_05_2022__10:22:22\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 1.1925461, Training accuracy: 0.5757534, Time: 06_05_2022__10:22:43\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 1.1922364, Training accuracy: 0.5760811, Time: 06_05_2022__10:23:03\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 1.1903595, Training accuracy: 0.5766000, Time: 06_05_2022__10:23:24\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 1.1886100, Training accuracy: 0.5775658, Time: 06_05_2022__10:23:45\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 1.1885881, Training accuracy: 0.5780195, Time: 06_05_2022__10:24:06\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 1.1869311, Training accuracy: 0.5784295, Time: 06_05_2022__10:24:27\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 1.1854042, Training accuracy: 0.5789241, Time: 06_05_2022__10:24:48\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 1.1843576, Training accuracy: 0.5790625, Time: 06_05_2022__10:25:08\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 1.1848587, Training accuracy: 0.5790432, Time: 06_05_2022__10:25:29\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 1.1848575, Training accuracy: 0.5792988, Time: 06_05_2022__10:25:50\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 1.1829630, Training accuracy: 0.5797892, Time: 06_05_2022__10:26:11\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 1.1834988, Training accuracy: 0.5799405, Time: 06_05_2022__10:26:32\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 1.1825940, Training accuracy: 0.5805000, Time: 06_05_2022__10:26:53\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 1.1821275, Training accuracy: 0.5805814, Time: 06_05_2022__10:27:14\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 1.1824686, Training accuracy: 0.5806897, Time: 06_05_2022__10:27:34\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 1.1807796, Training accuracy: 0.5813352, Time: 06_05_2022__10:27:55\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 1.1788364, Training accuracy: 0.5818820, Time: 06_05_2022__10:28:16\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 1.1776662, Training accuracy: 0.5822500, Time: 06_05_2022__10:28:37\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 1.1769788, Training accuracy: 0.5824451, Time: 06_05_2022__10:28:58\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 1.1752643, Training accuracy: 0.5828804, Time: 06_05_2022__10:29:19\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 1.1747564, Training accuracy: 0.5830108, Time: 06_05_2022__10:29:40\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 1.1739222, Training accuracy: 0.5834574, Time: 06_05_2022__10:30:01\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 1.1746666, Training accuracy: 0.5833947, Time: 06_05_2022__10:30:21\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 1.1730711, Training accuracy: 0.5839323, Time: 06_05_2022__10:30:42\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 1.1710103, Training accuracy: 0.5845876, Time: 06_05_2022__10:31:03\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 1.1690819, Training accuracy: 0.5854082, Time: 06_05_2022__10:31:24\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 1.1686240, Training accuracy: 0.5858586, Time: 06_05_2022__10:31:45\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 1.1681905, Training accuracy: 0.5861000, Time: 06_05_2022__10:32:06\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 1.1688470, Training accuracy: 0.5855693, Time: 06_05_2022__10:32:27\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 1.1672457, Training accuracy: 0.5862500, Time: 06_05_2022__10:32:48\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 1.1659153, Training accuracy: 0.5867961, Time: 06_05_2022__10:33:09\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 1.1647044, Training accuracy: 0.5871635, Time: 06_05_2022__10:33:29\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 1.1635685, Training accuracy: 0.5877381, Time: 06_05_2022__10:33:50\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 1.1615463, Training accuracy: 0.5886557, Time: 06_05_2022__10:34:11\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 1.1595898, Training accuracy: 0.5893925, Time: 06_05_2022__10:34:32\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 1.1587003, Training accuracy: 0.5896528, Time: 06_05_2022__10:34:53\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 1.1588585, Training accuracy: 0.5896101, Time: 06_05_2022__10:35:14\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 1.1580383, Training accuracy: 0.5897727, Time: 06_05_2022__10:35:35\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 1.1561019, Training accuracy: 0.5903829, Time: 06_05_2022__10:35:56\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 1.1550160, Training accuracy: 0.5906473, Time: 06_05_2022__10:36:17\n","Epoch 4 of 5, Average training loss: 1.1549513, Average training accuracy: 0.5906889, Time: 06_05_2022__10:36:27\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2529595687b140feb0ae747cdac411a1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.9469503, Validation accuracy: 0.6625000, Time: 06_05_2022__10:36:32 | Loss decreased from 1.1171501 to 0.9438410 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.9827824, Validation accuracy: 0.6462500, Time: 06_05_2022__10:36:40\n","Step: 300 of 1250, Validation loss: 1.0188397, Validation accuracy: 0.6458333, Time: 06_05_2022__10:36:45\n","Step: 400 of 1250, Validation loss: 1.0252644, Validation accuracy: 0.6406250, Time: 06_05_2022__10:36:51\n","Step: 500 of 1250, Validation loss: 1.0496836, Validation accuracy: 0.6335000, Time: 06_05_2022__10:36:56\n","Step: 600 of 1250, Validation loss: 1.0338350, Validation accuracy: 0.6412500, Time: 06_05_2022__10:37:01\n","Step: 700 of 1250, Validation loss: 1.0268868, Validation accuracy: 0.6421429, Time: 06_05_2022__10:37:06\n","Step: 800 of 1250, Validation loss: 1.0144233, Validation accuracy: 0.6453125, Time: 06_05_2022__10:37:11\n","Step: 900 of 1250, Validation loss: 1.0203382, Validation accuracy: 0.6411111, Time: 06_05_2022__10:37:17\n","Step: 1000 of 1250, Validation loss: 1.0210322, Validation accuracy: 0.6390000, Time: 06_05_2022__10:37:22\n","Step: 1100 of 1250, Validation loss: 1.0201490, Validation accuracy: 0.6438636, Time: 06_05_2022__10:37:27\n","Step: 1200 of 1250, Validation loss: 1.0226047, Validation accuracy: 0.6435417, Time: 06_05_2022__10:37:32\n","Average validation loss: 1.0230619, Average validation accuracy: 0.6440000, Time: 06_05_2022__10:37:35\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85314b5733e44913a56654e4d9b68b13"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 0.9741610, Training accuracy: 0.6500000, Time: 06_05_2022__10:37:56\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 1.0221423, Training accuracy: 0.6312500, Time: 06_05_2022__10:38:17\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 1.0380873, Training accuracy: 0.6250000, Time: 06_05_2022__10:38:37\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 1.0236598, Training accuracy: 0.6375000, Time: 06_05_2022__10:38:58\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 1.0282838, Training accuracy: 0.6340000, Time: 06_05_2022__10:39:19\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 1.0268059, Training accuracy: 0.6325000, Time: 06_05_2022__10:39:40\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 1.0307624, Training accuracy: 0.6328571, Time: 06_05_2022__10:40:01\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 1.0221486, Training accuracy: 0.6343750, Time: 06_05_2022__10:40:22\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 1.0286413, Training accuracy: 0.6325000, Time: 06_05_2022__10:40:43\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 1.0236912, Training accuracy: 0.6312500, Time: 06_05_2022__10:41:04\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 1.0200380, Training accuracy: 0.6318182, Time: 06_05_2022__10:41:25\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 1.0247956, Training accuracy: 0.6306250, Time: 06_05_2022__10:41:45\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 1.0291591, Training accuracy: 0.6301923, Time: 06_05_2022__10:42:06\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 1.0272751, Training accuracy: 0.6310714, Time: 06_05_2022__10:42:27\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 1.0327214, Training accuracy: 0.6300000, Time: 06_05_2022__10:42:48\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 1.0275276, Training accuracy: 0.6312500, Time: 06_05_2022__10:43:09\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 1.0279390, Training accuracy: 0.6323529, Time: 06_05_2022__10:43:30\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 1.0324018, Training accuracy: 0.6295833, Time: 06_05_2022__10:43:51\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 1.0290213, Training accuracy: 0.6315789, Time: 06_05_2022__10:44:12\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 1.0257048, Training accuracy: 0.6340000, Time: 06_05_2022__10:44:33\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 1.0231402, Training accuracy: 0.6358333, Time: 06_05_2022__10:44:53\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 1.0204994, Training accuracy: 0.6378409, Time: 06_05_2022__10:45:14\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 1.0188048, Training accuracy: 0.6385870, Time: 06_05_2022__10:45:35\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 1.0140549, Training accuracy: 0.6406250, Time: 06_05_2022__10:45:56\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 1.0112705, Training accuracy: 0.6416000, Time: 06_05_2022__10:46:17\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 1.0074610, Training accuracy: 0.6430769, Time: 06_05_2022__10:46:38\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 1.0049198, Training accuracy: 0.6436111, Time: 06_05_2022__10:46:59\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 1.0041964, Training accuracy: 0.6439286, Time: 06_05_2022__10:47:20\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 1.0030777, Training accuracy: 0.6439655, Time: 06_05_2022__10:47:41\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 1.0013332, Training accuracy: 0.6441667, Time: 06_05_2022__10:48:01\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 0.9987423, Training accuracy: 0.6456452, Time: 06_05_2022__10:48:22\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 0.9958138, Training accuracy: 0.6469531, Time: 06_05_2022__10:48:43\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 0.9970859, Training accuracy: 0.6465152, Time: 06_05_2022__10:49:04\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 0.9970329, Training accuracy: 0.6463235, Time: 06_05_2022__10:49:25\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 0.9962155, Training accuracy: 0.6462143, Time: 06_05_2022__10:49:46\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 0.9979251, Training accuracy: 0.6455556, Time: 06_05_2022__10:50:07\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 0.9963940, Training accuracy: 0.6456081, Time: 06_05_2022__10:50:28\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 0.9942972, Training accuracy: 0.6463158, Time: 06_05_2022__10:50:49\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 0.9960495, Training accuracy: 0.6461538, Time: 06_05_2022__10:51:09\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 0.9948935, Training accuracy: 0.6467500, Time: 06_05_2022__10:51:30\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 0.9952709, Training accuracy: 0.6471951, Time: 06_05_2022__10:51:51\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 0.9927987, Training accuracy: 0.6483929, Time: 06_05_2022__10:52:12\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 0.9918723, Training accuracy: 0.6491279, Time: 06_05_2022__10:52:33\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 0.9899661, Training accuracy: 0.6498864, Time: 06_05_2022__10:52:54\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 0.9902480, Training accuracy: 0.6501111, Time: 06_05_2022__10:53:15\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 0.9907413, Training accuracy: 0.6500543, Time: 06_05_2022__10:53:36\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 0.9894537, Training accuracy: 0.6513830, Time: 06_05_2022__10:53:57\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 0.9893135, Training accuracy: 0.6517188, Time: 06_05_2022__10:54:18\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 0.9889394, Training accuracy: 0.6515306, Time: 06_05_2022__10:54:38\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 0.9902888, Training accuracy: 0.6510000, Time: 06_05_2022__10:54:59\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 0.9897004, Training accuracy: 0.6508333, Time: 06_05_2022__10:55:20\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 0.9885947, Training accuracy: 0.6515865, Time: 06_05_2022__10:55:41\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 0.9902265, Training accuracy: 0.6515566, Time: 06_05_2022__10:56:02\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 0.9898164, Training accuracy: 0.6517130, Time: 06_05_2022__10:56:23\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 0.9902013, Training accuracy: 0.6515909, Time: 06_05_2022__10:56:44\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 0.9888115, Training accuracy: 0.6518750, Time: 06_05_2022__10:57:05\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 0.9871904, Training accuracy: 0.6522807, Time: 06_05_2022__10:57:26\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 0.9868661, Training accuracy: 0.6526724, Time: 06_05_2022__10:57:47\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 0.9872404, Training accuracy: 0.6530085, Time: 06_05_2022__10:58:07\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 0.9877308, Training accuracy: 0.6527500, Time: 06_05_2022__10:58:28\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 0.9877539, Training accuracy: 0.6527049, Time: 06_05_2022__10:58:49\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 0.9875266, Training accuracy: 0.6527419, Time: 06_05_2022__10:59:10\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 0.9869399, Training accuracy: 0.6530952, Time: 06_05_2022__10:59:31\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 0.9853546, Training accuracy: 0.6539453, Time: 06_05_2022__10:59:52\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 0.9845054, Training accuracy: 0.6542692, Time: 06_05_2022__11:00:13\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 0.9838044, Training accuracy: 0.6548864, Time: 06_05_2022__11:00:34\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 0.9821873, Training accuracy: 0.6551866, Time: 06_05_2022__11:00:55\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 0.9825140, Training accuracy: 0.6546691, Time: 06_05_2022__11:01:15\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 0.9810980, Training accuracy: 0.6551812, Time: 06_05_2022__11:01:36\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 0.9786304, Training accuracy: 0.6561071, Time: 06_05_2022__11:01:57\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 0.9795562, Training accuracy: 0.6561620, Time: 06_05_2022__11:02:18\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 0.9773449, Training accuracy: 0.6568750, Time: 06_05_2022__11:02:39\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 0.9766432, Training accuracy: 0.6572603, Time: 06_05_2022__11:03:00\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 0.9749383, Training accuracy: 0.6579392, Time: 06_05_2022__11:03:21\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 0.9738233, Training accuracy: 0.6582333, Time: 06_05_2022__11:03:42\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 0.9723250, Training accuracy: 0.6587171, Time: 06_05_2022__11:04:03\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 0.9723318, Training accuracy: 0.6586688, Time: 06_05_2022__11:04:23\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 0.9711868, Training accuracy: 0.6589103, Time: 06_05_2022__11:04:44\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 0.9699602, Training accuracy: 0.6593987, Time: 06_05_2022__11:05:05\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 0.9692492, Training accuracy: 0.6596563, Time: 06_05_2022__11:05:26\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 0.9695873, Training accuracy: 0.6596296, Time: 06_05_2022__11:05:47\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 0.9690770, Training accuracy: 0.6600305, Time: 06_05_2022__11:06:08\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 0.9680106, Training accuracy: 0.6605723, Time: 06_05_2022__11:06:29\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 0.9683960, Training accuracy: 0.6607738, Time: 06_05_2022__11:06:50\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 0.9680401, Training accuracy: 0.6609706, Time: 06_05_2022__11:07:11\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 0.9677439, Training accuracy: 0.6612500, Time: 06_05_2022__11:07:31\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 0.9671518, Training accuracy: 0.6613218, Time: 06_05_2022__11:07:52\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 0.9655836, Training accuracy: 0.6619602, Time: 06_05_2022__11:08:13\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 0.9640065, Training accuracy: 0.6626124, Time: 06_05_2022__11:08:34\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 0.9636218, Training accuracy: 0.6630000, Time: 06_05_2022__11:08:55\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 0.9634574, Training accuracy: 0.6632692, Time: 06_05_2022__11:09:16\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 0.9620505, Training accuracy: 0.6636141, Time: 06_05_2022__11:09:37\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 0.9624420, Training accuracy: 0.6635484, Time: 06_05_2022__11:09:58\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 0.9615716, Training accuracy: 0.6638564, Time: 06_05_2022__11:10:19\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 0.9618695, Training accuracy: 0.6639474, Time: 06_05_2022__11:10:40\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 0.9604312, Training accuracy: 0.6643750, Time: 06_05_2022__11:11:00\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 0.9595704, Training accuracy: 0.6647423, Time: 06_05_2022__11:11:21\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 0.9575123, Training accuracy: 0.6655612, Time: 06_05_2022__11:11:42\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 0.9569502, Training accuracy: 0.6655303, Time: 06_05_2022__11:12:03\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 0.9571560, Training accuracy: 0.6655500, Time: 06_05_2022__11:12:24\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 0.9578599, Training accuracy: 0.6652723, Time: 06_05_2022__11:12:45\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 0.9573125, Training accuracy: 0.6655637, Time: 06_05_2022__11:13:06\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 0.9566477, Training accuracy: 0.6658252, Time: 06_05_2022__11:13:27\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 0.9550762, Training accuracy: 0.6664183, Time: 06_05_2022__11:13:48\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 0.9537475, Training accuracy: 0.6672143, Time: 06_05_2022__11:14:08\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 0.9528757, Training accuracy: 0.6674057, Time: 06_05_2022__11:14:29\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 0.9518178, Training accuracy: 0.6680374, Time: 06_05_2022__11:14:50\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 0.9510589, Training accuracy: 0.6682407, Time: 06_05_2022__11:15:11\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 0.9510624, Training accuracy: 0.6685321, Time: 06_05_2022__11:15:32\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 0.9504611, Training accuracy: 0.6686364, Time: 06_05_2022__11:15:53\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 0.9493783, Training accuracy: 0.6691892, Time: 06_05_2022__11:16:14\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 0.9486496, Training accuracy: 0.6694866, Time: 06_05_2022__11:16:35\n","Epoch 5 of 5, Average training loss: 0.9486858, Average training accuracy: 0.6693111, Time: 06_05_2022__11:16:45\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66d5feae3aec4c5499b4fb44e2504aa5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.8367866, Validation accuracy: 0.7050000, Time: 06_05_2022__11:16:51 | Loss decreased from 0.9438410 to 0.8400458 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.8320493, Validation accuracy: 0.7062500, Time: 06_05_2022__11:16:58 | Loss decreased from 0.8400458 to 0.8317806 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.8582841, Validation accuracy: 0.6991667, Time: 06_05_2022__11:17:05\n","Step: 400 of 1250, Validation loss: 0.8550835, Validation accuracy: 0.6987500, Time: 06_05_2022__11:17:11\n","Step: 500 of 1250, Validation loss: 0.8887280, Validation accuracy: 0.6860000, Time: 06_05_2022__11:17:16\n","Step: 600 of 1250, Validation loss: 0.8917560, Validation accuracy: 0.6841667, Time: 06_05_2022__11:17:21\n","Step: 700 of 1250, Validation loss: 0.9002169, Validation accuracy: 0.6846429, Time: 06_05_2022__11:17:27\n","Step: 800 of 1250, Validation loss: 0.8898631, Validation accuracy: 0.6884375, Time: 06_05_2022__11:17:32\n","Step: 900 of 1250, Validation loss: 0.8903448, Validation accuracy: 0.6866667, Time: 06_05_2022__11:17:37\n","Step: 1000 of 1250, Validation loss: 0.8917846, Validation accuracy: 0.6850000, Time: 06_05_2022__11:17:42\n","Step: 1100 of 1250, Validation loss: 0.8900730, Validation accuracy: 0.6879545, Time: 06_05_2022__11:17:47\n","Step: 1200 of 1250, Validation loss: 0.8932174, Validation accuracy: 0.6868750, Time: 06_05_2022__11:17:53\n","Average validation loss: 0.8919795, Average validation accuracy: 0.6878000, Time: 06_05_2022__11:17:55\n","###################### Testing vgg19_batch_norm SGD, lr_0.1, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecd2aef1af904626baed5589e8fbbc82"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.6925000, Time: 06_05_2022__11:18:09\n","Step: 200 of 2500, Test accuracy: 0.6850000, Time: 06_05_2022__11:18:14\n","Step: 300 of 2500, Test accuracy: 0.6933333, Time: 06_05_2022__11:18:19\n","Step: 400 of 2500, Test accuracy: 0.6850000, Time: 06_05_2022__11:18:24\n","Step: 500 of 2500, Test accuracy: 0.6770000, Time: 06_05_2022__11:18:30\n","Step: 600 of 2500, Test accuracy: 0.6758333, Time: 06_05_2022__11:18:35\n","Step: 700 of 2500, Test accuracy: 0.6746429, Time: 06_05_2022__11:18:40\n","Step: 800 of 2500, Test accuracy: 0.6743750, Time: 06_05_2022__11:18:45\n","Step: 900 of 2500, Test accuracy: 0.6744444, Time: 06_05_2022__11:18:50\n","Step: 1000 of 2500, Test accuracy: 0.6765000, Time: 06_05_2022__11:18:56\n","Step: 1100 of 2500, Test accuracy: 0.6834091, Time: 06_05_2022__11:19:01\n","Step: 1200 of 2500, Test accuracy: 0.6833333, Time: 06_05_2022__11:19:06\n","Step: 1300 of 2500, Test accuracy: 0.6853846, Time: 06_05_2022__11:19:11\n","Step: 1400 of 2500, Test accuracy: 0.6858929, Time: 06_05_2022__11:19:16\n","Step: 1500 of 2500, Test accuracy: 0.6861667, Time: 06_05_2022__11:19:21\n","Step: 1600 of 2500, Test accuracy: 0.6860937, Time: 06_05_2022__11:19:27\n","Step: 1700 of 2500, Test accuracy: 0.6870588, Time: 06_05_2022__11:19:32\n","Step: 1800 of 2500, Test accuracy: 0.6858333, Time: 06_05_2022__11:19:37\n","Step: 1900 of 2500, Test accuracy: 0.6878947, Time: 06_05_2022__11:19:42\n","Step: 2000 of 2500, Test accuracy: 0.6871250, Time: 06_05_2022__11:19:47\n","Step: 2100 of 2500, Test accuracy: 0.6873810, Time: 06_05_2022__11:19:52\n","Step: 2200 of 2500, Test accuracy: 0.6875000, Time: 06_05_2022__11:19:58\n","Step: 2300 of 2500, Test accuracy: 0.6878261, Time: 06_05_2022__11:20:03\n","Step: 2400 of 2500, Test accuracy: 0.6876042, Time: 06_05_2022__11:20:08\n","Step: 2500 of 2500, Test accuracy: 0.6890000, Time: 06_05_2022__11:20:13\n","Average testing accuracy: 0.6890000, Time: 06_05_2022__11:20:13\n","###################### Training vgg19_batch_norm SGD, lr_0.1, momentum_0.6 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1047f6cbdef4002975523daf4af41bf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 8.1320510, Training accuracy: 0.1050000, Time: 06_05_2022__11:20:36\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 5.2119090, Training accuracy: 0.1025000, Time: 06_05_2022__11:20:57\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 4.2446527, Training accuracy: 0.1058333, Time: 06_05_2022__11:21:18\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 3.7593509, Training accuracy: 0.1075000, Time: 06_05_2022__11:21:39\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 3.4682180, Training accuracy: 0.1165000, Time: 06_05_2022__11:21:59\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 3.2689229, Training accuracy: 0.1175000, Time: 06_05_2022__11:22:20\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 3.1272837, Training accuracy: 0.1200000, Time: 06_05_2022__11:22:41\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 3.0211651, Training accuracy: 0.1228125, Time: 06_05_2022__11:23:02\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.9354883, Training accuracy: 0.1291667, Time: 06_05_2022__11:23:22\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.8696841, Training accuracy: 0.1290000, Time: 06_05_2022__11:23:43\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.8149483, Training accuracy: 0.1281818, Time: 06_05_2022__11:24:04\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.7671227, Training accuracy: 0.1300000, Time: 06_05_2022__11:24:25\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.7276587, Training accuracy: 0.1325000, Time: 06_05_2022__11:24:45\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.6916443, Training accuracy: 0.1357143, Time: 06_05_2022__11:25:06\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.6622781, Training accuracy: 0.1366667, Time: 06_05_2022__11:25:27\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.6357815, Training accuracy: 0.1384375, Time: 06_05_2022__11:25:48\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.6132325, Training accuracy: 0.1402941, Time: 06_05_2022__11:26:08\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.5912600, Training accuracy: 0.1418056, Time: 06_05_2022__11:26:29\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.5705633, Training accuracy: 0.1452632, Time: 06_05_2022__11:26:50\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.5538016, Training accuracy: 0.1473750, Time: 06_05_2022__11:27:11\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.5368502, Training accuracy: 0.1500000, Time: 06_05_2022__11:27:31\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.5241879, Training accuracy: 0.1509091, Time: 06_05_2022__11:27:52\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.5104231, Training accuracy: 0.1527174, Time: 06_05_2022__11:28:13\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.4979900, Training accuracy: 0.1540625, Time: 06_05_2022__11:28:34\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.4850792, Training accuracy: 0.1561000, Time: 06_05_2022__11:28:54\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.4722914, Training accuracy: 0.1589423, Time: 06_05_2022__11:29:15\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.4624578, Training accuracy: 0.1600000, Time: 06_05_2022__11:29:36\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.4520072, Training accuracy: 0.1610714, Time: 06_05_2022__11:29:57\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.4435749, Training accuracy: 0.1621552, Time: 06_05_2022__11:30:17\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.4341286, Training accuracy: 0.1623333, Time: 06_05_2022__11:30:38\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.4246858, Training accuracy: 0.1651613, Time: 06_05_2022__11:30:59\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.4154370, Training accuracy: 0.1659375, Time: 06_05_2022__11:31:20\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.4088572, Training accuracy: 0.1672727, Time: 06_05_2022__11:31:41\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.4017777, Training accuracy: 0.1683088, Time: 06_05_2022__11:32:01\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.3949942, Training accuracy: 0.1687857, Time: 06_05_2022__11:32:22\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.3882896, Training accuracy: 0.1694444, Time: 06_05_2022__11:32:43\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.3815339, Training accuracy: 0.1706757, Time: 06_05_2022__11:33:04\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.3763256, Training accuracy: 0.1707895, Time: 06_05_2022__11:33:25\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.3706091, Training accuracy: 0.1723718, Time: 06_05_2022__11:33:45\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.3641523, Training accuracy: 0.1744375, Time: 06_05_2022__11:34:06\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.3579785, Training accuracy: 0.1753659, Time: 06_05_2022__11:34:27\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.3517003, Training accuracy: 0.1769643, Time: 06_05_2022__11:34:48\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.3462262, Training accuracy: 0.1777907, Time: 06_05_2022__11:35:09\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.3403067, Training accuracy: 0.1789773, Time: 06_05_2022__11:35:29\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.3333856, Training accuracy: 0.1802222, Time: 06_05_2022__11:35:50\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.3286087, Training accuracy: 0.1807065, Time: 06_05_2022__11:36:11\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.3228957, Training accuracy: 0.1814894, Time: 06_05_2022__11:36:32\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 2.3176508, Training accuracy: 0.1829167, Time: 06_05_2022__11:36:53\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 2.3125035, Training accuracy: 0.1838776, Time: 06_05_2022__11:37:14\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 2.3088283, Training accuracy: 0.1842500, Time: 06_05_2022__11:37:34\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 2.3029623, Training accuracy: 0.1859314, Time: 06_05_2022__11:37:55\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 2.2978553, Training accuracy: 0.1871635, Time: 06_05_2022__11:38:16\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 2.2931453, Training accuracy: 0.1884906, Time: 06_05_2022__11:38:37\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 2.2885986, Training accuracy: 0.1892130, Time: 06_05_2022__11:38:58\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 2.2833707, Training accuracy: 0.1909545, Time: 06_05_2022__11:39:19\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 2.2788994, Training accuracy: 0.1916964, Time: 06_05_2022__11:39:39\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 2.2738983, Training accuracy: 0.1929386, Time: 06_05_2022__11:40:00\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 2.2689760, Training accuracy: 0.1944397, Time: 06_05_2022__11:40:21\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 2.2643969, Training accuracy: 0.1956780, Time: 06_05_2022__11:40:42\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 2.2604057, Training accuracy: 0.1963333, Time: 06_05_2022__11:41:03\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 2.2572689, Training accuracy: 0.1972131, Time: 06_05_2022__11:41:24\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 2.2534760, Training accuracy: 0.1983871, Time: 06_05_2022__11:41:44\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 2.2497143, Training accuracy: 0.1994048, Time: 06_05_2022__11:42:05\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 2.2459223, Training accuracy: 0.2001172, Time: 06_05_2022__11:42:26\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 2.2411371, Training accuracy: 0.2017308, Time: 06_05_2022__11:42:47\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 2.2376620, Training accuracy: 0.2029167, Time: 06_05_2022__11:43:08\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 2.2335839, Training accuracy: 0.2038433, Time: 06_05_2022__11:43:29\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 2.2306346, Training accuracy: 0.2045221, Time: 06_05_2022__11:43:49\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 2.2270649, Training accuracy: 0.2048551, Time: 06_05_2022__11:44:10\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 2.2229250, Training accuracy: 0.2060714, Time: 06_05_2022__11:44:31\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 2.2193009, Training accuracy: 0.2074296, Time: 06_05_2022__11:44:52\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 2.2154185, Training accuracy: 0.2082986, Time: 06_05_2022__11:45:13\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 2.2117737, Training accuracy: 0.2092123, Time: 06_05_2022__11:45:34\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 2.2091276, Training accuracy: 0.2096284, Time: 06_05_2022__11:45:54\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 2.2061977, Training accuracy: 0.2105667, Time: 06_05_2022__11:46:15\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 2.2034907, Training accuracy: 0.2110197, Time: 06_05_2022__11:46:36\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 2.1997509, Training accuracy: 0.2120779, Time: 06_05_2022__11:46:57\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 2.1962536, Training accuracy: 0.2131731, Time: 06_05_2022__11:47:18\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 2.1926677, Training accuracy: 0.2140823, Time: 06_05_2022__11:47:39\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 2.1898912, Training accuracy: 0.2148750, Time: 06_05_2022__11:47:59\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 2.1863193, Training accuracy: 0.2158951, Time: 06_05_2022__11:48:20\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 2.1826060, Training accuracy: 0.2168902, Time: 06_05_2022__11:48:41\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 2.1788216, Training accuracy: 0.2181024, Time: 06_05_2022__11:49:02\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 2.1754429, Training accuracy: 0.2191369, Time: 06_05_2022__11:49:23\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 2.1728204, Training accuracy: 0.2199412, Time: 06_05_2022__11:49:44\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 2.1698305, Training accuracy: 0.2207849, Time: 06_05_2022__11:50:04\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 2.1667836, Training accuracy: 0.2214943, Time: 06_05_2022__11:50:25\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 2.1635240, Training accuracy: 0.2229545, Time: 06_05_2022__11:50:46\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 2.1601851, Training accuracy: 0.2239326, Time: 06_05_2022__11:51:07\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 2.1568091, Training accuracy: 0.2247500, Time: 06_05_2022__11:51:28\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 2.1544350, Training accuracy: 0.2256319, Time: 06_05_2022__11:51:49\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 2.1513866, Training accuracy: 0.2267120, Time: 06_05_2022__11:52:10\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 2.1492117, Training accuracy: 0.2271774, Time: 06_05_2022__11:52:30\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 2.1470355, Training accuracy: 0.2278989, Time: 06_05_2022__11:52:51\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 2.1450469, Training accuracy: 0.2287105, Time: 06_05_2022__11:53:12\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 2.1419495, Training accuracy: 0.2296875, Time: 06_05_2022__11:53:33\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 2.1390038, Training accuracy: 0.2306443, Time: 06_05_2022__11:53:54\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 2.1364924, Training accuracy: 0.2315816, Time: 06_05_2022__11:54:14\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 2.1338815, Training accuracy: 0.2323232, Time: 06_05_2022__11:54:35\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 2.1314273, Training accuracy: 0.2335250, Time: 06_05_2022__11:54:56\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 2.1287021, Training accuracy: 0.2344802, Time: 06_05_2022__11:55:17\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 2.1257400, Training accuracy: 0.2354902, Time: 06_05_2022__11:55:38\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 2.1232119, Training accuracy: 0.2364563, Time: 06_05_2022__11:55:59\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 2.1205590, Training accuracy: 0.2372837, Time: 06_05_2022__11:56:20\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 2.1181456, Training accuracy: 0.2378095, Time: 06_05_2022__11:56:40\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 2.1151622, Training accuracy: 0.2390566, Time: 06_05_2022__11:57:01\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 2.1127296, Training accuracy: 0.2397196, Time: 06_05_2022__11:57:22\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 2.1097139, Training accuracy: 0.2409491, Time: 06_05_2022__11:57:43\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 2.1078209, Training accuracy: 0.2415596, Time: 06_05_2022__11:58:04\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 2.1054144, Training accuracy: 0.2424545, Time: 06_05_2022__11:58:25\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 2.1022925, Training accuracy: 0.2434009, Time: 06_05_2022__11:58:45\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 2.1002476, Training accuracy: 0.2437500, Time: 06_05_2022__11:59:06\n","Epoch 1 of 5, Average training loss: 2.0996534, Average training accuracy: 0.2439333, Time: 06_05_2022__11:59:17\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86d1ea1a000b47a3b901a7d6390e5361"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.7309989, Validation accuracy: 0.4075000, Time: 06_05_2022__11:59:22 | Loss decreased from inf to 1.7293160 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.7528904, Validation accuracy: 0.3900000, Time: 06_05_2022__11:59:29\n","Step: 300 of 1250, Validation loss: 1.7488454, Validation accuracy: 0.3916667, Time: 06_05_2022__11:59:35\n","Step: 400 of 1250, Validation loss: 1.7391092, Validation accuracy: 0.3943750, Time: 06_05_2022__11:59:40\n","Step: 500 of 1250, Validation loss: 1.7432625, Validation accuracy: 0.3940000, Time: 06_05_2022__11:59:45\n","Step: 600 of 1250, Validation loss: 1.7330499, Validation accuracy: 0.4020833, Time: 06_05_2022__11:59:50\n","Step: 700 of 1250, Validation loss: 1.7315883, Validation accuracy: 0.4028571, Time: 06_05_2022__11:59:56\n","Step: 800 of 1250, Validation loss: 1.7266894, Validation accuracy: 0.4031250, Time: 06_05_2022__12:00:01 | Loss decreased from 1.7293160 to 1.7271185 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.7235304, Validation accuracy: 0.4027778, Time: 06_05_2022__12:00:08 | Loss decreased from 1.7271185 to 1.7236331 .... Saving the model\n","Step: 1000 of 1250, Validation loss: 1.7279494, Validation accuracy: 0.4027500, Time: 06_05_2022__12:00:16\n","Step: 1100 of 1250, Validation loss: 1.7311929, Validation accuracy: 0.4027273, Time: 06_05_2022__12:00:21\n","Step: 1200 of 1250, Validation loss: 1.7304387, Validation accuracy: 0.4016667, Time: 06_05_2022__12:00:26\n","Average validation loss: 1.7301463, Average validation accuracy: 0.4006000, Time: 06_05_2022__12:00:29\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9775c7bea58c4469a2f69c1a9b410e9f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.7689699, Training accuracy: 0.3575000, Time: 06_05_2022__12:00:50\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.7962476, Training accuracy: 0.3562500, Time: 06_05_2022__12:01:11\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.8190033, Training accuracy: 0.3466667, Time: 06_05_2022__12:01:31\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.8172240, Training accuracy: 0.3481250, Time: 06_05_2022__12:01:52\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.8133751, Training accuracy: 0.3490000, Time: 06_05_2022__12:02:13\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.7989827, Training accuracy: 0.3516667, Time: 06_05_2022__12:02:34\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.8051714, Training accuracy: 0.3503571, Time: 06_05_2022__12:02:55\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.7947222, Training accuracy: 0.3509375, Time: 06_05_2022__12:03:16\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.7948665, Training accuracy: 0.3497222, Time: 06_05_2022__12:03:37\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.7922810, Training accuracy: 0.3525000, Time: 06_05_2022__12:03:57\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.7924361, Training accuracy: 0.3536364, Time: 06_05_2022__12:04:18\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.7876947, Training accuracy: 0.3545833, Time: 06_05_2022__12:04:39\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.7818110, Training accuracy: 0.3575000, Time: 06_05_2022__12:05:00\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.7829810, Training accuracy: 0.3562500, Time: 06_05_2022__12:05:21\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.7863239, Training accuracy: 0.3558333, Time: 06_05_2022__12:05:42\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.7905833, Training accuracy: 0.3531250, Time: 06_05_2022__12:06:02\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.7898689, Training accuracy: 0.3530882, Time: 06_05_2022__12:06:23\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.7880111, Training accuracy: 0.3530556, Time: 06_05_2022__12:06:44\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.7831670, Training accuracy: 0.3552632, Time: 06_05_2022__12:07:05\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.7826380, Training accuracy: 0.3543750, Time: 06_05_2022__12:07:26\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.7813307, Training accuracy: 0.3528571, Time: 06_05_2022__12:07:47\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.7831901, Training accuracy: 0.3529545, Time: 06_05_2022__12:08:08\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.7823422, Training accuracy: 0.3542391, Time: 06_05_2022__12:08:28\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.7835504, Training accuracy: 0.3538542, Time: 06_05_2022__12:08:49\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.7792532, Training accuracy: 0.3550000, Time: 06_05_2022__12:09:10\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.7771185, Training accuracy: 0.3553846, Time: 06_05_2022__12:09:31\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.7739409, Training accuracy: 0.3574074, Time: 06_05_2022__12:09:52\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.7731791, Training accuracy: 0.3574107, Time: 06_05_2022__12:10:13\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.7708846, Training accuracy: 0.3593966, Time: 06_05_2022__12:10:33\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.7711804, Training accuracy: 0.3590833, Time: 06_05_2022__12:10:54\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.7700187, Training accuracy: 0.3600000, Time: 06_05_2022__12:11:15\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.7679439, Training accuracy: 0.3605469, Time: 06_05_2022__12:11:36\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.7697370, Training accuracy: 0.3597727, Time: 06_05_2022__12:11:57\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.7697523, Training accuracy: 0.3592647, Time: 06_05_2022__12:12:18\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.7673357, Training accuracy: 0.3596429, Time: 06_05_2022__12:12:38\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.7679307, Training accuracy: 0.3586806, Time: 06_05_2022__12:12:59\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.7684586, Training accuracy: 0.3597297, Time: 06_05_2022__12:13:20\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.7674717, Training accuracy: 0.3594079, Time: 06_05_2022__12:13:41\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.7664886, Training accuracy: 0.3599359, Time: 06_05_2022__12:14:02\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.7650987, Training accuracy: 0.3599375, Time: 06_05_2022__12:14:23\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.7640231, Training accuracy: 0.3609146, Time: 06_05_2022__12:14:44\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.7616341, Training accuracy: 0.3621429, Time: 06_05_2022__12:15:04\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.7617135, Training accuracy: 0.3626163, Time: 06_05_2022__12:15:25\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.7593119, Training accuracy: 0.3629545, Time: 06_05_2022__12:15:46\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.7561632, Training accuracy: 0.3641111, Time: 06_05_2022__12:16:07\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.7550904, Training accuracy: 0.3640761, Time: 06_05_2022__12:16:28\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.7539552, Training accuracy: 0.3647340, Time: 06_05_2022__12:16:49\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.7525665, Training accuracy: 0.3657292, Time: 06_05_2022__12:17:10\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.7517286, Training accuracy: 0.3657653, Time: 06_05_2022__12:17:30\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.7532222, Training accuracy: 0.3657000, Time: 06_05_2022__12:17:51\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.7527434, Training accuracy: 0.3658333, Time: 06_05_2022__12:18:12\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.7525852, Training accuracy: 0.3659135, Time: 06_05_2022__12:18:33\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.7518821, Training accuracy: 0.3665566, Time: 06_05_2022__12:18:54\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.7513756, Training accuracy: 0.3667593, Time: 06_05_2022__12:19:15\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.7508628, Training accuracy: 0.3670000, Time: 06_05_2022__12:19:36\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.7513128, Training accuracy: 0.3671875, Time: 06_05_2022__12:19:56\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.7498346, Training accuracy: 0.3675877, Time: 06_05_2022__12:20:17\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.7483499, Training accuracy: 0.3678448, Time: 06_05_2022__12:20:38\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.7465314, Training accuracy: 0.3683898, Time: 06_05_2022__12:20:59\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.7456891, Training accuracy: 0.3684583, Time: 06_05_2022__12:21:20\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.7454101, Training accuracy: 0.3685246, Time: 06_05_2022__12:21:41\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.7440502, Training accuracy: 0.3690726, Time: 06_05_2022__12:22:02\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.7431971, Training accuracy: 0.3695238, Time: 06_05_2022__12:22:22\n"]}],"source":["#-- Parameters\n","epochs = 5\n","\n","for learning_rate in [0.1, 0.01, 0.001, 0.0001]:\n","  for mom in [0, 0.3, 0.6, 0.9]:\n","    #-- Freeze the randomness\n","    seed()\n","    model = vgg19_bn(pretrained=False)\n","    model_name = 'vgg19_batch_norm'\n","\n","    lr = learning_rate\n","    momentum = mom\n","    parameters = 'SGD, lr_{}, momentum_{}'.format(lr, momentum)\n","\n","    #-- Initiating a tensorboard writer that contains all logs for training, validation, and testing\n","    tb_writer = SummaryWriter('./models/CIFAR/runs', filename_suffix='_'+model_name+'_'+parameters)\n","\n","    #-- Create the model's critrion loss function and a optimization function \n","    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","\n","    #-- Train and valiate the model\n","    model, model_save_path = model_train(model, model_name, lr, momentum, optimizer, epochs, tb_writer, parameters)\n","\n","    #-- Load the best saved model for testing\n","    model.load_state_dict(torch.load(model_save_path))\n","    model.to(device)\n","\n","    #-- Set the model mode to evaluation to prepare for testing\n","    model.eval()\n","    model_test(model, model_name, tb_writer, parameters) \n","\n","    #-- Close the Tensoboard writer\n","    tb_writer.close()\n","\n","    #-- Delete the model\n","    del model"],"id":"T8zoxXiCJkKV"},{"cell_type":"markdown","source":["## Part 2\n"],"metadata":{"id":"tMvhEVVmLg2J"},"id":"tMvhEVVmLg2J"},{"cell_type":"code","execution_count":null,"id":"VAxuqRhq_Doi","metadata":{"id":"VAxuqRhq_Doi","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b137ab55f23e432e8394affc3f50bd1f","fc09d94cd83b42f1815d49c74134c9fc","5b8b7702e9d847a495ad9714a74abe49","57938843310c4c648f5832966b8a4fa5","452673977a2742d0b312947537e6c34f","78dd519a322742aabe2d402256097dc4","221af145d3c24e27857feffdcb4a50a3","dff6b9669dda418e9a6eba4e1af388db","4aee99d1acd34c81907c6f5162edb983","470db9784fe44ddc9353eda8ea70587e","be1277f684a34a24901a9dd2c4a8a893","03ac0b134a764af6b5b80ff19d0100e8","0b34f243c6614bafa5fef4cff969722e","580e376261c24b51aea191a9e069b468","56b4aa4f189948aa940a521c1f1f795b","5710be017f204824a6e92c385490285e","2e7ca0bf6b554609b1cb8e2145f4b826","2a36aeec2a71431b8b41764f5cfe0053","0be1584170e14cb893315f5a087973e3","95168bd8dfcb4a27953409bfb75d6705","05160d507e8d4c458a0dc0e8b0a9da7d","332f5f1c4cbb4d45bb2d265e28cf873d","db02b24dcf3c4489a222d46a3ee3f923","5b3c77162db749a887212517ae7e3d74","e76bec898eb54d13aed62a03f5341b06","f16757e6791a4fa98c4d7de83d3b446a","7935b61f5b4d4087a3c9ce25eef7e514","ed674e76b2904f0aa3b5ee8087000d60","1b54b40371d240acb401a88cfd9922e5","9359b3805ea54cce9dd32ba0d2fc7ba8","21e3860ec39b469da56c1b278e6287e8","73600e2a97be4999a9bb6a4577ab8acc","9e8cbbc36b4a47b7a53de1cf7c4a74d7","15ccceeaf8d440bea1f11b629fe49ab9","443e3af5ae7e46068f140a81dd7e0189","9fea46679d6340dab7dfaca2e9e002e4","318973bcc17444fa913b260d90c66a10","a40cfe6868bb451c88fc56b53be8f706","10aae37109534a13a0ce75159a0b1d21","e97d9b2615204cf8bbcb4b2afeea89d0","52f12c1210c54783ae419183c804c852","d1f8c5e4d4e24d109803ca6a8fa9bd9d","dd3ceac13d174e21907ea9b838043730","826304450ba04384b9d0b06228004414","c9919ebc356a4afc8ec99152faef8079","e19c4e5fecd445e59594e433e9719ef5","8c9b1d97469c4b9e9d280db3eabca13e","f00b3fa2f9504794a8b205593b6122b1","daa04796c55a47dc88297093b88a023a","e1285303134d47c69465b3f77a6e4fd1","04d1c90925174d59b9786cf135bec4f9","d1fc6bf2ead441b4a753d2061bb1368b","7888814373544dd586afa99f640700d4","8f1650b14da54697a5bdcdc777231f1f","f673a15872794d7491f829fe2f3f76da","fc83b7b437a544baa34cd352dfda80ee","86b28039aa3e4d37b6afcd866e97f457","51a1c8f4df1d43c7ba24f875db1ea8ff","da719d513f2d44b3a0fad66303a0acf6","b4fd352d6ae5459e9e418844633f5c3c","929a29b2a21e4e9788156260cfb13189","47cfd447f24c48a2865ea9cfd957891a","7effcac644a0410eb39df559c374eb52","06a4c3a60ca54249abc7ec73211201b2","cf666d69c3de41c8af46973a39d55853","919eddf6f91e430dbed135622cf46ab6","4008122cd1754742aa9355b2c49705c2","4748990e4fd3461f900f06907a483b1b","7b1fdbabbf1b4e37a61a2bd05a294764","d544a60c439b4da1894f4b95681f0069","b90eda56b91b4891a81092e01dd48093","e394b3791fbb47c9948a1cf15b61ae5f","fab207a24bed415b92bc2ff7c9bddae3","a26310e1928846bd8ecc8d19126f534d","2223325959df4dd8b16a9e6c2182dc0b","00d9e43c358246f481ae09823ab4507f","b861fb5970574db08f900e642d685547","10d4c3071e2941ca9d40cae0b1ec3c32","854e6d2d192b4e99be61e5cea6b7eb75","fb502c77b1334ac7ae8f51111345390c","4f093afc59204fc1938f1fc0d5e030d3","4f8b20b001d54b63a359624a5f80125c","7c235f059666460fa58dd8a1bcc3d84b","9903a845ce454dd89c85251cc3b05e10","5169a78ea6c4493f8b8eab899b1a835c","21e620c4e4c149dd891cd47de4d72770","6b244cf5687c449bad38dd9f018531b9","5c2790f1675a4db4a8be472a779f3528","58ba3412a4bc4c208e8d67416bfd47e9","42f43542482645b9b3e5e01bf5b0ef06","83d8d5753f6b4d1e8f9a66fcf4f4a359","a08749c412ce41eaafd410016ce1fb73","0679e3eca6d943fca5fe29b1c174f05b","64188c70a0ce4cbebe081b696fe23ab9","e61c8db1f22e4fe5a6732e0f36862eb2","1544f6adcd5d4b119f7a5cece6b19c76","a16d1d81698c4ddfab51bda62fa4cdae","3b33f9f7048c43feb7781df58e8a777f","42cf1a2235c54c26aaa7dc5a409f0aea","c8e83ae36f6a4365a1e83060fa5fecd9","fb779e8fdc764e11bda870ccee0408c9","646532c313bc4d119f1088ec89e8ddd4","38a682a57a134a6b84e5fd7c269718f7","a4e902128164461bb1b87c55a2e20969","7bdf1dd8e9dd4dbe8c552c440bc1ac1c","ae1a6ddaa75047719229de705063bd7f","ad732eb193424e18800db01a478085f8","0c75d583aea84190b36e1fa6bb9a317c","dca118fbe4204016ba5be93f8481764c","e04139901dae4ddb83a0d515cdd8044c","9ea03632c23842928537a99bdf0db25b","12e6fd3147394938ad582e9a39abeebf","844523e8f3184cae8679cb57f2f31a2d","36f8e7f593384911a86e1c79a91f14f6","b82e204dee3143b3853c65eabd5e259d","5e18b178d1cc44ff9960ebdd8c74b55a","2b9371ba2fbc418f89793710758ca1f5","ec98065cf827422d95d55db57e9664b3","fd8932f1bb3f495599052d7ed08cd706","b1045460e3bb4a61bb5bf0833456beec","4ef2bbf66f28445fbb02e5e3b935d93d","fc211b40720c4a6ca2bc1be418e9cc94","4eeb959d1062437db3d82fc46d9f1b4e","ce0d2d358aab483fb7041b631d977d3a","aeff6114af804101b98da1b3abba1bae","ef6e685a3b1e4edba2ff575e9ff6097d","4df332b5b6134f24906487309e3d4a01","f6684cf949464a0c984aa4200b1622e6","9cbf394aa1894eaa9509d373c676919f","b87b426dd8c24b84b246443dcaec245e","61699ee2c0484480b44d7cb0866393bd","b106d1ccf897494dbd506ce94a4cdf38","16371885b51d4bd8b7462b4c95da242a","ba3f2fa5e3cc47b0be434f5a34e8a588","16c9b8b7c93146d9b4a40bef37509c36","5551f5880ccb4aabafb8ca0a28d9bf12","c15f394fbd664dc089b81d9bab150559","754220e5b81441d7a06e4f244db687b7","482cb5d948ba4e70b992ceea4b690c64","3cd289e7c50f43c1b97c6bd62b5013b5","da317a65ee9d48b0855bfc5c7de00b25","1ac1eee1b060459881e64303aea17152","c5c3428a0c44423fb6b0ca9aa6fdec69","5a5a0d5431c54046a998ff1484f6ed13","8b32674b494e4826b4bc6d5dea7f8f7e","661c93bd7d9d464aa8b3d965b3f72ed4","617d7a91bd4e4a80af51b8c6b899c90b","c26506bb2b0c41239c5278c97ab17c6f","cae4857863f948059f256aea0bd95340","05ce4de9c3ac4db19429c98a31fe3128","8d092201041d42aab7155a2cbca24e91","ae366fe171fc409889eaa0438c167ff7","56e68ece4332473d9ac7c63fbd899c74","4a1e45140f4c4df6956f010d6258a08a","bdd0091d200a4725a28027ca23972336","d584347b8b894fd6b13c64f46a23d76c","d85e92c5762f49f28bbaee27b9f0633f","447cdd5b087f44daa1b72d227eaf7191","3cd014b0b51e4415947132c2a617ccff","cba178fe12264ad9bee4dd57abc1a5f0","68dd18b3e0ac4730bd7d0e9060c1e1d9","249af08dd24643b889b63851924cff56","c91b67e5a4dd487896038e45d1f06d69","bb72e1e70b7e45e3ab50040362cd2695","65a3c724b26b470eb20e5695c41b45e4","aad8fc5e82644f83b9b59c076f34d7e6","db046d68c3134c7280d06e0783a32fc4","e21c1045b717432c9edaf96953c163ab","714b4015fab1447f9e3277c1a6bbfcbf","cf47ca87e1d54d6c8f699b90106604d7","1508ce305012454c80d8744b667c67f4","81f5194024394b8cac37a46225444b5f","4b793d055b6a4266b6c221a1cdb49bb2","df42d35c6e6b40f9bd4be958b0468c7f","ba91591f84f84a5eade16dd2f935f0c8","a36497eb02894c5ba602aff4904215bb","2732ba59aa5a4414981b1c4f4c4d83ea","f450e415a9774334a88b00a94c17bb6c","83db264293da44e49f57cf46c7090253","7a39156e95514c9ca522e6c06d75c11e","812279f190bc4a03ac12130e059a4ac5","8761039ccb6743f8a3680e6341c16df8","e681cb8c22774b41a3f1a2b56f6fc935","30601e539f724fb5b3104d1f0298374e","504171dad4c54b1cbcce27d4593cb7c6","6462f5180e7642c9b01dbe0208394f1a","0834d667a88c47c6ab9b8cc92e0433bc","0db87686a8c045eeae025bc41287933d","9f48cc98d78d4a5999d64776b19485a3","c2bd6d4fe10d484d9d9bd66f55ebe80d","b477248e9366419bbdb5c4631b5828e6","fcf30655c13f4c6181495ad45500922b","f1c598f03b1043f499f3fafc2d085d84","5a7081e0b4ea407984a7b5b169eccc98","5b55483d31244708a919a7c9fddad8bd","e356910e1e00499ca3e9f6f3ade9946e","e01835ea96ab41e4b07d16fc14ab8b33","18f14e151e7943e8a8710af2bac73a96","9c4d8ea2bb58491490d588796541ee9f","85a346d032df4581a758b98bfde069c2","395ee44c2181492090c326ea38dcf891","291fe0eb226d4195af3c7371133ac8db","0767a9ddea264849b9103e2f15f59c96","d4ca4b242a484cd080b1f6c2dbad91af","a50939b46435413f8d97692b96ea12b7","c144eaeb2eb34c3791af70fd5c1862d9","13e2c4d78b5145fba6f43be687de85b6","2bd968874bbf4cacaf56687ad1bfa2ee","571fce62112f44d796d42de4e13413e6","f11fb58c50ba40478d8f8b4d3dc6c678","7b4600fd824549289cb012508e3b5029","2f58d5305309493fb835d058dd58dc76","64c1b1fb89904c859e46c23412b8941d","818897db4df04344b758c9d4900ad072","de223909d749477f818e8ef9f16c8a26","11247a21d9284fe2b1a5364e39a0e6d8","fa23da4a290a49cc98f95ad085d8459b","d178ee02f28244f3b54748e9f82a39da","d5d7a08ba0e845cb89395966e919f84d","41821533da57438c9f5668cfaa813727","0061ca8f11b44527bc04c67e53254e57","6eed5e4e5bd84a0c90aed51128ff7164","4787410bb7b44440a94fa8a6946ac52d","e36c65689e3747989197eba50014fd8f","677947ed8f284492ac93bdaa0f02b612","6b9382460d104f6cbd056d7e3b3a94ec","57a3bffa55974445bec8ee8ece38f607","f6ba29532d17472da6d1d53e8e1cdd35","7dc406cc8a97427987e3a49db7100a79","cda5033a70814c4d9ac1ff52b84f71ff","9af518e92d094809ac6ed0932bd2b9ea","4a168f90c9d9453881b8971f76d90942","2b320f15d29b4acc8bdd0a93b6d17904","2925b21bc9974663a4f6ee4d97790887","cde3e003d9e64628a0a1612c3b7b28f4","1fb14c3193714e809040da3eff6b119b","c6e85c9d3fb847e8bf2289d3e4a62c52","d495c71117eb43f7ac165b3f1c11d657","4b3a405b06954bafa333c41140b29d52","bad327727a21494e859d53054a2c59ae","25c6d2a0720f4a6e90ae1e5a9a784166","d6275172d41444dd8504d6bafca1cd6c","15e034948c0b45488d4b0c9b42105628","4d9c7e38097b4f4fae5e75a49e632eae","69d2108eb0f94306a8c1447ef6ddf644","c202e9b42ce14bf09915d279a07cdda3","0be6c26da5254262be9d5a9519ffd508","bce7ed908d7e4507a2fea1c8028eb9fa","6b9006118d884161bf9da1ae99547874","c1523a22c4e74f6bbadae4f69057975a","a542d289065d41f7ad15dec51fa5c467","688146ea3f954cb5bb108078128f9abc","a067fe09641e492d8b08e64610d14c7b","8bba9dbc3060437da8c6c1d9bda5a8ba","a45f95d1408641bdbc8b633cf9c93ce8","6bdb9b2228cf4a82947c5d3ede460398","2f32356db7d64f909ee782b1e744fafe","bf226838ea13481ea90b871cf529c5ae","d78d837ea1264487adb013d032f6128b","e8f6ca7617b84bdf8b64808ca1dec30e","8dd52fd934e74bdb99e34ba801876493","b552957995d949beb4f9e85ed1036f13","7683e8f501eb43e490322bff82bdc99f","1144ae41a5c24c3c88951db7138d46f3","591d28d4c44b406692bcc443f0a2ea83","2ba9e7b9ed6f45079674ef49a0af6569","c960982ebc8b47a0b575a52eb6e4d755","08152c3a01074eefb09cf0815855249e","10068dd373dc44a6a53ea9b566a273a7","e13a85b1948e4b869ddcc8d36a83a86b","f37de2fba4dc4e5793177cae2fda4f85","4c081e8700fb4d6880061707dd7c4328","920ad56b4cba42139a3531a36321265e","827ee04103f749039a9a2b7a599e56af","5e87f076b94a4bea927857ccc146c93e","88b2e0a6e0e94c9aa6b5d3c2167af601","3104a86693bb49bf816dcbdceb0d1870","1d60d0560a66426a91ad5b24c5c73b6d","6e91f3d738cf47f391bfa69006a77356","1acabd04c44543f881503727f805efe5","29aea2619b72461e9ba8e90733c29a30","cc64f5b4eb5741f4a9ca014a04a60c24","99a980a96cbc4a07a1ee0afca9d844b8","b20150f327fb42e68a1884ae318d54aa","e66fd8486c474ac4b4df80ba8ef41884","f4b78de041d945eeac51644bf4270f76","ef5084e78a0f435aa76348c681447f0a","e0340de7e4374f13b9feccf43e73a8ff","c9f7452d0e1c414bb5880e789918d938","cad5696d607f4ddbb4f6501060bf872f","9f780510bfed4f84b365cafdfbdfd754","0f8556d570c24e94a295c8e6ff4fd440","8e42de80fa414f7596e1d1acfd83ad4d","104efedf54b842a2bde784550010a093","487733aab4c24d25abccb7f26e71ab0d","c53b32f140724df6832b34f86e75ab5c","c18193c337cc48c39065cb561b34cca5","97fc13ecbad04413a2b93731f0393119","01bd70a936b5432280e4f281fa1965da","c985c0c8ba2f4e79a51d7eac9d317618","e720a064c0d040fe8573c7a44a33eb9f","e4a8491cf80141eea499d12aebb5db06","0d1367e2634642e19a52caeb68ed5edd","186e64a9c86e4386b12d722d3dd8f5c8","2c31c0276d9e4fb795241cfbc89ab95c","af769834ff324b63a157d6f422105b6e","a90deebe4f9e49c09ceef164157f4bca","6c454dd6150e4dab8c0f8a88dba3e7fe","3cc94c65663a468cb42833ba818a6435","04c2092b70d243f2863dbdf61d4de33a","01da0fad9d334b10a1aea516b067bc7c","2fc083bfdd0c463c8b7afb30c930fbca","16c0061323484810a5c74888748030da","859d0b0cfcf241a9a28f2a7db8f6654c","f51c0297b3644003ae65aad6fcdf5a6d","bc20a7d103014f309b3a78dc04dec157","ca99f5ade6f94759834812554a7b78bf","a48501ce8a6444fda0b1df6af6624ae6","8280ef48ddb14524b1eb3680d7976c72","54228c6911ba414580c989d88e235a95","45aa5d38a0884ba9865936bd1a7f29c2","e82339d5169a460689d6903788905fb5","2d286314f585469bb860640e46b271b8","df922521148d40798fdbdc7133d21eae","24f8c29fb4bd4ff6830d22794674b1c3","a3d998f827bc42549aafdd672b6544ba","93f27479f0194296938eea4fbbb6cef7","81863519ca60408da6a8ce14b1d9955c","dca2bfaddc30467d9f6e908e8bb34856","97411f6ec50240c6a3b67ae1761b2cc9","77257646902f43228469ad1464d9b48a","1fe76b7a863940bcab9f2cb1171cbd23","4214213d8a364bd8a91a16d3b617f5f3","8386d5334839491a9e7480d418724fde","ffcb41b1bdb44b67a50dac28e32c5252","dfaed932c5344d12800a208ac22010cd","e9259dfa91dd49eb8ecbe7e419852dea","4b44e674e9e045f89d1280dcd771b3db","66cb272b2c6b485497fd5d8eb0627cec","bc70285febdd42d7be1b0e18045dc104","ba7fea0909f345e696c45a579556facf","a96a0bf68aa445b2b253f55a099bef14","7dff75be2a0a47b0b395606da87a6731","1ca752587f7e4534a0e00e095d0c5dbe","1585e37b3c294b09a0720a763fa9a104","fe13dc73723042a88ef4d04a6051c2c0","6afdc798dca34e6dbd19ed3fd1014207","4875768f44544df2bc17d5cd1b453bd2","86ed0a0220294000b9eef7f385ed9dea","71c38c19f6484321a1bf38988b84cd0e","b3a842111f7e4d7c853722e8412283f0","a34ff9ebcbb34333a9f4b6336866630e","2ccd8bed5b904a86b88b1ac378df2e6f","945462a8c8d347318af3e8385714df5c","8688400a52e247fbaa8bb9e0958a2605","be90f4b669524fdea9b3755eb87493da","e3e8b307281d4ca8a13098452d162c4b","79a45f532dd54e278d12bcb8be34813e","200bb7e238a64f8baaf114524c39ddb3","990b09d4e08340a8bebe05f774811d1f","b623a00b213d4d5e987257f56d80ab29","7d65bc777e0942f39101f2b7ea9fd67a","d7b4a30c8bb64f7896a8bf535f1f5af7","3c7868dcad1a448ab0ad99e09d29b475","f73c74616aef4aaca3f92e5512b3638a","61fcc3f5644943fc8c8076e065ec6aa6","4cad372a00ed47cfbe4a6f593dcb8ef6","c95d8e281e6343c3a737b5bf47ab760e","977de746c6534be081e46d8143f05afd","6ad4d3e9aff64aa79a65b400fe937937","7e6bc15251d345bbb60b3326313f4162","9aaaae3f7a3b4759b83aa29c25aa3d38","0a92ec19967c4e6f993291fb1d37e52d","50c13715b43447a3826719a5c6a14ab1","48a9571be6cd478cb05ed546a0f77ec6","78527103db9b4e049d3fc19f73b18cf5","3d5e22766f5048628847c6fee3443a16","7b0d2b6e096842029fbd5f2a0893896b","961637a87d0e4512b83c98d523341d03","5978a6029f8647e9a8132b776b931354","6fd6cfec48354b7ea751aa43149d07a3","bdcbac8fd0ea44d3b81f4661da3e303d","c47ecc9da58b41b7a903e12cdec8f348","1b35fa6ca9684b42ac955ad689a76952","bd780b9fd0034df09656944d19f40dc0","68c8fe144f8b422eb10b5715d88fef48","5d349e44d2de4158bbaf8272d8a7ceda","9f9f29566cfe43b4b22dec156f46d101","f5aff0437dcf42099b3f93f1170a9d55","36220c67290743fab933c7b80db0a6c6","bc28e34725c04597a44c2a7aa97fd51b","d517b17388c947208e480d732161df31","367161e6664e41cdbdc03e96df67d030","5af30103df844111b96df3f80ab61d32","85026770f4c34d418cd270bbbe85872d","307b2eaccac645028a5770a5de1ed525","e1de98dffa1841968378d7869c2bf78a","6481d900805646979ecb68fc0af11ffe","ac9c76a4bc3840748ecb5e50a77c9c11","8bce746496c94e7b9be8b561351f4a6a","e67fb7f081624ac8844bb14d844e55ae","952d57fd4b444f58a074370cfee296df","0a1ebe35d6be4fcb9b0936cc5c487cbd","a97d1eb145194596a512a66d97e60997","c6f099f0a5e64bfe8eb6f4d3d7be021d","3c8e01fd75e54d698c6f0e9c2170be39","4f640e8e7ada45269c05e27a4f3e87ec","4a911299bdc34a028f24e7db71c5e232","723d2d2ad8214c2c9edc05aca467f10c","c117bb7adb834dbc9c85b62c3d1f06db","f9ce76722db84dd9800845a67be33dcc","d8783733aba34de9841782db810bfd7a","48b028f67e994871852a6b5c2de509f9","9f3223695ed7436bbb25c0fd2c1904fa","77f917ba72784b648b86aaa1a15ce614","b95e2e767aa645a3921e4f7448bce73f","00ae29b37d5c42228b2555b20cc072cc","dda355cce9f44ec3a97aef24fb33843a","ab76070935834008b0c56f9bb8e465be","671d607cfedc48ba8891a8d787d9420b","1ab0c6770d4a45dabcfee719f89ccf4e","daf6d43b0e06497a9f543b7eadfbc7e8","21894835c2c149abb18ec48ba6059779","07aef66f4f68476cb629a62adc03ac03","b03568c3144a4f138d83331adf3a8223","0072ad6860c84b0982762a77727b1725","1dcc37d3b04f46968bd182d62c946a62","4f3ed85d335e4f38bc07e3ae499d2e3e","d5f04c1cf34c43088bef52238eb219c6","2ec18c0f2aa84e6e85a06c24aee4a6cb","b11b45ba7bdd47afbb4a4f7bba1a7f2b","d23fa5080b4e4ff08ef15c9f27601f1e","23a30e55f4cc41358f2ab761177aeea0","92823f1e90014aea881f9a1b8fca955b","1f67f499c8514e98a352a089dd1330e0","9e4b1a2f0bf3458dab4501283e4ce4bd","e54bb091a29e411ca841d16bf9a7b7e2","f19e960dbb324164824f103130ce1a01","85100766c7304d33b2c087da09b3c3a1","80aec800626f4baaac880c56f88a9747","42f8e6c0aa4c4e3a94e804722788dc90","8835a2a6826543c39e9ce4b3148973aa","4404445b3b7942a58dc09b4f1db02443","c0f7aff39d1a438b96616e091081af76","91b090b2f16143e19c6c2cef75964c6d","9f4c3ad96b664096849da61176e19fb7","96c438b296e847faa8b0858151d8905a","4236581690c54480b0bd8802a69c759f","fb127c5237b543e5b9c65f96e3038120","b1e3207fec794c3099277eb028d6e37b","a624e0fd368f4c648253a2f5322ab345","a580f946fdc443709e7594c4d878f7c9","74de04f4a78e44f7a3f9aeffdb7afe96","4313686751164d3ba7fda7953e0c64ef","79a27e5bad1b4e339dabbbfb36a3f3e0","5a21fa9e75534daabfc34d803b1015f7","9c5f211abd394d8cac941c611cef53b5","ea126b0d63b14ba0b1d7de436bee63cb","96d00656da434fbe969b162930f1acce","6da378bac40941d5b108af255a466446","02552448cdf549f0b98b0130a80f7a31","54c3796f4519423ea7793426f173f065","0e803f7144fa4786b9079bf276fb8e71","1e4d540b06d14e77a7366c0c27c778a7","81a5673ef4d3458ba285d3602df197f2","525eb116e33b427fa9f714e386ebc69e","0e63d35f604643a6abdbd0e4a168f5bb","d13a7cb55c3b4ac7b9515577b76a11e6","e05d678547014318946f9f2e224e20cd","2d7becc2c9af454bb08efe183f0fa17b","c600b0269dc54307917069685d9f200c","ca6a838e9ba0411bb26d469127cdbe08","d46a00d45a29480ea57965a75c3d8bbf","f902b17ae2d948818d03e25e9602fb81","43fb350e29704aea9969cdfd50310f35","c8c9a9b770454f83a616e9259f05322d","dcca604792234140ad9995cb7485d3b1","fc406f11e32743a1a39c97d3aa7d9169","bb9d308d0f434bcf83110a07b14dbb32","9d178e12b5c14bac8f71fd3c0cfdf372","080d0a5b8b8d4d5b9ae9f18a471a603e","c0810f5f755145ff91a3fe4670ff14cf","fd9c6c1276bc45cc905c558d3f721159","fa63b2073f0a48a6a1ef895ce06acb4b","92063a0fd32844899ded29d36b10050e","eb85bebd600d42d79946c4ebb87110fe","4337d622c0cd47b59736d4c82bd121b3","6104efc61e064d3fa102742912a12ebc","9d12a00f6f3f4657945ced8e0ac5bdf4","ddfe57d909c04ba3a1b7d4a46a66283a","5e867af739fe41b987d774339682f899","561f9d7430f94d72b6e8b4cf80aec0e4","2e97a2299e8c461288bdcb79da610edb","278d4379834749a48c60119a21726c48","c8ff67b1f3b346dc935453d605a88edb","e8763dc389884a2baa867712da03bca9","2f9b554b33f44bd78ebb72c29868c183","23f5550f4bdc4f53a9ce792686c92e9f","d39e0010aed7474294835eedba55efe2","e5e76a70b90b4edb877fc51739c5e159","43e75373b7044f638358e840cf009a87","dd560becd85541279f65b21de47613a8","2958af2d5eb3452785c6f2870e2c74ba","f888d15235dd460c99b7fe7d965bef3f","8669bb437df7464a9d7da7c583296440","9c2f108181184f1a8d57cc3b760045d4","b1e276799585476bb41ecebf66d3a04a","87f9ffce012a4d0bbe4c95c1e6490cef","9c376f293bc24f88b334149b69a40810","c78ecb2d075d4871b413e26997817abc","7cade2e6cb4147e3a67445ab83be689d","80bf8a964a3248bf97376e07135d961f","3ccd36ef8a464745a0583da299ddd3bf","0634be87228e4b539c27f455f88a8ddf","efde767f445f44b6856addc6c88c361b","777c4480550f47f7b504c6422d6d31bc","0c6d1d72c076463ca412f395dcd210ce","01765cbe201945ae84539f584847ace4","71637189905c44d4adb547be62c2a15d","d161083b58534121a1478b49bb163fe4","10bab8ce38724cd9b0a1ff4a6ab7a066","56852ee6401a4c77b9cc1dd686c1c954","8b1a4c2a88d2436eb381b20edb1731ae","7029217fab1c47358806c810faa7a997","92c43838546c44ddb0f28835d7a59738","6c77abe8f34e4e0f86152c7ba4e1ddda","ff220babb4ec467991f5ae555ab29c47","55c7c4e4eb4d4a95a81cc95347801240","fa01ef68dd1e4ea399b4a5cd21076492","bbcb353588b24f749537b1dc0192f48e","9f5b47faa54d4064834843de9e7cb60b","fd66977905144345bf929c2156a237b4","919b809f294140c6883f634cbd4c1d0b","20dcdad3faf24825af52299d4b1ccda3","59551f855d3c4fa8be70647106e5b66d","ed68349fcd9b44c1a346261134baf746","219b6c39c8de46828a7404e3e35d7f24","e3327e7fc3e640dc956f07e2667d89a0","53c6555d23b540a783c9dde944bd3c73","cc8c02a59d00495daf786e9e5b5e9379","66c5da1965594655a5e0ef606cdf329f","322ade7011af459bba623cb4235cb89f","7d1bf14b3f884408a844c5fea0d4a978","c1334353e0b149608e359c7c00e77971","0759711c6ac24815acf272a98a893f0f","700f36dcb3d347ec8a4fdb19da892016","5a7dd85576514a45b8b8adbae8a52e23","eea245757bb64b44917a09743808d097","f929f736e6d24b11a9e3621fbefe4f5f","345d9092b59b46ff8833f4f7015c6f99","26dfcf5956ee4841b6894b89cf70d948","41c29cb9ce4742a18713882e4eb97e4c","dba63ca28a924fe681c986c88d704f44","31c9d3b467ee4f47b298dc862e6877f0","cb99eed43c814cafbaaa334c48fa367c","5e3f5445edb9412a83674ed2c6ca6488","b9ac3bf7fac343f6bd2b16c53a8d9b05","11a8b98b622845c4a78d4c3dc7896b21","373dc009c0104a00bed17d5d9d3e8609","b2995df5958047a7a3a2b6defa86c02b","393d820d05ef4d5b9e1aef82ac7bb105","55c5d97ce1414f8689d5fc8fdf6cd43e","814fb7276f4842879f00a3c286594afc","350474b595954737aa2a7133db38fc56","8f4587428d8b4708be12c585395e69d7","d3cf6ff3af3b4e01885baa1c0e52c1aa","431890be19ac4cb3875396d040c75e00","40932f372c904ce3a9be10dd2f3cf348","cffb550d551943babc4d85f0fab752c2","df8b53662d0543768ffb974ecf3ea8d6","a3fc97e2732b4bb297984de189f3e254","029e2ed64fec4bb8b353486d16e439f8","d0005bdd06414fcab7d8932ca691ef54","1174b72a20e747629f6e5112a3ba73a1","7c9db69c4cc34bf7801c9b5f01a0e9c5","7b5994faa7b048f89eb89fa15e0c0e12","2656791a55c846cd9b6b2f4306a02cb4","fd5022f7c6454f4896db82dda6b3c941","5027fc2e85b54d36bd451d3a8761bf09","e32eb8ed0f224eccb5057b3b48bc0b61","c1d75ffc0b7c4d3ca7a74a7739972028","e1899f0769604124b9b5ee3286cf90cf","2012ed9c34db40cfb1bab180ac7290b3","1157c68c520c4da386aa8bbf9d21d402","dd4bb265b509409fb5fa10297a194d73","c98e8a6e153e4db28baef5a560e1ebe4","7ce17a664f264541828a39276280b959","7fc1348e686e40ec8e2eed2efac71810","7860c57a3c8f4d3eb31ed53517050a2f","142be23e4d724825bbd1e6e9b8aff83e","407c25e9225147da9395f0b9be8ca81c","ecef90c609174944a1fd2c365496a235","200882d3451545bcaff41ceca8076cc8","8f0b2b5a6f674d76b86cea71e77e4f1e","eedf6372946c4ac3bf28d373c5ce5513","4dc798d55d424a8b847fb76c4c2c2c23","add7901c35ba415d9c1e20c6494768e3","413b9a3ab65f488b8e2897e1c7915ba5","5ab1ea7b721c4d9eaf35eaf5c6f76ff3","4e6bc7c21276440882a0688cf70890ba","77d84a78e105406abca34b949bfa520c","8c21622a2b6d433f9b7014d9806cecbc","174ec40df47a43cebdc27b10be166e64","f383b19be0e34c2ebff6af9c3d2b2049","8c7ff768979c4166a4b867af7e421324","100e8f71d8464f59a4b1fcaae7dace89","77af75899f364293969a541a93ff18a7","f44575fbf07145499407c93c6ce690a7","d63227084ec64a4cada920ac9577667d","cac3a3154e3e490a8612be46d9feb4e9","bbf145b7ea014e22bdcb9f4c022bcac8","8c383f092f5441ddab91a6532e461f55","bfd6888f56d246758d1bf405f3bbe614","ff699c2972e54be6bf7b1813f2bd9627","006f3efa5f9b4fc0b1c97f35e7932e91","99608e4edbce4919b449f83c8692336c","072b2976f64148329937c1feef91aa8b","a21ebeb50eba4057abbaba22d23e7eac","4f5e94f31bd145b5b999fadf5f98ff9a","f20ad2a947704b558ffa89e467f9ae3e","10cfab65aa4d4a20aa2c84aaa854687e","aa668b7239a445c786b5ab62deaa8ce3","2eae0ce3a0ad4593a913240ee55101a8","1700d13d5d9c4fcc9f46eafe6ddebdda","3f9a8e05641045f6b52f9694820756ce","0ec3399d554047fb92b17a861bb82e8e","b24bd684cea5428dab429906e3f3c7f2","89ae773cccc4487991539b8cda005baa","2b2c6f4e723a413b8b478081c83523e8","1cad13af917540e7bb5792fe267e12d1","a8dd62c44bea47efa70389e3ee5b7e5a","ee1f6ca8ba24434e97060489b2352896","37c26273624640a2a42152402f392cdf","30aeb59e467f4f3b855c6dd3aa6441c0","e3a011bef73b4e389288ca6b7d0f87f4","b37f6f120bd840e5bd3273da00d4d152","b35b7e01d3fc4693b4e134a91dc7c2b4","1b312715316b4075a50cdc4ade5f435f","689b8b5da5d9490c91c722574d9dff69","830463286f62498693f3cf633e9e58e0","3a8eed575fcc4e4d8d5455bc9c958ec5","adf121f38f164517be7ae690cb040ddc","ab67c87855944c9b9b9bd417fe8c7eb3","763392b4d0ee43158c4dab59f163a29c","a011591d7a3e45f8b4351ee694d096f9","450491d1f9e840a3b599be204e1eeb45","24cf229e8962496fbbb5c7148232dc06","1397552d9e44403b980d1b4018af16b5","80687fc74b8d457dbb03f4768e11626e","d60e3b48fdb94610a269f44cb9c200e1","a585b26af1534e6ba8a6afd1f2d0ea28","4b659f6e0028416e9bce3e27125b303f","00047b39557343d59c672fbbe101d43c","5a5a077bcbc4425a94f9a53b59af8bcd","e2a856fbcb7e4a3f9b26eb4c974a5185","c159d31412234d2abd7b28efe98cb0b0","aec15b09516144b886e03f41b8d68a78","fdd47e2eef8548ca86817cba9ec4459d","407484b52c8a40f19c65d8a113eebc6e","a13b4f5728684f0f86cc0a3da33fd120","8803f9a49af8413cbb2e2c64d2f42b13","aeea479aaa9a4c8dafb44ce4a89801c3","0844143b96d74efa973affa847111c8f","a50938bbf7674d2296b6d91922664ec3","ee7ec1a1aff14331b0d99e044e0a52a1","2edbc8273f6b42ffbb96bba225c3caaf","16f16ed209cc4b1fa50b0068ca682c6c","93a89c43e8dd4779b2c990bccb3fca5c","a346bfdf2ebc41989d3105695d12b41e","8fb60565ffd34b63a194e6b80fc677dd","1b67548880ee4f96bda5ebcba9b724a5","bcac1741e9b240e998ac6e426047afbe","8163a5e1223f4c79845148d9d23f63e5","28be7f1699924b9bb01cb3bc014bd5b2","d7b05c5b8a9749028b61b802c2ddef88","184a74ac517049a9a1616645cc14f1d3","f2c669293420448b9bb078561760e877","7915006778b44d95b254d86ea854e074","572cf2c227ef401c982938943e486216","8138211d9b0c4ee096c29774119c1d0b","f9bf751d171547f787e935bf297b93d8","71838d49904c4f29970b14df003f48d4","93cb7ba95f034b71ad1b9d745d30d5c9","51acfdb77cf442c3921bd97d952d1707","1b1f704cb6ba48448e46059259868741","bc67016f962e4307b6965d73ecad1d73","014c33c3a3da457ab2f8789d925089d3","82024472425d45588cac0cbc78e8187d","c3f22301c25a4c6da453c4a056220118","caf2db15b7914f9da9d32c8d28188edf","ec67de78b9434d1ea8966b3dc39ea28c","58492a8d8af94b5ba409c35836c648f0","3be5dff528b24ef79e002e188d2750d5","3d696b25acce45e498e6435c7dd3e3a7","0161a222d93647f3a8ae068c9579e645","4a11f15807164d01913578eadda55c0c","f73976e797e6462fa28b3bd984bc48e7","9f9f74ae04904403962d27ab26a8da56","5873048b5a474d148104e7bb996a429a","27208263b9b54659909cedd0607cfb73","92a498f5468b4700800bf69daedde660","5d3ed4091fa24fd7812d4b1763cd19f1","abcdf0cbc9fe47bab0be129ae31afb44","d5c2902bc4214061920444d203595a9e","3ce5038050a24edfb4cdecda31d22f50","b70a21a181d84aabbb420d1edefb7b69","bb4de79fb9ca41b18f1d791674d8a500","5afe6f22cb5c464c98774822dc2c4593","db777c60903e4bd8a49175c30231da29","d38ba663408f482f9b65f65a741a14ff","a04a8941af8b4b20a1a1e3851493745a","8664a584101e4011b567cb29e7a97a95","fd16f369a15742388a96fdd87d930885","d307c9c409f44782a2fa53e5abb1bfdd","98d74c46912843aa9cf5e96e81b58967","2aa07520f53c4d1aa7530837e17088d7","4309bde411764744af1cb1600a9a4442","884efe8b219e47b1b44c0cef5d42db6e","2618127275b24dbbadb037e017d80e46","154408089e3f48d88865c93e7c4d01e6","d7f4642d9026462d958edededb0e3439","3a63e1c1fabe4480becf2fdf44bd9c04","8f955baee22a4f2eaa917207a11221bd","adfac3c6043c424d8130ac567f9fe943","aa303bb5ccf84c9e89e14fefc6f0c273","6db6333eabdb4126862c1320f1dc9ed0","f9931f939ac14045a2979a0f8b114c53","aa86faccaeed49a59b770d26614efe5a","b749f982dd754fb48c7360387e3702ee","e7e0cd955ba149c58be36cebb6be03eb","051a67c0f7f3432083bdb6841cddd4d9","564707e32fe047e9af7e7bbacf5bc446","b1003d79d147443dbf38ed7dac14fe8e","e01297cc2a3a458a86e6c9e2a5166c9e","95da8775fd87496f8b2233736f2def92","0ec28e584ad74140a38883ffbe1e6ab6","f9d80a4d281e4a069854bc0342ce8cea","a4cfa05b8fe64d32816fbe3143dc3798","5cca9a3194344b4fa251e8d7a43c4975","f77f25e029434f3ab62b8c2dea49b939","d2d60c4691fe4153a3cfcac19538d2d1","defad190d8c14174a775b50405c653c7","f9e315afa2614f2cb4a178d9549dcf63","b6baeb02237d42f48baeef8b76bb10e5","b7e290823c514e20b63be2b63a98e6c6","1f4da29338e141538436691eefa2a470","e4c07aaff09e4c61b7ed4aa5afa948ca","470c5c0db67b4e55bc0ad9e0a8418c0e","8bf44792175d4dea8788fce8a478216c","b678de52028448b4b20862df56086514","85f95d3b712b4be3898e28ed4f349c8b","3af815a0197641f3a3e9276d54a2173c","6d48c2090f7b461289684dc04e8dfbf2","599efe49a2784053b1f7900827674204","21d953c407494ebc80c5e0d1fbe4e770","9f78c13e36dd4d9fa54e7f339527cf58","aeb06c8fa2a54468b1d52023a1575fe4","7c25200fa6b944c3ab5b5f56a210f64d","f6c73802c6ad407485047962861a2ce5"]},"outputId":"eef54126-d2ed-4bd5-9008-2f050c0293d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["###################### Training vgg19_batch_norm SGD, lr_0.1, momentum_0.6 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b137ab55f23e432e8394affc3f50bd1f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 8.1320510, Training accuracy: 0.1050000, Time: 07_05_2022__00:24:09\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 5.2119090, Training accuracy: 0.1025000, Time: 07_05_2022__00:24:29\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 4.2446527, Training accuracy: 0.1058333, Time: 07_05_2022__00:24:50\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 3.7593509, Training accuracy: 0.1075000, Time: 07_05_2022__00:25:10\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 3.4682180, Training accuracy: 0.1165000, Time: 07_05_2022__00:25:31\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 3.2689229, Training accuracy: 0.1175000, Time: 07_05_2022__00:25:51\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 3.1272837, Training accuracy: 0.1200000, Time: 07_05_2022__00:26:11\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 3.0211651, Training accuracy: 0.1228125, Time: 07_05_2022__00:26:32\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.9354883, Training accuracy: 0.1291667, Time: 07_05_2022__00:26:52\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.8696841, Training accuracy: 0.1290000, Time: 07_05_2022__00:27:12\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.8149483, Training accuracy: 0.1281818, Time: 07_05_2022__00:27:33\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.7671227, Training accuracy: 0.1300000, Time: 07_05_2022__00:27:53\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.7276587, Training accuracy: 0.1325000, Time: 07_05_2022__00:28:13\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.6916443, Training accuracy: 0.1357143, Time: 07_05_2022__00:28:34\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.6622781, Training accuracy: 0.1366667, Time: 07_05_2022__00:28:54\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.6357815, Training accuracy: 0.1384375, Time: 07_05_2022__00:29:14\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.6132325, Training accuracy: 0.1402941, Time: 07_05_2022__00:29:35\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.5912600, Training accuracy: 0.1418056, Time: 07_05_2022__00:29:55\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.5705633, Training accuracy: 0.1452632, Time: 07_05_2022__00:30:15\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.5538016, Training accuracy: 0.1473750, Time: 07_05_2022__00:30:36\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.5368502, Training accuracy: 0.1500000, Time: 07_05_2022__00:30:56\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.5241879, Training accuracy: 0.1509091, Time: 07_05_2022__00:31:16\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.5104231, Training accuracy: 0.1527174, Time: 07_05_2022__00:31:37\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.4979900, Training accuracy: 0.1540625, Time: 07_05_2022__00:31:57\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.4850792, Training accuracy: 0.1561000, Time: 07_05_2022__00:32:17\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.4722914, Training accuracy: 0.1589423, Time: 07_05_2022__00:32:38\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.4624578, Training accuracy: 0.1600000, Time: 07_05_2022__00:32:58\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.4520072, Training accuracy: 0.1610714, Time: 07_05_2022__00:33:18\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.4435749, Training accuracy: 0.1621552, Time: 07_05_2022__00:33:39\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.4341286, Training accuracy: 0.1623333, Time: 07_05_2022__00:33:59\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.4246858, Training accuracy: 0.1651613, Time: 07_05_2022__00:34:19\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.4154370, Training accuracy: 0.1659375, Time: 07_05_2022__00:34:39\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.4088572, Training accuracy: 0.1672727, Time: 07_05_2022__00:35:00\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.4017777, Training accuracy: 0.1683088, Time: 07_05_2022__00:35:20\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.3949942, Training accuracy: 0.1687857, Time: 07_05_2022__00:35:40\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.3882896, Training accuracy: 0.1694444, Time: 07_05_2022__00:36:01\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.3815339, Training accuracy: 0.1706757, Time: 07_05_2022__00:36:21\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.3763256, Training accuracy: 0.1707895, Time: 07_05_2022__00:36:42\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.3706091, Training accuracy: 0.1723718, Time: 07_05_2022__00:37:02\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.3641523, Training accuracy: 0.1744375, Time: 07_05_2022__00:37:22\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.3579785, Training accuracy: 0.1753659, Time: 07_05_2022__00:37:43\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.3517003, Training accuracy: 0.1769643, Time: 07_05_2022__00:38:03\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.3462262, Training accuracy: 0.1777907, Time: 07_05_2022__00:38:24\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.3403067, Training accuracy: 0.1789773, Time: 07_05_2022__00:38:44\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.3333856, Training accuracy: 0.1802222, Time: 07_05_2022__00:39:04\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.3286087, Training accuracy: 0.1807065, Time: 07_05_2022__00:39:25\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.3228957, Training accuracy: 0.1814894, Time: 07_05_2022__00:39:45\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 2.3176508, Training accuracy: 0.1829167, Time: 07_05_2022__00:40:05\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 2.3125035, Training accuracy: 0.1838776, Time: 07_05_2022__00:40:26\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 2.3088283, Training accuracy: 0.1842500, Time: 07_05_2022__00:40:46\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 2.3029623, Training accuracy: 0.1859314, Time: 07_05_2022__00:41:07\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 2.2978553, Training accuracy: 0.1871635, Time: 07_05_2022__00:41:27\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 2.2931453, Training accuracy: 0.1884906, Time: 07_05_2022__00:41:47\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 2.2885986, Training accuracy: 0.1892130, Time: 07_05_2022__00:42:08\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 2.2833707, Training accuracy: 0.1909545, Time: 07_05_2022__00:42:28\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 2.2788994, Training accuracy: 0.1916964, Time: 07_05_2022__00:42:49\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 2.2738983, Training accuracy: 0.1929386, Time: 07_05_2022__00:43:09\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 2.2689760, Training accuracy: 0.1944397, Time: 07_05_2022__00:43:29\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 2.2643969, Training accuracy: 0.1956780, Time: 07_05_2022__00:43:50\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 2.2604057, Training accuracy: 0.1963333, Time: 07_05_2022__00:44:10\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 2.2572689, Training accuracy: 0.1972131, Time: 07_05_2022__00:44:31\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 2.2534760, Training accuracy: 0.1983871, Time: 07_05_2022__00:44:51\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 2.2497143, Training accuracy: 0.1994048, Time: 07_05_2022__00:45:11\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 2.2459223, Training accuracy: 0.2001172, Time: 07_05_2022__00:45:32\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 2.2411371, Training accuracy: 0.2017308, Time: 07_05_2022__00:45:52\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 2.2376620, Training accuracy: 0.2029167, Time: 07_05_2022__00:46:13\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 2.2335839, Training accuracy: 0.2038433, Time: 07_05_2022__00:46:33\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 2.2306346, Training accuracy: 0.2045221, Time: 07_05_2022__00:46:53\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 2.2270649, Training accuracy: 0.2048551, Time: 07_05_2022__00:47:14\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 2.2229250, Training accuracy: 0.2060714, Time: 07_05_2022__00:47:34\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 2.2193009, Training accuracy: 0.2074296, Time: 07_05_2022__00:47:55\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 2.2154185, Training accuracy: 0.2082986, Time: 07_05_2022__00:48:15\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 2.2117737, Training accuracy: 0.2092123, Time: 07_05_2022__00:48:35\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 2.2091276, Training accuracy: 0.2096284, Time: 07_05_2022__00:48:56\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 2.2061977, Training accuracy: 0.2105667, Time: 07_05_2022__00:49:16\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 2.2034907, Training accuracy: 0.2110197, Time: 07_05_2022__00:49:37\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 2.1997509, Training accuracy: 0.2120779, Time: 07_05_2022__00:49:57\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 2.1962536, Training accuracy: 0.2131731, Time: 07_05_2022__00:50:17\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 2.1926677, Training accuracy: 0.2140823, Time: 07_05_2022__00:50:38\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 2.1898912, Training accuracy: 0.2148750, Time: 07_05_2022__00:50:58\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 2.1863193, Training accuracy: 0.2158951, Time: 07_05_2022__00:51:19\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 2.1826060, Training accuracy: 0.2168902, Time: 07_05_2022__00:51:39\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 2.1788216, Training accuracy: 0.2181024, Time: 07_05_2022__00:51:59\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 2.1754429, Training accuracy: 0.2191369, Time: 07_05_2022__00:52:20\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 2.1728204, Training accuracy: 0.2199412, Time: 07_05_2022__00:52:40\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 2.1698305, Training accuracy: 0.2207849, Time: 07_05_2022__00:53:00\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 2.1667836, Training accuracy: 0.2214943, Time: 07_05_2022__00:53:21\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 2.1635240, Training accuracy: 0.2229545, Time: 07_05_2022__00:53:41\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 2.1601851, Training accuracy: 0.2239326, Time: 07_05_2022__00:54:02\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 2.1568091, Training accuracy: 0.2247500, Time: 07_05_2022__00:54:22\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 2.1544350, Training accuracy: 0.2256319, Time: 07_05_2022__00:54:42\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 2.1513866, Training accuracy: 0.2267120, Time: 07_05_2022__00:55:03\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 2.1492117, Training accuracy: 0.2271774, Time: 07_05_2022__00:55:23\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 2.1470355, Training accuracy: 0.2278989, Time: 07_05_2022__00:55:44\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 2.1450469, Training accuracy: 0.2287105, Time: 07_05_2022__00:56:04\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 2.1419495, Training accuracy: 0.2296875, Time: 07_05_2022__00:56:24\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 2.1390038, Training accuracy: 0.2306443, Time: 07_05_2022__00:56:45\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 2.1364924, Training accuracy: 0.2315816, Time: 07_05_2022__00:57:05\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 2.1338815, Training accuracy: 0.2323232, Time: 07_05_2022__00:57:26\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 2.1314273, Training accuracy: 0.2335250, Time: 07_05_2022__00:57:46\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 2.1287021, Training accuracy: 0.2344802, Time: 07_05_2022__00:58:06\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 2.1257400, Training accuracy: 0.2354902, Time: 07_05_2022__00:58:27\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 2.1232119, Training accuracy: 0.2364563, Time: 07_05_2022__00:58:47\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 2.1205590, Training accuracy: 0.2372837, Time: 07_05_2022__00:59:07\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 2.1181456, Training accuracy: 0.2378095, Time: 07_05_2022__00:59:28\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 2.1151622, Training accuracy: 0.2390566, Time: 07_05_2022__00:59:48\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 2.1127296, Training accuracy: 0.2397196, Time: 07_05_2022__01:00:09\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 2.1097139, Training accuracy: 0.2409491, Time: 07_05_2022__01:00:29\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 2.1078209, Training accuracy: 0.2415596, Time: 07_05_2022__01:00:49\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 2.1054144, Training accuracy: 0.2424545, Time: 07_05_2022__01:01:10\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 2.1022925, Training accuracy: 0.2434009, Time: 07_05_2022__01:01:30\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 2.1002476, Training accuracy: 0.2437500, Time: 07_05_2022__01:01:50\n","Epoch 1 of 5, Average training loss: 2.0996534, Average training accuracy: 0.2439333, Time: 07_05_2022__01:02:01\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03ac0b134a764af6b5b80ff19d0100e8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.7309989, Validation accuracy: 0.4075000, Time: 07_05_2022__01:02:06 | Loss decreased from inf to 1.7293160 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.7528904, Validation accuracy: 0.3900000, Time: 07_05_2022__01:02:13\n","Step: 300 of 1250, Validation loss: 1.7488454, Validation accuracy: 0.3916667, Time: 07_05_2022__01:02:18\n","Step: 400 of 1250, Validation loss: 1.7391092, Validation accuracy: 0.3943750, Time: 07_05_2022__01:02:24\n","Step: 500 of 1250, Validation loss: 1.7432625, Validation accuracy: 0.3940000, Time: 07_05_2022__01:02:29\n","Step: 600 of 1250, Validation loss: 1.7330499, Validation accuracy: 0.4020833, Time: 07_05_2022__01:02:34\n","Step: 700 of 1250, Validation loss: 1.7315883, Validation accuracy: 0.4028571, Time: 07_05_2022__01:02:39\n","Step: 800 of 1250, Validation loss: 1.7266894, Validation accuracy: 0.4031250, Time: 07_05_2022__01:02:44 | Loss decreased from 1.7293160 to 1.7271185 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.7235304, Validation accuracy: 0.4027778, Time: 07_05_2022__01:02:51 | Loss decreased from 1.7271185 to 1.7236331 .... Saving the model\n","Step: 1000 of 1250, Validation loss: 1.7279494, Validation accuracy: 0.4027500, Time: 07_05_2022__01:02:59\n","Step: 1100 of 1250, Validation loss: 1.7311929, Validation accuracy: 0.4027273, Time: 07_05_2022__01:03:04\n","Step: 1200 of 1250, Validation loss: 1.7304387, Validation accuracy: 0.4016667, Time: 07_05_2022__01:03:09\n","Average validation loss: 1.7301463, Average validation accuracy: 0.4006000, Time: 07_05_2022__01:03:11\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db02b24dcf3c4489a222d46a3ee3f923"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.7689699, Training accuracy: 0.3575000, Time: 07_05_2022__01:03:32\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.7962476, Training accuracy: 0.3562500, Time: 07_05_2022__01:03:52\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.8190033, Training accuracy: 0.3466667, Time: 07_05_2022__01:04:13\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.8172240, Training accuracy: 0.3481250, Time: 07_05_2022__01:04:33\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.8133751, Training accuracy: 0.3490000, Time: 07_05_2022__01:04:53\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.7989827, Training accuracy: 0.3516667, Time: 07_05_2022__01:05:14\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.8051714, Training accuracy: 0.3503571, Time: 07_05_2022__01:05:34\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.7947222, Training accuracy: 0.3509375, Time: 07_05_2022__01:05:55\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.7948665, Training accuracy: 0.3497222, Time: 07_05_2022__01:06:15\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.7922810, Training accuracy: 0.3525000, Time: 07_05_2022__01:06:35\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.7924361, Training accuracy: 0.3536364, Time: 07_05_2022__01:06:56\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.7876947, Training accuracy: 0.3545833, Time: 07_05_2022__01:07:16\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.7818110, Training accuracy: 0.3575000, Time: 07_05_2022__01:07:36\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.7829810, Training accuracy: 0.3562500, Time: 07_05_2022__01:07:57\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.7863239, Training accuracy: 0.3558333, Time: 07_05_2022__01:08:17\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.7905833, Training accuracy: 0.3531250, Time: 07_05_2022__01:08:38\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.7898689, Training accuracy: 0.3530882, Time: 07_05_2022__01:08:58\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.7880111, Training accuracy: 0.3530556, Time: 07_05_2022__01:09:18\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.7831670, Training accuracy: 0.3552632, Time: 07_05_2022__01:09:39\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.7826380, Training accuracy: 0.3543750, Time: 07_05_2022__01:09:59\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.7813307, Training accuracy: 0.3528571, Time: 07_05_2022__01:10:19\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.7831901, Training accuracy: 0.3529545, Time: 07_05_2022__01:10:40\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.7823422, Training accuracy: 0.3542391, Time: 07_05_2022__01:11:00\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.7835504, Training accuracy: 0.3538542, Time: 07_05_2022__01:11:20\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.7792532, Training accuracy: 0.3550000, Time: 07_05_2022__01:11:41\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.7771185, Training accuracy: 0.3553846, Time: 07_05_2022__01:12:01\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.7739409, Training accuracy: 0.3574074, Time: 07_05_2022__01:12:21\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.7731791, Training accuracy: 0.3574107, Time: 07_05_2022__01:12:42\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.7708846, Training accuracy: 0.3593966, Time: 07_05_2022__01:13:02\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.7711804, Training accuracy: 0.3590833, Time: 07_05_2022__01:13:23\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.7700187, Training accuracy: 0.3600000, Time: 07_05_2022__01:13:43\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.7679439, Training accuracy: 0.3605469, Time: 07_05_2022__01:14:03\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.7697370, Training accuracy: 0.3597727, Time: 07_05_2022__01:14:24\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.7697523, Training accuracy: 0.3592647, Time: 07_05_2022__01:14:44\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.7673357, Training accuracy: 0.3596429, Time: 07_05_2022__01:15:04\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.7679307, Training accuracy: 0.3586806, Time: 07_05_2022__01:15:25\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.7684586, Training accuracy: 0.3597297, Time: 07_05_2022__01:15:45\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.7674717, Training accuracy: 0.3594079, Time: 07_05_2022__01:16:05\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.7664886, Training accuracy: 0.3599359, Time: 07_05_2022__01:16:26\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.7650987, Training accuracy: 0.3599375, Time: 07_05_2022__01:16:46\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.7640231, Training accuracy: 0.3609146, Time: 07_05_2022__01:17:07\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.7616341, Training accuracy: 0.3621429, Time: 07_05_2022__01:17:27\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.7617135, Training accuracy: 0.3626163, Time: 07_05_2022__01:17:47\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.7593119, Training accuracy: 0.3629545, Time: 07_05_2022__01:18:07\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.7561632, Training accuracy: 0.3641111, Time: 07_05_2022__01:18:28\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.7550904, Training accuracy: 0.3640761, Time: 07_05_2022__01:18:48\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.7539552, Training accuracy: 0.3647340, Time: 07_05_2022__01:19:09\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.7525665, Training accuracy: 0.3657292, Time: 07_05_2022__01:19:29\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.7517286, Training accuracy: 0.3657653, Time: 07_05_2022__01:19:49\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.7532222, Training accuracy: 0.3657000, Time: 07_05_2022__01:20:10\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.7527434, Training accuracy: 0.3658333, Time: 07_05_2022__01:20:30\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.7525852, Training accuracy: 0.3659135, Time: 07_05_2022__01:20:50\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.7518821, Training accuracy: 0.3665566, Time: 07_05_2022__01:21:11\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.7513756, Training accuracy: 0.3667593, Time: 07_05_2022__01:21:31\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.7508628, Training accuracy: 0.3670000, Time: 07_05_2022__01:21:51\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.7513128, Training accuracy: 0.3671875, Time: 07_05_2022__01:22:12\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.7498346, Training accuracy: 0.3675877, Time: 07_05_2022__01:22:32\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.7483499, Training accuracy: 0.3678448, Time: 07_05_2022__01:22:52\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.7465314, Training accuracy: 0.3683898, Time: 07_05_2022__01:23:13\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.7456891, Training accuracy: 0.3684583, Time: 07_05_2022__01:23:33\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.7454101, Training accuracy: 0.3685246, Time: 07_05_2022__01:23:54\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.7440502, Training accuracy: 0.3690726, Time: 07_05_2022__01:24:14\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.7431971, Training accuracy: 0.3695238, Time: 07_05_2022__01:24:34\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.7427162, Training accuracy: 0.3692969, Time: 07_05_2022__01:24:55\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.7412648, Training accuracy: 0.3700000, Time: 07_05_2022__01:25:15\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.7410266, Training accuracy: 0.3708333, Time: 07_05_2022__01:25:36\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.7402197, Training accuracy: 0.3710821, Time: 07_05_2022__01:25:56\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.7401858, Training accuracy: 0.3716912, Time: 07_05_2022__01:26:16\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.7397592, Training accuracy: 0.3719203, Time: 07_05_2022__01:26:37\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.7384133, Training accuracy: 0.3722500, Time: 07_05_2022__01:26:57\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.7376103, Training accuracy: 0.3727113, Time: 07_05_2022__01:27:17\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.7366144, Training accuracy: 0.3730903, Time: 07_05_2022__01:27:38\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.7360783, Training accuracy: 0.3730822, Time: 07_05_2022__01:27:58\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.7352730, Training accuracy: 0.3732432, Time: 07_05_2022__01:28:19\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.7350162, Training accuracy: 0.3732667, Time: 07_05_2022__01:28:39\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.7337358, Training accuracy: 0.3736513, Time: 07_05_2022__01:28:59\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.7329470, Training accuracy: 0.3738312, Time: 07_05_2022__01:29:20\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.7308890, Training accuracy: 0.3744231, Time: 07_05_2022__01:29:40\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.7300541, Training accuracy: 0.3744620, Time: 07_05_2022__01:30:01\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.7297376, Training accuracy: 0.3744375, Time: 07_05_2022__01:30:21\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.7291416, Training accuracy: 0.3745679, Time: 07_05_2022__01:30:41\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.7285294, Training accuracy: 0.3749085, Time: 07_05_2022__01:31:02\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.7259039, Training accuracy: 0.3759639, Time: 07_05_2022__01:31:22\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.7263689, Training accuracy: 0.3761310, Time: 07_05_2022__01:31:42\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.7254715, Training accuracy: 0.3768235, Time: 07_05_2022__01:32:03\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.7249219, Training accuracy: 0.3770349, Time: 07_05_2022__01:32:23\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.7240469, Training accuracy: 0.3772701, Time: 07_05_2022__01:32:44\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.7222178, Training accuracy: 0.3782670, Time: 07_05_2022__01:33:04\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.7204269, Training accuracy: 0.3788483, Time: 07_05_2022__01:33:24\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.7194231, Training accuracy: 0.3792500, Time: 07_05_2022__01:33:45\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.7194983, Training accuracy: 0.3793956, Time: 07_05_2022__01:34:05\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.7176419, Training accuracy: 0.3802717, Time: 07_05_2022__01:34:25\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.7180518, Training accuracy: 0.3800538, Time: 07_05_2022__01:34:46\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.7175004, Training accuracy: 0.3801330, Time: 07_05_2022__01:35:06\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.7177728, Training accuracy: 0.3803158, Time: 07_05_2022__01:35:27\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.7156788, Training accuracy: 0.3809635, Time: 07_05_2022__01:35:47\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.7146570, Training accuracy: 0.3814433, Time: 07_05_2022__01:36:07\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.7134880, Training accuracy: 0.3818622, Time: 07_05_2022__01:36:28\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.7129479, Training accuracy: 0.3820960, Time: 07_05_2022__01:36:48\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.7126370, Training accuracy: 0.3825250, Time: 07_05_2022__01:37:09\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.7120336, Training accuracy: 0.3831436, Time: 07_05_2022__01:37:29\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.7105961, Training accuracy: 0.3836275, Time: 07_05_2022__01:37:50\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.7092606, Training accuracy: 0.3840777, Time: 07_05_2022__01:38:10\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.7090329, Training accuracy: 0.3840865, Time: 07_05_2022__01:38:30\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.7086890, Training accuracy: 0.3839524, Time: 07_05_2022__01:38:51\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.7075178, Training accuracy: 0.3843160, Time: 07_05_2022__01:39:11\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.7068002, Training accuracy: 0.3845093, Time: 07_05_2022__01:39:32\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.7054106, Training accuracy: 0.3849306, Time: 07_05_2022__01:39:52\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.7042843, Training accuracy: 0.3855046, Time: 07_05_2022__01:40:13\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.7030679, Training accuracy: 0.3861591, Time: 07_05_2022__01:40:33\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.7013401, Training accuracy: 0.3865541, Time: 07_05_2022__01:40:53\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.7005483, Training accuracy: 0.3871205, Time: 07_05_2022__01:41:14\n","Epoch 2 of 5, Average training loss: 1.7004172, Average training accuracy: 0.3871333, Time: 07_05_2022__01:41:24\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15ccceeaf8d440bea1f11b629fe49ab9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.4733443, Validation accuracy: 0.4550000, Time: 07_05_2022__01:41:29 | Loss decreased from 1.7236331 to 1.4710378 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.4669488, Validation accuracy: 0.4587500, Time: 07_05_2022__01:41:36 | Loss decreased from 1.4710378 to 1.4677482 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.4823738, Validation accuracy: 0.4466667, Time: 07_05_2022__01:41:44\n","Step: 400 of 1250, Validation loss: 1.4797458, Validation accuracy: 0.4543750, Time: 07_05_2022__01:41:49\n","Step: 500 of 1250, Validation loss: 1.4862889, Validation accuracy: 0.4515000, Time: 07_05_2022__01:41:54\n","Step: 600 of 1250, Validation loss: 1.4794135, Validation accuracy: 0.4554167, Time: 07_05_2022__01:41:59\n","Step: 700 of 1250, Validation loss: 1.4605513, Validation accuracy: 0.4675000, Time: 07_05_2022__01:42:04 | Loss decreased from 1.4677482 to 1.4604249 .... Saving the model\n","Step: 800 of 1250, Validation loss: 1.4541320, Validation accuracy: 0.4690625, Time: 07_05_2022__01:42:11 | Loss decreased from 1.4604249 to 1.4547268 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.4595366, Validation accuracy: 0.4658333, Time: 07_05_2022__01:42:19\n","Step: 1000 of 1250, Validation loss: 1.4638870, Validation accuracy: 0.4622500, Time: 07_05_2022__01:42:24\n","Step: 1100 of 1250, Validation loss: 1.4698323, Validation accuracy: 0.4611364, Time: 07_05_2022__01:42:29\n","Step: 1200 of 1250, Validation loss: 1.4732385, Validation accuracy: 0.4593750, Time: 07_05_2022__01:42:34\n","Average validation loss: 1.4756057, Average validation accuracy: 0.4580000, Time: 07_05_2022__01:42:37\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9919ebc356a4afc8ec99152faef8079"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.5342058, Training accuracy: 0.4725000, Time: 07_05_2022__01:42:57\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.5638961, Training accuracy: 0.4437500, Time: 07_05_2022__01:43:18\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.5831506, Training accuracy: 0.4333333, Time: 07_05_2022__01:43:38\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.5727561, Training accuracy: 0.4418750, Time: 07_05_2022__01:43:59\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.5684206, Training accuracy: 0.4365000, Time: 07_05_2022__01:44:19\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.5622344, Training accuracy: 0.4391667, Time: 07_05_2022__01:44:39\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.5671007, Training accuracy: 0.4389286, Time: 07_05_2022__01:45:00\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.5625012, Training accuracy: 0.4387500, Time: 07_05_2022__01:45:20\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.5571683, Training accuracy: 0.4425000, Time: 07_05_2022__01:45:41\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.5581074, Training accuracy: 0.4420000, Time: 07_05_2022__01:46:01\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.5576631, Training accuracy: 0.4436364, Time: 07_05_2022__01:46:22\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.5580180, Training accuracy: 0.4422917, Time: 07_05_2022__01:46:42\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.5544967, Training accuracy: 0.4450000, Time: 07_05_2022__01:47:02\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.5522362, Training accuracy: 0.4467857, Time: 07_05_2022__01:47:23\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.5560794, Training accuracy: 0.4456667, Time: 07_05_2022__01:47:43\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.5608484, Training accuracy: 0.4406250, Time: 07_05_2022__01:48:04\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.5587536, Training accuracy: 0.4426471, Time: 07_05_2022__01:48:24\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.5577856, Training accuracy: 0.4425000, Time: 07_05_2022__01:48:45\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.5559249, Training accuracy: 0.4428947, Time: 07_05_2022__01:49:05\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.5549464, Training accuracy: 0.4426250, Time: 07_05_2022__01:49:25\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.5530870, Training accuracy: 0.4417857, Time: 07_05_2022__01:49:46\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.5525518, Training accuracy: 0.4427273, Time: 07_05_2022__01:50:06\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.5533390, Training accuracy: 0.4423913, Time: 07_05_2022__01:50:27\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.5522901, Training accuracy: 0.4428125, Time: 07_05_2022__01:50:47\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.5512619, Training accuracy: 0.4422000, Time: 07_05_2022__01:51:07\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.5485690, Training accuracy: 0.4433654, Time: 07_05_2022__01:51:28\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.5480371, Training accuracy: 0.4427778, Time: 07_05_2022__01:51:48\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.5485404, Training accuracy: 0.4431250, Time: 07_05_2022__01:52:09\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.5480517, Training accuracy: 0.4434483, Time: 07_05_2022__01:52:29\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.5471232, Training accuracy: 0.4449167, Time: 07_05_2022__01:52:50\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.5447452, Training accuracy: 0.4462903, Time: 07_05_2022__01:53:10\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.5421237, Training accuracy: 0.4473437, Time: 07_05_2022__01:53:30\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.5436267, Training accuracy: 0.4462121, Time: 07_05_2022__01:53:51\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.5454226, Training accuracy: 0.4459559, Time: 07_05_2022__01:54:11\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.5449455, Training accuracy: 0.4462857, Time: 07_05_2022__01:54:32\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.5460888, Training accuracy: 0.4459722, Time: 07_05_2022__01:54:52\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.5472684, Training accuracy: 0.4451351, Time: 07_05_2022__01:55:13\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.5459183, Training accuracy: 0.4455263, Time: 07_05_2022__01:55:33\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.5459320, Training accuracy: 0.4454487, Time: 07_05_2022__01:55:54\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.5460095, Training accuracy: 0.4453750, Time: 07_05_2022__01:56:14\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.5464815, Training accuracy: 0.4448171, Time: 07_05_2022__01:56:34\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.5436359, Training accuracy: 0.4458929, Time: 07_05_2022__01:56:55\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.5429907, Training accuracy: 0.4461628, Time: 07_05_2022__01:57:15\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.5416619, Training accuracy: 0.4469886, Time: 07_05_2022__01:57:36\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.5390152, Training accuracy: 0.4479444, Time: 07_05_2022__01:57:56\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.5392500, Training accuracy: 0.4478804, Time: 07_05_2022__01:58:16\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.5388145, Training accuracy: 0.4478723, Time: 07_05_2022__01:58:37\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.5374025, Training accuracy: 0.4481250, Time: 07_05_2022__01:58:57\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.5395894, Training accuracy: 0.4476020, Time: 07_05_2022__01:59:18\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.5398690, Training accuracy: 0.4477000, Time: 07_05_2022__01:59:38\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.5387927, Training accuracy: 0.4478922, Time: 07_05_2022__01:59:58\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.5396243, Training accuracy: 0.4478365, Time: 07_05_2022__02:00:19\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.5398327, Training accuracy: 0.4483962, Time: 07_05_2022__02:00:39\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.5406298, Training accuracy: 0.4483796, Time: 07_05_2022__02:01:00\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.5395897, Training accuracy: 0.4484545, Time: 07_05_2022__02:01:20\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.5390421, Training accuracy: 0.4487946, Time: 07_05_2022__02:01:41\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.5382741, Training accuracy: 0.4491228, Time: 07_05_2022__02:02:01\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.5377130, Training accuracy: 0.4496121, Time: 07_05_2022__02:02:22\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.5372035, Training accuracy: 0.4503390, Time: 07_05_2022__02:02:42\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.5373669, Training accuracy: 0.4502500, Time: 07_05_2022__02:03:02\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.5384958, Training accuracy: 0.4495902, Time: 07_05_2022__02:03:23\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.5373845, Training accuracy: 0.4497984, Time: 07_05_2022__02:03:43\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.5379523, Training accuracy: 0.4496032, Time: 07_05_2022__02:04:04\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.5372897, Training accuracy: 0.4499609, Time: 07_05_2022__02:04:24\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.5349062, Training accuracy: 0.4507692, Time: 07_05_2022__02:04:45\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.5340094, Training accuracy: 0.4516288, Time: 07_05_2022__02:05:05\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.5322175, Training accuracy: 0.4522015, Time: 07_05_2022__02:05:26\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.5321216, Training accuracy: 0.4522794, Time: 07_05_2022__02:05:46\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.5320265, Training accuracy: 0.4522464, Time: 07_05_2022__02:06:07\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.5306130, Training accuracy: 0.4529643, Time: 07_05_2022__02:06:27\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.5305231, Training accuracy: 0.4533099, Time: 07_05_2022__02:06:47\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.5295289, Training accuracy: 0.4538542, Time: 07_05_2022__02:07:08\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.5293127, Training accuracy: 0.4538014, Time: 07_05_2022__02:07:28\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.5290650, Training accuracy: 0.4537838, Time: 07_05_2022__02:07:49\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.5274899, Training accuracy: 0.4547000, Time: 07_05_2022__02:08:09\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.5266779, Training accuracy: 0.4551974, Time: 07_05_2022__02:08:30\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.5256695, Training accuracy: 0.4557143, Time: 07_05_2022__02:08:50\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.5240020, Training accuracy: 0.4560256, Time: 07_05_2022__02:09:11\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.5236095, Training accuracy: 0.4562658, Time: 07_05_2022__02:09:31\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.5234297, Training accuracy: 0.4565938, Time: 07_05_2022__02:09:51\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.5239474, Training accuracy: 0.4565123, Time: 07_05_2022__02:10:12\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.5227305, Training accuracy: 0.4570732, Time: 07_05_2022__02:10:32\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.5208731, Training accuracy: 0.4576506, Time: 07_05_2022__02:10:53\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.5212501, Training accuracy: 0.4576190, Time: 07_05_2022__02:11:13\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.5202464, Training accuracy: 0.4578824, Time: 07_05_2022__02:11:34\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.5195948, Training accuracy: 0.4581395, Time: 07_05_2022__02:11:54\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.5188245, Training accuracy: 0.4585632, Time: 07_05_2022__02:12:15\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.5174766, Training accuracy: 0.4594886, Time: 07_05_2022__02:12:35\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 1.5167688, Training accuracy: 0.4598034, Time: 07_05_2022__02:12:56\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 1.5154052, Training accuracy: 0.4602222, Time: 07_05_2022__02:13:16\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 1.5151546, Training accuracy: 0.4601923, Time: 07_05_2022__02:13:36\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 1.5140737, Training accuracy: 0.4607065, Time: 07_05_2022__02:13:57\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 1.5146050, Training accuracy: 0.4605108, Time: 07_05_2022__02:14:17\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 1.5142889, Training accuracy: 0.4604255, Time: 07_05_2022__02:14:38\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 1.5149577, Training accuracy: 0.4602105, Time: 07_05_2022__02:14:58\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 1.5132088, Training accuracy: 0.4607552, Time: 07_05_2022__02:15:19\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 1.5111122, Training accuracy: 0.4615464, Time: 07_05_2022__02:15:39\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 1.5096802, Training accuracy: 0.4621939, Time: 07_05_2022__02:16:00\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 1.5092896, Training accuracy: 0.4621212, Time: 07_05_2022__02:16:20\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 1.5090650, Training accuracy: 0.4624750, Time: 07_05_2022__02:16:41\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 1.5093639, Training accuracy: 0.4625743, Time: 07_05_2022__02:17:01\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 1.5079766, Training accuracy: 0.4628431, Time: 07_05_2022__02:17:21\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 1.5061412, Training accuracy: 0.4633495, Time: 07_05_2022__02:17:42\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 1.5058203, Training accuracy: 0.4637260, Time: 07_05_2022__02:18:02\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 1.5047049, Training accuracy: 0.4642381, Time: 07_05_2022__02:18:23\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 1.5034584, Training accuracy: 0.4646462, Time: 07_05_2022__02:18:43\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 1.5026601, Training accuracy: 0.4649533, Time: 07_05_2022__02:19:04\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 1.5015220, Training accuracy: 0.4652778, Time: 07_05_2022__02:19:24\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 1.5010083, Training accuracy: 0.4655505, Time: 07_05_2022__02:19:44\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 1.5004302, Training accuracy: 0.4657500, Time: 07_05_2022__02:20:05\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 1.4989457, Training accuracy: 0.4663288, Time: 07_05_2022__02:20:25\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 1.4983301, Training accuracy: 0.4662946, Time: 07_05_2022__02:20:46\n","Epoch 3 of 5, Average training loss: 1.4981801, Average training accuracy: 0.4662889, Time: 07_05_2022__02:20:56\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc83b7b437a544baa34cd352dfda80ee"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.2563823, Validation accuracy: 0.5425000, Time: 07_05_2022__02:21:01 | Loss decreased from 1.4547268 to 1.2552099 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.2224828, Validation accuracy: 0.5600000, Time: 07_05_2022__02:21:09 | Loss decreased from 1.2552099 to 1.2218921 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.2420429, Validation accuracy: 0.5600000, Time: 07_05_2022__02:21:16\n","Step: 400 of 1250, Validation loss: 1.2719776, Validation accuracy: 0.5487500, Time: 07_05_2022__02:21:21\n","Step: 500 of 1250, Validation loss: 1.2865161, Validation accuracy: 0.5435000, Time: 07_05_2022__02:21:26\n","Step: 600 of 1250, Validation loss: 1.2805999, Validation accuracy: 0.5466667, Time: 07_05_2022__02:21:31\n","Step: 700 of 1250, Validation loss: 1.2666272, Validation accuracy: 0.5510714, Time: 07_05_2022__02:21:36\n","Step: 800 of 1250, Validation loss: 1.2568541, Validation accuracy: 0.5553125, Time: 07_05_2022__02:21:42\n","Step: 900 of 1250, Validation loss: 1.2599091, Validation accuracy: 0.5533333, Time: 07_05_2022__02:21:47\n","Step: 1000 of 1250, Validation loss: 1.2612938, Validation accuracy: 0.5505000, Time: 07_05_2022__02:21:52\n","Step: 1100 of 1250, Validation loss: 1.2615778, Validation accuracy: 0.5504545, Time: 07_05_2022__02:21:57\n","Step: 1200 of 1250, Validation loss: 1.2673391, Validation accuracy: 0.5485417, Time: 07_05_2022__02:22:02\n","Average validation loss: 1.2680678, Average validation accuracy: 0.5480000, Time: 07_05_2022__02:22:05\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4008122cd1754742aa9355b2c49705c2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 1.3429522, Training accuracy: 0.5200000, Time: 07_05_2022__02:22:25\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 1.3612659, Training accuracy: 0.5125000, Time: 07_05_2022__02:22:45\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 1.3880817, Training accuracy: 0.5050000, Time: 07_05_2022__02:23:06\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 1.3734781, Training accuracy: 0.5106250, Time: 07_05_2022__02:23:26\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 1.3619577, Training accuracy: 0.5120000, Time: 07_05_2022__02:23:47\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 1.3546948, Training accuracy: 0.5166667, Time: 07_05_2022__02:24:07\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 1.3677659, Training accuracy: 0.5110714, Time: 07_05_2022__02:24:28\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 1.3652426, Training accuracy: 0.5137500, Time: 07_05_2022__02:24:48\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 1.3734886, Training accuracy: 0.5111111, Time: 07_05_2022__02:25:09\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 1.3708714, Training accuracy: 0.5125000, Time: 07_05_2022__02:25:29\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 1.3657737, Training accuracy: 0.5163636, Time: 07_05_2022__02:25:50\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 1.3685822, Training accuracy: 0.5164583, Time: 07_05_2022__02:26:10\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 1.3683143, Training accuracy: 0.5153846, Time: 07_05_2022__02:26:30\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 1.3650318, Training accuracy: 0.5153571, Time: 07_05_2022__02:26:51\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 1.3690071, Training accuracy: 0.5126667, Time: 07_05_2022__02:27:11\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 1.3709297, Training accuracy: 0.5114062, Time: 07_05_2022__02:27:32\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 1.3731526, Training accuracy: 0.5111765, Time: 07_05_2022__02:27:52\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 1.3743929, Training accuracy: 0.5106944, Time: 07_05_2022__02:28:13\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 1.3698894, Training accuracy: 0.5122368, Time: 07_05_2022__02:28:33\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 1.3693063, Training accuracy: 0.5110000, Time: 07_05_2022__02:28:54\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 1.3631029, Training accuracy: 0.5130952, Time: 07_05_2022__02:29:14\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 1.3589748, Training accuracy: 0.5162500, Time: 07_05_2022__02:29:35\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 1.3620631, Training accuracy: 0.5154348, Time: 07_05_2022__02:29:55\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 1.3588554, Training accuracy: 0.5158333, Time: 07_05_2022__02:30:16\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 1.3586834, Training accuracy: 0.5164000, Time: 07_05_2022__02:30:36\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 1.3545056, Training accuracy: 0.5182692, Time: 07_05_2022__02:30:57\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 1.3530769, Training accuracy: 0.5186111, Time: 07_05_2022__02:31:17\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 1.3533790, Training accuracy: 0.5180357, Time: 07_05_2022__02:31:37\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 1.3517155, Training accuracy: 0.5193103, Time: 07_05_2022__02:31:58\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 1.3516185, Training accuracy: 0.5200833, Time: 07_05_2022__02:32:18\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 1.3491170, Training accuracy: 0.5218548, Time: 07_05_2022__02:32:39\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 1.3468294, Training accuracy: 0.5226563, Time: 07_05_2022__02:32:59\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 1.3482916, Training accuracy: 0.5220455, Time: 07_05_2022__02:33:19\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 1.3478239, Training accuracy: 0.5221324, Time: 07_05_2022__02:33:40\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 1.3461466, Training accuracy: 0.5231429, Time: 07_05_2022__02:34:00\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 1.3475440, Training accuracy: 0.5218056, Time: 07_05_2022__02:34:21\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 1.3484565, Training accuracy: 0.5212838, Time: 07_05_2022__02:34:41\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 1.3465090, Training accuracy: 0.5219079, Time: 07_05_2022__02:35:02\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 1.3473895, Training accuracy: 0.5219231, Time: 07_05_2022__02:35:22\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 1.3473568, Training accuracy: 0.5208750, Time: 07_05_2022__02:35:43\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 1.3479453, Training accuracy: 0.5207317, Time: 07_05_2022__02:36:03\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 1.3445330, Training accuracy: 0.5221429, Time: 07_05_2022__02:36:24\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 1.3436657, Training accuracy: 0.5230233, Time: 07_05_2022__02:36:44\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 1.3433614, Training accuracy: 0.5232955, Time: 07_05_2022__02:37:05\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 1.3411658, Training accuracy: 0.5243333, Time: 07_05_2022__02:37:25\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 1.3416678, Training accuracy: 0.5240217, Time: 07_05_2022__02:37:46\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 1.3393085, Training accuracy: 0.5244149, Time: 07_05_2022__02:38:06\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 1.3386635, Training accuracy: 0.5246354, Time: 07_05_2022__02:38:26\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 1.3386458, Training accuracy: 0.5248980, Time: 07_05_2022__02:38:47\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 1.3373766, Training accuracy: 0.5258000, Time: 07_05_2022__02:39:07\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 1.3361975, Training accuracy: 0.5257353, Time: 07_05_2022__02:39:28\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 1.3377493, Training accuracy: 0.5256250, Time: 07_05_2022__02:39:48\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 1.3377916, Training accuracy: 0.5258019, Time: 07_05_2022__02:40:09\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 1.3385815, Training accuracy: 0.5254167, Time: 07_05_2022__02:40:29\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 1.3387912, Training accuracy: 0.5252727, Time: 07_05_2022__02:40:50\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 1.3388376, Training accuracy: 0.5254911, Time: 07_05_2022__02:41:10\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 1.3379673, Training accuracy: 0.5255263, Time: 07_05_2022__02:41:30\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 1.3376763, Training accuracy: 0.5256466, Time: 07_05_2022__02:41:51\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 1.3371217, Training accuracy: 0.5265254, Time: 07_05_2022__02:42:11\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 1.3364713, Training accuracy: 0.5267917, Time: 07_05_2022__02:42:32\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 1.3362738, Training accuracy: 0.5264754, Time: 07_05_2022__02:42:52\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 1.3358705, Training accuracy: 0.5270161, Time: 07_05_2022__02:43:13\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 1.3368308, Training accuracy: 0.5269841, Time: 07_05_2022__02:43:33\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 1.3358892, Training accuracy: 0.5275391, Time: 07_05_2022__02:43:54\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 1.3347134, Training accuracy: 0.5278462, Time: 07_05_2022__02:44:14\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 1.3323617, Training accuracy: 0.5287879, Time: 07_05_2022__02:44:35\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 1.3317348, Training accuracy: 0.5293657, Time: 07_05_2022__02:44:55\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 1.3310454, Training accuracy: 0.5295956, Time: 07_05_2022__02:45:16\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 1.3304376, Training accuracy: 0.5301449, Time: 07_05_2022__02:45:36\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 1.3280952, Training accuracy: 0.5311071, Time: 07_05_2022__02:45:56\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 1.3288352, Training accuracy: 0.5307394, Time: 07_05_2022__02:46:17\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 1.3276607, Training accuracy: 0.5314931, Time: 07_05_2022__02:46:37\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 1.3274089, Training accuracy: 0.5318151, Time: 07_05_2022__02:46:58\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 1.3271052, Training accuracy: 0.5318919, Time: 07_05_2022__02:47:18\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 1.3256171, Training accuracy: 0.5329667, Time: 07_05_2022__02:47:38\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 1.3238821, Training accuracy: 0.5338158, Time: 07_05_2022__02:47:59\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 1.3239424, Training accuracy: 0.5336039, Time: 07_05_2022__02:48:19\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 1.3229560, Training accuracy: 0.5339744, Time: 07_05_2022__02:48:40\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 1.3219693, Training accuracy: 0.5343671, Time: 07_05_2022__02:49:00\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 1.3206069, Training accuracy: 0.5350000, Time: 07_05_2022__02:49:21\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 1.3207650, Training accuracy: 0.5350617, Time: 07_05_2022__02:49:41\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 1.3198650, Training accuracy: 0.5351829, Time: 07_05_2022__02:50:01\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 1.3177154, Training accuracy: 0.5358133, Time: 07_05_2022__02:50:22\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 1.3182502, Training accuracy: 0.5355060, Time: 07_05_2022__02:50:42\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 1.3170598, Training accuracy: 0.5362059, Time: 07_05_2022__02:51:03\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 1.3170939, Training accuracy: 0.5363081, Time: 07_05_2022__02:51:23\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 1.3169444, Training accuracy: 0.5364943, Time: 07_05_2022__02:51:44\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 1.3157935, Training accuracy: 0.5370455, Time: 07_05_2022__02:52:04\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 1.3141978, Training accuracy: 0.5378652, Time: 07_05_2022__02:52:25\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 1.3135584, Training accuracy: 0.5380556, Time: 07_05_2022__02:52:45\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 1.3137535, Training accuracy: 0.5380220, Time: 07_05_2022__02:53:06\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 1.3122671, Training accuracy: 0.5384783, Time: 07_05_2022__02:53:26\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 1.3125070, Training accuracy: 0.5381989, Time: 07_05_2022__02:53:46\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 1.3117827, Training accuracy: 0.5384309, Time: 07_05_2022__02:54:07\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 1.3123918, Training accuracy: 0.5383947, Time: 07_05_2022__02:54:27\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 1.3113954, Training accuracy: 0.5385156, Time: 07_05_2022__02:54:48\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 1.3101951, Training accuracy: 0.5390979, Time: 07_05_2022__02:55:08\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 1.3089946, Training accuracy: 0.5396684, Time: 07_05_2022__02:55:29\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 1.3083424, Training accuracy: 0.5397475, Time: 07_05_2022__02:55:49\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 1.3075547, Training accuracy: 0.5400500, Time: 07_05_2022__02:56:10\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 1.3086575, Training accuracy: 0.5397277, Time: 07_05_2022__02:56:30\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 1.3074214, Training accuracy: 0.5400980, Time: 07_05_2022__02:56:51\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 1.3062949, Training accuracy: 0.5408010, Time: 07_05_2022__02:57:11\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 1.3057577, Training accuracy: 0.5409856, Time: 07_05_2022__02:57:31\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 1.3048031, Training accuracy: 0.5414286, Time: 07_05_2022__02:57:52\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 1.3037417, Training accuracy: 0.5420283, Time: 07_05_2022__02:58:12\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 1.3029834, Training accuracy: 0.5425234, Time: 07_05_2022__02:58:33\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 1.3020403, Training accuracy: 0.5429398, Time: 07_05_2022__02:58:53\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 1.3020889, Training accuracy: 0.5429128, Time: 07_05_2022__02:59:14\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 1.3014136, Training accuracy: 0.5432955, Time: 07_05_2022__02:59:34\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 1.2992827, Training accuracy: 0.5439640, Time: 07_05_2022__02:59:55\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 1.2983221, Training accuracy: 0.5442857, Time: 07_05_2022__03:00:15\n","Epoch 4 of 5, Average training loss: 1.2989137, Average training accuracy: 0.5441556, Time: 07_05_2022__03:00:25\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10d4c3071e2941ca9d40cae0b1ec3c32"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.1554871, Validation accuracy: 0.6150000, Time: 07_05_2022__03:00:30 | Loss decreased from 1.2218921 to 1.1541998 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.1708519, Validation accuracy: 0.5787500, Time: 07_05_2022__03:00:38\n","Step: 300 of 1250, Validation loss: 1.1688314, Validation accuracy: 0.5833333, Time: 07_05_2022__03:00:43\n","Step: 400 of 1250, Validation loss: 1.1779888, Validation accuracy: 0.5856250, Time: 07_05_2022__03:00:49\n","Step: 500 of 1250, Validation loss: 1.1914713, Validation accuracy: 0.5790000, Time: 07_05_2022__03:00:54\n","Step: 600 of 1250, Validation loss: 1.1827603, Validation accuracy: 0.5837500, Time: 07_05_2022__03:00:59\n","Step: 700 of 1250, Validation loss: 1.1697753, Validation accuracy: 0.5892857, Time: 07_05_2022__03:01:04\n","Step: 800 of 1250, Validation loss: 1.1561148, Validation accuracy: 0.5978125, Time: 07_05_2022__03:01:09\n","Step: 900 of 1250, Validation loss: 1.1572562, Validation accuracy: 0.5961111, Time: 07_05_2022__03:01:14\n","Step: 1000 of 1250, Validation loss: 1.1617127, Validation accuracy: 0.5930000, Time: 07_05_2022__03:01:19\n","Step: 1100 of 1250, Validation loss: 1.1659182, Validation accuracy: 0.5929545, Time: 07_05_2022__03:01:24\n","Step: 1200 of 1250, Validation loss: 1.1673883, Validation accuracy: 0.5925000, Time: 07_05_2022__03:01:29\n","Average validation loss: 1.1657334, Average validation accuracy: 0.5934000, Time: 07_05_2022__03:01:32\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ba3412a4bc4c208e8d67416bfd47e9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 1.1142324, Training accuracy: 0.6100000, Time: 07_05_2022__03:01:52\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 1.1541370, Training accuracy: 0.5975000, Time: 07_05_2022__03:02:13\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 1.1895577, Training accuracy: 0.5950000, Time: 07_05_2022__03:02:33\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 1.1566348, Training accuracy: 0.6068750, Time: 07_05_2022__03:02:54\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 1.1481556, Training accuracy: 0.6100000, Time: 07_05_2022__03:03:14\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 1.1575108, Training accuracy: 0.6100000, Time: 07_05_2022__03:03:35\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 1.1693061, Training accuracy: 0.6053571, Time: 07_05_2022__03:03:55\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 1.1650246, Training accuracy: 0.6053125, Time: 07_05_2022__03:04:15\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 1.1749017, Training accuracy: 0.6011111, Time: 07_05_2022__03:04:36\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 1.1779369, Training accuracy: 0.5980000, Time: 07_05_2022__03:04:56\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 1.1780294, Training accuracy: 0.5956818, Time: 07_05_2022__03:05:17\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 1.1806954, Training accuracy: 0.5941667, Time: 07_05_2022__03:05:37\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 1.1810275, Training accuracy: 0.5925000, Time: 07_05_2022__03:05:58\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 1.1811277, Training accuracy: 0.5917857, Time: 07_05_2022__03:06:18\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 1.1879036, Training accuracy: 0.5890000, Time: 07_05_2022__03:06:38\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 1.1890583, Training accuracy: 0.5878125, Time: 07_05_2022__03:06:59\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 1.1917114, Training accuracy: 0.5873529, Time: 07_05_2022__03:07:19\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 1.1938451, Training accuracy: 0.5861111, Time: 07_05_2022__03:07:40\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 1.1868394, Training accuracy: 0.5881579, Time: 07_05_2022__03:08:00\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 1.1843860, Training accuracy: 0.5892500, Time: 07_05_2022__03:08:21\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 1.1802464, Training accuracy: 0.5910714, Time: 07_05_2022__03:08:41\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 1.1769069, Training accuracy: 0.5917045, Time: 07_05_2022__03:09:02\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 1.1776426, Training accuracy: 0.5921739, Time: 07_05_2022__03:09:22\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 1.1732131, Training accuracy: 0.5938542, Time: 07_05_2022__03:09:43\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 1.1728440, Training accuracy: 0.5939000, Time: 07_05_2022__03:10:03\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 1.1693212, Training accuracy: 0.5946154, Time: 07_05_2022__03:10:23\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 1.1658743, Training accuracy: 0.5945370, Time: 07_05_2022__03:10:44\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 1.1650822, Training accuracy: 0.5940179, Time: 07_05_2022__03:11:04\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 1.1664547, Training accuracy: 0.5937069, Time: 07_05_2022__03:11:25\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 1.1660944, Training accuracy: 0.5936667, Time: 07_05_2022__03:11:45\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 1.1624939, Training accuracy: 0.5945161, Time: 07_05_2022__03:12:06\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 1.1602127, Training accuracy: 0.5958594, Time: 07_05_2022__03:12:26\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 1.1606485, Training accuracy: 0.5956818, Time: 07_05_2022__03:12:47\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 1.1598672, Training accuracy: 0.5957353, Time: 07_05_2022__03:13:07\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 1.1586341, Training accuracy: 0.5965000, Time: 07_05_2022__03:13:28\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 1.1601227, Training accuracy: 0.5945833, Time: 07_05_2022__03:13:48\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 1.1606362, Training accuracy: 0.5938514, Time: 07_05_2022__03:14:09\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 1.1568886, Training accuracy: 0.5943421, Time: 07_05_2022__03:14:29\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 1.1579889, Training accuracy: 0.5934615, Time: 07_05_2022__03:14:50\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 1.1557492, Training accuracy: 0.5942500, Time: 07_05_2022__03:15:10\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 1.1562381, Training accuracy: 0.5940244, Time: 07_05_2022__03:15:31\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 1.1535326, Training accuracy: 0.5946429, Time: 07_05_2022__03:15:51\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 1.1531307, Training accuracy: 0.5950581, Time: 07_05_2022__03:16:12\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 1.1538050, Training accuracy: 0.5948864, Time: 07_05_2022__03:16:32\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 1.1523760, Training accuracy: 0.5955000, Time: 07_05_2022__03:16:53\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 1.1522775, Training accuracy: 0.5952717, Time: 07_05_2022__03:17:13\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 1.1504296, Training accuracy: 0.5963298, Time: 07_05_2022__03:17:34\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 1.1490018, Training accuracy: 0.5968750, Time: 07_05_2022__03:17:54\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 1.1505842, Training accuracy: 0.5963776, Time: 07_05_2022__03:18:15\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 1.1502448, Training accuracy: 0.5967500, Time: 07_05_2022__03:18:35\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 1.1503963, Training accuracy: 0.5963235, Time: 07_05_2022__03:18:56\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 1.1515283, Training accuracy: 0.5959615, Time: 07_05_2022__03:19:16\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 1.1519306, Training accuracy: 0.5959434, Time: 07_05_2022__03:19:36\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 1.1516971, Training accuracy: 0.5957407, Time: 07_05_2022__03:19:57\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 1.1519473, Training accuracy: 0.5963182, Time: 07_05_2022__03:20:17\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 1.1514209, Training accuracy: 0.5962054, Time: 07_05_2022__03:20:38\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 1.1498491, Training accuracy: 0.5963158, Time: 07_05_2022__03:20:58\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 1.1496410, Training accuracy: 0.5963362, Time: 07_05_2022__03:21:19\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 1.1497664, Training accuracy: 0.5964407, Time: 07_05_2022__03:21:39\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 1.1511893, Training accuracy: 0.5960833, Time: 07_05_2022__03:22:00\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 1.1516366, Training accuracy: 0.5960656, Time: 07_05_2022__03:22:20\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 1.1519738, Training accuracy: 0.5958871, Time: 07_05_2022__03:22:41\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 1.1520977, Training accuracy: 0.5955952, Time: 07_05_2022__03:23:01\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 1.1499105, Training accuracy: 0.5964063, Time: 07_05_2022__03:23:22\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 1.1489019, Training accuracy: 0.5970385, Time: 07_05_2022__03:23:42\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 1.1475688, Training accuracy: 0.5973864, Time: 07_05_2022__03:24:03\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 1.1470500, Training accuracy: 0.5972761, Time: 07_05_2022__03:24:23\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 1.1472942, Training accuracy: 0.5969853, Time: 07_05_2022__03:24:44\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 1.1464019, Training accuracy: 0.5969928, Time: 07_05_2022__03:25:04\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 1.1442377, Training accuracy: 0.5974643, Time: 07_05_2022__03:25:25\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 1.1450988, Training accuracy: 0.5976761, Time: 07_05_2022__03:25:45\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 1.1434177, Training accuracy: 0.5981944, Time: 07_05_2022__03:26:06\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 1.1425552, Training accuracy: 0.5980479, Time: 07_05_2022__03:26:26\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 1.1409688, Training accuracy: 0.5983108, Time: 07_05_2022__03:26:46\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 1.1395117, Training accuracy: 0.5992000, Time: 07_05_2022__03:27:07\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 1.1382889, Training accuracy: 0.5999013, Time: 07_05_2022__03:27:27\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 1.1375347, Training accuracy: 0.6003896, Time: 07_05_2022__03:27:48\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 1.1364669, Training accuracy: 0.6003205, Time: 07_05_2022__03:28:08\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 1.1350848, Training accuracy: 0.6007278, Time: 07_05_2022__03:28:29\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 1.1344845, Training accuracy: 0.6008438, Time: 07_05_2022__03:28:49\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 1.1348224, Training accuracy: 0.6008951, Time: 07_05_2022__03:29:10\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 1.1338396, Training accuracy: 0.6015549, Time: 07_05_2022__03:29:30\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 1.1333551, Training accuracy: 0.6023193, Time: 07_05_2022__03:29:51\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 1.1338345, Training accuracy: 0.6021726, Time: 07_05_2022__03:30:11\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 1.1332821, Training accuracy: 0.6023235, Time: 07_05_2022__03:30:32\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 1.1329319, Training accuracy: 0.6025872, Time: 07_05_2022__03:30:52\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 1.1329576, Training accuracy: 0.6023276, Time: 07_05_2022__03:31:12\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 1.1310426, Training accuracy: 0.6033807, Time: 07_05_2022__03:31:33\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 1.1299388, Training accuracy: 0.6038483, Time: 07_05_2022__03:31:53\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 1.1288500, Training accuracy: 0.6044722, Time: 07_05_2022__03:32:14\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 1.1285207, Training accuracy: 0.6047802, Time: 07_05_2022__03:32:34\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 1.1277823, Training accuracy: 0.6047826, Time: 07_05_2022__03:32:55\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 1.1282645, Training accuracy: 0.6044624, Time: 07_05_2022__03:33:15\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 1.1281677, Training accuracy: 0.6048138, Time: 07_05_2022__03:33:36\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 1.1290757, Training accuracy: 0.6051316, Time: 07_05_2022__03:33:56\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 1.1282648, Training accuracy: 0.6052344, Time: 07_05_2022__03:34:17\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 1.1269607, Training accuracy: 0.6056959, Time: 07_05_2022__03:34:37\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 1.1256232, Training accuracy: 0.6062245, Time: 07_05_2022__03:34:58\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 1.1244271, Training accuracy: 0.6067677, Time: 07_05_2022__03:35:18\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 1.1240373, Training accuracy: 0.6073250, Time: 07_05_2022__03:35:39\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 1.1248606, Training accuracy: 0.6070545, Time: 07_05_2022__03:35:59\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 1.1240770, Training accuracy: 0.6072549, Time: 07_05_2022__03:36:20\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 1.1230483, Training accuracy: 0.6075728, Time: 07_05_2022__03:36:40\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 1.1228682, Training accuracy: 0.6075481, Time: 07_05_2022__03:37:01\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 1.1218236, Training accuracy: 0.6080238, Time: 07_05_2022__03:37:21\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 1.1212116, Training accuracy: 0.6082075, Time: 07_05_2022__03:37:41\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 1.1201009, Training accuracy: 0.6085280, Time: 07_05_2022__03:38:02\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 1.1192478, Training accuracy: 0.6089352, Time: 07_05_2022__03:38:22\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 1.1186073, Training accuracy: 0.6093119, Time: 07_05_2022__03:38:43\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 1.1186366, Training accuracy: 0.6095682, Time: 07_05_2022__03:39:03\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 1.1181220, Training accuracy: 0.6098423, Time: 07_05_2022__03:39:24\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 1.1174314, Training accuracy: 0.6098884, Time: 07_05_2022__03:39:44\n","Epoch 5 of 5, Average training loss: 1.1175427, Average training accuracy: 0.6099333, Time: 07_05_2022__03:39:55\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8e83ae36f6a4365a1e83060fa5fecd9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.9787725, Validation accuracy: 0.6550000, Time: 07_05_2022__03:40:00 | Loss decreased from 1.1541998 to 0.9766989 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.9910018, Validation accuracy: 0.6512500, Time: 07_05_2022__03:40:07\n","Step: 300 of 1250, Validation loss: 1.0176166, Validation accuracy: 0.6458333, Time: 07_05_2022__03:40:12\n","Step: 400 of 1250, Validation loss: 1.0024655, Validation accuracy: 0.6500000, Time: 07_05_2022__03:40:17\n","Step: 500 of 1250, Validation loss: 1.0236264, Validation accuracy: 0.6450000, Time: 07_05_2022__03:40:23\n","Step: 600 of 1250, Validation loss: 1.0047512, Validation accuracy: 0.6525000, Time: 07_05_2022__03:40:28\n","Step: 700 of 1250, Validation loss: 0.9938843, Validation accuracy: 0.6550000, Time: 07_05_2022__03:40:33\n","Step: 800 of 1250, Validation loss: 0.9823638, Validation accuracy: 0.6584375, Time: 07_05_2022__03:40:38\n","Step: 900 of 1250, Validation loss: 0.9845888, Validation accuracy: 0.6600000, Time: 07_05_2022__03:40:43\n","Step: 1000 of 1250, Validation loss: 0.9902923, Validation accuracy: 0.6557500, Time: 07_05_2022__03:40:48\n","Step: 1100 of 1250, Validation loss: 0.9910873, Validation accuracy: 0.6561364, Time: 07_05_2022__03:40:53\n","Step: 1200 of 1250, Validation loss: 0.9925864, Validation accuracy: 0.6562500, Time: 07_05_2022__03:40:58\n","Average validation loss: 0.9902331, Average validation accuracy: 0.6578000, Time: 07_05_2022__03:41:01\n","###################### Testing vgg19_batch_norm SGD, lr_0.1, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea03632c23842928537a99bdf0db25b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.6250000, Time: 07_05_2022__03:41:15\n","Step: 200 of 2500, Test accuracy: 0.6437500, Time: 07_05_2022__03:41:21\n","Step: 300 of 2500, Test accuracy: 0.6650000, Time: 07_05_2022__03:41:26\n","Step: 400 of 2500, Test accuracy: 0.6593750, Time: 07_05_2022__03:41:31\n","Step: 500 of 2500, Test accuracy: 0.6555000, Time: 07_05_2022__03:41:36\n","Step: 600 of 2500, Test accuracy: 0.6558333, Time: 07_05_2022__03:41:41\n","Step: 700 of 2500, Test accuracy: 0.6467857, Time: 07_05_2022__03:41:46\n","Step: 800 of 2500, Test accuracy: 0.6475000, Time: 07_05_2022__03:41:51\n","Step: 900 of 2500, Test accuracy: 0.6436111, Time: 07_05_2022__03:41:56\n","Step: 1000 of 2500, Test accuracy: 0.6435000, Time: 07_05_2022__03:42:01\n","Step: 1100 of 2500, Test accuracy: 0.6490909, Time: 07_05_2022__03:42:07\n","Step: 1200 of 2500, Test accuracy: 0.6529167, Time: 07_05_2022__03:42:12\n","Step: 1300 of 2500, Test accuracy: 0.6532692, Time: 07_05_2022__03:42:17\n","Step: 1400 of 2500, Test accuracy: 0.6530357, Time: 07_05_2022__03:42:22\n","Step: 1500 of 2500, Test accuracy: 0.6553333, Time: 07_05_2022__03:42:27\n","Step: 1600 of 2500, Test accuracy: 0.6540625, Time: 07_05_2022__03:42:32\n","Step: 1700 of 2500, Test accuracy: 0.6542647, Time: 07_05_2022__03:42:37\n","Step: 1800 of 2500, Test accuracy: 0.6551389, Time: 07_05_2022__03:42:42\n","Step: 1900 of 2500, Test accuracy: 0.6559211, Time: 07_05_2022__03:42:47\n","Step: 2000 of 2500, Test accuracy: 0.6555000, Time: 07_05_2022__03:42:52\n","Step: 2100 of 2500, Test accuracy: 0.6557143, Time: 07_05_2022__03:42:57\n","Step: 2200 of 2500, Test accuracy: 0.6557955, Time: 07_05_2022__03:43:02\n","Step: 2300 of 2500, Test accuracy: 0.6578261, Time: 07_05_2022__03:43:07\n","Step: 2400 of 2500, Test accuracy: 0.6581250, Time: 07_05_2022__03:43:13\n","Step: 2500 of 2500, Test accuracy: 0.6576000, Time: 07_05_2022__03:43:18\n","Average testing accuracy: 0.6576000, Time: 07_05_2022__03:43:18\n","###################### Training vgg19_batch_norm SGD, lr_0.1, momentum_0.9 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc211b40720c4a6ca2bc1be418e9cc94"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 10.7094366, Training accuracy: 0.1025000, Time: 07_05_2022__03:43:40\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 6.5183922, Training accuracy: 0.0875000, Time: 07_05_2022__03:43:59\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 5.1147402, Training accuracy: 0.0941667, Time: 07_05_2022__03:44:19\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 4.4126542, Training accuracy: 0.0931250, Time: 07_05_2022__03:44:38\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 3.9913680, Training accuracy: 0.0935000, Time: 07_05_2022__03:44:57\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 3.7096322, Training accuracy: 0.0962500, Time: 07_05_2022__03:45:17\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 3.5090344, Training accuracy: 0.0985714, Time: 07_05_2022__03:45:36\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 3.3587062, Training accuracy: 0.0990625, Time: 07_05_2022__03:45:55\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 3.2414523, Training accuracy: 0.0975000, Time: 07_05_2022__03:46:15\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 3.1482492, Training accuracy: 0.0970000, Time: 07_05_2022__03:46:34\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 3.0715241, Training accuracy: 0.0972727, Time: 07_05_2022__03:46:53\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 3.0077855, Training accuracy: 0.0947917, Time: 07_05_2022__03:47:13\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.9536468, Training accuracy: 0.0942308, Time: 07_05_2022__03:47:32\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.9072222, Training accuracy: 0.0933929, Time: 07_05_2022__03:47:51\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.8668865, Training accuracy: 0.0936667, Time: 07_05_2022__03:48:10\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.8315970, Training accuracy: 0.0932812, Time: 07_05_2022__03:48:30\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.8007162, Training accuracy: 0.0929412, Time: 07_05_2022__03:48:49\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.7732532, Training accuracy: 0.0927778, Time: 07_05_2022__03:49:08\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.7484508, Training accuracy: 0.0928947, Time: 07_05_2022__03:49:28\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.7260849, Training accuracy: 0.0941250, Time: 07_05_2022__03:49:47\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.7059447, Training accuracy: 0.0944048, Time: 07_05_2022__03:50:06\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.6877139, Training accuracy: 0.0942045, Time: 07_05_2022__03:50:26\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.6709682, Training accuracy: 0.0951087, Time: 07_05_2022__03:50:45\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.6556613, Training accuracy: 0.0956250, Time: 07_05_2022__03:51:04\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.6415260, Training accuracy: 0.0963000, Time: 07_05_2022__03:51:24\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.6285262, Training accuracy: 0.0955769, Time: 07_05_2022__03:51:43\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.6164480, Training accuracy: 0.0960185, Time: 07_05_2022__03:52:02\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.6053063, Training accuracy: 0.0958036, Time: 07_05_2022__03:52:22\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.5948757, Training accuracy: 0.0961207, Time: 07_05_2022__03:52:41\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.5852917, Training accuracy: 0.0948333, Time: 07_05_2022__03:53:00\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.5761720, Training accuracy: 0.0945968, Time: 07_05_2022__03:53:19\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.5675503, Training accuracy: 0.0953125, Time: 07_05_2022__03:53:39\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.5595107, Training accuracy: 0.0950758, Time: 07_05_2022__03:53:58\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.5519840, Training accuracy: 0.0947059, Time: 07_05_2022__03:54:17\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.5448834, Training accuracy: 0.0955714, Time: 07_05_2022__03:54:37\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.5381557, Training accuracy: 0.0965278, Time: 07_05_2022__03:54:56\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.5317881, Training accuracy: 0.0960811, Time: 07_05_2022__03:55:15\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.5257929, Training accuracy: 0.0966447, Time: 07_05_2022__03:55:35\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.5201215, Training accuracy: 0.0967308, Time: 07_05_2022__03:55:54\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.5147520, Training accuracy: 0.0967500, Time: 07_05_2022__03:56:13\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.5096262, Training accuracy: 0.0966463, Time: 07_05_2022__03:56:33\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.5047156, Training accuracy: 0.0969048, Time: 07_05_2022__03:56:52\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.5000330, Training accuracy: 0.0965698, Time: 07_05_2022__03:57:11\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.4955915, Training accuracy: 0.0968182, Time: 07_05_2022__03:57:31\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.4913077, Training accuracy: 0.0970000, Time: 07_05_2022__03:57:50\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.4872575, Training accuracy: 0.0966304, Time: 07_05_2022__03:58:09\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.4833681, Training accuracy: 0.0963830, Time: 07_05_2022__03:58:29\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 2.4795834, Training accuracy: 0.0968750, Time: 07_05_2022__03:58:48\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 2.4759867, Training accuracy: 0.0965306, Time: 07_05_2022__03:59:07\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 2.4725096, Training accuracy: 0.0964500, Time: 07_05_2022__03:59:26\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 2.4692093, Training accuracy: 0.0961275, Time: 07_05_2022__03:59:46\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 2.4660295, Training accuracy: 0.0962500, Time: 07_05_2022__04:00:05\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 2.4629598, Training accuracy: 0.0965094, Time: 07_05_2022__04:00:24\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 2.4599914, Training accuracy: 0.0965741, Time: 07_05_2022__04:00:44\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 2.4571447, Training accuracy: 0.0965909, Time: 07_05_2022__04:01:03\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 2.4543922, Training accuracy: 0.0962500, Time: 07_05_2022__04:01:22\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 2.4517209, Training accuracy: 0.0960088, Time: 07_05_2022__04:01:41\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 2.4491601, Training accuracy: 0.0960345, Time: 07_05_2022__04:02:01\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 2.4466762, Training accuracy: 0.0963559, Time: 07_05_2022__04:02:20\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 2.4442666, Training accuracy: 0.0965417, Time: 07_05_2022__04:02:39\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 2.4419544, Training accuracy: 0.0964344, Time: 07_05_2022__04:02:59\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 2.4397158, Training accuracy: 0.0968145, Time: 07_05_2022__04:03:18\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 2.4375399, Training accuracy: 0.0970238, Time: 07_05_2022__04:03:37\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 2.4354494, Training accuracy: 0.0973047, Time: 07_05_2022__04:03:57\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 2.4334168, Training accuracy: 0.0970385, Time: 07_05_2022__04:04:16\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 2.4314567, Training accuracy: 0.0967424, Time: 07_05_2022__04:04:35\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 2.4295205, Training accuracy: 0.0967910, Time: 07_05_2022__04:04:55\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 2.4276959, Training accuracy: 0.0968382, Time: 07_05_2022__04:05:14\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 2.4259043, Training accuracy: 0.0968478, Time: 07_05_2022__04:05:33\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 2.4241487, Training accuracy: 0.0968929, Time: 07_05_2022__04:05:52\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 2.4224503, Training accuracy: 0.0967958, Time: 07_05_2022__04:06:12\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 2.4208023, Training accuracy: 0.0966319, Time: 07_05_2022__04:06:31\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 2.4191758, Training accuracy: 0.0962671, Time: 07_05_2022__04:06:50\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 2.4175976, Training accuracy: 0.0961486, Time: 07_05_2022__04:07:10\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 2.4160703, Training accuracy: 0.0960000, Time: 07_05_2022__04:07:29\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 2.4145735, Training accuracy: 0.0959211, Time: 07_05_2022__04:07:48\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 2.4131166, Training accuracy: 0.0957143, Time: 07_05_2022__04:08:08\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 2.4117007, Training accuracy: 0.0957372, Time: 07_05_2022__04:08:27\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 2.4103241, Training accuracy: 0.0958228, Time: 07_05_2022__04:08:46\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 2.4089875, Training accuracy: 0.0957812, Time: 07_05_2022__04:09:05\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 2.4076746, Training accuracy: 0.0958642, Time: 07_05_2022__04:09:25\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 2.4064227, Training accuracy: 0.0956098, Time: 07_05_2022__04:09:44\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 2.4051659, Training accuracy: 0.0956928, Time: 07_05_2022__04:10:03\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 2.4039398, Training accuracy: 0.0958036, Time: 07_05_2022__04:10:23\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 2.4027579, Training accuracy: 0.0958235, Time: 07_05_2022__04:10:42\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 2.4016004, Training accuracy: 0.0958430, Time: 07_05_2022__04:11:01\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 2.4004704, Training accuracy: 0.0958333, Time: 07_05_2022__04:11:20\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 2.3993429, Training accuracy: 0.0962216, Time: 07_05_2022__04:11:40\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 2.3982666, Training accuracy: 0.0960674, Time: 07_05_2022__04:11:59\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 2.3972038, Training accuracy: 0.0960833, Time: 07_05_2022__04:12:18\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 2.3961683, Training accuracy: 0.0962088, Time: 07_05_2022__04:12:38\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 2.3951633, Training accuracy: 0.0961413, Time: 07_05_2022__04:12:57\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 2.3941629, Training accuracy: 0.0962366, Time: 07_05_2022__04:13:16\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 2.3932045, Training accuracy: 0.0960904, Time: 07_05_2022__04:13:35\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 2.3922398, Training accuracy: 0.0961579, Time: 07_05_2022__04:13:55\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 2.3913016, Training accuracy: 0.0961719, Time: 07_05_2022__04:14:14\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 2.3903894, Training accuracy: 0.0961340, Time: 07_05_2022__04:14:33\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 2.3894896, Training accuracy: 0.0963010, Time: 07_05_2022__04:14:53\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 2.3886121, Training accuracy: 0.0962879, Time: 07_05_2022__04:15:12\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 2.3877432, Training accuracy: 0.0961750, Time: 07_05_2022__04:15:31\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 2.3869042, Training accuracy: 0.0961634, Time: 07_05_2022__04:15:51\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 2.3860779, Training accuracy: 0.0962010, Time: 07_05_2022__04:16:10\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 2.3852877, Training accuracy: 0.0958738, Time: 07_05_2022__04:16:29\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 2.3844641, Training accuracy: 0.0961779, Time: 07_05_2022__04:16:48\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 2.3837048, Training accuracy: 0.0961190, Time: 07_05_2022__04:17:08\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 2.3829290, Training accuracy: 0.0962972, Time: 07_05_2022__04:17:27\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 2.3821826, Training accuracy: 0.0964486, Time: 07_05_2022__04:17:46\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 2.3814495, Training accuracy: 0.0964815, Time: 07_05_2022__04:18:06\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 2.3807545, Training accuracy: 0.0964450, Time: 07_05_2022__04:18:25\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 2.3800527, Training accuracy: 0.0962727, Time: 07_05_2022__04:18:44\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 2.3793497, Training accuracy: 0.0963964, Time: 07_05_2022__04:19:03\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 2.3786650, Training accuracy: 0.0965179, Time: 07_05_2022__04:19:23\n","Epoch 1 of 5, Average training loss: 2.3783277, Average training accuracy: 0.0965111, Time: 07_05_2022__04:19:32\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16371885b51d4bd8b7462b4c95da242a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 2.3049739, Validation accuracy: 0.1050000, Time: 07_05_2022__04:19:37 | Loss decreased from inf to 2.3050746 .... Saving the model\n","Step: 200 of 1250, Validation loss: 2.3038397, Validation accuracy: 0.1000000, Time: 07_05_2022__04:19:45 | Loss decreased from 2.3050746 to 2.3037944 .... Saving the model\n","Step: 300 of 1250, Validation loss: 2.3036231, Validation accuracy: 0.1075000, Time: 07_05_2022__04:19:52 | Loss decreased from 2.3037944 to 2.3036265 .... Saving the model\n","Step: 400 of 1250, Validation loss: 2.3032953, Validation accuracy: 0.1000000, Time: 07_05_2022__04:19:59 | Loss decreased from 2.3036265 to 2.3033048 .... Saving the model\n","Step: 500 of 1250, Validation loss: 2.3032104, Validation accuracy: 0.1030000, Time: 07_05_2022__04:20:07 | Loss decreased from 2.3033048 to 2.3031993 .... Saving the model\n","Step: 600 of 1250, Validation loss: 2.3031129, Validation accuracy: 0.1016667, Time: 07_05_2022__04:20:15 | Loss decreased from 2.3031993 to 2.3031259 .... Saving the model\n","Step: 700 of 1250, Validation loss: 2.3030203, Validation accuracy: 0.1046429, Time: 07_05_2022__04:20:22 | Loss decreased from 2.3031259 to 2.3030220 .... Saving the model\n","Step: 800 of 1250, Validation loss: 2.3031000, Validation accuracy: 0.1034375, Time: 07_05_2022__04:20:30\n","Step: 900 of 1250, Validation loss: 2.3030339, Validation accuracy: 0.1016667, Time: 07_05_2022__04:20:35\n","Step: 1000 of 1250, Validation loss: 2.3029559, Validation accuracy: 0.1007500, Time: 07_05_2022__04:20:40 | Loss decreased from 2.3030220 to 2.3029630 .... Saving the model\n","Step: 1100 of 1250, Validation loss: 2.3028881, Validation accuracy: 0.0995455, Time: 07_05_2022__04:20:47 | Loss decreased from 2.3029630 to 2.3028846 .... Saving the model\n","Step: 1200 of 1250, Validation loss: 2.3028483, Validation accuracy: 0.0993750, Time: 07_05_2022__04:20:55 | Loss decreased from 2.3028846 to 2.3028429 .... Saving the model\n","Average validation loss: 2.3028227, Average validation accuracy: 0.1000000, Time: 07_05_2022__04:21:00\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a5a0d5431c54046a998ff1484f6ed13"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 2.3023049, Training accuracy: 0.0750000, Time: 07_05_2022__04:21:19\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 2.3023545, Training accuracy: 0.0825000, Time: 07_05_2022__04:21:39\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 2.3025230, Training accuracy: 0.0841667, Time: 07_05_2022__04:21:58\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 2.3025471, Training accuracy: 0.0868750, Time: 07_05_2022__04:22:17\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 2.3029118, Training accuracy: 0.0850000, Time: 07_05_2022__04:22:36\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 2.3028978, Training accuracy: 0.0920833, Time: 07_05_2022__04:22:56\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 2.3026281, Training accuracy: 0.0910714, Time: 07_05_2022__04:23:15\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 2.3027413, Training accuracy: 0.0906250, Time: 07_05_2022__04:23:34\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 2.3027558, Training accuracy: 0.0916667, Time: 07_05_2022__04:23:54\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 2.3026802, Training accuracy: 0.0957500, Time: 07_05_2022__04:24:13\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 2.3026993, Training accuracy: 0.0936364, Time: 07_05_2022__04:24:32\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 2.3026890, Training accuracy: 0.0937500, Time: 07_05_2022__04:24:52\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 2.3026361, Training accuracy: 0.0953846, Time: 07_05_2022__04:25:11\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 2.3026110, Training accuracy: 0.0951786, Time: 07_05_2022__04:25:30\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 2.3025722, Training accuracy: 0.0970000, Time: 07_05_2022__04:25:49\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 2.3026038, Training accuracy: 0.0970312, Time: 07_05_2022__04:26:09\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 2.3025368, Training accuracy: 0.0980882, Time: 07_05_2022__04:26:28\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 2.3025345, Training accuracy: 0.0983333, Time: 07_05_2022__04:26:47\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 2.3026620, Training accuracy: 0.0981579, Time: 07_05_2022__04:27:07\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 2.3025405, Training accuracy: 0.0987500, Time: 07_05_2022__04:27:26\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 2.3025406, Training accuracy: 0.0978571, Time: 07_05_2022__04:27:45\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 2.3024379, Training accuracy: 0.0984091, Time: 07_05_2022__04:28:04\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 2.3024965, Training accuracy: 0.0991304, Time: 07_05_2022__04:28:24\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 2.3024481, Training accuracy: 0.0988542, Time: 07_05_2022__04:28:43\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 2.3024559, Training accuracy: 0.0994000, Time: 07_05_2022__04:29:02\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 2.3024569, Training accuracy: 0.0992308, Time: 07_05_2022__04:29:22\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 2.3025032, Training accuracy: 0.0989815, Time: 07_05_2022__04:29:41\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 2.3025266, Training accuracy: 0.0984821, Time: 07_05_2022__04:30:00\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 2.3025586, Training accuracy: 0.0976724, Time: 07_05_2022__04:30:20\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 2.3026073, Training accuracy: 0.0976667, Time: 07_05_2022__04:30:39\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 2.3025967, Training accuracy: 0.0978226, Time: 07_05_2022__04:30:58\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 2.3026241, Training accuracy: 0.0972656, Time: 07_05_2022__04:31:17\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 2.3026035, Training accuracy: 0.0978788, Time: 07_05_2022__04:31:37\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 2.3025868, Training accuracy: 0.0981618, Time: 07_05_2022__04:31:56\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 2.3026099, Training accuracy: 0.0980714, Time: 07_05_2022__04:32:15\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 2.3026432, Training accuracy: 0.0979861, Time: 07_05_2022__04:32:35\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 2.3025882, Training accuracy: 0.0987162, Time: 07_05_2022__04:32:54\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 2.3026364, Training accuracy: 0.0984211, Time: 07_05_2022__04:33:13\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 2.3026625, Training accuracy: 0.0982692, Time: 07_05_2022__04:33:32\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 2.3026419, Training accuracy: 0.0983125, Time: 07_05_2022__04:33:52\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 2.3026473, Training accuracy: 0.0982317, Time: 07_05_2022__04:34:11\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 2.3026519, Training accuracy: 0.0987500, Time: 07_05_2022__04:34:30\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 2.3026675, Training accuracy: 0.0984302, Time: 07_05_2022__04:34:50\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 2.3027039, Training accuracy: 0.0982386, Time: 07_05_2022__04:35:09\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 2.3026903, Training accuracy: 0.0983333, Time: 07_05_2022__04:35:28\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 2.3027280, Training accuracy: 0.0980978, Time: 07_05_2022__04:35:48\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 2.3027554, Training accuracy: 0.0977660, Time: 07_05_2022__04:36:07\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 2.3027719, Training accuracy: 0.0976042, Time: 07_05_2022__04:36:26\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 2.3027700, Training accuracy: 0.0978061, Time: 07_05_2022__04:36:46\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 2.3027876, Training accuracy: 0.0976500, Time: 07_05_2022__04:37:05\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 2.3027935, Training accuracy: 0.0977451, Time: 07_05_2022__04:37:24\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 2.3027786, Training accuracy: 0.0981250, Time: 07_05_2022__04:37:43\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 2.3027747, Training accuracy: 0.0982075, Time: 07_05_2022__04:38:03\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 2.3027759, Training accuracy: 0.0984722, Time: 07_05_2022__04:38:22\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 2.3027827, Training accuracy: 0.0982727, Time: 07_05_2022__04:38:41\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 2.3027854, Training accuracy: 0.0981696, Time: 07_05_2022__04:39:01\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 2.3028011, Training accuracy: 0.0984211, Time: 07_05_2022__04:39:20\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 2.3027864, Training accuracy: 0.0984052, Time: 07_05_2022__04:39:39\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 2.3027616, Training accuracy: 0.0986017, Time: 07_05_2022__04:39:59\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 2.3027656, Training accuracy: 0.0983333, Time: 07_05_2022__04:40:18\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 2.3027553, Training accuracy: 0.0984016, Time: 07_05_2022__04:40:37\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 2.3027708, Training accuracy: 0.0982661, Time: 07_05_2022__04:40:56\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 2.3027718, Training accuracy: 0.0981746, Time: 07_05_2022__04:41:16\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 2.3027711, Training accuracy: 0.0983594, Time: 07_05_2022__04:41:35\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 2.3027652, Training accuracy: 0.0986538, Time: 07_05_2022__04:41:54\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 2.3027605, Training accuracy: 0.0987121, Time: 07_05_2022__04:42:14\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 2.3027696, Training accuracy: 0.0985821, Time: 07_05_2022__04:42:33\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 2.3027702, Training accuracy: 0.0989338, Time: 07_05_2022__04:42:52\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 2.3027650, Training accuracy: 0.0988043, Time: 07_05_2022__04:43:12\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 2.3027619, Training accuracy: 0.0986071, Time: 07_05_2022__04:43:31\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 2.3027879, Training accuracy: 0.0983451, Time: 07_05_2022__04:43:50\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 2.3027846, Training accuracy: 0.0983333, Time: 07_05_2022__04:44:09\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 2.3027876, Training accuracy: 0.0983219, Time: 07_05_2022__04:44:29\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 2.3027830, Training accuracy: 0.0986486, Time: 07_05_2022__04:44:48\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 2.3027981, Training accuracy: 0.0984667, Time: 07_05_2022__04:45:07\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 2.3028070, Training accuracy: 0.0983553, Time: 07_05_2022__04:45:27\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 2.3027921, Training accuracy: 0.0984416, Time: 07_05_2022__04:45:46\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 2.3027971, Training accuracy: 0.0984615, Time: 07_05_2022__04:46:05\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 2.3028071, Training accuracy: 0.0983544, Time: 07_05_2022__04:46:25\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 2.3028166, Training accuracy: 0.0979687, Time: 07_05_2022__04:46:44\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 2.3028139, Training accuracy: 0.0979630, Time: 07_05_2022__04:47:03\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 2.3028110, Training accuracy: 0.0981098, Time: 07_05_2022__04:47:22\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 2.3027898, Training accuracy: 0.0984036, Time: 07_05_2022__04:47:42\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 2.3027882, Training accuracy: 0.0982440, Time: 07_05_2022__04:48:01\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 2.3027886, Training accuracy: 0.0984706, Time: 07_05_2022__04:48:20\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 2.3028051, Training accuracy: 0.0983721, Time: 07_05_2022__04:48:39\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 2.3028031, Training accuracy: 0.0984770, Time: 07_05_2022__04:48:59\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 2.3028103, Training accuracy: 0.0984943, Time: 07_05_2022__04:49:18\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 2.3028150, Training accuracy: 0.0985393, Time: 07_05_2022__04:49:37\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 2.3028012, Training accuracy: 0.0985556, Time: 07_05_2022__04:49:57\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 2.3027942, Training accuracy: 0.0985440, Time: 07_05_2022__04:50:16\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 2.3027888, Training accuracy: 0.0986685, Time: 07_05_2022__04:50:35\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 2.3027995, Training accuracy: 0.0987097, Time: 07_05_2022__04:50:55\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 2.3027958, Training accuracy: 0.0989894, Time: 07_05_2022__04:51:14\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 2.3027729, Training accuracy: 0.0992105, Time: 07_05_2022__04:51:33\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 2.3027816, Training accuracy: 0.0992969, Time: 07_05_2022__04:51:53\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 2.3027731, Training accuracy: 0.0993041, Time: 07_05_2022__04:52:12\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 2.3027871, Training accuracy: 0.0990561, Time: 07_05_2022__04:52:31\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 2.3027995, Training accuracy: 0.0990152, Time: 07_05_2022__04:52:50\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 2.3028036, Training accuracy: 0.0992000, Time: 07_05_2022__04:53:10\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 2.3027985, Training accuracy: 0.0991089, Time: 07_05_2022__04:53:29\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 2.3027944, Training accuracy: 0.0989706, Time: 07_05_2022__04:53:48\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 2.3027928, Training accuracy: 0.0989320, Time: 07_05_2022__04:54:08\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 2.3027893, Training accuracy: 0.0989904, Time: 07_05_2022__04:54:27\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 2.3027848, Training accuracy: 0.0990476, Time: 07_05_2022__04:54:46\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 2.3027905, Training accuracy: 0.0987736, Time: 07_05_2022__04:55:05\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 2.3027957, Training accuracy: 0.0987383, Time: 07_05_2022__04:55:25\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 2.3028030, Training accuracy: 0.0986111, Time: 07_05_2022__04:55:44\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 2.3028055, Training accuracy: 0.0986468, Time: 07_05_2022__04:56:03\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 2.3028093, Training accuracy: 0.0986818, Time: 07_05_2022__04:56:23\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 2.3028020, Training accuracy: 0.0985586, Time: 07_05_2022__04:56:42\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 2.3028000, Training accuracy: 0.0986161, Time: 07_05_2022__04:57:01\n","Epoch 2 of 5, Average training loss: 2.3027956, Average training accuracy: 0.0986667, Time: 07_05_2022__04:57:11\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdd0091d200a4725a28027ca23972336"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 2.3030616, Validation accuracy: 0.0850000, Time: 07_05_2022__04:57:16\n","Step: 200 of 1250, Validation loss: 2.3031861, Validation accuracy: 0.0950000, Time: 07_05_2022__04:57:21\n","Step: 300 of 1250, Validation loss: 2.3027850, Validation accuracy: 0.0975000, Time: 07_05_2022__04:57:26 | Loss decreased from 2.3028429 to 2.3027683 .... Saving the model\n","Step: 400 of 1250, Validation loss: 2.3027495, Validation accuracy: 0.1000000, Time: 07_05_2022__04:57:33 | Loss decreased from 2.3027683 to 2.3027444 .... Saving the model\n","Step: 500 of 1250, Validation loss: 2.3026814, Validation accuracy: 0.0985000, Time: 07_05_2022__04:57:41 | Loss decreased from 2.3027444 to 2.3026774 .... Saving the model\n","Step: 600 of 1250, Validation loss: 2.3026303, Validation accuracy: 0.1033333, Time: 07_05_2022__04:57:48 | Loss decreased from 2.3026774 to 2.3026276 .... Saving the model\n","Step: 700 of 1250, Validation loss: 2.3026010, Validation accuracy: 0.1007143, Time: 07_05_2022__04:57:56 | Loss decreased from 2.3026276 to 2.3025978 .... Saving the model\n","Step: 800 of 1250, Validation loss: 2.3026729, Validation accuracy: 0.0993750, Time: 07_05_2022__04:58:03\n","Step: 900 of 1250, Validation loss: 2.3026484, Validation accuracy: 0.0988889, Time: 07_05_2022__04:58:09\n","Step: 1000 of 1250, Validation loss: 2.3026334, Validation accuracy: 0.0997500, Time: 07_05_2022__04:58:14\n","Step: 1100 of 1250, Validation loss: 2.3026803, Validation accuracy: 0.1002273, Time: 07_05_2022__04:58:19\n","Step: 1200 of 1250, Validation loss: 2.3026911, Validation accuracy: 0.0989583, Time: 07_05_2022__04:58:24\n","Average validation loss: 2.3026785, Average validation accuracy: 0.1000000, Time: 07_05_2022__04:58:27\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aad8fc5e82644f83b9b59c076f34d7e6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 2.3034427, Training accuracy: 0.0875000, Time: 07_05_2022__04:58:46\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 2.3031205, Training accuracy: 0.0962500, Time: 07_05_2022__04:59:05\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 2.3031833, Training accuracy: 0.0950000, Time: 07_05_2022__04:59:25\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 2.3029230, Training accuracy: 0.1018750, Time: 07_05_2022__04:59:44\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 2.3027300, Training accuracy: 0.1000000, Time: 07_05_2022__05:00:03\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 2.3027557, Training accuracy: 0.1000000, Time: 07_05_2022__05:00:23\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 2.3026812, Training accuracy: 0.1028571, Time: 07_05_2022__05:00:42\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 2.3027392, Training accuracy: 0.1006250, Time: 07_05_2022__05:01:01\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 2.3028047, Training accuracy: 0.0997222, Time: 07_05_2022__05:01:21\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 2.3027909, Training accuracy: 0.0992500, Time: 07_05_2022__05:01:40\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 2.3028100, Training accuracy: 0.0984091, Time: 07_05_2022__05:01:59\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 2.3028039, Training accuracy: 0.0968750, Time: 07_05_2022__05:02:19\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 2.3027977, Training accuracy: 0.0961538, Time: 07_05_2022__05:02:38\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 2.3027844, Training accuracy: 0.0971429, Time: 07_05_2022__05:02:57\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 2.3027860, Training accuracy: 0.0968333, Time: 07_05_2022__05:03:17\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 2.3027941, Training accuracy: 0.0973438, Time: 07_05_2022__05:03:36\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 2.3027614, Training accuracy: 0.0980882, Time: 07_05_2022__05:03:55\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 2.3027363, Training accuracy: 0.0973611, Time: 07_05_2022__05:04:15\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 2.3027678, Training accuracy: 0.0971053, Time: 07_05_2022__05:04:34\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 2.3027466, Training accuracy: 0.0975000, Time: 07_05_2022__05:04:53\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 2.3027536, Training accuracy: 0.0971429, Time: 07_05_2022__05:05:13\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 2.3027703, Training accuracy: 0.0975000, Time: 07_05_2022__05:05:32\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 2.3027650, Training accuracy: 0.0977174, Time: 07_05_2022__05:05:51\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 2.3027730, Training accuracy: 0.0982292, Time: 07_05_2022__05:06:10\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 2.3028028, Training accuracy: 0.0981000, Time: 07_05_2022__05:06:30\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 2.3028050, Training accuracy: 0.0985577, Time: 07_05_2022__05:06:49\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 2.3028193, Training accuracy: 0.0975926, Time: 07_05_2022__05:07:08\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 2.3028190, Training accuracy: 0.0976786, Time: 07_05_2022__05:07:28\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 2.3028325, Training accuracy: 0.0977586, Time: 07_05_2022__05:07:47\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 2.3028182, Training accuracy: 0.0972500, Time: 07_05_2022__05:08:06\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 2.3028171, Training accuracy: 0.0981452, Time: 07_05_2022__05:08:26\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 2.3028332, Training accuracy: 0.0985937, Time: 07_05_2022__05:08:45\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 2.3028198, Training accuracy: 0.0986364, Time: 07_05_2022__05:09:04\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 2.3028113, Training accuracy: 0.0983088, Time: 07_05_2022__05:09:23\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 2.3028019, Training accuracy: 0.0975714, Time: 07_05_2022__05:09:43\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 2.3028037, Training accuracy: 0.0975694, Time: 07_05_2022__05:10:02\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 2.3028093, Training accuracy: 0.0971622, Time: 07_05_2022__05:10:21\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 2.3028213, Training accuracy: 0.0966447, Time: 07_05_2022__05:10:41\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 2.3028164, Training accuracy: 0.0964744, Time: 07_05_2022__05:11:00\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 2.3028023, Training accuracy: 0.0967500, Time: 07_05_2022__05:11:19\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 2.3027952, Training accuracy: 0.0961585, Time: 07_05_2022__05:11:39\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 2.3027917, Training accuracy: 0.0963095, Time: 07_05_2022__05:11:58\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 2.3027784, Training accuracy: 0.0968023, Time: 07_05_2022__05:12:17\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 2.3027701, Training accuracy: 0.0976136, Time: 07_05_2022__05:12:36\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 2.3027841, Training accuracy: 0.0971111, Time: 07_05_2022__05:12:56\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 2.3027935, Training accuracy: 0.0967391, Time: 07_05_2022__05:13:15\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 2.3027973, Training accuracy: 0.0959574, Time: 07_05_2022__05:13:34\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 2.3027814, Training accuracy: 0.0960938, Time: 07_05_2022__05:13:54\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 2.3027752, Training accuracy: 0.0960204, Time: 07_05_2022__05:14:13\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 2.3027662, Training accuracy: 0.0961500, Time: 07_05_2022__05:14:32\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 2.3027589, Training accuracy: 0.0963725, Time: 07_05_2022__05:14:52\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 2.3027525, Training accuracy: 0.0959135, Time: 07_05_2022__05:15:11\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 2.3027608, Training accuracy: 0.0962736, Time: 07_05_2022__05:15:30\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 2.3027611, Training accuracy: 0.0959722, Time: 07_05_2022__05:15:50\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 2.3027631, Training accuracy: 0.0955909, Time: 07_05_2022__05:16:09\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 2.3027612, Training accuracy: 0.0954464, Time: 07_05_2022__05:16:28\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 2.3027613, Training accuracy: 0.0958333, Time: 07_05_2022__05:16:47\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 2.3027568, Training accuracy: 0.0961638, Time: 07_05_2022__05:17:07\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 2.3027425, Training accuracy: 0.0965254, Time: 07_05_2022__05:17:26\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 2.3027428, Training accuracy: 0.0963750, Time: 07_05_2022__05:17:45\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 2.3027446, Training accuracy: 0.0963934, Time: 07_05_2022__05:18:05\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 2.3027450, Training accuracy: 0.0964516, Time: 07_05_2022__05:18:24\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 2.3027435, Training accuracy: 0.0959524, Time: 07_05_2022__05:18:43\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 2.3027525, Training accuracy: 0.0960938, Time: 07_05_2022__05:19:03\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 2.3027531, Training accuracy: 0.0963462, Time: 07_05_2022__05:19:22\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 2.3027517, Training accuracy: 0.0967045, Time: 07_05_2022__05:19:41\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 2.3027520, Training accuracy: 0.0963433, Time: 07_05_2022__05:20:01\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 2.3027465, Training accuracy: 0.0961765, Time: 07_05_2022__05:20:20\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 2.3027528, Training accuracy: 0.0960870, Time: 07_05_2022__05:20:39\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 2.3027621, Training accuracy: 0.0962500, Time: 07_05_2022__05:20:58\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 2.3027626, Training accuracy: 0.0961268, Time: 07_05_2022__05:21:18\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 2.3027571, Training accuracy: 0.0964583, Time: 07_05_2022__05:21:37\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 2.3027502, Training accuracy: 0.0966781, Time: 07_05_2022__05:21:56\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 2.3027517, Training accuracy: 0.0967568, Time: 07_05_2022__05:22:16\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 2.3027569, Training accuracy: 0.0964333, Time: 07_05_2022__05:22:35\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 2.3027557, Training accuracy: 0.0966118, Time: 07_05_2022__05:22:54\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 2.3027499, Training accuracy: 0.0968831, Time: 07_05_2022__05:23:14\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 2.3027497, Training accuracy: 0.0966346, Time: 07_05_2022__05:23:33\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 2.3027491, Training accuracy: 0.0965823, Time: 07_05_2022__05:23:52\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 2.3027468, Training accuracy: 0.0964375, Time: 07_05_2022__05:24:12\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 2.3027474, Training accuracy: 0.0966049, Time: 07_05_2022__05:24:31\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 2.3027542, Training accuracy: 0.0964939, Time: 07_05_2022__05:24:50\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 2.3027409, Training accuracy: 0.0969578, Time: 07_05_2022__05:25:09\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 2.3027367, Training accuracy: 0.0968155, Time: 07_05_2022__05:25:29\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 2.3027371, Training accuracy: 0.0969118, Time: 07_05_2022__05:25:48\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 2.3027404, Training accuracy: 0.0968023, Time: 07_05_2022__05:26:07\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 2.3027330, Training accuracy: 0.0967241, Time: 07_05_2022__05:26:27\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 2.3027272, Training accuracy: 0.0968750, Time: 07_05_2022__05:26:46\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 2.3027232, Training accuracy: 0.0968258, Time: 07_05_2022__05:27:05\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 2.3027173, Training accuracy: 0.0970556, Time: 07_05_2022__05:27:25\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 2.3027199, Training accuracy: 0.0970055, Time: 07_05_2022__05:27:44\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 2.3027156, Training accuracy: 0.0973098, Time: 07_05_2022__05:28:03\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 2.3027123, Training accuracy: 0.0976075, Time: 07_05_2022__05:28:23\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 2.3027171, Training accuracy: 0.0974468, Time: 07_05_2022__05:28:42\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 2.3027135, Training accuracy: 0.0975263, Time: 07_05_2022__05:29:01\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 2.3027130, Training accuracy: 0.0975260, Time: 07_05_2022__05:29:21\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 2.3027115, Training accuracy: 0.0973969, Time: 07_05_2022__05:29:40\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 2.3027098, Training accuracy: 0.0973724, Time: 07_05_2022__05:29:59\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 2.3027074, Training accuracy: 0.0975000, Time: 07_05_2022__05:30:19\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 2.3027052, Training accuracy: 0.0977500, Time: 07_05_2022__05:30:38\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 2.3027042, Training accuracy: 0.0977723, Time: 07_05_2022__05:30:57\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 2.3027088, Training accuracy: 0.0977451, Time: 07_05_2022__05:31:16\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 2.3027086, Training accuracy: 0.0974757, Time: 07_05_2022__05:31:36\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 2.3027018, Training accuracy: 0.0976683, Time: 07_05_2022__05:31:55\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 2.3026979, Training accuracy: 0.0977857, Time: 07_05_2022__05:32:14\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 2.3026999, Training accuracy: 0.0978538, Time: 07_05_2022__05:32:34\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 2.3026947, Training accuracy: 0.0980374, Time: 07_05_2022__05:32:53\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 2.3026917, Training accuracy: 0.0980324, Time: 07_05_2022__05:33:12\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 2.3026913, Training accuracy: 0.0982569, Time: 07_05_2022__05:33:32\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 2.3026889, Training accuracy: 0.0982955, Time: 07_05_2022__05:33:51\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 2.3026962, Training accuracy: 0.0982207, Time: 07_05_2022__05:34:10\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 2.3026994, Training accuracy: 0.0980804, Time: 07_05_2022__05:34:30\n","Epoch 3 of 5, Average training loss: 2.3026980, Average training accuracy: 0.0982667, Time: 07_05_2022__05:34:39\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2732ba59aa5a4414981b1c4f4c4d83ea"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 2.3029520, Validation accuracy: 0.0975000, Time: 07_05_2022__05:34:44\n","Step: 200 of 1250, Validation loss: 2.3029028, Validation accuracy: 0.0787500, Time: 07_05_2022__05:34:49\n","Step: 300 of 1250, Validation loss: 2.3028259, Validation accuracy: 0.0858333, Time: 07_05_2022__05:34:54\n","Step: 400 of 1250, Validation loss: 2.3027144, Validation accuracy: 0.0881250, Time: 07_05_2022__05:35:00\n","Step: 500 of 1250, Validation loss: 2.3026448, Validation accuracy: 0.0900000, Time: 07_05_2022__05:35:05\n","Step: 600 of 1250, Validation loss: 2.3026184, Validation accuracy: 0.0920833, Time: 07_05_2022__05:35:10\n","Step: 700 of 1250, Validation loss: 2.3025834, Validation accuracy: 0.0950000, Time: 07_05_2022__05:35:15 | Loss decreased from 2.3025978 to 2.3025804 .... Saving the model\n","Step: 800 of 1250, Validation loss: 2.3026330, Validation accuracy: 0.0953125, Time: 07_05_2022__05:35:22\n","Step: 900 of 1250, Validation loss: 2.3026032, Validation accuracy: 0.0986111, Time: 07_05_2022__05:35:27\n","Step: 1000 of 1250, Validation loss: 2.3025707, Validation accuracy: 0.1020000, Time: 07_05_2022__05:35:33 | Loss decreased from 2.3025804 to 2.3025753 .... Saving the model\n","Step: 1100 of 1250, Validation loss: 2.3025771, Validation accuracy: 0.1009091, Time: 07_05_2022__05:35:40 | Loss decreased from 2.3025753 to 2.3025742 .... Saving the model\n","Step: 1200 of 1250, Validation loss: 2.3025889, Validation accuracy: 0.1018750, Time: 07_05_2022__05:35:47\n","Average validation loss: 2.3025955, Average validation accuracy: 0.1012000, Time: 07_05_2022__05:35:50\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0db87686a8c045eeae025bc41287933d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 2.3028608, Training accuracy: 0.1125000, Time: 07_05_2022__05:36:10\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 2.3028387, Training accuracy: 0.0950000, Time: 07_05_2022__05:36:29\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 2.3027274, Training accuracy: 0.1008333, Time: 07_05_2022__05:36:48\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 2.3026261, Training accuracy: 0.1006250, Time: 07_05_2022__05:37:07\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 2.3025770, Training accuracy: 0.1045000, Time: 07_05_2022__05:37:27\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 2.3025946, Training accuracy: 0.1070833, Time: 07_05_2022__05:37:46\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 2.3025261, Training accuracy: 0.1071429, Time: 07_05_2022__05:38:05\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 2.3025178, Training accuracy: 0.1046875, Time: 07_05_2022__05:38:25\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 2.3025326, Training accuracy: 0.1033333, Time: 07_05_2022__05:38:44\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 2.3025543, Training accuracy: 0.1012500, Time: 07_05_2022__05:39:03\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 2.3026172, Training accuracy: 0.0981818, Time: 07_05_2022__05:39:23\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 2.3025752, Training accuracy: 0.0989583, Time: 07_05_2022__05:39:42\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 2.3025427, Training accuracy: 0.0978846, Time: 07_05_2022__05:40:01\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 2.3025299, Training accuracy: 0.0969643, Time: 07_05_2022__05:40:20\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 2.3025325, Training accuracy: 0.0973333, Time: 07_05_2022__05:40:40\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 2.3024851, Training accuracy: 0.0982813, Time: 07_05_2022__05:40:59\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 2.3024684, Training accuracy: 0.0986765, Time: 07_05_2022__05:41:18\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 2.3024988, Training accuracy: 0.0991667, Time: 07_05_2022__05:41:38\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 2.3025027, Training accuracy: 0.0998684, Time: 07_05_2022__05:41:57\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 2.3025174, Training accuracy: 0.0991250, Time: 07_05_2022__05:42:16\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 2.3025290, Training accuracy: 0.0997619, Time: 07_05_2022__05:42:36\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 2.3025600, Training accuracy: 0.0992045, Time: 07_05_2022__05:42:55\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 2.3025396, Training accuracy: 0.0988043, Time: 07_05_2022__05:43:14\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 2.3025354, Training accuracy: 0.0988542, Time: 07_05_2022__05:43:34\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 2.3025586, Training accuracy: 0.0995000, Time: 07_05_2022__05:43:53\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 2.3025725, Training accuracy: 0.0995192, Time: 07_05_2022__05:44:12\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 2.3025869, Training accuracy: 0.0992593, Time: 07_05_2022__05:44:31\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 2.3025788, Training accuracy: 0.0988393, Time: 07_05_2022__05:44:51\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 2.3025902, Training accuracy: 0.0991379, Time: 07_05_2022__05:45:10\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 2.3025994, Training accuracy: 0.0985000, Time: 07_05_2022__05:45:29\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 2.3026030, Training accuracy: 0.0984677, Time: 07_05_2022__05:45:49\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 2.3026228, Training accuracy: 0.0984375, Time: 07_05_2022__05:46:08\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 2.3026298, Training accuracy: 0.0981818, Time: 07_05_2022__05:46:27\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 2.3026317, Training accuracy: 0.0989706, Time: 07_05_2022__05:46:47\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 2.3026514, Training accuracy: 0.0988571, Time: 07_05_2022__05:47:06\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 2.3026367, Training accuracy: 0.0994444, Time: 07_05_2022__05:47:25\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 2.3026387, Training accuracy: 0.0990541, Time: 07_05_2022__05:47:45\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 2.3026351, Training accuracy: 0.0994737, Time: 07_05_2022__05:48:04\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 2.3026453, Training accuracy: 0.0991667, Time: 07_05_2022__05:48:23\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 2.3026603, Training accuracy: 0.0988750, Time: 07_05_2022__05:48:42\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 2.3026364, Training accuracy: 0.1003049, Time: 07_05_2022__05:49:02\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 2.3026450, Training accuracy: 0.1005952, Time: 07_05_2022__05:49:21\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 2.3026623, Training accuracy: 0.1008140, Time: 07_05_2022__05:49:40\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 2.3026627, Training accuracy: 0.1006818, Time: 07_05_2022__05:50:00\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 2.3026633, Training accuracy: 0.1003889, Time: 07_05_2022__05:50:19\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 2.3026595, Training accuracy: 0.1001630, Time: 07_05_2022__05:50:38\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 2.3026606, Training accuracy: 0.0997340, Time: 07_05_2022__05:50:58\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 2.3026540, Training accuracy: 0.0998437, Time: 07_05_2022__05:51:17\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 2.3026631, Training accuracy: 0.0995408, Time: 07_05_2022__05:51:36\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 2.3026624, Training accuracy: 0.0995500, Time: 07_05_2022__05:51:55\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 2.3026861, Training accuracy: 0.0989216, Time: 07_05_2022__05:52:15\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 2.3026817, Training accuracy: 0.0990385, Time: 07_05_2022__05:52:34\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 2.3026777, Training accuracy: 0.0996226, Time: 07_05_2022__05:52:53\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 2.3026852, Training accuracy: 0.0996296, Time: 07_05_2022__05:53:13\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 2.3026935, Training accuracy: 0.0995909, Time: 07_05_2022__05:53:32\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 2.3026884, Training accuracy: 0.0995089, Time: 07_05_2022__05:53:51\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 2.3026895, Training accuracy: 0.0992544, Time: 07_05_2022__05:54:11\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 2.3026847, Training accuracy: 0.0996552, Time: 07_05_2022__05:54:30\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 2.3026726, Training accuracy: 0.0995763, Time: 07_05_2022__05:54:49\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 2.3026746, Training accuracy: 0.0996667, Time: 07_05_2022__05:55:09\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 2.3026755, Training accuracy: 0.0995082, Time: 07_05_2022__05:55:28\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 2.3026797, Training accuracy: 0.0993145, Time: 07_05_2022__05:55:47\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 2.3026760, Training accuracy: 0.0990079, Time: 07_05_2022__05:56:06\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 2.3026753, Training accuracy: 0.0990234, Time: 07_05_2022__05:56:26\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 2.3026745, Training accuracy: 0.0993462, Time: 07_05_2022__05:56:45\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 2.3026717, Training accuracy: 0.0994697, Time: 07_05_2022__05:57:04\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 2.3026655, Training accuracy: 0.0994776, Time: 07_05_2022__05:57:24\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 2.3026690, Training accuracy: 0.0995221, Time: 07_05_2022__05:57:43\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 2.3026620, Training accuracy: 0.0996377, Time: 07_05_2022__05:58:02\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 2.3026575, Training accuracy: 0.0995357, Time: 07_05_2022__05:58:22\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 2.3026647, Training accuracy: 0.0989789, Time: 07_05_2022__05:58:41\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 2.3026617, Training accuracy: 0.0990972, Time: 07_05_2022__05:59:00\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 2.3026573, Training accuracy: 0.0990411, Time: 07_05_2022__05:59:20\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 2.3026650, Training accuracy: 0.0989527, Time: 07_05_2022__05:59:39\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 2.3026680, Training accuracy: 0.0987667, Time: 07_05_2022__05:59:58\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 2.3026656, Training accuracy: 0.0987829, Time: 07_05_2022__06:00:17\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 2.3026568, Training accuracy: 0.0988636, Time: 07_05_2022__06:00:37\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 2.3026538, Training accuracy: 0.0990705, Time: 07_05_2022__06:00:56\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 2.3026575, Training accuracy: 0.0991772, Time: 07_05_2022__06:01:15\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 2.3026574, Training accuracy: 0.0992187, Time: 07_05_2022__06:01:35\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 2.3026594, Training accuracy: 0.0992901, Time: 07_05_2022__06:01:54\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 2.3026631, Training accuracy: 0.0991463, Time: 07_05_2022__06:02:13\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 2.3026541, Training accuracy: 0.0993373, Time: 07_05_2022__06:02:32\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 2.3026516, Training accuracy: 0.0991667, Time: 07_05_2022__06:02:52\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 2.3026428, Training accuracy: 0.0997059, Time: 07_05_2022__06:03:11\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 2.3026521, Training accuracy: 0.0996221, Time: 07_05_2022__06:03:30\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 2.3026440, Training accuracy: 0.0996839, Time: 07_05_2022__06:03:50\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 2.3026431, Training accuracy: 0.0998295, Time: 07_05_2022__06:04:09\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 2.3026438, Training accuracy: 0.0999157, Time: 07_05_2022__06:04:28\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 2.3026444, Training accuracy: 0.1001389, Time: 07_05_2022__06:04:48\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 2.3026486, Training accuracy: 0.1001374, Time: 07_05_2022__06:05:07\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 2.3026404, Training accuracy: 0.1003261, Time: 07_05_2022__06:05:26\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 2.3026355, Training accuracy: 0.1003495, Time: 07_05_2022__06:05:46\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 2.3026290, Training accuracy: 0.1005585, Time: 07_05_2022__06:06:05\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 2.3026292, Training accuracy: 0.1006842, Time: 07_05_2022__06:06:24\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 2.3026335, Training accuracy: 0.1005990, Time: 07_05_2022__06:06:43\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 2.3026331, Training accuracy: 0.1007990, Time: 07_05_2022__06:07:03\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 2.3026271, Training accuracy: 0.1009184, Time: 07_05_2022__06:07:22\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 2.3026205, Training accuracy: 0.1010606, Time: 07_05_2022__06:07:41\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 2.3026168, Training accuracy: 0.1012000, Time: 07_05_2022__06:08:01\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 2.3026128, Training accuracy: 0.1013119, Time: 07_05_2022__06:08:20\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 2.3026149, Training accuracy: 0.1014216, Time: 07_05_2022__06:08:39\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 2.3026240, Training accuracy: 0.1011893, Time: 07_05_2022__06:08:58\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 2.3026206, Training accuracy: 0.1012500, Time: 07_05_2022__06:09:18\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 2.3026225, Training accuracy: 0.1013095, Time: 07_05_2022__06:09:37\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 2.3026229, Training accuracy: 0.1013679, Time: 07_05_2022__06:09:56\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 2.3026177, Training accuracy: 0.1014019, Time: 07_05_2022__06:10:16\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 2.3026179, Training accuracy: 0.1012963, Time: 07_05_2022__06:10:35\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 2.3026123, Training accuracy: 0.1014220, Time: 07_05_2022__06:10:54\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 2.3026154, Training accuracy: 0.1013636, Time: 07_05_2022__06:11:14\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 2.3026272, Training accuracy: 0.1009009, Time: 07_05_2022__06:11:33\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 2.3026297, Training accuracy: 0.1008705, Time: 07_05_2022__06:11:52\n","Epoch 4 of 5, Average training loss: 2.3026314, Average training accuracy: 0.1007111, Time: 07_05_2022__06:12:02\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c4d8ea2bb58491490d588796541ee9f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 2.3029491, Validation accuracy: 0.0850000, Time: 07_05_2022__06:12:07\n","Step: 200 of 1250, Validation loss: 2.3027455, Validation accuracy: 0.0950000, Time: 07_05_2022__06:12:12\n","Step: 300 of 1250, Validation loss: 2.3026184, Validation accuracy: 0.0975000, Time: 07_05_2022__06:12:17\n","Step: 400 of 1250, Validation loss: 2.3025849, Validation accuracy: 0.1000000, Time: 07_05_2022__06:12:22\n","Step: 500 of 1250, Validation loss: 2.3025541, Validation accuracy: 0.0985000, Time: 07_05_2022__06:12:27 | Loss decreased from 2.3025742 to 2.3025612 .... Saving the model\n","Step: 600 of 1250, Validation loss: 2.3025392, Validation accuracy: 0.1033333, Time: 07_05_2022__06:12:34 | Loss decreased from 2.3025612 to 2.3025342 .... Saving the model\n","Step: 700 of 1250, Validation loss: 2.3025876, Validation accuracy: 0.1007143, Time: 07_05_2022__06:12:42\n","Step: 800 of 1250, Validation loss: 2.3026268, Validation accuracy: 0.0993750, Time: 07_05_2022__06:12:47\n","Step: 900 of 1250, Validation loss: 2.3025976, Validation accuracy: 0.0988889, Time: 07_05_2022__06:12:52\n","Step: 1000 of 1250, Validation loss: 2.3025694, Validation accuracy: 0.0997500, Time: 07_05_2022__06:12:57\n","Step: 1100 of 1250, Validation loss: 2.3025777, Validation accuracy: 0.1002273, Time: 07_05_2022__06:13:02\n","Step: 1200 of 1250, Validation loss: 2.3025927, Validation accuracy: 0.0989583, Time: 07_05_2022__06:13:07\n","Average validation loss: 2.3026069, Average validation accuracy: 0.1000000, Time: 07_05_2022__06:13:10\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f11fb58c50ba40478d8f8b4d3dc6c678"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 2.3026103, Training accuracy: 0.0725000, Time: 07_05_2022__06:13:29\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 2.3027925, Training accuracy: 0.0825000, Time: 07_05_2022__06:13:49\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 2.3026978, Training accuracy: 0.0791667, Time: 07_05_2022__06:14:08\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 2.3027190, Training accuracy: 0.0837500, Time: 07_05_2022__06:14:27\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 2.3027087, Training accuracy: 0.0885000, Time: 07_05_2022__06:14:47\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 2.3027304, Training accuracy: 0.0937500, Time: 07_05_2022__06:15:06\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 2.3027202, Training accuracy: 0.0932143, Time: 07_05_2022__06:15:25\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 2.3026606, Training accuracy: 0.0912500, Time: 07_05_2022__06:15:44\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 2.3026434, Training accuracy: 0.0936111, Time: 07_05_2022__06:16:04\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 2.3027445, Training accuracy: 0.0910000, Time: 07_05_2022__06:16:23\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 2.3027354, Training accuracy: 0.0915909, Time: 07_05_2022__06:16:42\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 2.3027523, Training accuracy: 0.0925000, Time: 07_05_2022__06:17:02\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 2.3026841, Training accuracy: 0.0940385, Time: 07_05_2022__06:17:21\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 2.3026481, Training accuracy: 0.0932143, Time: 07_05_2022__06:17:40\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 2.3026148, Training accuracy: 0.0956667, Time: 07_05_2022__06:17:59\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 2.3026302, Training accuracy: 0.0959375, Time: 07_05_2022__06:18:19\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 2.3026253, Training accuracy: 0.0947059, Time: 07_05_2022__06:18:38\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 2.3026600, Training accuracy: 0.0956944, Time: 07_05_2022__06:18:57\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 2.3026635, Training accuracy: 0.0972368, Time: 07_05_2022__06:19:17\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 2.3026284, Training accuracy: 0.0977500, Time: 07_05_2022__06:19:36\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 2.3026121, Training accuracy: 0.0966667, Time: 07_05_2022__06:19:55\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 2.3026138, Training accuracy: 0.0961364, Time: 07_05_2022__06:20:15\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 2.3025995, Training accuracy: 0.0963043, Time: 07_05_2022__06:20:34\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 2.3026098, Training accuracy: 0.0963542, Time: 07_05_2022__06:20:53\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 2.3026185, Training accuracy: 0.0974000, Time: 07_05_2022__06:21:12\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 2.3026280, Training accuracy: 0.0974038, Time: 07_05_2022__06:21:32\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 2.3026371, Training accuracy: 0.0969444, Time: 07_05_2022__06:21:51\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 2.3026431, Training accuracy: 0.0967857, Time: 07_05_2022__06:22:10\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 2.3026369, Training accuracy: 0.0975862, Time: 07_05_2022__06:22:30\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 2.3026435, Training accuracy: 0.0973333, Time: 07_05_2022__06:22:49\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 2.3026528, Training accuracy: 0.0974194, Time: 07_05_2022__06:23:08\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 2.3026426, Training accuracy: 0.0974219, Time: 07_05_2022__06:23:28\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 2.3026444, Training accuracy: 0.0975758, Time: 07_05_2022__06:23:47\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 2.3026475, Training accuracy: 0.0978676, Time: 07_05_2022__06:24:06\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 2.3026481, Training accuracy: 0.0981429, Time: 07_05_2022__06:24:25\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 2.3026471, Training accuracy: 0.0981250, Time: 07_05_2022__06:24:45\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 2.3026418, Training accuracy: 0.0981757, Time: 07_05_2022__06:25:04\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 2.3026604, Training accuracy: 0.0978947, Time: 07_05_2022__06:25:23\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 2.3026576, Training accuracy: 0.0970513, Time: 07_05_2022__06:25:43\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 2.3026728, Training accuracy: 0.0968750, Time: 07_05_2022__06:26:02\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 2.3026567, Training accuracy: 0.0970122, Time: 07_05_2022__06:26:21\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 2.3026548, Training accuracy: 0.0967857, Time: 07_05_2022__06:26:41\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 2.3026559, Training accuracy: 0.0970930, Time: 07_05_2022__06:27:00\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 2.3026590, Training accuracy: 0.0971023, Time: 07_05_2022__06:27:19\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 2.3026655, Training accuracy: 0.0973333, Time: 07_05_2022__06:27:39\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 2.3026672, Training accuracy: 0.0979348, Time: 07_05_2022__06:27:58\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 2.3026762, Training accuracy: 0.0977660, Time: 07_05_2022__06:28:17\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 2.3026607, Training accuracy: 0.0982813, Time: 07_05_2022__06:28:36\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 2.3026559, Training accuracy: 0.0981122, Time: 07_05_2022__06:28:56\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 2.3026518, Training accuracy: 0.0980000, Time: 07_05_2022__06:29:15\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 2.3026646, Training accuracy: 0.0973039, Time: 07_05_2022__06:29:34\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 2.3026570, Training accuracy: 0.0971154, Time: 07_05_2022__06:29:54\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 2.3026585, Training accuracy: 0.0968868, Time: 07_05_2022__06:30:13\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 2.3026632, Training accuracy: 0.0968981, Time: 07_05_2022__06:30:32\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 2.3026695, Training accuracy: 0.0968636, Time: 07_05_2022__06:30:52\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 2.3026738, Training accuracy: 0.0966071, Time: 07_05_2022__06:31:11\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 2.3026667, Training accuracy: 0.0969737, Time: 07_05_2022__06:31:30\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 2.3026621, Training accuracy: 0.0968534, Time: 07_05_2022__06:31:49\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 2.3026517, Training accuracy: 0.0971186, Time: 07_05_2022__06:32:09\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 2.3026520, Training accuracy: 0.0972917, Time: 07_05_2022__06:32:28\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 2.3026527, Training accuracy: 0.0975410, Time: 07_05_2022__06:32:47\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 2.3026595, Training accuracy: 0.0974194, Time: 07_05_2022__06:33:07\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 2.3026531, Training accuracy: 0.0975000, Time: 07_05_2022__06:33:26\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 2.3026553, Training accuracy: 0.0975781, Time: 07_05_2022__06:33:45\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 2.3026578, Training accuracy: 0.0977308, Time: 07_05_2022__06:34:05\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 2.3026584, Training accuracy: 0.0980303, Time: 07_05_2022__06:34:24\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 2.3026579, Training accuracy: 0.0982836, Time: 07_05_2022__06:34:43\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 2.3026627, Training accuracy: 0.0981250, Time: 07_05_2022__06:35:03\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 2.3026671, Training accuracy: 0.0978623, Time: 07_05_2022__06:35:22\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 2.3026620, Training accuracy: 0.0978214, Time: 07_05_2022__06:35:41\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 2.3026668, Training accuracy: 0.0978169, Time: 07_05_2022__06:36:00\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 2.3026640, Training accuracy: 0.0981944, Time: 07_05_2022__06:36:20\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 2.3026637, Training accuracy: 0.0985959, Time: 07_05_2022__06:36:39\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 2.3026630, Training accuracy: 0.0986149, Time: 07_05_2022__06:36:58\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 2.3026645, Training accuracy: 0.0984333, Time: 07_05_2022__06:37:18\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 2.3026552, Training accuracy: 0.0983882, Time: 07_05_2022__06:37:37\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 2.3026452, Training accuracy: 0.0982468, Time: 07_05_2022__06:37:56\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 2.3026489, Training accuracy: 0.0985256, Time: 07_05_2022__06:38:16\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 2.3026491, Training accuracy: 0.0986392, Time: 07_05_2022__06:38:35\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 2.3026559, Training accuracy: 0.0985000, Time: 07_05_2022__06:38:54\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 2.3026528, Training accuracy: 0.0986420, Time: 07_05_2022__06:39:14\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 2.3026505, Training accuracy: 0.0985976, Time: 07_05_2022__06:39:33\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 2.3026433, Training accuracy: 0.0987048, Time: 07_05_2022__06:39:52\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 2.3026389, Training accuracy: 0.0986310, Time: 07_05_2022__06:40:11\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 2.3026399, Training accuracy: 0.0986471, Time: 07_05_2022__06:40:31\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 2.3026479, Training accuracy: 0.0984884, Time: 07_05_2022__06:40:50\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 2.3026426, Training accuracy: 0.0985057, Time: 07_05_2022__06:41:09\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 2.3026416, Training accuracy: 0.0984943, Time: 07_05_2022__06:41:29\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 2.3026478, Training accuracy: 0.0983427, Time: 07_05_2022__06:41:48\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 2.3026433, Training accuracy: 0.0985833, Time: 07_05_2022__06:42:07\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 2.3026414, Training accuracy: 0.0987088, Time: 07_05_2022__06:42:27\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 2.3026383, Training accuracy: 0.0985598, Time: 07_05_2022__06:42:46\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 2.3026384, Training accuracy: 0.0984677, Time: 07_05_2022__06:43:05\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 2.3026480, Training accuracy: 0.0980585, Time: 07_05_2022__06:43:25\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 2.3026496, Training accuracy: 0.0981053, Time: 07_05_2022__06:43:44\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 2.3026515, Training accuracy: 0.0981510, Time: 07_05_2022__06:44:03\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 2.3026514, Training accuracy: 0.0981701, Time: 07_05_2022__06:44:22\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 2.3026525, Training accuracy: 0.0982908, Time: 07_05_2022__06:44:42\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 2.3026543, Training accuracy: 0.0983586, Time: 07_05_2022__06:45:01\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 2.3026484, Training accuracy: 0.0984750, Time: 07_05_2022__06:45:20\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 2.3026463, Training accuracy: 0.0985149, Time: 07_05_2022__06:45:40\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 2.3026487, Training accuracy: 0.0985294, Time: 07_05_2022__06:45:59\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 2.3026486, Training accuracy: 0.0985437, Time: 07_05_2022__06:46:18\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 2.3026465, Training accuracy: 0.0989183, Time: 07_05_2022__06:46:38\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 2.3026459, Training accuracy: 0.0989524, Time: 07_05_2022__06:46:57\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 2.3026468, Training accuracy: 0.0989387, Time: 07_05_2022__06:47:16\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 2.3026437, Training accuracy: 0.0989486, Time: 07_05_2022__06:47:35\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 2.3026435, Training accuracy: 0.0987963, Time: 07_05_2022__06:47:55\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 2.3026410, Training accuracy: 0.0988303, Time: 07_05_2022__06:48:14\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 2.3026412, Training accuracy: 0.0987273, Time: 07_05_2022__06:48:33\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 2.3026418, Training accuracy: 0.0987613, Time: 07_05_2022__06:48:53\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 2.3026415, Training accuracy: 0.0988839, Time: 07_05_2022__06:49:12\n","Epoch 5 of 5, Average training loss: 2.3026432, Average training accuracy: 0.0989556, Time: 07_05_2022__06:49:22\n","###################### Validating vgg19_batch_norm SGD, lr_0.1, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0061ca8f11b44527bc04c67e53254e57"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 2.3030518, Validation accuracy: 0.0975000, Time: 07_05_2022__06:49:27\n","Step: 200 of 1250, Validation loss: 2.3028582, Validation accuracy: 0.0787500, Time: 07_05_2022__06:49:32\n","Step: 300 of 1250, Validation loss: 2.3027459, Validation accuracy: 0.0858333, Time: 07_05_2022__06:49:37\n","Step: 400 of 1250, Validation loss: 2.3026428, Validation accuracy: 0.0881250, Time: 07_05_2022__06:49:42\n","Step: 500 of 1250, Validation loss: 2.3026102, Validation accuracy: 0.0900000, Time: 07_05_2022__06:49:47\n","Step: 600 of 1250, Validation loss: 2.3025838, Validation accuracy: 0.0920833, Time: 07_05_2022__06:49:52\n","Step: 700 of 1250, Validation loss: 2.3026105, Validation accuracy: 0.0946429, Time: 07_05_2022__06:49:57\n","Step: 800 of 1250, Validation loss: 2.3026690, Validation accuracy: 0.0950000, Time: 07_05_2022__06:50:02\n","Step: 900 of 1250, Validation loss: 2.3026245, Validation accuracy: 0.0983333, Time: 07_05_2022__06:50:07\n","Step: 1000 of 1250, Validation loss: 2.3025655, Validation accuracy: 0.1017500, Time: 07_05_2022__06:50:12\n","Step: 1100 of 1250, Validation loss: 2.3025700, Validation accuracy: 0.1002273, Time: 07_05_2022__06:50:17\n","Step: 1200 of 1250, Validation loss: 2.3025893, Validation accuracy: 0.1012500, Time: 07_05_2022__06:50:22\n","Average validation loss: 2.3026038, Average validation accuracy: 0.1006000, Time: 07_05_2022__06:50:25\n","###################### Testing vgg19_batch_norm SGD, lr_0.1, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a168f90c9d9453881b8971f76d90942"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.1200000, Time: 07_05_2022__06:50:38\n","Step: 200 of 2500, Test accuracy: 0.1187500, Time: 07_05_2022__06:50:43\n","Step: 300 of 2500, Test accuracy: 0.1175000, Time: 07_05_2022__06:50:48\n","Step: 400 of 2500, Test accuracy: 0.1106250, Time: 07_05_2022__06:50:53\n","Step: 500 of 2500, Test accuracy: 0.1080000, Time: 07_05_2022__06:50:58\n","Step: 600 of 2500, Test accuracy: 0.1041667, Time: 07_05_2022__06:51:03\n","Step: 700 of 2500, Test accuracy: 0.1042857, Time: 07_05_2022__06:51:08\n","Step: 800 of 2500, Test accuracy: 0.1012500, Time: 07_05_2022__06:51:14\n","Step: 900 of 2500, Test accuracy: 0.1000000, Time: 07_05_2022__06:51:19\n","Step: 1000 of 2500, Test accuracy: 0.0990000, Time: 07_05_2022__06:51:24\n","Step: 1100 of 2500, Test accuracy: 0.0984091, Time: 07_05_2022__06:51:29\n","Step: 1200 of 2500, Test accuracy: 0.0989583, Time: 07_05_2022__06:51:34\n","Step: 1300 of 2500, Test accuracy: 0.0992308, Time: 07_05_2022__06:51:39\n","Step: 1400 of 2500, Test accuracy: 0.1000000, Time: 07_05_2022__06:51:44\n","Step: 1500 of 2500, Test accuracy: 0.1005000, Time: 07_05_2022__06:51:49\n","Step: 1600 of 2500, Test accuracy: 0.0992187, Time: 07_05_2022__06:51:54\n","Step: 1700 of 2500, Test accuracy: 0.0989706, Time: 07_05_2022__06:51:59\n","Step: 1800 of 2500, Test accuracy: 0.0995833, Time: 07_05_2022__06:52:04\n","Step: 1900 of 2500, Test accuracy: 0.0988158, Time: 07_05_2022__06:52:09\n","Step: 2000 of 2500, Test accuracy: 0.0986250, Time: 07_05_2022__06:52:14\n","Step: 2100 of 2500, Test accuracy: 0.0988095, Time: 07_05_2022__06:52:19\n","Step: 2200 of 2500, Test accuracy: 0.1002273, Time: 07_05_2022__06:52:24\n","Step: 2300 of 2500, Test accuracy: 0.1004348, Time: 07_05_2022__06:52:29\n","Step: 2400 of 2500, Test accuracy: 0.1005208, Time: 07_05_2022__06:52:34\n","Step: 2500 of 2500, Test accuracy: 0.1000000, Time: 07_05_2022__06:52:40\n","Average testing accuracy: 0.1000000, Time: 07_05_2022__06:52:40\n","###################### Training vgg19_batch_norm SGD, lr_0.01, momentum_0 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15e034948c0b45488d4b0c9b42105628"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 2.9460472, Training accuracy: 0.1250000, Time: 07_05_2022__06:53:01\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 2.7269358, Training accuracy: 0.1325000, Time: 07_05_2022__06:53:21\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 2.6291376, Training accuracy: 0.1366667, Time: 07_05_2022__06:53:40\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 2.5515345, Training accuracy: 0.1437500, Time: 07_05_2022__06:54:00\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 2.4846848, Training accuracy: 0.1515000, Time: 07_05_2022__06:54:19\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 2.4368472, Training accuracy: 0.1566667, Time: 07_05_2022__06:54:38\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.4053622, Training accuracy: 0.1625000, Time: 07_05_2022__06:54:58\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.3741539, Training accuracy: 0.1668750, Time: 07_05_2022__06:55:17\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.3546495, Training accuracy: 0.1680556, Time: 07_05_2022__06:55:37\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.3358370, Training accuracy: 0.1710000, Time: 07_05_2022__06:55:56\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.3159337, Training accuracy: 0.1752273, Time: 07_05_2022__06:56:16\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.2982867, Training accuracy: 0.1758333, Time: 07_05_2022__06:56:35\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.2854255, Training accuracy: 0.1769231, Time: 07_05_2022__06:56:54\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.2681020, Training accuracy: 0.1814286, Time: 07_05_2022__06:57:14\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.2549245, Training accuracy: 0.1866667, Time: 07_05_2022__06:57:33\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.2410922, Training accuracy: 0.1900000, Time: 07_05_2022__06:57:53\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.2307006, Training accuracy: 0.1933824, Time: 07_05_2022__06:58:12\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.2154025, Training accuracy: 0.1977778, Time: 07_05_2022__06:58:32\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.2023055, Training accuracy: 0.2014474, Time: 07_05_2022__06:58:51\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.1924349, Training accuracy: 0.2040000, Time: 07_05_2022__06:59:11\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.1811281, Training accuracy: 0.2072619, Time: 07_05_2022__06:59:30\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.1722180, Training accuracy: 0.2103409, Time: 07_05_2022__06:59:49\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.1621462, Training accuracy: 0.2129348, Time: 07_05_2022__07:00:09\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.1509104, Training accuracy: 0.2153125, Time: 07_05_2022__07:00:28\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.1387480, Training accuracy: 0.2191000, Time: 07_05_2022__07:00:48\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.1302076, Training accuracy: 0.2225000, Time: 07_05_2022__07:01:07\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.1198211, Training accuracy: 0.2279630, Time: 07_05_2022__07:01:27\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.1106803, Training accuracy: 0.2315179, Time: 07_05_2022__07:01:46\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.1029999, Training accuracy: 0.2351724, Time: 07_05_2022__07:02:05\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.0964138, Training accuracy: 0.2369167, Time: 07_05_2022__07:02:25\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.0870199, Training accuracy: 0.2391935, Time: 07_05_2022__07:02:44\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.0781413, Training accuracy: 0.2413281, Time: 07_05_2022__07:03:04\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.0720006, Training accuracy: 0.2437121, Time: 07_05_2022__07:03:23\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.0661979, Training accuracy: 0.2447794, Time: 07_05_2022__07:03:43\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.0592111, Training accuracy: 0.2467143, Time: 07_05_2022__07:04:02\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.0540597, Training accuracy: 0.2478472, Time: 07_05_2022__07:04:21\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.0490497, Training accuracy: 0.2498649, Time: 07_05_2022__07:04:41\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.0426059, Training accuracy: 0.2531579, Time: 07_05_2022__07:05:00\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.0374944, Training accuracy: 0.2549359, Time: 07_05_2022__07:05:20\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.0327527, Training accuracy: 0.2570000, Time: 07_05_2022__07:05:39\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.0285802, Training accuracy: 0.2593293, Time: 07_05_2022__07:05:59\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.0211153, Training accuracy: 0.2625595, Time: 07_05_2022__07:06:18\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.0162800, Training accuracy: 0.2637791, Time: 07_05_2022__07:06:38\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.0090694, Training accuracy: 0.2663636, Time: 07_05_2022__07:06:57\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.0028838, Training accuracy: 0.2685000, Time: 07_05_2022__07:07:16\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 1.9973321, Training accuracy: 0.2701087, Time: 07_05_2022__07:07:36\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 1.9917816, Training accuracy: 0.2713830, Time: 07_05_2022__07:07:55\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 1.9875531, Training accuracy: 0.2726042, Time: 07_05_2022__07:08:15\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 1.9830107, Training accuracy: 0.2737755, Time: 07_05_2022__07:08:34\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 1.9804601, Training accuracy: 0.2747000, Time: 07_05_2022__07:08:54\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 1.9748675, Training accuracy: 0.2767157, Time: 07_05_2022__07:09:13\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 1.9712411, Training accuracy: 0.2781731, Time: 07_05_2022__07:09:32\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 1.9668710, Training accuracy: 0.2795755, Time: 07_05_2022__07:09:52\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 1.9632027, Training accuracy: 0.2811574, Time: 07_05_2022__07:10:11\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 1.9590251, Training accuracy: 0.2826364, Time: 07_05_2022__07:10:31\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 1.9542190, Training accuracy: 0.2842857, Time: 07_05_2022__07:10:50\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 1.9495823, Training accuracy: 0.2858333, Time: 07_05_2022__07:11:10\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 1.9461084, Training accuracy: 0.2870690, Time: 07_05_2022__07:11:29\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 1.9424457, Training accuracy: 0.2884322, Time: 07_05_2022__07:11:48\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 1.9387399, Training accuracy: 0.2896250, Time: 07_05_2022__07:12:08\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 1.9356554, Training accuracy: 0.2908197, Time: 07_05_2022__07:12:27\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 1.9311853, Training accuracy: 0.2927016, Time: 07_05_2022__07:12:47\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 1.9275000, Training accuracy: 0.2936508, Time: 07_05_2022__07:13:06\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 1.9244049, Training accuracy: 0.2944922, Time: 07_05_2022__07:13:26\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 1.9205092, Training accuracy: 0.2961923, Time: 07_05_2022__07:13:45\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 1.9173097, Training accuracy: 0.2971212, Time: 07_05_2022__07:14:05\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 1.9131267, Training accuracy: 0.2985075, Time: 07_05_2022__07:14:24\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 1.9104202, Training accuracy: 0.2996691, Time: 07_05_2022__07:14:43\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 1.9069514, Training accuracy: 0.3010507, Time: 07_05_2022__07:15:03\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 1.9021794, Training accuracy: 0.3023929, Time: 07_05_2022__07:15:22\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 1.8988724, Training accuracy: 0.3034859, Time: 07_05_2022__07:15:42\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 1.8953129, Training accuracy: 0.3049306, Time: 07_05_2022__07:16:01\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 1.8919607, Training accuracy: 0.3063699, Time: 07_05_2022__07:16:21\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 1.8892933, Training accuracy: 0.3073986, Time: 07_05_2022__07:16:40\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 1.8865881, Training accuracy: 0.3086667, Time: 07_05_2022__07:16:59\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 1.8830976, Training accuracy: 0.3098355, Time: 07_05_2022__07:17:19\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 1.8798270, Training accuracy: 0.3109416, Time: 07_05_2022__07:17:38\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 1.8760787, Training accuracy: 0.3125641, Time: 07_05_2022__07:17:58\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 1.8731485, Training accuracy: 0.3133544, Time: 07_05_2022__07:18:17\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 1.8701448, Training accuracy: 0.3145312, Time: 07_05_2022__07:18:37\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 1.8668767, Training accuracy: 0.3154321, Time: 07_05_2022__07:18:56\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 1.8646897, Training accuracy: 0.3162805, Time: 07_05_2022__07:19:16\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 1.8608019, Training accuracy: 0.3177711, Time: 07_05_2022__07:19:35\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 1.8585312, Training accuracy: 0.3187500, Time: 07_05_2022__07:19:54\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 1.8551585, Training accuracy: 0.3201176, Time: 07_05_2022__07:20:14\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 1.8524721, Training accuracy: 0.3214826, Time: 07_05_2022__07:20:33\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 1.8497679, Training accuracy: 0.3224425, Time: 07_05_2022__07:20:53\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 1.8457431, Training accuracy: 0.3242330, Time: 07_05_2022__07:21:12\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 1.8426543, Training accuracy: 0.3253652, Time: 07_05_2022__07:21:32\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 1.8396194, Training accuracy: 0.3263889, Time: 07_05_2022__07:21:51\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 1.8365948, Training accuracy: 0.3275549, Time: 07_05_2022__07:22:11\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 1.8333281, Training accuracy: 0.3286413, Time: 07_05_2022__07:22:30\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 1.8303118, Training accuracy: 0.3299462, Time: 07_05_2022__07:22:49\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 1.8276768, Training accuracy: 0.3309309, Time: 07_05_2022__07:23:09\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 1.8264035, Training accuracy: 0.3315789, Time: 07_05_2022__07:23:28\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 1.8225202, Training accuracy: 0.3330469, Time: 07_05_2022__07:23:48\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 1.8188022, Training accuracy: 0.3345103, Time: 07_05_2022__07:24:07\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 1.8153893, Training accuracy: 0.3356122, Time: 07_05_2022__07:24:27\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 1.8134427, Training accuracy: 0.3366162, Time: 07_05_2022__07:24:46\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 1.8105191, Training accuracy: 0.3376500, Time: 07_05_2022__07:25:06\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 1.8086570, Training accuracy: 0.3385891, Time: 07_05_2022__07:25:25\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 1.8057383, Training accuracy: 0.3396814, Time: 07_05_2022__07:25:45\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 1.8023699, Training accuracy: 0.3408252, Time: 07_05_2022__07:26:04\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 1.7993534, Training accuracy: 0.3416587, Time: 07_05_2022__07:26:23\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 1.7975271, Training accuracy: 0.3425000, Time: 07_05_2022__07:26:43\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 1.7948044, Training accuracy: 0.3433255, Time: 07_05_2022__07:27:02\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 1.7915855, Training accuracy: 0.3444626, Time: 07_05_2022__07:27:22\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 1.7888631, Training accuracy: 0.3456944, Time: 07_05_2022__07:27:41\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 1.7871671, Training accuracy: 0.3464220, Time: 07_05_2022__07:28:01\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 1.7844300, Training accuracy: 0.3475909, Time: 07_05_2022__07:28:20\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 1.7814826, Training accuracy: 0.3486486, Time: 07_05_2022__07:28:40\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 1.7790422, Training accuracy: 0.3495982, Time: 07_05_2022__07:28:59\n","Epoch 1 of 5, Average training loss: 1.7779294, Average training accuracy: 0.3502000, Time: 07_05_2022__07:29:09\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bba9dbc3060437da8c6c1d9bda5a8ba"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.3328088, Validation accuracy: 0.5300000, Time: 07_05_2022__07:29:14 | Loss decreased from inf to 1.3315576 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.3076137, Validation accuracy: 0.5400000, Time: 07_05_2022__07:29:21 | Loss decreased from 1.3315576 to 1.3102354 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.3327106, Validation accuracy: 0.5191667, Time: 07_05_2022__07:29:29\n","Step: 400 of 1250, Validation loss: 1.3256569, Validation accuracy: 0.5162500, Time: 07_05_2022__07:29:34\n","Step: 500 of 1250, Validation loss: 1.3254874, Validation accuracy: 0.5175000, Time: 07_05_2022__07:29:40\n","Step: 600 of 1250, Validation loss: 1.3159959, Validation accuracy: 0.5229167, Time: 07_05_2022__07:29:45\n","Step: 700 of 1250, Validation loss: 1.3102068, Validation accuracy: 0.5289286, Time: 07_05_2022__07:29:50\n","Step: 800 of 1250, Validation loss: 1.3064484, Validation accuracy: 0.5309375, Time: 07_05_2022__07:29:55 | Loss decreased from 1.3102354 to 1.3071966 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.3077511, Validation accuracy: 0.5272222, Time: 07_05_2022__07:30:03\n","Step: 1000 of 1250, Validation loss: 1.3130431, Validation accuracy: 0.5245000, Time: 07_05_2022__07:30:08\n","Step: 1100 of 1250, Validation loss: 1.3142950, Validation accuracy: 0.5238636, Time: 07_05_2022__07:30:13\n","Step: 1200 of 1250, Validation loss: 1.3148488, Validation accuracy: 0.5227083, Time: 07_05_2022__07:30:18\n","Average validation loss: 1.3135535, Average validation accuracy: 0.5232000, Time: 07_05_2022__07:30:21\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"591d28d4c44b406692bcc443f0a2ea83"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.4135793, Training accuracy: 0.4850000, Time: 07_05_2022__07:30:40\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.4104324, Training accuracy: 0.4825000, Time: 07_05_2022__07:30:59\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.4377795, Training accuracy: 0.4666667, Time: 07_05_2022__07:31:19\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.4315144, Training accuracy: 0.4656250, Time: 07_05_2022__07:31:38\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.4382147, Training accuracy: 0.4680000, Time: 07_05_2022__07:31:58\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.4397383, Training accuracy: 0.4654167, Time: 07_05_2022__07:32:17\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.4454853, Training accuracy: 0.4650000, Time: 07_05_2022__07:32:37\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.4495685, Training accuracy: 0.4646875, Time: 07_05_2022__07:32:56\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.4460891, Training accuracy: 0.4686111, Time: 07_05_2022__07:33:16\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.4427408, Training accuracy: 0.4732500, Time: 07_05_2022__07:33:35\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.4431775, Training accuracy: 0.4704545, Time: 07_05_2022__07:33:55\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.4407350, Training accuracy: 0.4706250, Time: 07_05_2022__07:34:14\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.4353771, Training accuracy: 0.4738462, Time: 07_05_2022__07:34:33\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.4317088, Training accuracy: 0.4758929, Time: 07_05_2022__07:34:53\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.4320696, Training accuracy: 0.4761667, Time: 07_05_2022__07:35:12\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.4264779, Training accuracy: 0.4776563, Time: 07_05_2022__07:35:32\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.4229464, Training accuracy: 0.4810294, Time: 07_05_2022__07:35:51\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.4213578, Training accuracy: 0.4818056, Time: 07_05_2022__07:36:11\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.4192119, Training accuracy: 0.4828947, Time: 07_05_2022__07:36:30\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.4161225, Training accuracy: 0.4828750, Time: 07_05_2022__07:36:50\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.4129383, Training accuracy: 0.4839286, Time: 07_05_2022__07:37:09\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.4101135, Training accuracy: 0.4863636, Time: 07_05_2022__07:37:29\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.4081889, Training accuracy: 0.4870652, Time: 07_05_2022__07:37:48\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.4055941, Training accuracy: 0.4876042, Time: 07_05_2022__07:38:07\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.4025163, Training accuracy: 0.4885000, Time: 07_05_2022__07:38:27\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.4020104, Training accuracy: 0.4900962, Time: 07_05_2022__07:38:46\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.3970949, Training accuracy: 0.4914815, Time: 07_05_2022__07:39:06\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.3952456, Training accuracy: 0.4923214, Time: 07_05_2022__07:39:25\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.3933648, Training accuracy: 0.4929310, Time: 07_05_2022__07:39:45\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.3920700, Training accuracy: 0.4942500, Time: 07_05_2022__07:40:04\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.3879166, Training accuracy: 0.4962097, Time: 07_05_2022__07:40:24\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.3829405, Training accuracy: 0.4988281, Time: 07_05_2022__07:40:43\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.3825615, Training accuracy: 0.4992424, Time: 07_05_2022__07:41:03\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.3798641, Training accuracy: 0.5011029, Time: 07_05_2022__07:41:22\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.3764494, Training accuracy: 0.5032143, Time: 07_05_2022__07:41:41\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.3772024, Training accuracy: 0.5029861, Time: 07_05_2022__07:42:01\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.3751983, Training accuracy: 0.5040541, Time: 07_05_2022__07:42:20\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.3739483, Training accuracy: 0.5051974, Time: 07_05_2022__07:42:40\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.3705723, Training accuracy: 0.5058333, Time: 07_05_2022__07:42:59\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.3684789, Training accuracy: 0.5061875, Time: 07_05_2022__07:43:19\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.3687853, Training accuracy: 0.5070732, Time: 07_05_2022__07:43:38\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.3626740, Training accuracy: 0.5089881, Time: 07_05_2022__07:43:58\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.3609866, Training accuracy: 0.5100000, Time: 07_05_2022__07:44:17\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.3583355, Training accuracy: 0.5106818, Time: 07_05_2022__07:44:37\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.3570518, Training accuracy: 0.5111667, Time: 07_05_2022__07:44:56\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.3556308, Training accuracy: 0.5120109, Time: 07_05_2022__07:45:16\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.3533676, Training accuracy: 0.5129255, Time: 07_05_2022__07:45:35\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.3528994, Training accuracy: 0.5129167, Time: 07_05_2022__07:45:54\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.3502787, Training accuracy: 0.5135204, Time: 07_05_2022__07:46:14\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.3497043, Training accuracy: 0.5139000, Time: 07_05_2022__07:46:33\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.3466594, Training accuracy: 0.5151961, Time: 07_05_2022__07:46:53\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.3461748, Training accuracy: 0.5155288, Time: 07_05_2022__07:47:12\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.3453321, Training accuracy: 0.5166981, Time: 07_05_2022__07:47:32\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.3434600, Training accuracy: 0.5180093, Time: 07_05_2022__07:47:51\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.3418561, Training accuracy: 0.5189545, Time: 07_05_2022__07:48:11\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.3392711, Training accuracy: 0.5198214, Time: 07_05_2022__07:48:30\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.3362858, Training accuracy: 0.5207895, Time: 07_05_2022__07:48:50\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.3359881, Training accuracy: 0.5207328, Time: 07_05_2022__07:49:09\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.3347632, Training accuracy: 0.5210169, Time: 07_05_2022__07:49:29\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.3342034, Training accuracy: 0.5216250, Time: 07_05_2022__07:49:48\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.3322733, Training accuracy: 0.5222951, Time: 07_05_2022__07:50:07\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.3293192, Training accuracy: 0.5230242, Time: 07_05_2022__07:50:27\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.3280713, Training accuracy: 0.5232937, Time: 07_05_2022__07:50:46\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.3262829, Training accuracy: 0.5237891, Time: 07_05_2022__07:51:06\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.3240541, Training accuracy: 0.5250000, Time: 07_05_2022__07:51:25\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.3222146, Training accuracy: 0.5256439, Time: 07_05_2022__07:51:45\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.3199435, Training accuracy: 0.5265672, Time: 07_05_2022__07:52:04\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.3190697, Training accuracy: 0.5269118, Time: 07_05_2022__07:52:24\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.3167744, Training accuracy: 0.5278261, Time: 07_05_2022__07:52:43\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.3138323, Training accuracy: 0.5292500, Time: 07_05_2022__07:53:03\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.3128327, Training accuracy: 0.5298239, Time: 07_05_2022__07:53:22\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.3112750, Training accuracy: 0.5304167, Time: 07_05_2022__07:53:41\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.3097936, Training accuracy: 0.5304110, Time: 07_05_2022__07:54:01\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.3078293, Training accuracy: 0.5312838, Time: 07_05_2022__07:54:20\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.3061966, Training accuracy: 0.5321000, Time: 07_05_2022__07:54:40\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.3036565, Training accuracy: 0.5333553, Time: 07_05_2022__07:54:59\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.3025543, Training accuracy: 0.5338636, Time: 07_05_2022__07:55:19\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.3007738, Training accuracy: 0.5346474, Time: 07_05_2022__07:55:38\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.2986986, Training accuracy: 0.5353797, Time: 07_05_2022__07:55:58\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.2969048, Training accuracy: 0.5362813, Time: 07_05_2022__07:56:17\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.2960559, Training accuracy: 0.5367284, Time: 07_05_2022__07:56:37\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.2956514, Training accuracy: 0.5371646, Time: 07_05_2022__07:56:56\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.2937621, Training accuracy: 0.5377711, Time: 07_05_2022__07:57:16\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.2927679, Training accuracy: 0.5380655, Time: 07_05_2022__07:57:35\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.2912154, Training accuracy: 0.5386471, Time: 07_05_2022__07:57:54\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.2896132, Training accuracy: 0.5395058, Time: 07_05_2022__07:58:14\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.2874960, Training accuracy: 0.5401724, Time: 07_05_2022__07:58:33\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.2851232, Training accuracy: 0.5408807, Time: 07_05_2022__07:58:53\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.2827469, Training accuracy: 0.5416573, Time: 07_05_2022__07:59:12\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.2802626, Training accuracy: 0.5425000, Time: 07_05_2022__07:59:32\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.2793134, Training accuracy: 0.5429121, Time: 07_05_2022__07:59:51\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.2768986, Training accuracy: 0.5439130, Time: 07_05_2022__08:00:11\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.2756027, Training accuracy: 0.5443011, Time: 07_05_2022__08:00:30\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.2746562, Training accuracy: 0.5446543, Time: 07_05_2022__08:00:50\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.2748611, Training accuracy: 0.5448158, Time: 07_05_2022__08:01:09\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.2722469, Training accuracy: 0.5461198, Time: 07_05_2022__08:01:28\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.2697013, Training accuracy: 0.5470103, Time: 07_05_2022__08:01:48\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.2672124, Training accuracy: 0.5481378, Time: 07_05_2022__08:02:07\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.2665760, Training accuracy: 0.5485859, Time: 07_05_2022__08:02:27\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.2647809, Training accuracy: 0.5495500, Time: 07_05_2022__08:02:46\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.2638187, Training accuracy: 0.5498515, Time: 07_05_2022__08:03:06\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.2628104, Training accuracy: 0.5503431, Time: 07_05_2022__08:03:25\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.2604680, Training accuracy: 0.5511408, Time: 07_05_2022__08:03:45\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.2584770, Training accuracy: 0.5519952, Time: 07_05_2022__08:04:04\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.2571235, Training accuracy: 0.5527619, Time: 07_05_2022__08:04:24\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.2557498, Training accuracy: 0.5533726, Time: 07_05_2022__08:04:43\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.2536166, Training accuracy: 0.5540888, Time: 07_05_2022__08:05:03\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.2524682, Training accuracy: 0.5543287, Time: 07_05_2022__08:05:22\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.2513768, Training accuracy: 0.5550229, Time: 07_05_2022__08:05:41\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.2499649, Training accuracy: 0.5556818, Time: 07_05_2022__08:06:01\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.2477486, Training accuracy: 0.5567117, Time: 07_05_2022__08:06:20\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.2469910, Training accuracy: 0.5570536, Time: 07_05_2022__08:06:40\n","Epoch 2 of 5, Average training loss: 1.2463705, Average training accuracy: 0.5572667, Time: 07_05_2022__08:06:50\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88b2e0a6e0e94c9aa6b5d3c2167af601"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.9746350, Validation accuracy: 0.6575000, Time: 07_05_2022__08:06:55 | Loss decreased from 1.3071966 to 0.9773644 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.9390914, Validation accuracy: 0.6712500, Time: 07_05_2022__08:07:02 | Loss decreased from 0.9773644 to 0.9407431 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.9740704, Validation accuracy: 0.6500000, Time: 07_05_2022__08:07:09\n","Step: 400 of 1250, Validation loss: 0.9751074, Validation accuracy: 0.6531250, Time: 07_05_2022__08:07:15\n","Step: 500 of 1250, Validation loss: 0.9758664, Validation accuracy: 0.6525000, Time: 07_05_2022__08:07:20\n","Step: 600 of 1250, Validation loss: 0.9641832, Validation accuracy: 0.6566667, Time: 07_05_2022__08:07:25\n","Step: 700 of 1250, Validation loss: 0.9528004, Validation accuracy: 0.6600000, Time: 07_05_2022__08:07:30\n","Step: 800 of 1250, Validation loss: 0.9465096, Validation accuracy: 0.6615625, Time: 07_05_2022__08:07:35\n","Step: 900 of 1250, Validation loss: 0.9498716, Validation accuracy: 0.6616667, Time: 07_05_2022__08:07:40\n","Step: 1000 of 1250, Validation loss: 0.9504855, Validation accuracy: 0.6622500, Time: 07_05_2022__08:07:46\n","Step: 1100 of 1250, Validation loss: 0.9540233, Validation accuracy: 0.6611364, Time: 07_05_2022__08:07:51\n","Step: 1200 of 1250, Validation loss: 0.9651284, Validation accuracy: 0.6552083, Time: 07_05_2022__08:07:56\n","Average validation loss: 0.9665171, Average validation accuracy: 0.6538000, Time: 07_05_2022__08:07:58\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef5084e78a0f435aa76348c681447f0a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 0.9535746, Training accuracy: 0.6425000, Time: 07_05_2022__08:08:18\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.0072613, Training accuracy: 0.6312500, Time: 07_05_2022__08:08:37\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.0159729, Training accuracy: 0.6325000, Time: 07_05_2022__08:08:57\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 0.9914165, Training accuracy: 0.6412500, Time: 07_05_2022__08:09:16\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 0.9998942, Training accuracy: 0.6450000, Time: 07_05_2022__08:09:36\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.0119467, Training accuracy: 0.6462500, Time: 07_05_2022__08:09:55\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.0276960, Training accuracy: 0.6392857, Time: 07_05_2022__08:10:15\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.0301424, Training accuracy: 0.6371875, Time: 07_05_2022__08:10:34\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.0322488, Training accuracy: 0.6350000, Time: 07_05_2022__08:10:54\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.0294453, Training accuracy: 0.6362500, Time: 07_05_2022__08:11:13\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.0350976, Training accuracy: 0.6350000, Time: 07_05_2022__08:11:33\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.0348525, Training accuracy: 0.6356250, Time: 07_05_2022__08:11:52\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.0356693, Training accuracy: 0.6353846, Time: 07_05_2022__08:12:12\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.0355416, Training accuracy: 0.6369643, Time: 07_05_2022__08:12:31\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.0390288, Training accuracy: 0.6365000, Time: 07_05_2022__08:12:51\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.0381209, Training accuracy: 0.6392187, Time: 07_05_2022__08:13:10\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.0394887, Training accuracy: 0.6383824, Time: 07_05_2022__08:13:30\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.0403578, Training accuracy: 0.6375000, Time: 07_05_2022__08:13:49\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.0391969, Training accuracy: 0.6371053, Time: 07_05_2022__08:14:09\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.0372011, Training accuracy: 0.6366250, Time: 07_05_2022__08:14:29\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.0319698, Training accuracy: 0.6380952, Time: 07_05_2022__08:14:48\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.0311127, Training accuracy: 0.6373864, Time: 07_05_2022__08:15:08\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.0291100, Training accuracy: 0.6388043, Time: 07_05_2022__08:15:27\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.0275208, Training accuracy: 0.6389583, Time: 07_05_2022__08:15:47\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.0258834, Training accuracy: 0.6396000, Time: 07_05_2022__08:16:06\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.0248180, Training accuracy: 0.6404808, Time: 07_05_2022__08:16:26\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.0216083, Training accuracy: 0.6425926, Time: 07_05_2022__08:16:45\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.0225020, Training accuracy: 0.6424107, Time: 07_05_2022__08:17:05\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.0200408, Training accuracy: 0.6437069, Time: 07_05_2022__08:17:24\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.0192611, Training accuracy: 0.6441667, Time: 07_05_2022__08:17:44\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.0168957, Training accuracy: 0.6452419, Time: 07_05_2022__08:18:03\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.0142096, Training accuracy: 0.6464062, Time: 07_05_2022__08:18:23\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.0150085, Training accuracy: 0.6456818, Time: 07_05_2022__08:18:42\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.0143204, Training accuracy: 0.6455147, Time: 07_05_2022__08:19:02\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.0135636, Training accuracy: 0.6457857, Time: 07_05_2022__08:19:21\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.0138678, Training accuracy: 0.6455556, Time: 07_05_2022__08:19:41\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.0131651, Training accuracy: 0.6448649, Time: 07_05_2022__08:20:01\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.0107840, Training accuracy: 0.6452632, Time: 07_05_2022__08:20:20\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.0094983, Training accuracy: 0.6455128, Time: 07_05_2022__08:20:40\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.0071105, Training accuracy: 0.6469375, Time: 07_05_2022__08:20:59\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.0091412, Training accuracy: 0.6465854, Time: 07_05_2022__08:21:19\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.0059941, Training accuracy: 0.6478571, Time: 07_05_2022__08:21:38\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.0021487, Training accuracy: 0.6490116, Time: 07_05_2022__08:21:58\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.0017531, Training accuracy: 0.6493182, Time: 07_05_2022__08:22:17\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.0011515, Training accuracy: 0.6501111, Time: 07_05_2022__08:22:37\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.0008948, Training accuracy: 0.6506522, Time: 07_05_2022__08:22:56\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.0006424, Training accuracy: 0.6511170, Time: 07_05_2022__08:23:16\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.0008424, Training accuracy: 0.6508333, Time: 07_05_2022__08:23:35\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 0.9993644, Training accuracy: 0.6507143, Time: 07_05_2022__08:23:55\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 0.9994508, Training accuracy: 0.6511500, Time: 07_05_2022__08:24:14\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 0.9981106, Training accuracy: 0.6512745, Time: 07_05_2022__08:24:34\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 0.9977010, Training accuracy: 0.6511538, Time: 07_05_2022__08:24:53\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 0.9973311, Training accuracy: 0.6516038, Time: 07_05_2022__08:25:13\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 0.9961756, Training accuracy: 0.6519444, Time: 07_05_2022__08:25:32\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 0.9955300, Training accuracy: 0.6525455, Time: 07_05_2022__08:25:52\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 0.9945972, Training accuracy: 0.6526339, Time: 07_05_2022__08:26:11\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 0.9940667, Training accuracy: 0.6530702, Time: 07_05_2022__08:26:31\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 0.9942262, Training accuracy: 0.6528879, Time: 07_05_2022__08:26:50\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 0.9940355, Training accuracy: 0.6528390, Time: 07_05_2022__08:27:10\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 0.9941397, Training accuracy: 0.6528750, Time: 07_05_2022__08:27:29\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 0.9945894, Training accuracy: 0.6525410, Time: 07_05_2022__08:27:49\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 0.9928255, Training accuracy: 0.6527823, Time: 07_05_2022__08:28:09\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 0.9931804, Training accuracy: 0.6523810, Time: 07_05_2022__08:28:28\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 0.9928610, Training accuracy: 0.6525781, Time: 07_05_2022__08:28:48\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 0.9922328, Training accuracy: 0.6526538, Time: 07_05_2022__08:29:07\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 0.9915982, Training accuracy: 0.6532197, Time: 07_05_2022__08:29:27\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 0.9904849, Training accuracy: 0.6535448, Time: 07_05_2022__08:29:46\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 0.9899362, Training accuracy: 0.6532721, Time: 07_05_2022__08:30:06\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 0.9896593, Training accuracy: 0.6536232, Time: 07_05_2022__08:30:25\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 0.9877636, Training accuracy: 0.6545357, Time: 07_05_2022__08:30:45\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 0.9880344, Training accuracy: 0.6543310, Time: 07_05_2022__08:31:04\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 0.9865818, Training accuracy: 0.6548611, Time: 07_05_2022__08:31:24\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 0.9853266, Training accuracy: 0.6551370, Time: 07_05_2022__08:31:43\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 0.9845799, Training accuracy: 0.6554054, Time: 07_05_2022__08:32:03\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 0.9834754, Training accuracy: 0.6562000, Time: 07_05_2022__08:32:22\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 0.9825986, Training accuracy: 0.6568092, Time: 07_05_2022__08:32:42\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 0.9816281, Training accuracy: 0.6572727, Time: 07_05_2022__08:33:01\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 0.9801949, Training accuracy: 0.6578526, Time: 07_05_2022__08:33:21\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 0.9790235, Training accuracy: 0.6583228, Time: 07_05_2022__08:33:40\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 0.9776860, Training accuracy: 0.6583125, Time: 07_05_2022__08:34:00\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 0.9774690, Training accuracy: 0.6585185, Time: 07_05_2022__08:34:19\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 0.9778792, Training accuracy: 0.6584756, Time: 07_05_2022__08:34:39\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 0.9774766, Training accuracy: 0.6587651, Time: 07_05_2022__08:34:59\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 0.9778632, Training accuracy: 0.6582738, Time: 07_05_2022__08:35:18\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 0.9768789, Training accuracy: 0.6586471, Time: 07_05_2022__08:35:38\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 0.9761982, Training accuracy: 0.6589244, Time: 07_05_2022__08:35:57\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 0.9761001, Training accuracy: 0.6591954, Time: 07_05_2022__08:36:17\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 0.9745461, Training accuracy: 0.6598295, Time: 07_05_2022__08:36:36\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 0.9729609, Training accuracy: 0.6605337, Time: 07_05_2022__08:36:56\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 0.9721911, Training accuracy: 0.6607500, Time: 07_05_2022__08:37:15\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 0.9711756, Training accuracy: 0.6610989, Time: 07_05_2022__08:37:35\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 0.9702733, Training accuracy: 0.6613043, Time: 07_05_2022__08:37:54\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 0.9701644, Training accuracy: 0.6613172, Time: 07_05_2022__08:38:14\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 0.9693608, Training accuracy: 0.6614894, Time: 07_05_2022__08:38:33\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 0.9697705, Training accuracy: 0.6616053, Time: 07_05_2022__08:38:53\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 0.9683542, Training accuracy: 0.6622135, Time: 07_05_2022__08:39:12\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 0.9666287, Training accuracy: 0.6628351, Time: 07_05_2022__08:39:32\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 0.9649970, Training accuracy: 0.6635204, Time: 07_05_2022__08:39:51\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 0.9650491, Training accuracy: 0.6636364, Time: 07_05_2022__08:40:11\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 0.9643975, Training accuracy: 0.6640000, Time: 07_05_2022__08:40:30\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 0.9639390, Training accuracy: 0.6639356, Time: 07_05_2022__08:40:50\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 0.9628560, Training accuracy: 0.6644118, Time: 07_05_2022__08:41:10\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 0.9613049, Training accuracy: 0.6649029, Time: 07_05_2022__08:41:29\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 0.9598723, Training accuracy: 0.6653606, Time: 07_05_2022__08:41:49\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 0.9594074, Training accuracy: 0.6657619, Time: 07_05_2022__08:42:08\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 0.9594837, Training accuracy: 0.6659198, Time: 07_05_2022__08:42:28\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 0.9577346, Training accuracy: 0.6665654, Time: 07_05_2022__08:42:47\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 0.9570077, Training accuracy: 0.6667824, Time: 07_05_2022__08:43:07\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 0.9576009, Training accuracy: 0.6664679, Time: 07_05_2022__08:43:26\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 0.9571609, Training accuracy: 0.6667045, Time: 07_05_2022__08:43:46\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 0.9559984, Training accuracy: 0.6670045, Time: 07_05_2022__08:44:05\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 0.9554599, Training accuracy: 0.6671205, Time: 07_05_2022__08:44:25\n","Epoch 3 of 5, Average training loss: 0.9551565, Average training accuracy: 0.6673778, Time: 07_05_2022__08:44:35\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97fc13ecbad04413a2b93731f0393119"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.8415854, Validation accuracy: 0.7050000, Time: 07_05_2022__08:44:40 | Loss decreased from 0.9407431 to 0.8447295 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.8124852, Validation accuracy: 0.7112500, Time: 07_05_2022__08:44:47 | Loss decreased from 0.8447295 to 0.8131745 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.8366745, Validation accuracy: 0.7041667, Time: 07_05_2022__08:44:55\n","Step: 400 of 1250, Validation loss: 0.8227791, Validation accuracy: 0.7087500, Time: 07_05_2022__08:45:00\n","Step: 500 of 1250, Validation loss: 0.8314415, Validation accuracy: 0.7060000, Time: 07_05_2022__08:45:05\n","Step: 600 of 1250, Validation loss: 0.8188738, Validation accuracy: 0.7108333, Time: 07_05_2022__08:45:10\n","Step: 700 of 1250, Validation loss: 0.8128140, Validation accuracy: 0.7160714, Time: 07_05_2022__08:45:16 | Loss decreased from 0.8131745 to 0.8114383 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.7968170, Validation accuracy: 0.7212500, Time: 07_05_2022__08:45:23 | Loss decreased from 0.8114383 to 0.7965835 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.8004101, Validation accuracy: 0.7219444, Time: 07_05_2022__08:45:31\n","Step: 1000 of 1250, Validation loss: 0.7998350, Validation accuracy: 0.7227500, Time: 07_05_2022__08:45:36\n","Step: 1100 of 1250, Validation loss: 0.8004730, Validation accuracy: 0.7213636, Time: 07_05_2022__08:45:42\n","Step: 1200 of 1250, Validation loss: 0.8118414, Validation accuracy: 0.7156250, Time: 07_05_2022__08:45:47\n","Average validation loss: 0.8106659, Average validation accuracy: 0.7160000, Time: 07_05_2022__08:45:49\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc94c65663a468cb42833ba818a6435"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 0.7418780, Training accuracy: 0.7525000, Time: 07_05_2022__08:46:09\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 0.8069336, Training accuracy: 0.7275000, Time: 07_05_2022__08:46:28\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 0.8106062, Training accuracy: 0.7166667, Time: 07_05_2022__08:46:48\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 0.7847947, Training accuracy: 0.7243750, Time: 07_05_2022__08:47:07\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 0.8026473, Training accuracy: 0.7185000, Time: 07_05_2022__08:47:27\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 0.8103613, Training accuracy: 0.7183333, Time: 07_05_2022__08:47:46\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 0.8184902, Training accuracy: 0.7160714, Time: 07_05_2022__08:48:06\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 0.8175470, Training accuracy: 0.7184375, Time: 07_05_2022__08:48:25\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 0.8251163, Training accuracy: 0.7147222, Time: 07_05_2022__08:48:45\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 0.8141787, Training accuracy: 0.7185000, Time: 07_05_2022__08:49:04\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 0.8175207, Training accuracy: 0.7181818, Time: 07_05_2022__08:49:24\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 0.8181586, Training accuracy: 0.7158333, Time: 07_05_2022__08:49:43\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 0.8231551, Training accuracy: 0.7151923, Time: 07_05_2022__08:50:03\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 0.8258686, Training accuracy: 0.7132143, Time: 07_05_2022__08:50:22\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 0.8264723, Training accuracy: 0.7115000, Time: 07_05_2022__08:50:42\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 0.8255971, Training accuracy: 0.7131250, Time: 07_05_2022__08:51:01\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 0.8296000, Training accuracy: 0.7136765, Time: 07_05_2022__08:51:21\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 0.8384476, Training accuracy: 0.7105556, Time: 07_05_2022__08:51:40\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 0.8388239, Training accuracy: 0.7110526, Time: 07_05_2022__08:52:00\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 0.8380755, Training accuracy: 0.7106250, Time: 07_05_2022__08:52:19\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 0.8330396, Training accuracy: 0.7120238, Time: 07_05_2022__08:52:39\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 0.8315786, Training accuracy: 0.7125000, Time: 07_05_2022__08:52:58\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 0.8300819, Training accuracy: 0.7123913, Time: 07_05_2022__08:53:18\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 0.8285810, Training accuracy: 0.7130208, Time: 07_05_2022__08:53:37\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 0.8279698, Training accuracy: 0.7130000, Time: 07_05_2022__08:53:57\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 0.8294848, Training accuracy: 0.7117308, Time: 07_05_2022__08:54:16\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 0.8280070, Training accuracy: 0.7125000, Time: 07_05_2022__08:54:36\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 0.8278156, Training accuracy: 0.7122321, Time: 07_05_2022__08:54:55\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 0.8254564, Training accuracy: 0.7124138, Time: 07_05_2022__08:55:15\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 0.8260368, Training accuracy: 0.7116667, Time: 07_05_2022__08:55:34\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 0.8224434, Training accuracy: 0.7132258, Time: 07_05_2022__08:55:54\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 0.8204038, Training accuracy: 0.7136719, Time: 07_05_2022__08:56:13\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 0.8211430, Training accuracy: 0.7135606, Time: 07_05_2022__08:56:33\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 0.8200888, Training accuracy: 0.7140441, Time: 07_05_2022__08:56:52\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 0.8194860, Training accuracy: 0.7141429, Time: 07_05_2022__08:57:12\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 0.8195607, Training accuracy: 0.7141667, Time: 07_05_2022__08:57:31\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 0.8199778, Training accuracy: 0.7143919, Time: 07_05_2022__08:57:51\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 0.8184045, Training accuracy: 0.7145395, Time: 07_05_2022__08:58:10\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 0.8164714, Training accuracy: 0.7141667, Time: 07_05_2022__08:58:30\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 0.8154214, Training accuracy: 0.7148125, Time: 07_05_2022__08:58:49\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 0.8187941, Training accuracy: 0.7138415, Time: 07_05_2022__08:59:09\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 0.8147768, Training accuracy: 0.7150595, Time: 07_05_2022__08:59:28\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 0.8124475, Training accuracy: 0.7155814, Time: 07_05_2022__08:59:48\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 0.8108429, Training accuracy: 0.7159091, Time: 07_05_2022__09:00:07\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 0.8105731, Training accuracy: 0.7165000, Time: 07_05_2022__09:00:27\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 0.8119762, Training accuracy: 0.7164130, Time: 07_05_2022__09:00:46\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 0.8110856, Training accuracy: 0.7170213, Time: 07_05_2022__09:01:06\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 0.8113959, Training accuracy: 0.7167708, Time: 07_05_2022__09:01:25\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 0.8111571, Training accuracy: 0.7165306, Time: 07_05_2022__09:01:45\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 0.8117130, Training accuracy: 0.7166500, Time: 07_05_2022__09:02:04\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 0.8124378, Training accuracy: 0.7166176, Time: 07_05_2022__09:02:24\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 0.8121481, Training accuracy: 0.7169712, Time: 07_05_2022__09:02:43\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 0.8126250, Training accuracy: 0.7167925, Time: 07_05_2022__09:03:03\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 0.8118898, Training accuracy: 0.7169444, Time: 07_05_2022__09:03:22\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 0.8131238, Training accuracy: 0.7163182, Time: 07_05_2022__09:03:42\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 0.8124907, Training accuracy: 0.7165179, Time: 07_05_2022__09:04:01\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 0.8115619, Training accuracy: 0.7169298, Time: 07_05_2022__09:04:21\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 0.8111948, Training accuracy: 0.7166379, Time: 07_05_2022__09:04:40\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 0.8113142, Training accuracy: 0.7163983, Time: 07_05_2022__09:05:00\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 0.8118302, Training accuracy: 0.7167083, Time: 07_05_2022__09:05:19\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 0.8117267, Training accuracy: 0.7164754, Time: 07_05_2022__09:05:39\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 0.8107942, Training accuracy: 0.7168952, Time: 07_05_2022__09:05:58\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 0.8118824, Training accuracy: 0.7161905, Time: 07_05_2022__09:06:18\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 0.8118544, Training accuracy: 0.7163281, Time: 07_05_2022__09:06:37\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 0.8116044, Training accuracy: 0.7169615, Time: 07_05_2022__09:06:57\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 0.8113045, Training accuracy: 0.7171591, Time: 07_05_2022__09:07:16\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 0.8101501, Training accuracy: 0.7172761, Time: 07_05_2022__09:07:36\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 0.8096481, Training accuracy: 0.7172426, Time: 07_05_2022__09:07:55\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 0.8086287, Training accuracy: 0.7177536, Time: 07_05_2022__09:08:15\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 0.8078769, Training accuracy: 0.7180000, Time: 07_05_2022__09:08:34\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 0.8080876, Training accuracy: 0.7176761, Time: 07_05_2022__09:08:54\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 0.8070958, Training accuracy: 0.7181597, Time: 07_05_2022__09:09:13\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 0.8058606, Training accuracy: 0.7187329, Time: 07_05_2022__09:09:33\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 0.8060196, Training accuracy: 0.7187162, Time: 07_05_2022__09:09:52\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 0.8050058, Training accuracy: 0.7189000, Time: 07_05_2022__09:10:12\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 0.8041185, Training accuracy: 0.7193421, Time: 07_05_2022__09:10:31\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 0.8041333, Training accuracy: 0.7193506, Time: 07_05_2022__09:10:51\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 0.8042855, Training accuracy: 0.7195833, Time: 07_05_2022__09:11:10\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 0.8022682, Training accuracy: 0.7202215, Time: 07_05_2022__09:11:30\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 0.8013110, Training accuracy: 0.7204375, Time: 07_05_2022__09:11:49\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 0.8023976, Training accuracy: 0.7200617, Time: 07_05_2022__09:12:09\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 0.8021468, Training accuracy: 0.7200610, Time: 07_05_2022__09:12:28\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 0.8021593, Training accuracy: 0.7201807, Time: 07_05_2022__09:12:48\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 0.8029055, Training accuracy: 0.7201488, Time: 07_05_2022__09:13:07\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 0.8026205, Training accuracy: 0.7203235, Time: 07_05_2022__09:13:27\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 0.8016193, Training accuracy: 0.7207849, Time: 07_05_2022__09:13:46\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 0.8017910, Training accuracy: 0.7209483, Time: 07_05_2022__09:14:06\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 0.8003789, Training accuracy: 0.7215909, Time: 07_05_2022__09:14:25\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 0.7989787, Training accuracy: 0.7221910, Time: 07_05_2022__09:14:45\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 0.7988490, Training accuracy: 0.7220556, Time: 07_05_2022__09:15:04\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 0.7986723, Training accuracy: 0.7220604, Time: 07_05_2022__09:15:24\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 0.7984574, Training accuracy: 0.7218478, Time: 07_05_2022__09:15:43\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 0.7983297, Training accuracy: 0.7219355, Time: 07_05_2022__09:16:03\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 0.7982273, Training accuracy: 0.7221277, Time: 07_05_2022__09:16:22\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 0.7994109, Training accuracy: 0.7218684, Time: 07_05_2022__09:16:42\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 0.7982828, Training accuracy: 0.7222396, Time: 07_05_2022__09:17:01\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 0.7964672, Training accuracy: 0.7232216, Time: 07_05_2022__09:17:20\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 0.7949472, Training accuracy: 0.7237245, Time: 07_05_2022__09:17:40\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 0.7947408, Training accuracy: 0.7239646, Time: 07_05_2022__09:17:59\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 0.7946056, Training accuracy: 0.7244000, Time: 07_05_2022__09:18:19\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 0.7953559, Training accuracy: 0.7239604, Time: 07_05_2022__09:18:38\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 0.7947123, Training accuracy: 0.7241176, Time: 07_05_2022__09:18:58\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 0.7940481, Training accuracy: 0.7245631, Time: 07_05_2022__09:19:17\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 0.7922188, Training accuracy: 0.7248798, Time: 07_05_2022__09:19:37\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 0.7917452, Training accuracy: 0.7250238, Time: 07_05_2022__09:19:56\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 0.7925476, Training accuracy: 0.7247642, Time: 07_05_2022__09:20:16\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 0.7918703, Training accuracy: 0.7247897, Time: 07_05_2022__09:20:35\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 0.7918103, Training accuracy: 0.7249537, Time: 07_05_2022__09:20:55\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 0.7923172, Training accuracy: 0.7250459, Time: 07_05_2022__09:21:14\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 0.7921202, Training accuracy: 0.7250227, Time: 07_05_2022__09:21:34\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 0.7911680, Training accuracy: 0.7256306, Time: 07_05_2022__09:21:53\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 0.7904832, Training accuracy: 0.7258036, Time: 07_05_2022__09:22:13\n","Epoch 4 of 5, Average training loss: 0.7903440, Average training accuracy: 0.7257778, Time: 07_05_2022__09:22:23\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54228c6911ba414580c989d88e235a95"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.7548333, Validation accuracy: 0.7375000, Time: 07_05_2022__09:22:28 | Loss decreased from 0.7965835 to 0.7583058 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.7279132, Validation accuracy: 0.7425000, Time: 07_05_2022__09:22:35 | Loss decreased from 0.7583058 to 0.7273026 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.7577195, Validation accuracy: 0.7300000, Time: 07_05_2022__09:22:43\n","Step: 400 of 1250, Validation loss: 0.7501244, Validation accuracy: 0.7343750, Time: 07_05_2022__09:22:48\n","Step: 500 of 1250, Validation loss: 0.7590828, Validation accuracy: 0.7325000, Time: 07_05_2022__09:22:53\n","Step: 600 of 1250, Validation loss: 0.7425971, Validation accuracy: 0.7395833, Time: 07_05_2022__09:22:58\n","Step: 700 of 1250, Validation loss: 0.7286522, Validation accuracy: 0.7450000, Time: 07_05_2022__09:23:03\n","Step: 800 of 1250, Validation loss: 0.7147075, Validation accuracy: 0.7453125, Time: 07_05_2022__09:23:09 | Loss decreased from 0.7273026 to 0.7146760 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.7153874, Validation accuracy: 0.7463889, Time: 07_05_2022__09:23:16\n","Step: 1000 of 1250, Validation loss: 0.7119737, Validation accuracy: 0.7475000, Time: 07_05_2022__09:23:21 | Loss decreased from 0.7146760 to 0.7113667 .... Saving the model\n","Step: 1100 of 1250, Validation loss: 0.7174527, Validation accuracy: 0.7468182, Time: 07_05_2022__09:23:29\n","Step: 1200 of 1250, Validation loss: 0.7284916, Validation accuracy: 0.7418750, Time: 07_05_2022__09:23:34\n","Average validation loss: 0.7289398, Average validation accuracy: 0.7424000, Time: 07_05_2022__09:23:37\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77257646902f43228469ad1464d9b48a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 0.6258897, Training accuracy: 0.7850000, Time: 07_05_2022__09:23:56\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 0.6778588, Training accuracy: 0.7662500, Time: 07_05_2022__09:24:16\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 0.6852815, Training accuracy: 0.7616667, Time: 07_05_2022__09:24:35\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 0.6502106, Training accuracy: 0.7681250, Time: 07_05_2022__09:24:55\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 0.6553905, Training accuracy: 0.7690000, Time: 07_05_2022__09:25:14\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 0.6736961, Training accuracy: 0.7641667, Time: 07_05_2022__09:25:34\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 0.6809578, Training accuracy: 0.7582143, Time: 07_05_2022__09:25:53\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 0.6832414, Training accuracy: 0.7571875, Time: 07_05_2022__09:26:13\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 0.6937168, Training accuracy: 0.7558333, Time: 07_05_2022__09:26:32\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 0.6888430, Training accuracy: 0.7557500, Time: 07_05_2022__09:26:52\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 0.6930936, Training accuracy: 0.7554545, Time: 07_05_2022__09:27:11\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 0.6971438, Training accuracy: 0.7541667, Time: 07_05_2022__09:27:31\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 0.7048740, Training accuracy: 0.7528846, Time: 07_05_2022__09:27:50\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 0.7074346, Training accuracy: 0.7532143, Time: 07_05_2022__09:28:10\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 0.7114932, Training accuracy: 0.7518333, Time: 07_05_2022__09:28:29\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 0.7125402, Training accuracy: 0.7520313, Time: 07_05_2022__09:28:49\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 0.7141272, Training accuracy: 0.7523529, Time: 07_05_2022__09:29:08\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 0.7176297, Training accuracy: 0.7509722, Time: 07_05_2022__09:29:28\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 0.7175859, Training accuracy: 0.7505263, Time: 07_05_2022__09:29:47\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 0.7171704, Training accuracy: 0.7501250, Time: 07_05_2022__09:30:07\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 0.7177858, Training accuracy: 0.7517857, Time: 07_05_2022__09:30:26\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 0.7161725, Training accuracy: 0.7530682, Time: 07_05_2022__09:30:46\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 0.7105756, Training accuracy: 0.7550000, Time: 07_05_2022__09:31:05\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 0.7079114, Training accuracy: 0.7548958, Time: 07_05_2022__09:31:25\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 0.7076383, Training accuracy: 0.7542000, Time: 07_05_2022__09:31:44\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 0.7085181, Training accuracy: 0.7535577, Time: 07_05_2022__09:32:04\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 0.7074966, Training accuracy: 0.7545370, Time: 07_05_2022__09:32:23\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 0.7091637, Training accuracy: 0.7537500, Time: 07_05_2022__09:32:43\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 0.7085872, Training accuracy: 0.7535345, Time: 07_05_2022__09:33:02\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 0.7081997, Training accuracy: 0.7535000, Time: 07_05_2022__09:33:22\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 0.7053187, Training accuracy: 0.7542742, Time: 07_05_2022__09:33:41\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 0.7039984, Training accuracy: 0.7550000, Time: 07_05_2022__09:34:01\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 0.7046719, Training accuracy: 0.7548485, Time: 07_05_2022__09:34:20\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 0.7053399, Training accuracy: 0.7550000, Time: 07_05_2022__09:34:40\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 0.7043346, Training accuracy: 0.7547143, Time: 07_05_2022__09:34:59\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 0.7042096, Training accuracy: 0.7548611, Time: 07_05_2022__09:35:19\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 0.7055523, Training accuracy: 0.7546622, Time: 07_05_2022__09:35:38\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 0.7049258, Training accuracy: 0.7555921, Time: 07_05_2022__09:35:58\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 0.7055377, Training accuracy: 0.7548077, Time: 07_05_2022__09:36:17\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 0.7027598, Training accuracy: 0.7559375, Time: 07_05_2022__09:36:37\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 0.7049494, Training accuracy: 0.7550610, Time: 07_05_2022__09:36:56\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 0.7026409, Training accuracy: 0.7554762, Time: 07_05_2022__09:37:16\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 0.7004455, Training accuracy: 0.7563953, Time: 07_05_2022__09:37:35\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 0.6984601, Training accuracy: 0.7571023, Time: 07_05_2022__09:37:55\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 0.6973811, Training accuracy: 0.7571111, Time: 07_05_2022__09:38:14\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 0.6970669, Training accuracy: 0.7573913, Time: 07_05_2022__09:38:34\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 0.6969411, Training accuracy: 0.7573936, Time: 07_05_2022__09:38:53\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 0.6977960, Training accuracy: 0.7575521, Time: 07_05_2022__09:39:13\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 0.6968894, Training accuracy: 0.7582143, Time: 07_05_2022__09:39:32\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 0.6984950, Training accuracy: 0.7582000, Time: 07_05_2022__09:39:52\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 0.6982011, Training accuracy: 0.7581863, Time: 07_05_2022__09:40:11\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 0.6983628, Training accuracy: 0.7581250, Time: 07_05_2022__09:40:31\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 0.6993094, Training accuracy: 0.7576415, Time: 07_05_2022__09:40:50\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 0.6985674, Training accuracy: 0.7579630, Time: 07_05_2022__09:41:10\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 0.6998083, Training accuracy: 0.7574545, Time: 07_05_2022__09:41:29\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 0.6988830, Training accuracy: 0.7577679, Time: 07_05_2022__09:41:49\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 0.6973314, Training accuracy: 0.7579386, Time: 07_05_2022__09:42:08\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 0.6975960, Training accuracy: 0.7578017, Time: 07_05_2022__09:42:28\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 0.6979922, Training accuracy: 0.7573729, Time: 07_05_2022__09:42:47\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 0.6985389, Training accuracy: 0.7572917, Time: 07_05_2022__09:43:07\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 0.6986516, Training accuracy: 0.7571311, Time: 07_05_2022__09:43:26\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 0.6975067, Training accuracy: 0.7574194, Time: 07_05_2022__09:43:46\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 0.6972750, Training accuracy: 0.7575794, Time: 07_05_2022__09:44:05\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 0.6965747, Training accuracy: 0.7578516, Time: 07_05_2022__09:44:25\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 0.6955800, Training accuracy: 0.7582692, Time: 07_05_2022__09:44:44\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 0.6949106, Training accuracy: 0.7587121, Time: 07_05_2022__09:45:04\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 0.6940079, Training accuracy: 0.7589925, Time: 07_05_2022__09:45:23\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 0.6940442, Training accuracy: 0.7591544, Time: 07_05_2022__09:45:43\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 0.6927492, Training accuracy: 0.7593116, Time: 07_05_2022__09:46:02\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 0.6921390, Training accuracy: 0.7594643, Time: 07_05_2022__09:46:22\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 0.6915900, Training accuracy: 0.7594366, Time: 07_05_2022__09:46:41\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 0.6908520, Training accuracy: 0.7597569, Time: 07_05_2022__09:47:01\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 0.6894399, Training accuracy: 0.7601370, Time: 07_05_2022__09:47:20\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 0.6894113, Training accuracy: 0.7602703, Time: 07_05_2022__09:47:40\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 0.6878693, Training accuracy: 0.7604667, Time: 07_05_2022__09:47:59\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 0.6867475, Training accuracy: 0.7607566, Time: 07_05_2022__09:48:19\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 0.6873743, Training accuracy: 0.7608442, Time: 07_05_2022__09:48:38\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 0.6870797, Training accuracy: 0.7611218, Time: 07_05_2022__09:48:58\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 0.6857315, Training accuracy: 0.7615506, Time: 07_05_2022__09:49:17\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 0.6847679, Training accuracy: 0.7618750, Time: 07_05_2022__09:49:37\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 0.6861634, Training accuracy: 0.7612963, Time: 07_05_2022__09:49:56\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 0.6859674, Training accuracy: 0.7615244, Time: 07_05_2022__09:50:16\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 0.6852699, Training accuracy: 0.7617470, Time: 07_05_2022__09:50:35\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 0.6863164, Training accuracy: 0.7615476, Time: 07_05_2022__09:50:55\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 0.6866350, Training accuracy: 0.7616471, Time: 07_05_2022__09:51:14\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 0.6859180, Training accuracy: 0.7620349, Time: 07_05_2022__09:51:34\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 0.6863656, Training accuracy: 0.7616954, Time: 07_05_2022__09:51:53\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 0.6857388, Training accuracy: 0.7619318, Time: 07_05_2022__09:52:13\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 0.6852944, Training accuracy: 0.7618820, Time: 07_05_2022__09:52:32\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 0.6852653, Training accuracy: 0.7621389, Time: 07_05_2022__09:52:52\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 0.6852115, Training accuracy: 0.7619780, Time: 07_05_2022__09:53:11\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 0.6848915, Training accuracy: 0.7621196, Time: 07_05_2022__09:53:31\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 0.6850746, Training accuracy: 0.7619086, Time: 07_05_2022__09:53:50\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 0.6846094, Training accuracy: 0.7619415, Time: 07_05_2022__09:54:10\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 0.6855878, Training accuracy: 0.7617632, Time: 07_05_2022__09:54:29\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 0.6847938, Training accuracy: 0.7618750, Time: 07_05_2022__09:54:49\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 0.6837106, Training accuracy: 0.7623969, Time: 07_05_2022__09:55:08\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 0.6829279, Training accuracy: 0.7626786, Time: 07_05_2022__09:55:28\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 0.6829213, Training accuracy: 0.7627525, Time: 07_05_2022__09:55:47\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 0.6823732, Training accuracy: 0.7631750, Time: 07_05_2022__09:56:07\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 0.6824877, Training accuracy: 0.7632673, Time: 07_05_2022__09:56:26\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 0.6823157, Training accuracy: 0.7634559, Time: 07_05_2022__09:56:46\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 0.6813626, Training accuracy: 0.7636408, Time: 07_05_2022__09:57:05\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 0.6802182, Training accuracy: 0.7640385, Time: 07_05_2022__09:57:25\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 0.6795986, Training accuracy: 0.7642857, Time: 07_05_2022__09:57:44\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 0.6800535, Training accuracy: 0.7641274, Time: 07_05_2022__09:58:04\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 0.6786246, Training accuracy: 0.7645561, Time: 07_05_2022__09:58:23\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 0.6779839, Training accuracy: 0.7649769, Time: 07_05_2022__09:58:43\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 0.6785432, Training accuracy: 0.7649541, Time: 07_05_2022__09:59:02\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 0.6786048, Training accuracy: 0.7650455, Time: 07_05_2022__09:59:22\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 0.6781360, Training accuracy: 0.7652252, Time: 07_05_2022__09:59:41\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 0.6777915, Training accuracy: 0.7652679, Time: 07_05_2022__10:00:01\n","Epoch 5 of 5, Average training loss: 0.6780366, Average training accuracy: 0.7651556, Time: 07_05_2022__10:00:11\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a96a0bf68aa445b2b253f55a099bef14"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.7189494, Validation accuracy: 0.7550000, Time: 07_05_2022__10:00:16\n","Step: 200 of 1250, Validation loss: 0.7365702, Validation accuracy: 0.7400000, Time: 07_05_2022__10:00:21\n","Step: 300 of 1250, Validation loss: 0.7483459, Validation accuracy: 0.7408333, Time: 07_05_2022__10:00:26\n","Step: 400 of 1250, Validation loss: 0.7292286, Validation accuracy: 0.7468750, Time: 07_05_2022__10:00:31\n","Step: 500 of 1250, Validation loss: 0.7401571, Validation accuracy: 0.7465000, Time: 07_05_2022__10:00:36\n","Step: 600 of 1250, Validation loss: 0.7398440, Validation accuracy: 0.7516667, Time: 07_05_2022__10:00:41\n","Step: 700 of 1250, Validation loss: 0.7225675, Validation accuracy: 0.7546429, Time: 07_05_2022__10:00:46\n","Step: 800 of 1250, Validation loss: 0.7047221, Validation accuracy: 0.7581250, Time: 07_05_2022__10:00:52 | Loss decreased from 0.7113667 to 0.7048258 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.7003221, Validation accuracy: 0.7619444, Time: 07_05_2022__10:00:59 | Loss decreased from 0.7048258 to 0.7006837 .... Saving the model\n","Step: 1000 of 1250, Validation loss: 0.6987650, Validation accuracy: 0.7637500, Time: 07_05_2022__10:01:07 | Loss decreased from 0.7006837 to 0.6980932 .... Saving the model\n","Step: 1100 of 1250, Validation loss: 0.7035445, Validation accuracy: 0.7618182, Time: 07_05_2022__10:01:15\n","Step: 1200 of 1250, Validation loss: 0.7080930, Validation accuracy: 0.7597917, Time: 07_05_2022__10:01:20\n","Average validation loss: 0.7031488, Average validation accuracy: 0.7612000, Time: 07_05_2022__10:01:22\n","###################### Testing vgg19_batch_norm SGD, lr_0.01, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ccd8bed5b904a86b88b1ac378df2e6f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.7825000, Time: 07_05_2022__10:01:37\n","Step: 200 of 2500, Test accuracy: 0.7787500, Time: 07_05_2022__10:01:42\n","Step: 300 of 2500, Test accuracy: 0.7700000, Time: 07_05_2022__10:01:47\n","Step: 400 of 2500, Test accuracy: 0.7593750, Time: 07_05_2022__10:01:52\n","Step: 500 of 2500, Test accuracy: 0.7480000, Time: 07_05_2022__10:01:57\n","Step: 600 of 2500, Test accuracy: 0.7475000, Time: 07_05_2022__10:02:03\n","Step: 700 of 2500, Test accuracy: 0.7478571, Time: 07_05_2022__10:02:08\n","Step: 800 of 2500, Test accuracy: 0.7515625, Time: 07_05_2022__10:02:13\n","Step: 900 of 2500, Test accuracy: 0.7494444, Time: 07_05_2022__10:02:18\n","Step: 1000 of 2500, Test accuracy: 0.7472500, Time: 07_05_2022__10:02:23\n","Step: 1100 of 2500, Test accuracy: 0.7511364, Time: 07_05_2022__10:02:28\n","Step: 1200 of 2500, Test accuracy: 0.7531250, Time: 07_05_2022__10:02:33\n","Step: 1300 of 2500, Test accuracy: 0.7550000, Time: 07_05_2022__10:02:38\n","Step: 1400 of 2500, Test accuracy: 0.7548214, Time: 07_05_2022__10:02:44\n","Step: 1500 of 2500, Test accuracy: 0.7556667, Time: 07_05_2022__10:02:49\n","Step: 1600 of 2500, Test accuracy: 0.7573437, Time: 07_05_2022__10:02:54\n","Step: 1700 of 2500, Test accuracy: 0.7569118, Time: 07_05_2022__10:02:59\n","Step: 1800 of 2500, Test accuracy: 0.7558333, Time: 07_05_2022__10:03:04\n","Step: 1900 of 2500, Test accuracy: 0.7575000, Time: 07_05_2022__10:03:09\n","Step: 2000 of 2500, Test accuracy: 0.7571250, Time: 07_05_2022__10:03:14\n","Step: 2100 of 2500, Test accuracy: 0.7572619, Time: 07_05_2022__10:03:19\n","Step: 2200 of 2500, Test accuracy: 0.7562500, Time: 07_05_2022__10:03:24\n","Step: 2300 of 2500, Test accuracy: 0.7570652, Time: 07_05_2022__10:03:30\n","Step: 2400 of 2500, Test accuracy: 0.7581250, Time: 07_05_2022__10:03:35\n","Step: 2500 of 2500, Test accuracy: 0.7574000, Time: 07_05_2022__10:03:40\n","Average testing accuracy: 0.7574000, Time: 07_05_2022__10:03:40\n","###################### Training vgg19_batch_norm SGD, lr_0.01, momentum_0.3 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c7868dcad1a448ab0ad99e09d29b475"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 3.1508377, Training accuracy: 0.1075000, Time: 07_05_2022__10:04:03\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 2.8190097, Training accuracy: 0.1275000, Time: 07_05_2022__10:04:23\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 2.6872211, Training accuracy: 0.1258333, Time: 07_05_2022__10:04:44\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 2.6088540, Training accuracy: 0.1300000, Time: 07_05_2022__10:05:04\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 2.5408953, Training accuracy: 0.1380000, Time: 07_05_2022__10:05:25\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 2.4945658, Training accuracy: 0.1404167, Time: 07_05_2022__10:05:46\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.4576107, Training accuracy: 0.1410714, Time: 07_05_2022__10:06:06\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.4260801, Training accuracy: 0.1462500, Time: 07_05_2022__10:06:27\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.3991850, Training accuracy: 0.1508333, Time: 07_05_2022__10:06:47\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.3789001, Training accuracy: 0.1530000, Time: 07_05_2022__10:07:08\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.3582475, Training accuracy: 0.1568182, Time: 07_05_2022__10:07:28\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.3393411, Training accuracy: 0.1558333, Time: 07_05_2022__10:07:49\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.3233124, Training accuracy: 0.1596154, Time: 07_05_2022__10:08:10\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.3059891, Training accuracy: 0.1644643, Time: 07_05_2022__10:08:30\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.2948466, Training accuracy: 0.1668333, Time: 07_05_2022__10:08:51\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.2836701, Training accuracy: 0.1710937, Time: 07_05_2022__10:09:11\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.2725180, Training accuracy: 0.1736765, Time: 07_05_2022__10:09:32\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.2592831, Training accuracy: 0.1775000, Time: 07_05_2022__10:09:52\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.2466965, Training accuracy: 0.1810526, Time: 07_05_2022__10:10:13\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.2380832, Training accuracy: 0.1831250, Time: 07_05_2022__10:10:33\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.2263645, Training accuracy: 0.1873810, Time: 07_05_2022__10:10:54\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.2174771, Training accuracy: 0.1909091, Time: 07_05_2022__10:11:15\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.2062433, Training accuracy: 0.1952174, Time: 07_05_2022__10:11:35\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.1960931, Training accuracy: 0.1998958, Time: 07_05_2022__10:11:56\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.1831447, Training accuracy: 0.2048000, Time: 07_05_2022__10:12:16\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.1746240, Training accuracy: 0.2100000, Time: 07_05_2022__10:12:37\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.1661614, Training accuracy: 0.2118519, Time: 07_05_2022__10:12:57\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.1568595, Training accuracy: 0.2150000, Time: 07_05_2022__10:13:18\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.1489605, Training accuracy: 0.2175862, Time: 07_05_2022__10:13:39\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.1416910, Training accuracy: 0.2197500, Time: 07_05_2022__10:13:59\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.1316621, Training accuracy: 0.2229032, Time: 07_05_2022__10:14:20\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.1223644, Training accuracy: 0.2251563, Time: 07_05_2022__10:14:40\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.1164425, Training accuracy: 0.2270455, Time: 07_05_2022__10:15:01\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.1104711, Training accuracy: 0.2289706, Time: 07_05_2022__10:15:21\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.1028324, Training accuracy: 0.2310714, Time: 07_05_2022__10:15:42\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.0979923, Training accuracy: 0.2324306, Time: 07_05_2022__10:16:03\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.0934562, Training accuracy: 0.2340541, Time: 07_05_2022__10:16:23\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.0866756, Training accuracy: 0.2366447, Time: 07_05_2022__10:16:44\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.0814604, Training accuracy: 0.2383974, Time: 07_05_2022__10:17:04\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.0752949, Training accuracy: 0.2413750, Time: 07_05_2022__10:17:25\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.0714533, Training accuracy: 0.2423780, Time: 07_05_2022__10:17:45\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.0644891, Training accuracy: 0.2445833, Time: 07_05_2022__10:18:06\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.0596099, Training accuracy: 0.2463372, Time: 07_05_2022__10:18:26\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.0531341, Training accuracy: 0.2488068, Time: 07_05_2022__10:18:47\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.0467837, Training accuracy: 0.2511111, Time: 07_05_2022__10:19:08\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.0408739, Training accuracy: 0.2533696, Time: 07_05_2022__10:19:28\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.0359997, Training accuracy: 0.2550000, Time: 07_05_2022__10:19:49\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 2.0306105, Training accuracy: 0.2564063, Time: 07_05_2022__10:20:09\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 2.0267904, Training accuracy: 0.2582653, Time: 07_05_2022__10:20:30\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 2.0234355, Training accuracy: 0.2594000, Time: 07_05_2022__10:20:50\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 2.0175595, Training accuracy: 0.2615686, Time: 07_05_2022__10:21:11\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 2.0152954, Training accuracy: 0.2627885, Time: 07_05_2022__10:21:32\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 2.0098090, Training accuracy: 0.2649057, Time: 07_05_2022__10:21:52\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 2.0056588, Training accuracy: 0.2661574, Time: 07_05_2022__10:22:13\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 2.0008190, Training accuracy: 0.2677273, Time: 07_05_2022__10:22:33\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 1.9962720, Training accuracy: 0.2694196, Time: 07_05_2022__10:22:54\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 1.9917616, Training accuracy: 0.2702632, Time: 07_05_2022__10:23:14\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 1.9879395, Training accuracy: 0.2715086, Time: 07_05_2022__10:23:35\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 1.9838020, Training accuracy: 0.2734322, Time: 07_05_2022__10:23:56\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 1.9792694, Training accuracy: 0.2748333, Time: 07_05_2022__10:24:16\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 1.9770022, Training accuracy: 0.2754508, Time: 07_05_2022__10:24:37\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 1.9719708, Training accuracy: 0.2775403, Time: 07_05_2022__10:24:57\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 1.9682734, Training accuracy: 0.2788889, Time: 07_05_2022__10:25:18\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 1.9640027, Training accuracy: 0.2806250, Time: 07_05_2022__10:25:39\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 1.9594445, Training accuracy: 0.2825000, Time: 07_05_2022__10:25:59\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 1.9563813, Training accuracy: 0.2837500, Time: 07_05_2022__10:26:20\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 1.9515777, Training accuracy: 0.2855597, Time: 07_05_2022__10:26:40\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 1.9491151, Training accuracy: 0.2858088, Time: 07_05_2022__10:27:01\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 1.9459948, Training accuracy: 0.2872101, Time: 07_05_2022__10:27:21\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 1.9416783, Training accuracy: 0.2884643, Time: 07_05_2022__10:27:42\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 1.9381059, Training accuracy: 0.2894014, Time: 07_05_2022__10:28:02\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 1.9346243, Training accuracy: 0.2903472, Time: 07_05_2022__10:28:23\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 1.9307589, Training accuracy: 0.2918151, Time: 07_05_2022__10:28:44\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 1.9281385, Training accuracy: 0.2928041, Time: 07_05_2022__10:29:04\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 1.9247823, Training accuracy: 0.2937667, Time: 07_05_2022__10:29:25\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 1.9211841, Training accuracy: 0.2948355, Time: 07_05_2022__10:29:45\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 1.9180302, Training accuracy: 0.2960065, Time: 07_05_2022__10:30:06\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 1.9141253, Training accuracy: 0.2972115, Time: 07_05_2022__10:30:26\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 1.9108312, Training accuracy: 0.2982911, Time: 07_05_2022__10:30:47\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 1.9078593, Training accuracy: 0.2992500, Time: 07_05_2022__10:31:07\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 1.9039514, Training accuracy: 0.3007407, Time: 07_05_2022__10:31:28\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 1.9016000, Training accuracy: 0.3016159, Time: 07_05_2022__10:31:49\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 1.8982874, Training accuracy: 0.3028313, Time: 07_05_2022__10:32:09\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 1.8958332, Training accuracy: 0.3038393, Time: 07_05_2022__10:32:30\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 1.8924931, Training accuracy: 0.3051765, Time: 07_05_2022__10:32:50\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 1.8889842, Training accuracy: 0.3065407, Time: 07_05_2022__10:33:11\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 1.8858319, Training accuracy: 0.3077874, Time: 07_05_2022__10:33:32\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 1.8820934, Training accuracy: 0.3092898, Time: 07_05_2022__10:33:52\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 1.8791802, Training accuracy: 0.3105899, Time: 07_05_2022__10:34:13\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 1.8763217, Training accuracy: 0.3115833, Time: 07_05_2022__10:34:33\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 1.8730419, Training accuracy: 0.3130769, Time: 07_05_2022__10:34:54\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 1.8696427, Training accuracy: 0.3139946, Time: 07_05_2022__10:35:14\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 1.8667072, Training accuracy: 0.3150000, Time: 07_05_2022__10:35:35\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 1.8640710, Training accuracy: 0.3160638, Time: 07_05_2022__10:35:56\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 1.8625513, Training accuracy: 0.3163684, Time: 07_05_2022__10:36:16\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 1.8585781, Training accuracy: 0.3176823, Time: 07_05_2022__10:36:37\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 1.8547392, Training accuracy: 0.3190206, Time: 07_05_2022__10:36:57\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 1.8510460, Training accuracy: 0.3204337, Time: 07_05_2022__10:37:18\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 1.8485476, Training accuracy: 0.3216667, Time: 07_05_2022__10:37:39\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 1.8461851, Training accuracy: 0.3221750, Time: 07_05_2022__10:37:59\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 1.8444060, Training accuracy: 0.3227723, Time: 07_05_2022__10:38:20\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 1.8415411, Training accuracy: 0.3237745, Time: 07_05_2022__10:38:40\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 1.8384140, Training accuracy: 0.3250728, Time: 07_05_2022__10:39:01\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 1.8350339, Training accuracy: 0.3262500, Time: 07_05_2022__10:39:22\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 1.8326685, Training accuracy: 0.3272857, Time: 07_05_2022__10:39:42\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 1.8297797, Training accuracy: 0.3283255, Time: 07_05_2022__10:40:03\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 1.8264740, Training accuracy: 0.3295561, Time: 07_05_2022__10:40:23\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 1.8236329, Training accuracy: 0.3307407, Time: 07_05_2022__10:40:44\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 1.8217427, Training accuracy: 0.3314908, Time: 07_05_2022__10:41:04\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 1.8189416, Training accuracy: 0.3328182, Time: 07_05_2022__10:41:25\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 1.8161859, Training accuracy: 0.3339189, Time: 07_05_2022__10:41:46\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 1.8136326, Training accuracy: 0.3345536, Time: 07_05_2022__10:42:06\n","Epoch 1 of 5, Average training loss: 1.8123916, Average training accuracy: 0.3351778, Time: 07_05_2022__10:42:16\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48a9571be6cd478cb05ed546a0f77ec6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.3196907, Validation accuracy: 0.5425000, Time: 07_05_2022__10:42:22 | Loss decreased from inf to 1.3185810 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.3250548, Validation accuracy: 0.5287500, Time: 07_05_2022__10:42:30\n","Step: 300 of 1250, Validation loss: 1.3307369, Validation accuracy: 0.5266667, Time: 07_05_2022__10:42:35\n","Step: 400 of 1250, Validation loss: 1.3195620, Validation accuracy: 0.5343750, Time: 07_05_2022__10:42:40\n","Step: 500 of 1250, Validation loss: 1.3234360, Validation accuracy: 0.5280000, Time: 07_05_2022__10:42:45\n","Step: 600 of 1250, Validation loss: 1.3167500, Validation accuracy: 0.5308333, Time: 07_05_2022__10:42:50 | Loss decreased from 1.3185810 to 1.3171484 .... Saving the model\n","Step: 700 of 1250, Validation loss: 1.3137304, Validation accuracy: 0.5357143, Time: 07_05_2022__10:42:58 | Loss decreased from 1.3171484 to 1.3138032 .... Saving the model\n","Step: 800 of 1250, Validation loss: 1.3112639, Validation accuracy: 0.5346875, Time: 07_05_2022__10:43:05 | Loss decreased from 1.3138032 to 1.3118781 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.3131617, Validation accuracy: 0.5325000, Time: 07_05_2022__10:43:13\n","Step: 1000 of 1250, Validation loss: 1.3163619, Validation accuracy: 0.5285000, Time: 07_05_2022__10:43:18\n","Step: 1100 of 1250, Validation loss: 1.3155027, Validation accuracy: 0.5281818, Time: 07_05_2022__10:43:23\n","Step: 1200 of 1250, Validation loss: 1.3152319, Validation accuracy: 0.5264583, Time: 07_05_2022__10:43:28\n","Average validation loss: 1.3131413, Average validation accuracy: 0.5276000, Time: 07_05_2022__10:43:31\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68c8fe144f8b422eb10b5715d88fef48"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.4351362, Training accuracy: 0.4750000, Time: 07_05_2022__10:43:52\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.4419613, Training accuracy: 0.4762500, Time: 07_05_2022__10:44:12\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.4552821, Training accuracy: 0.4700000, Time: 07_05_2022__10:44:33\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.4421995, Training accuracy: 0.4675000, Time: 07_05_2022__10:44:53\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.4490557, Training accuracy: 0.4665000, Time: 07_05_2022__10:45:14\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.4536869, Training accuracy: 0.4645833, Time: 07_05_2022__10:45:34\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.4607764, Training accuracy: 0.4646429, Time: 07_05_2022__10:45:55\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.4563573, Training accuracy: 0.4662500, Time: 07_05_2022__10:46:16\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.4487223, Training accuracy: 0.4683333, Time: 07_05_2022__10:46:36\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.4432590, Training accuracy: 0.4752500, Time: 07_05_2022__10:46:57\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.4488354, Training accuracy: 0.4743182, Time: 07_05_2022__10:47:17\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.4498254, Training accuracy: 0.4729167, Time: 07_05_2022__10:47:38\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.4438429, Training accuracy: 0.4773077, Time: 07_05_2022__10:47:59\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.4417616, Training accuracy: 0.4775000, Time: 07_05_2022__10:48:19\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.4445418, Training accuracy: 0.4738333, Time: 07_05_2022__10:48:40\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.4430978, Training accuracy: 0.4739062, Time: 07_05_2022__10:49:00\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.4443354, Training accuracy: 0.4738235, Time: 07_05_2022__10:49:21\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.4435508, Training accuracy: 0.4741667, Time: 07_05_2022__10:49:42\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.4387876, Training accuracy: 0.4743421, Time: 07_05_2022__10:50:02\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.4356116, Training accuracy: 0.4763750, Time: 07_05_2022__10:50:23\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.4320950, Training accuracy: 0.4777381, Time: 07_05_2022__10:50:43\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.4308153, Training accuracy: 0.4788636, Time: 07_05_2022__10:51:04\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.4258121, Training accuracy: 0.4807609, Time: 07_05_2022__10:51:25\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.4207665, Training accuracy: 0.4832292, Time: 07_05_2022__10:51:45\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.4174188, Training accuracy: 0.4837000, Time: 07_05_2022__10:52:06\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.4137287, Training accuracy: 0.4862500, Time: 07_05_2022__10:52:26\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.4063768, Training accuracy: 0.4880556, Time: 07_05_2022__10:52:47\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.4063073, Training accuracy: 0.4882143, Time: 07_05_2022__10:53:07\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.4048190, Training accuracy: 0.4893103, Time: 07_05_2022__10:53:28\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.4044673, Training accuracy: 0.4892500, Time: 07_05_2022__10:53:49\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.4005568, Training accuracy: 0.4917742, Time: 07_05_2022__10:54:09\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.3949847, Training accuracy: 0.4935937, Time: 07_05_2022__10:54:30\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.3940332, Training accuracy: 0.4941667, Time: 07_05_2022__10:54:50\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.3925298, Training accuracy: 0.4947059, Time: 07_05_2022__10:55:11\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.3896337, Training accuracy: 0.4958571, Time: 07_05_2022__10:55:32\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.3894575, Training accuracy: 0.4962500, Time: 07_05_2022__10:55:52\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.3887986, Training accuracy: 0.4962838, Time: 07_05_2022__10:56:13\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.3864056, Training accuracy: 0.4976316, Time: 07_05_2022__10:56:33\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.3823371, Training accuracy: 0.4990385, Time: 07_05_2022__10:56:54\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.3802907, Training accuracy: 0.5001250, Time: 07_05_2022__10:57:14\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.3796924, Training accuracy: 0.5014634, Time: 07_05_2022__10:57:35\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.3746664, Training accuracy: 0.5032143, Time: 07_05_2022__10:57:56\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.3723800, Training accuracy: 0.5046512, Time: 07_05_2022__10:58:16\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.3696286, Training accuracy: 0.5053409, Time: 07_05_2022__10:58:37\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.3676156, Training accuracy: 0.5064444, Time: 07_05_2022__10:58:57\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.3669168, Training accuracy: 0.5073913, Time: 07_05_2022__10:59:18\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.3646635, Training accuracy: 0.5084574, Time: 07_05_2022__10:59:39\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.3628356, Training accuracy: 0.5090104, Time: 07_05_2022__10:59:59\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.3604656, Training accuracy: 0.5094898, Time: 07_05_2022__11:00:20\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.3589182, Training accuracy: 0.5103500, Time: 07_05_2022__11:00:40\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.3566804, Training accuracy: 0.5114706, Time: 07_05_2022__11:01:01\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.3560993, Training accuracy: 0.5118269, Time: 07_05_2022__11:01:22\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.3549234, Training accuracy: 0.5117453, Time: 07_05_2022__11:01:42\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.3534233, Training accuracy: 0.5129630, Time: 07_05_2022__11:02:03\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.3520613, Training accuracy: 0.5135000, Time: 07_05_2022__11:02:23\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.3500656, Training accuracy: 0.5143304, Time: 07_05_2022__11:02:44\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.3476803, Training accuracy: 0.5153070, Time: 07_05_2022__11:03:05\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.3468243, Training accuracy: 0.5155603, Time: 07_05_2022__11:03:25\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.3456194, Training accuracy: 0.5162712, Time: 07_05_2022__11:03:46\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.3452121, Training accuracy: 0.5170417, Time: 07_05_2022__11:04:06\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.3439451, Training accuracy: 0.5173770, Time: 07_05_2022__11:04:27\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.3405832, Training accuracy: 0.5190726, Time: 07_05_2022__11:04:48\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.3397372, Training accuracy: 0.5190476, Time: 07_05_2022__11:05:08\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.3381685, Training accuracy: 0.5195703, Time: 07_05_2022__11:05:29\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.3359940, Training accuracy: 0.5205769, Time: 07_05_2022__11:05:49\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.3342998, Training accuracy: 0.5217045, Time: 07_05_2022__11:06:10\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.3314754, Training accuracy: 0.5227612, Time: 07_05_2022__11:06:31\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.3303435, Training accuracy: 0.5230515, Time: 07_05_2022__11:06:51\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.3283633, Training accuracy: 0.5240217, Time: 07_05_2022__11:07:12\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.3253242, Training accuracy: 0.5248214, Time: 07_05_2022__11:07:32\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.3243095, Training accuracy: 0.5258451, Time: 07_05_2022__11:07:53\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.3223759, Training accuracy: 0.5265625, Time: 07_05_2022__11:08:14\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.3215093, Training accuracy: 0.5268836, Time: 07_05_2022__11:08:34\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.3192125, Training accuracy: 0.5276014, Time: 07_05_2022__11:08:55\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.3172976, Training accuracy: 0.5284333, Time: 07_05_2022__11:09:15\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.3141965, Training accuracy: 0.5296382, Time: 07_05_2022__11:09:36\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.3124299, Training accuracy: 0.5303247, Time: 07_05_2022__11:09:57\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.3110934, Training accuracy: 0.5310577, Time: 07_05_2022__11:10:17\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.3086871, Training accuracy: 0.5317722, Time: 07_05_2022__11:10:38\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.3067621, Training accuracy: 0.5320625, Time: 07_05_2022__11:10:58\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.3054945, Training accuracy: 0.5326852, Time: 07_05_2022__11:11:19\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.3039577, Training accuracy: 0.5330183, Time: 07_05_2022__11:11:40\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.3021961, Training accuracy: 0.5337048, Time: 07_05_2022__11:12:00\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.3015382, Training accuracy: 0.5339583, Time: 07_05_2022__11:12:21\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.3000564, Training accuracy: 0.5347059, Time: 07_05_2022__11:12:41\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.2976330, Training accuracy: 0.5358721, Time: 07_05_2022__11:13:02\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.2956259, Training accuracy: 0.5365230, Time: 07_05_2022__11:13:23\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.2934371, Training accuracy: 0.5375284, Time: 07_05_2022__11:13:43\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.2911569, Training accuracy: 0.5382865, Time: 07_05_2022__11:14:04\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.2888805, Training accuracy: 0.5394722, Time: 07_05_2022__11:14:25\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.2874947, Training accuracy: 0.5397527, Time: 07_05_2022__11:14:45\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.2853816, Training accuracy: 0.5405978, Time: 07_05_2022__11:15:06\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.2844968, Training accuracy: 0.5410753, Time: 07_05_2022__11:15:26\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.2828282, Training accuracy: 0.5418883, Time: 07_05_2022__11:15:47\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.2828108, Training accuracy: 0.5418947, Time: 07_05_2022__11:16:08\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.2806947, Training accuracy: 0.5425000, Time: 07_05_2022__11:16:28\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.2778677, Training accuracy: 0.5436082, Time: 07_05_2022__11:16:49\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.2758497, Training accuracy: 0.5444388, Time: 07_05_2022__11:17:09\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.2747219, Training accuracy: 0.5447727, Time: 07_05_2022__11:17:30\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.2730418, Training accuracy: 0.5453750, Time: 07_05_2022__11:17:51\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.2720554, Training accuracy: 0.5457426, Time: 07_05_2022__11:18:11\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.2702033, Training accuracy: 0.5465686, Time: 07_05_2022__11:18:32\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.2680934, Training accuracy: 0.5474272, Time: 07_05_2022__11:18:52\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.2659601, Training accuracy: 0.5483413, Time: 07_05_2022__11:19:13\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.2647790, Training accuracy: 0.5490238, Time: 07_05_2022__11:19:34\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.2631964, Training accuracy: 0.5497642, Time: 07_05_2022__11:19:54\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.2610683, Training accuracy: 0.5506542, Time: 07_05_2022__11:20:15\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.2593372, Training accuracy: 0.5514352, Time: 07_05_2022__11:20:35\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.2582467, Training accuracy: 0.5520872, Time: 07_05_2022__11:20:56\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.2567046, Training accuracy: 0.5527273, Time: 07_05_2022__11:21:17\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.2546701, Training accuracy: 0.5534009, Time: 07_05_2022__11:21:37\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.2534475, Training accuracy: 0.5540179, Time: 07_05_2022__11:21:58\n","Epoch 2 of 5, Average training loss: 1.2529499, Average training accuracy: 0.5540000, Time: 07_05_2022__11:22:08\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1de98dffa1841968378d7869c2bf78a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.9463051, Validation accuracy: 0.6925000, Time: 07_05_2022__11:22:13 | Loss decreased from 1.3118781 to 0.9496897 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.9347321, Validation accuracy: 0.6750000, Time: 07_05_2022__11:22:21 | Loss decreased from 0.9496897 to 0.9361855 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.9534270, Validation accuracy: 0.6616667, Time: 07_05_2022__11:22:28\n","Step: 400 of 1250, Validation loss: 0.9453351, Validation accuracy: 0.6643750, Time: 07_05_2022__11:22:33\n","Step: 500 of 1250, Validation loss: 0.9523023, Validation accuracy: 0.6635000, Time: 07_05_2022__11:22:39\n","Step: 600 of 1250, Validation loss: 0.9461520, Validation accuracy: 0.6633333, Time: 07_05_2022__11:22:44\n","Step: 700 of 1250, Validation loss: 0.9359504, Validation accuracy: 0.6685714, Time: 07_05_2022__11:22:49 | Loss decreased from 0.9361855 to 0.9354258 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.9238119, Validation accuracy: 0.6737500, Time: 07_05_2022__11:22:57 | Loss decreased from 0.9354258 to 0.9239631 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.9256492, Validation accuracy: 0.6744444, Time: 07_05_2022__11:23:04\n","Step: 1000 of 1250, Validation loss: 0.9301555, Validation accuracy: 0.6717500, Time: 07_05_2022__11:23:09\n","Step: 1100 of 1250, Validation loss: 0.9278304, Validation accuracy: 0.6738636, Time: 07_05_2022__11:23:14\n","Step: 1200 of 1250, Validation loss: 0.9372978, Validation accuracy: 0.6681250, Time: 07_05_2022__11:23:20\n","Average validation loss: 0.9360997, Average validation accuracy: 0.6684000, Time: 07_05_2022__11:23:22\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a911299bdc34a028f24e7db71c5e232"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.0013039, Training accuracy: 0.6300000, Time: 07_05_2022__11:23:43\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.0115878, Training accuracy: 0.6375000, Time: 07_05_2022__11:24:03\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.0349187, Training accuracy: 0.6266667, Time: 07_05_2022__11:24:24\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.0157547, Training accuracy: 0.6343750, Time: 07_05_2022__11:24:45\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.0110485, Training accuracy: 0.6395000, Time: 07_05_2022__11:25:05\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.0275836, Training accuracy: 0.6383333, Time: 07_05_2022__11:25:26\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.0356894, Training accuracy: 0.6382143, Time: 07_05_2022__11:25:47\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.0374376, Training accuracy: 0.6381250, Time: 07_05_2022__11:26:07\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.0375304, Training accuracy: 0.6372222, Time: 07_05_2022__11:26:28\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.0333475, Training accuracy: 0.6385000, Time: 07_05_2022__11:26:48\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.0383682, Training accuracy: 0.6363636, Time: 07_05_2022__11:27:09\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.0389999, Training accuracy: 0.6358333, Time: 07_05_2022__11:27:30\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.0366290, Training accuracy: 0.6361538, Time: 07_05_2022__11:27:50\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.0389959, Training accuracy: 0.6353571, Time: 07_05_2022__11:28:11\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.0406878, Training accuracy: 0.6348333, Time: 07_05_2022__11:28:32\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.0410954, Training accuracy: 0.6360938, Time: 07_05_2022__11:28:52\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.0409826, Training accuracy: 0.6357353, Time: 07_05_2022__11:29:13\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.0439750, Training accuracy: 0.6351389, Time: 07_05_2022__11:29:33\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.0407927, Training accuracy: 0.6361842, Time: 07_05_2022__11:29:54\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.0394735, Training accuracy: 0.6371250, Time: 07_05_2022__11:30:15\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.0352927, Training accuracy: 0.6388095, Time: 07_05_2022__11:30:35\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.0328645, Training accuracy: 0.6400000, Time: 07_05_2022__11:30:56\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.0302646, Training accuracy: 0.6410870, Time: 07_05_2022__11:31:16\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.0281370, Training accuracy: 0.6417708, Time: 07_05_2022__11:31:37\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.0263131, Training accuracy: 0.6423000, Time: 07_05_2022__11:31:58\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.0243331, Training accuracy: 0.6429808, Time: 07_05_2022__11:32:18\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.0196502, Training accuracy: 0.6438889, Time: 07_05_2022__11:32:39\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.0213237, Training accuracy: 0.6434821, Time: 07_05_2022__11:33:00\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.0204720, Training accuracy: 0.6443103, Time: 07_05_2022__11:33:20\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.0191322, Training accuracy: 0.6445833, Time: 07_05_2022__11:33:41\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.0156011, Training accuracy: 0.6452419, Time: 07_05_2022__11:34:01\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.0126170, Training accuracy: 0.6462500, Time: 07_05_2022__11:34:22\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.0128258, Training accuracy: 0.6463636, Time: 07_05_2022__11:34:43\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.0115285, Training accuracy: 0.6463971, Time: 07_05_2022__11:35:03\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.0101989, Training accuracy: 0.6467857, Time: 07_05_2022__11:35:24\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.0108631, Training accuracy: 0.6456250, Time: 07_05_2022__11:35:45\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.0105432, Training accuracy: 0.6449324, Time: 07_05_2022__11:36:05\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.0082892, Training accuracy: 0.6457237, Time: 07_05_2022__11:36:26\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.0051997, Training accuracy: 0.6462821, Time: 07_05_2022__11:36:46\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.0027941, Training accuracy: 0.6467500, Time: 07_05_2022__11:37:07\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.0042783, Training accuracy: 0.6459756, Time: 07_05_2022__11:37:28\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.0008782, Training accuracy: 0.6476190, Time: 07_05_2022__11:37:48\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 0.9987578, Training accuracy: 0.6482558, Time: 07_05_2022__11:38:09\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 0.9974761, Training accuracy: 0.6485795, Time: 07_05_2022__11:38:30\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 0.9971188, Training accuracy: 0.6491111, Time: 07_05_2022__11:38:50\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 0.9978327, Training accuracy: 0.6489130, Time: 07_05_2022__11:39:11\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 0.9973411, Training accuracy: 0.6497340, Time: 07_05_2022__11:39:32\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 0.9967004, Training accuracy: 0.6499479, Time: 07_05_2022__11:39:52\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 0.9963165, Training accuracy: 0.6501020, Time: 07_05_2022__11:40:13\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 0.9951518, Training accuracy: 0.6509500, Time: 07_05_2022__11:40:33\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 0.9938166, Training accuracy: 0.6518627, Time: 07_05_2022__11:40:54\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 0.9932313, Training accuracy: 0.6518750, Time: 07_05_2022__11:41:15\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 0.9932841, Training accuracy: 0.6518396, Time: 07_05_2022__11:41:35\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 0.9919868, Training accuracy: 0.6518981, Time: 07_05_2022__11:41:56\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 0.9912221, Training accuracy: 0.6524091, Time: 07_05_2022__11:42:17\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 0.9903664, Training accuracy: 0.6525446, Time: 07_05_2022__11:42:37\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 0.9891228, Training accuracy: 0.6526754, Time: 07_05_2022__11:42:58\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 0.9878688, Training accuracy: 0.6535776, Time: 07_05_2022__11:43:18\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 0.9874530, Training accuracy: 0.6537288, Time: 07_05_2022__11:43:39\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 0.9874453, Training accuracy: 0.6535833, Time: 07_05_2022__11:44:00\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 0.9878502, Training accuracy: 0.6533197, Time: 07_05_2022__11:44:20\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 0.9865829, Training accuracy: 0.6535081, Time: 07_05_2022__11:44:41\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 0.9876571, Training accuracy: 0.6530556, Time: 07_05_2022__11:45:02\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 0.9875789, Training accuracy: 0.6528125, Time: 07_05_2022__11:45:22\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 0.9860645, Training accuracy: 0.6527692, Time: 07_05_2022__11:45:43\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 0.9856077, Training accuracy: 0.6532197, Time: 07_05_2022__11:46:03\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 0.9843156, Training accuracy: 0.6536194, Time: 07_05_2022__11:46:24\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 0.9839742, Training accuracy: 0.6536029, Time: 07_05_2022__11:46:45\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 0.9831960, Training accuracy: 0.6541304, Time: 07_05_2022__11:47:05\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 0.9808674, Training accuracy: 0.6553929, Time: 07_05_2022__11:47:26\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 0.9807923, Training accuracy: 0.6554930, Time: 07_05_2022__11:47:47\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 0.9793512, Training accuracy: 0.6559028, Time: 07_05_2022__11:48:07\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 0.9786837, Training accuracy: 0.6563699, Time: 07_05_2022__11:48:28\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 0.9773360, Training accuracy: 0.6569932, Time: 07_05_2022__11:48:48\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 0.9758959, Training accuracy: 0.6576000, Time: 07_05_2022__11:49:09\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 0.9740860, Training accuracy: 0.6585855, Time: 07_05_2022__11:49:30\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 0.9736853, Training accuracy: 0.6590260, Time: 07_05_2022__11:49:50\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 0.9728612, Training accuracy: 0.6591987, Time: 07_05_2022__11:50:11\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 0.9713530, Training accuracy: 0.6597152, Time: 07_05_2022__11:50:32\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 0.9700604, Training accuracy: 0.6601250, Time: 07_05_2022__11:50:52\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 0.9697062, Training accuracy: 0.6602469, Time: 07_05_2022__11:51:13\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 0.9695127, Training accuracy: 0.6603659, Time: 07_05_2022__11:51:34\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 0.9682943, Training accuracy: 0.6609639, Time: 07_05_2022__11:51:54\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 0.9684999, Training accuracy: 0.6607738, Time: 07_05_2022__11:52:15\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 0.9678277, Training accuracy: 0.6610294, Time: 07_05_2022__11:52:35\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 0.9667869, Training accuracy: 0.6613953, Time: 07_05_2022__11:52:56\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 0.9660931, Training accuracy: 0.6617241, Time: 07_05_2022__11:53:17\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 0.9646668, Training accuracy: 0.6619886, Time: 07_05_2022__11:53:37\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 0.9628693, Training accuracy: 0.6627247, Time: 07_05_2022__11:53:58\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 0.9615445, Training accuracy: 0.6630278, Time: 07_05_2022__11:54:19\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 0.9610633, Training accuracy: 0.6634066, Time: 07_05_2022__11:54:39\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 0.9602255, Training accuracy: 0.6638587, Time: 07_05_2022__11:55:00\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 0.9596558, Training accuracy: 0.6638978, Time: 07_05_2022__11:55:20\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 0.9593641, Training accuracy: 0.6640957, Time: 07_05_2022__11:55:41\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 0.9600998, Training accuracy: 0.6637368, Time: 07_05_2022__11:56:02\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 0.9578465, Training accuracy: 0.6646875, Time: 07_05_2022__11:56:22\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 0.9557259, Training accuracy: 0.6655155, Time: 07_05_2022__11:56:43\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 0.9543190, Training accuracy: 0.6661990, Time: 07_05_2022__11:57:04\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 0.9542961, Training accuracy: 0.6662626, Time: 07_05_2022__11:57:24\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 0.9533358, Training accuracy: 0.6666500, Time: 07_05_2022__11:57:45\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 0.9532602, Training accuracy: 0.6668812, Time: 07_05_2022__11:58:05\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 0.9522206, Training accuracy: 0.6672304, Time: 07_05_2022__11:58:26\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 0.9509883, Training accuracy: 0.6675971, Time: 07_05_2022__11:58:47\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 0.9491252, Training accuracy: 0.6681490, Time: 07_05_2022__11:59:07\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 0.9486915, Training accuracy: 0.6684286, Time: 07_05_2022__11:59:28\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 0.9484668, Training accuracy: 0.6686085, Time: 07_05_2022__11:59:49\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 0.9469399, Training accuracy: 0.6689720, Time: 07_05_2022__12:00:09\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 0.9460104, Training accuracy: 0.6693519, Time: 07_05_2022__12:00:30\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 0.9460737, Training accuracy: 0.6694725, Time: 07_05_2022__12:00:51\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 0.9455003, Training accuracy: 0.6696591, Time: 07_05_2022__12:01:11\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 0.9441271, Training accuracy: 0.6703153, Time: 07_05_2022__12:01:32\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 0.9433847, Training accuracy: 0.6704911, Time: 07_05_2022__12:01:52\n","Epoch 3 of 5, Average training loss: 0.9432185, Average training accuracy: 0.6705778, Time: 07_05_2022__12:02:03\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab76070935834008b0c56f9bb8e465be"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.7923691, Validation accuracy: 0.7125000, Time: 07_05_2022__12:02:08 | Loss decreased from 0.9239631 to 0.7983391 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.7626467, Validation accuracy: 0.7175000, Time: 07_05_2022__12:02:15 | Loss decreased from 0.7983391 to 0.7630231 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.7858754, Validation accuracy: 0.7166667, Time: 07_05_2022__12:02:23\n","Step: 400 of 1250, Validation loss: 0.7742531, Validation accuracy: 0.7206250, Time: 07_05_2022__12:02:28\n","Step: 500 of 1250, Validation loss: 0.7842339, Validation accuracy: 0.7180000, Time: 07_05_2022__12:02:33\n","Step: 600 of 1250, Validation loss: 0.7725290, Validation accuracy: 0.7283333, Time: 07_05_2022__12:02:39\n","Step: 700 of 1250, Validation loss: 0.7636593, Validation accuracy: 0.7332143, Time: 07_05_2022__12:02:44 | Loss decreased from 0.7630231 to 0.7620603 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.7529489, Validation accuracy: 0.7350000, Time: 07_05_2022__12:02:51 | Loss decreased from 0.7620603 to 0.7525310 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.7573889, Validation accuracy: 0.7361111, Time: 07_05_2022__12:02:59\n","Step: 1000 of 1250, Validation loss: 0.7561617, Validation accuracy: 0.7335000, Time: 07_05_2022__12:03:04\n","Step: 1100 of 1250, Validation loss: 0.7570013, Validation accuracy: 0.7350000, Time: 07_05_2022__12:03:09\n","Step: 1200 of 1250, Validation loss: 0.7681712, Validation accuracy: 0.7316667, Time: 07_05_2022__12:03:14\n","Average validation loss: 0.7679395, Average validation accuracy: 0.7312000, Time: 07_05_2022__12:03:17\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ec18c0f2aa84e6e85a06c24aee4a6cb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 0.7144593, Training accuracy: 0.7275000, Time: 07_05_2022__12:03:38\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 0.7713732, Training accuracy: 0.7175000, Time: 07_05_2022__12:03:58\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 0.7885976, Training accuracy: 0.7191667, Time: 07_05_2022__12:04:19\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 0.7725976, Training accuracy: 0.7293750, Time: 07_05_2022__12:04:40\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 0.7715033, Training accuracy: 0.7305000, Time: 07_05_2022__12:05:00\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 0.7853013, Training accuracy: 0.7333333, Time: 07_05_2022__12:05:21\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 0.7939019, Training accuracy: 0.7267857, Time: 07_05_2022__12:05:41\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 0.7946408, Training accuracy: 0.7265625, Time: 07_05_2022__12:06:02\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 0.7986615, Training accuracy: 0.7244444, Time: 07_05_2022__12:06:23\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 0.7908865, Training accuracy: 0.7285000, Time: 07_05_2022__12:06:43\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 0.7937747, Training accuracy: 0.7284091, Time: 07_05_2022__12:07:04\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 0.8000020, Training accuracy: 0.7250000, Time: 07_05_2022__12:07:25\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 0.8051113, Training accuracy: 0.7228846, Time: 07_05_2022__12:07:45\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 0.8068661, Training accuracy: 0.7228571, Time: 07_05_2022__12:08:06\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 0.8086624, Training accuracy: 0.7211667, Time: 07_05_2022__12:08:27\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 0.8095058, Training accuracy: 0.7223437, Time: 07_05_2022__12:08:47\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 0.8096499, Training accuracy: 0.7220588, Time: 07_05_2022__12:09:08\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 0.8164234, Training accuracy: 0.7197222, Time: 07_05_2022__12:09:29\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 0.8145846, Training accuracy: 0.7209211, Time: 07_05_2022__12:09:49\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 0.8137914, Training accuracy: 0.7206250, Time: 07_05_2022__12:10:10\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 0.8110946, Training accuracy: 0.7219048, Time: 07_05_2022__12:10:30\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 0.8093537, Training accuracy: 0.7219318, Time: 07_05_2022__12:10:51\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 0.8063749, Training accuracy: 0.7217391, Time: 07_05_2022__12:11:12\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 0.8037478, Training accuracy: 0.7221875, Time: 07_05_2022__12:11:32\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 0.8027652, Training accuracy: 0.7218000, Time: 07_05_2022__12:11:53\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 0.8039895, Training accuracy: 0.7213462, Time: 07_05_2022__12:12:14\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 0.8014647, Training accuracy: 0.7221296, Time: 07_05_2022__12:12:34\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 0.8021500, Training accuracy: 0.7217857, Time: 07_05_2022__12:12:55\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 0.7999403, Training accuracy: 0.7231034, Time: 07_05_2022__12:13:16\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 0.8008191, Training accuracy: 0.7225000, Time: 07_05_2022__12:13:36\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 0.7969049, Training accuracy: 0.7245968, Time: 07_05_2022__12:13:57\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 0.7956243, Training accuracy: 0.7249219, Time: 07_05_2022__12:14:18\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 0.7956293, Training accuracy: 0.7253030, Time: 07_05_2022__12:14:38\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 0.7950967, Training accuracy: 0.7252941, Time: 07_05_2022__12:14:59\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 0.7953716, Training accuracy: 0.7250000, Time: 07_05_2022__12:15:20\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 0.7953142, Training accuracy: 0.7246528, Time: 07_05_2022__12:15:40\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 0.7959751, Training accuracy: 0.7240541, Time: 07_05_2022__12:16:01\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 0.7942892, Training accuracy: 0.7243421, Time: 07_05_2022__12:16:22\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 0.7928221, Training accuracy: 0.7242308, Time: 07_05_2022__12:16:42\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 0.7911100, Training accuracy: 0.7243125, Time: 07_05_2022__12:17:03\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 0.7920597, Training accuracy: 0.7237805, Time: 07_05_2022__12:17:23\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 0.7889603, Training accuracy: 0.7244643, Time: 07_05_2022__12:17:44\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 0.7878245, Training accuracy: 0.7250000, Time: 07_05_2022__12:18:05\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 0.7867537, Training accuracy: 0.7253409, Time: 07_05_2022__12:18:25\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 0.7850410, Training accuracy: 0.7258889, Time: 07_05_2022__12:18:46\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 0.7854658, Training accuracy: 0.7256522, Time: 07_05_2022__12:19:07\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 0.7841951, Training accuracy: 0.7263830, Time: 07_05_2022__12:19:27\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 0.7846308, Training accuracy: 0.7261458, Time: 07_05_2022__12:19:48\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 0.7844677, Training accuracy: 0.7260714, Time: 07_05_2022__12:20:08\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 0.7846156, Training accuracy: 0.7260500, Time: 07_05_2022__12:20:29\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 0.7845013, Training accuracy: 0.7263235, Time: 07_05_2022__12:20:50\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 0.7853419, Training accuracy: 0.7262981, Time: 07_05_2022__12:21:10\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 0.7858359, Training accuracy: 0.7263208, Time: 07_05_2022__12:21:31\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 0.7846743, Training accuracy: 0.7269444, Time: 07_05_2022__12:21:52\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 0.7852785, Training accuracy: 0.7270909, Time: 07_05_2022__12:22:12\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 0.7846527, Training accuracy: 0.7272321, Time: 07_05_2022__12:22:33\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 0.7839921, Training accuracy: 0.7273684, Time: 07_05_2022__12:22:54\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 0.7842839, Training accuracy: 0.7273707, Time: 07_05_2022__12:23:14\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 0.7847069, Training accuracy: 0.7269915, Time: 07_05_2022__12:23:35\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 0.7864191, Training accuracy: 0.7268750, Time: 07_05_2022__12:23:55\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 0.7870293, Training accuracy: 0.7265984, Time: 07_05_2022__12:24:16\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 0.7862502, Training accuracy: 0.7270565, Time: 07_05_2022__12:24:37\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 0.7867656, Training accuracy: 0.7269841, Time: 07_05_2022__12:24:57\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 0.7868767, Training accuracy: 0.7268750, Time: 07_05_2022__12:25:18\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 0.7852091, Training accuracy: 0.7276538, Time: 07_05_2022__12:25:39\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 0.7846151, Training accuracy: 0.7278030, Time: 07_05_2022__12:25:59\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 0.7836952, Training accuracy: 0.7280970, Time: 07_05_2022__12:26:20\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 0.7829509, Training accuracy: 0.7282353, Time: 07_05_2022__12:26:41\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 0.7818664, Training accuracy: 0.7283696, Time: 07_05_2022__12:27:01\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 0.7803941, Training accuracy: 0.7288214, Time: 07_05_2022__12:27:22\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 0.7804427, Training accuracy: 0.7284859, Time: 07_05_2022__12:27:42\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 0.7792039, Training accuracy: 0.7289236, Time: 07_05_2022__12:28:03\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 0.7786213, Training accuracy: 0.7292123, Time: 07_05_2022__12:28:24\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 0.7786947, Training accuracy: 0.7291554, Time: 07_05_2022__12:28:44\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 0.7784448, Training accuracy: 0.7291333, Time: 07_05_2022__12:29:05\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 0.7775889, Training accuracy: 0.7295066, Time: 07_05_2022__12:29:26\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 0.7773215, Training accuracy: 0.7296429, Time: 07_05_2022__12:29:46\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 0.7764945, Training accuracy: 0.7300321, Time: 07_05_2022__12:30:07\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 0.7749373, Training accuracy: 0.7304747, Time: 07_05_2022__12:30:28\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 0.7739722, Training accuracy: 0.7305000, Time: 07_05_2022__12:30:48\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 0.7748726, Training accuracy: 0.7301852, Time: 07_05_2022__12:31:09\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 0.7751565, Training accuracy: 0.7301829, Time: 07_05_2022__12:31:29\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 0.7754064, Training accuracy: 0.7302410, Time: 07_05_2022__12:31:50\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 0.7763163, Training accuracy: 0.7299405, Time: 07_05_2022__12:32:11\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 0.7762113, Training accuracy: 0.7300000, Time: 07_05_2022__12:32:31\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 0.7757080, Training accuracy: 0.7303779, Time: 07_05_2022__12:32:52\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 0.7752858, Training accuracy: 0.7306322, Time: 07_05_2022__12:33:13\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 0.7745222, Training accuracy: 0.7312216, Time: 07_05_2022__12:33:33\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 0.7736101, Training accuracy: 0.7315730, Time: 07_05_2022__12:33:54\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 0.7733898, Training accuracy: 0.7316389, Time: 07_05_2022__12:34:14\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 0.7728689, Training accuracy: 0.7318681, Time: 07_05_2022__12:34:35\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 0.7723419, Training accuracy: 0.7320109, Time: 07_05_2022__12:34:56\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 0.7720741, Training accuracy: 0.7320968, Time: 07_05_2022__12:35:16\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 0.7722660, Training accuracy: 0.7323138, Time: 07_05_2022__12:35:37\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 0.7739215, Training accuracy: 0.7318684, Time: 07_05_2022__12:35:58\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 0.7726932, Training accuracy: 0.7322396, Time: 07_05_2022__12:36:18\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 0.7709227, Training accuracy: 0.7330155, Time: 07_05_2022__12:36:39\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 0.7698099, Training accuracy: 0.7333673, Time: 07_05_2022__12:37:00\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 0.7699778, Training accuracy: 0.7333838, Time: 07_05_2022__12:37:20\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 0.7695372, Training accuracy: 0.7337500, Time: 07_05_2022__12:37:41\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 0.7696362, Training accuracy: 0.7333911, Time: 07_05_2022__12:38:01\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 0.7684763, Training accuracy: 0.7338235, Time: 07_05_2022__12:38:22\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 0.7679848, Training accuracy: 0.7340777, Time: 07_05_2022__12:38:43\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 0.7665590, Training accuracy: 0.7343510, Time: 07_05_2022__12:39:03\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 0.7660878, Training accuracy: 0.7347381, Time: 07_05_2022__12:39:24\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 0.7663788, Training accuracy: 0.7347170, Time: 07_05_2022__12:39:45\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 0.7656751, Training accuracy: 0.7349533, Time: 07_05_2022__12:40:05\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 0.7649541, Training accuracy: 0.7352546, Time: 07_05_2022__12:40:26\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 0.7649193, Training accuracy: 0.7353440, Time: 07_05_2022__12:40:46\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 0.7647106, Training accuracy: 0.7354545, Time: 07_05_2022__12:41:07\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 0.7640407, Training accuracy: 0.7355631, Time: 07_05_2022__12:41:28\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 0.7636345, Training accuracy: 0.7355580, Time: 07_05_2022__12:41:48\n","Epoch 4 of 5, Average training loss: 0.7636696, Average training accuracy: 0.7354889, Time: 07_05_2022__12:41:59\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42f8e6c0aa4c4e3a94e804722788dc90"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.6740387, Validation accuracy: 0.7700000, Time: 07_05_2022__12:42:04 | Loss decreased from 0.7525310 to 0.6797044 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.6783991, Validation accuracy: 0.7537500, Time: 07_05_2022__12:42:12 | Loss decreased from 0.6797044 to 0.6772249 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.7018088, Validation accuracy: 0.7525000, Time: 07_05_2022__12:42:20\n","Step: 400 of 1250, Validation loss: 0.6942062, Validation accuracy: 0.7556250, Time: 07_05_2022__12:42:25\n","Step: 500 of 1250, Validation loss: 0.6963720, Validation accuracy: 0.7595000, Time: 07_05_2022__12:42:30\n","Step: 600 of 1250, Validation loss: 0.6894553, Validation accuracy: 0.7620833, Time: 07_05_2022__12:42:35\n","Step: 700 of 1250, Validation loss: 0.6844874, Validation accuracy: 0.7632143, Time: 07_05_2022__12:42:40\n","Step: 800 of 1250, Validation loss: 0.6693509, Validation accuracy: 0.7656250, Time: 07_05_2022__12:42:45 | Loss decreased from 0.6772249 to 0.6688440 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.6699885, Validation accuracy: 0.7658333, Time: 07_05_2022__12:42:53\n","Step: 1000 of 1250, Validation loss: 0.6687031, Validation accuracy: 0.7652500, Time: 07_05_2022__12:42:58 | Loss decreased from 0.6688440 to 0.6684352 .... Saving the model\n","Step: 1100 of 1250, Validation loss: 0.6717007, Validation accuracy: 0.7661364, Time: 07_05_2022__12:43:06\n","Step: 1200 of 1250, Validation loss: 0.6842030, Validation accuracy: 0.7604167, Time: 07_05_2022__12:43:11\n","Average validation loss: 0.6841615, Average validation accuracy: 0.7608000, Time: 07_05_2022__12:43:14\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a580f946fdc443709e7594c4d878f7c9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 0.5694286, Training accuracy: 0.8075000, Time: 07_05_2022__12:43:34\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 0.6204840, Training accuracy: 0.7825000, Time: 07_05_2022__12:43:55\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 0.6397299, Training accuracy: 0.7841667, Time: 07_05_2022__12:44:16\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 0.6260575, Training accuracy: 0.7893750, Time: 07_05_2022__12:44:36\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 0.6255531, Training accuracy: 0.7865000, Time: 07_05_2022__12:44:57\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 0.6433304, Training accuracy: 0.7820833, Time: 07_05_2022__12:45:18\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 0.6579036, Training accuracy: 0.7778571, Time: 07_05_2022__12:45:38\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 0.6521074, Training accuracy: 0.7803125, Time: 07_05_2022__12:45:59\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 0.6597767, Training accuracy: 0.7747222, Time: 07_05_2022__12:46:20\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 0.6578100, Training accuracy: 0.7750000, Time: 07_05_2022__12:46:40\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 0.6655811, Training accuracy: 0.7709091, Time: 07_05_2022__12:47:01\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 0.6704244, Training accuracy: 0.7685417, Time: 07_05_2022__12:47:21\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 0.6755505, Training accuracy: 0.7669231, Time: 07_05_2022__12:47:42\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 0.6798553, Training accuracy: 0.7666071, Time: 07_05_2022__12:48:03\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 0.6837414, Training accuracy: 0.7658333, Time: 07_05_2022__12:48:23\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 0.6832837, Training accuracy: 0.7679687, Time: 07_05_2022__12:48:44\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 0.6846700, Training accuracy: 0.7672059, Time: 07_05_2022__12:49:05\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 0.6883743, Training accuracy: 0.7652778, Time: 07_05_2022__12:49:25\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 0.6872141, Training accuracy: 0.7660526, Time: 07_05_2022__12:49:46\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 0.6874486, Training accuracy: 0.7666250, Time: 07_05_2022__12:50:07\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 0.6842157, Training accuracy: 0.7673810, Time: 07_05_2022__12:50:27\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 0.6832153, Training accuracy: 0.7669318, Time: 07_05_2022__12:50:48\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 0.6794608, Training accuracy: 0.7681522, Time: 07_05_2022__12:51:09\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 0.6766840, Training accuracy: 0.7682292, Time: 07_05_2022__12:51:29\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 0.6755597, Training accuracy: 0.7689000, Time: 07_05_2022__12:51:50\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 0.6743043, Training accuracy: 0.7696154, Time: 07_05_2022__12:52:11\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 0.6732771, Training accuracy: 0.7694444, Time: 07_05_2022__12:52:31\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 0.6741875, Training accuracy: 0.7692857, Time: 07_05_2022__12:52:52\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 0.6729456, Training accuracy: 0.7696552, Time: 07_05_2022__12:53:12\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 0.6728823, Training accuracy: 0.7699167, Time: 07_05_2022__12:53:33\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 0.6712270, Training accuracy: 0.7706452, Time: 07_05_2022__12:53:54\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 0.6682376, Training accuracy: 0.7712500, Time: 07_05_2022__12:54:14\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 0.6691018, Training accuracy: 0.7707576, Time: 07_05_2022__12:54:35\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 0.6681178, Training accuracy: 0.7714706, Time: 07_05_2022__12:54:56\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 0.6673034, Training accuracy: 0.7712857, Time: 07_05_2022__12:55:16\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 0.6681433, Training accuracy: 0.7710417, Time: 07_05_2022__12:55:37\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 0.6698354, Training accuracy: 0.7706081, Time: 07_05_2022__12:55:58\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 0.6679040, Training accuracy: 0.7711842, Time: 07_05_2022__12:56:18\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 0.6677037, Training accuracy: 0.7710897, Time: 07_05_2022__12:56:39\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 0.6654573, Training accuracy: 0.7721250, Time: 07_05_2022__12:57:00\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 0.6668574, Training accuracy: 0.7715244, Time: 07_05_2022__12:57:20\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 0.6657849, Training accuracy: 0.7722024, Time: 07_05_2022__12:57:41\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 0.6649869, Training accuracy: 0.7723256, Time: 07_05_2022__12:58:02\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 0.6638506, Training accuracy: 0.7727273, Time: 07_05_2022__12:58:22\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 0.6635333, Training accuracy: 0.7728889, Time: 07_05_2022__12:58:43\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 0.6650294, Training accuracy: 0.7725543, Time: 07_05_2022__12:59:03\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 0.6645122, Training accuracy: 0.7728723, Time: 07_05_2022__12:59:24\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 0.6647896, Training accuracy: 0.7726042, Time: 07_05_2022__12:59:45\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 0.6639818, Training accuracy: 0.7725000, Time: 07_05_2022__13:00:05\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 0.6638987, Training accuracy: 0.7727500, Time: 07_05_2022__13:00:26\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 0.6632303, Training accuracy: 0.7730882, Time: 07_05_2022__13:00:47\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 0.6629952, Training accuracy: 0.7729327, Time: 07_05_2022__13:01:07\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 0.6632217, Training accuracy: 0.7726415, Time: 07_05_2022__13:01:28\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 0.6622006, Training accuracy: 0.7726852, Time: 07_05_2022__13:01:49\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 0.6634638, Training accuracy: 0.7721818, Time: 07_05_2022__13:02:09\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 0.6629994, Training accuracy: 0.7725000, Time: 07_05_2022__13:02:30\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 0.6628196, Training accuracy: 0.7723246, Time: 07_05_2022__13:02:51\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 0.6625017, Training accuracy: 0.7724569, Time: 07_05_2022__13:03:11\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 0.6630010, Training accuracy: 0.7727119, Time: 07_05_2022__13:03:32\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 0.6639086, Training accuracy: 0.7723333, Time: 07_05_2022__13:03:53\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 0.6637345, Training accuracy: 0.7725410, Time: 07_05_2022__13:04:13\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 0.6633772, Training accuracy: 0.7728226, Time: 07_05_2022__13:04:34\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 0.6632926, Training accuracy: 0.7726984, Time: 07_05_2022__13:04:55\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 0.6624452, Training accuracy: 0.7728906, Time: 07_05_2022__13:05:15\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 0.6615018, Training accuracy: 0.7730385, Time: 07_05_2022__13:05:36\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 0.6611953, Training accuracy: 0.7731818, Time: 07_05_2022__13:05:56\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 0.6602578, Training accuracy: 0.7736567, Time: 07_05_2022__13:06:17\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 0.6603780, Training accuracy: 0.7736029, Time: 07_05_2022__13:06:38\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 0.6588570, Training accuracy: 0.7741667, Time: 07_05_2022__13:06:58\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 0.6577004, Training accuracy: 0.7743929, Time: 07_05_2022__13:07:19\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 0.6577789, Training accuracy: 0.7743310, Time: 07_05_2022__13:07:40\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 0.6565332, Training accuracy: 0.7748611, Time: 07_05_2022__13:08:00\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 0.6555377, Training accuracy: 0.7750685, Time: 07_05_2022__13:08:21\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 0.6551564, Training accuracy: 0.7750000, Time: 07_05_2022__13:08:42\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 0.6543022, Training accuracy: 0.7749667, Time: 07_05_2022__13:09:02\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 0.6531105, Training accuracy: 0.7752303, Time: 07_05_2022__13:09:23\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 0.6530397, Training accuracy: 0.7753247, Time: 07_05_2022__13:09:44\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 0.6527078, Training accuracy: 0.7752885, Time: 07_05_2022__13:10:04\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 0.6514636, Training accuracy: 0.7759177, Time: 07_05_2022__13:10:25\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 0.6509061, Training accuracy: 0.7760000, Time: 07_05_2022__13:10:45\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 0.6512127, Training accuracy: 0.7756481, Time: 07_05_2022__13:11:06\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 0.6508907, Training accuracy: 0.7757622, Time: 07_05_2022__13:11:27\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 0.6505922, Training accuracy: 0.7758133, Time: 07_05_2022__13:11:47\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 0.6515064, Training accuracy: 0.7754167, Time: 07_05_2022__13:12:08\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 0.6517440, Training accuracy: 0.7752647, Time: 07_05_2022__13:12:29\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 0.6511526, Training accuracy: 0.7755523, Time: 07_05_2022__13:12:49\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 0.6514453, Training accuracy: 0.7754310, Time: 07_05_2022__13:13:10\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 0.6505685, Training accuracy: 0.7759091, Time: 07_05_2022__13:13:30\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 0.6503009, Training accuracy: 0.7759270, Time: 07_05_2022__13:13:51\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 0.6501196, Training accuracy: 0.7760833, Time: 07_05_2022__13:14:12\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 0.6496801, Training accuracy: 0.7762637, Time: 07_05_2022__13:14:32\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 0.6494156, Training accuracy: 0.7763043, Time: 07_05_2022__13:14:53\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 0.6493987, Training accuracy: 0.7763710, Time: 07_05_2022__13:15:14\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 0.6487561, Training accuracy: 0.7765691, Time: 07_05_2022__13:15:34\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 0.6494318, Training accuracy: 0.7764474, Time: 07_05_2022__13:15:55\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 0.6486630, Training accuracy: 0.7767448, Time: 07_05_2022__13:16:16\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 0.6471438, Training accuracy: 0.7772938, Time: 07_05_2022__13:16:36\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 0.6460681, Training accuracy: 0.7777551, Time: 07_05_2022__13:16:57\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 0.6467370, Training accuracy: 0.7774242, Time: 07_05_2022__13:17:17\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 0.6460116, Training accuracy: 0.7778250, Time: 07_05_2022__13:17:38\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 0.6463509, Training accuracy: 0.7775990, Time: 07_05_2022__13:17:59\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 0.6461729, Training accuracy: 0.7775490, Time: 07_05_2022__13:18:19\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 0.6454832, Training accuracy: 0.7777913, Time: 07_05_2022__13:18:40\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 0.6447465, Training accuracy: 0.7780288, Time: 07_05_2022__13:19:01\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 0.6442383, Training accuracy: 0.7781190, Time: 07_05_2022__13:19:21\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 0.6449282, Training accuracy: 0.7779009, Time: 07_05_2022__13:19:42\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 0.6438156, Training accuracy: 0.7782477, Time: 07_05_2022__13:20:03\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 0.6436141, Training accuracy: 0.7784259, Time: 07_05_2022__13:20:23\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 0.6439526, Training accuracy: 0.7783486, Time: 07_05_2022__13:20:44\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 0.6437060, Training accuracy: 0.7784091, Time: 07_05_2022__13:21:05\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 0.6432283, Training accuracy: 0.7784910, Time: 07_05_2022__13:21:25\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 0.6428743, Training accuracy: 0.7786161, Time: 07_05_2022__13:21:46\n","Epoch 5 of 5, Average training loss: 0.6429325, Average training accuracy: 0.7785556, Time: 07_05_2022__13:21:56\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e803f7144fa4786b9079bf276fb8e71"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.6897917, Validation accuracy: 0.7725000, Time: 07_05_2022__13:22:01\n","Step: 200 of 1250, Validation loss: 0.6786069, Validation accuracy: 0.7662500, Time: 07_05_2022__13:22:06\n","Step: 300 of 1250, Validation loss: 0.6938968, Validation accuracy: 0.7700000, Time: 07_05_2022__13:22:12\n","Step: 400 of 1250, Validation loss: 0.6806232, Validation accuracy: 0.7781250, Time: 07_05_2022__13:22:17\n","Step: 500 of 1250, Validation loss: 0.6831927, Validation accuracy: 0.7775000, Time: 07_05_2022__13:22:22\n","Step: 600 of 1250, Validation loss: 0.6822744, Validation accuracy: 0.7775000, Time: 07_05_2022__13:22:27\n","Step: 700 of 1250, Validation loss: 0.6742223, Validation accuracy: 0.7796429, Time: 07_05_2022__13:22:32\n","Step: 800 of 1250, Validation loss: 0.6611425, Validation accuracy: 0.7834375, Time: 07_05_2022__13:22:37 | Loss decreased from 0.6684352 to 0.6610726 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.6600482, Validation accuracy: 0.7836111, Time: 07_05_2022__13:22:45 | Loss decreased from 0.6610726 to 0.6599666 .... Saving the model\n","Step: 1000 of 1250, Validation loss: 0.6624348, Validation accuracy: 0.7810000, Time: 07_05_2022__13:22:52\n","Step: 1100 of 1250, Validation loss: 0.6663707, Validation accuracy: 0.7806818, Time: 07_05_2022__13:22:58\n","Step: 1200 of 1250, Validation loss: 0.6756598, Validation accuracy: 0.7758333, Time: 07_05_2022__13:23:03\n","Average validation loss: 0.6732152, Average validation accuracy: 0.7766000, Time: 07_05_2022__13:23:06\n","###################### Testing vgg19_batch_norm SGD, lr_0.01, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f902b17ae2d948818d03e25e9602fb81"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.8025000, Time: 07_05_2022__13:23:19\n","Step: 200 of 2500, Test accuracy: 0.7850000, Time: 07_05_2022__13:23:24\n","Step: 300 of 2500, Test accuracy: 0.7825000, Time: 07_05_2022__13:23:29\n","Step: 400 of 2500, Test accuracy: 0.7718750, Time: 07_05_2022__13:23:34\n","Step: 500 of 2500, Test accuracy: 0.7635000, Time: 07_05_2022__13:23:39\n","Step: 600 of 2500, Test accuracy: 0.7587500, Time: 07_05_2022__13:23:45\n","Step: 700 of 2500, Test accuracy: 0.7585714, Time: 07_05_2022__13:23:50\n","Step: 800 of 2500, Test accuracy: 0.7640625, Time: 07_05_2022__13:23:55\n","Step: 900 of 2500, Test accuracy: 0.7633333, Time: 07_05_2022__13:24:00\n","Step: 1000 of 2500, Test accuracy: 0.7627500, Time: 07_05_2022__13:24:05\n","Step: 1100 of 2500, Test accuracy: 0.7672727, Time: 07_05_2022__13:24:10\n","Step: 1200 of 2500, Test accuracy: 0.7702083, Time: 07_05_2022__13:24:15\n","Step: 1300 of 2500, Test accuracy: 0.7717308, Time: 07_05_2022__13:24:20\n","Step: 1400 of 2500, Test accuracy: 0.7721429, Time: 07_05_2022__13:24:26\n","Step: 1500 of 2500, Test accuracy: 0.7718333, Time: 07_05_2022__13:24:31\n","Step: 1600 of 2500, Test accuracy: 0.7709375, Time: 07_05_2022__13:24:36\n","Step: 1700 of 2500, Test accuracy: 0.7702941, Time: 07_05_2022__13:24:41\n","Step: 1800 of 2500, Test accuracy: 0.7687500, Time: 07_05_2022__13:24:46\n","Step: 1900 of 2500, Test accuracy: 0.7697368, Time: 07_05_2022__13:24:51\n","Step: 2000 of 2500, Test accuracy: 0.7693750, Time: 07_05_2022__13:24:56\n","Step: 2100 of 2500, Test accuracy: 0.7689286, Time: 07_05_2022__13:25:01\n","Step: 2200 of 2500, Test accuracy: 0.7675000, Time: 07_05_2022__13:25:07\n","Step: 2300 of 2500, Test accuracy: 0.7685870, Time: 07_05_2022__13:25:12\n","Step: 2400 of 2500, Test accuracy: 0.7688542, Time: 07_05_2022__13:25:17\n","Step: 2500 of 2500, Test accuracy: 0.7683000, Time: 07_05_2022__13:25:22\n","Average testing accuracy: 0.7683000, Time: 07_05_2022__13:25:22\n","###################### Training vgg19_batch_norm SGD, lr_0.01, momentum_0.6 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92063a0fd32844899ded29d36b10050e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 3.6717897, Training accuracy: 0.0950000, Time: 07_05_2022__13:25:45\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 3.0545113, Training accuracy: 0.1150000, Time: 07_05_2022__13:26:05\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 2.8336945, Training accuracy: 0.1133333, Time: 07_05_2022__13:26:26\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 2.7136169, Training accuracy: 0.1168750, Time: 07_05_2022__13:26:47\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 2.6291074, Training accuracy: 0.1250000, Time: 07_05_2022__13:27:07\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 2.5735533, Training accuracy: 0.1254167, Time: 07_05_2022__13:27:28\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.5359332, Training accuracy: 0.1239286, Time: 07_05_2022__13:27:48\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.5074321, Training accuracy: 0.1259375, Time: 07_05_2022__13:28:09\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.4848294, Training accuracy: 0.1277778, Time: 07_05_2022__13:28:29\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.4650715, Training accuracy: 0.1272500, Time: 07_05_2022__13:28:50\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.4483403, Training accuracy: 0.1272727, Time: 07_05_2022__13:29:11\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.4342214, Training accuracy: 0.1283333, Time: 07_05_2022__13:29:31\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.4225494, Training accuracy: 0.1301923, Time: 07_05_2022__13:29:52\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.4114514, Training accuracy: 0.1291071, Time: 07_05_2022__13:30:12\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.4022361, Training accuracy: 0.1296667, Time: 07_05_2022__13:30:33\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.3936503, Training accuracy: 0.1284375, Time: 07_05_2022__13:30:54\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.3862213, Training accuracy: 0.1286765, Time: 07_05_2022__13:31:14\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.3789255, Training accuracy: 0.1297222, Time: 07_05_2022__13:31:35\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.3704150, Training accuracy: 0.1339474, Time: 07_05_2022__13:31:55\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.3639527, Training accuracy: 0.1343750, Time: 07_05_2022__13:32:16\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.3543365, Training accuracy: 0.1360714, Time: 07_05_2022__13:32:36\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.3482074, Training accuracy: 0.1376136, Time: 07_05_2022__13:32:57\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.3407073, Training accuracy: 0.1392391, Time: 07_05_2022__13:33:18\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.3329491, Training accuracy: 0.1415625, Time: 07_05_2022__13:33:38\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.3260976, Training accuracy: 0.1444000, Time: 07_05_2022__13:33:59\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.3191351, Training accuracy: 0.1475000, Time: 07_05_2022__13:34:19\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.3123094, Training accuracy: 0.1509259, Time: 07_05_2022__13:34:40\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.3069478, Training accuracy: 0.1521429, Time: 07_05_2022__13:35:00\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.3004902, Training accuracy: 0.1546552, Time: 07_05_2022__13:35:21\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.2948992, Training accuracy: 0.1560833, Time: 07_05_2022__13:35:41\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.2866507, Training accuracy: 0.1583871, Time: 07_05_2022__13:36:02\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.2799603, Training accuracy: 0.1613281, Time: 07_05_2022__13:36:23\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.2745111, Training accuracy: 0.1634091, Time: 07_05_2022__13:36:43\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.2686906, Training accuracy: 0.1649265, Time: 07_05_2022__13:37:04\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.2628253, Training accuracy: 0.1667857, Time: 07_05_2022__13:37:24\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.2581252, Training accuracy: 0.1681944, Time: 07_05_2022__13:37:45\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.2547647, Training accuracy: 0.1690541, Time: 07_05_2022__13:38:06\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.2492012, Training accuracy: 0.1715132, Time: 07_05_2022__13:38:26\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.2444759, Training accuracy: 0.1726923, Time: 07_05_2022__13:38:47\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.2386700, Training accuracy: 0.1750000, Time: 07_05_2022__13:39:07\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.2345236, Training accuracy: 0.1764634, Time: 07_05_2022__13:39:28\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.2282053, Training accuracy: 0.1791667, Time: 07_05_2022__13:39:48\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.2230287, Training accuracy: 0.1810465, Time: 07_05_2022__13:40:09\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.2171171, Training accuracy: 0.1835795, Time: 07_05_2022__13:40:30\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.2114885, Training accuracy: 0.1853333, Time: 07_05_2022__13:40:50\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.2064320, Training accuracy: 0.1873370, Time: 07_05_2022__13:41:11\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.2020497, Training accuracy: 0.1892553, Time: 07_05_2022__13:41:31\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 2.1993209, Training accuracy: 0.1908333, Time: 07_05_2022__13:41:52\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 2.1945226, Training accuracy: 0.1928571, Time: 07_05_2022__13:42:12\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 2.1923300, Training accuracy: 0.1936000, Time: 07_05_2022__13:42:33\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 2.1869037, Training accuracy: 0.1956373, Time: 07_05_2022__13:42:54\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 2.1831841, Training accuracy: 0.1971154, Time: 07_05_2022__13:43:14\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 2.1782226, Training accuracy: 0.1988208, Time: 07_05_2022__13:43:35\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 2.1739660, Training accuracy: 0.1998148, Time: 07_05_2022__13:43:55\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 2.1686929, Training accuracy: 0.2020000, Time: 07_05_2022__13:44:16\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 2.1652877, Training accuracy: 0.2037500, Time: 07_05_2022__13:44:37\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 2.1605467, Training accuracy: 0.2051754, Time: 07_05_2022__13:44:57\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 2.1569438, Training accuracy: 0.2066379, Time: 07_05_2022__13:45:18\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 2.1528845, Training accuracy: 0.2079661, Time: 07_05_2022__13:45:38\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 2.1483663, Training accuracy: 0.2100417, Time: 07_05_2022__13:45:59\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 2.1458212, Training accuracy: 0.2114754, Time: 07_05_2022__13:46:19\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 2.1414013, Training accuracy: 0.2129435, Time: 07_05_2022__13:46:40\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 2.1377685, Training accuracy: 0.2140079, Time: 07_05_2022__13:47:00\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 2.1341828, Training accuracy: 0.2151562, Time: 07_05_2022__13:47:21\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 2.1291947, Training accuracy: 0.2167692, Time: 07_05_2022__13:47:42\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 2.1257403, Training accuracy: 0.2178409, Time: 07_05_2022__13:48:02\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 2.1213357, Training accuracy: 0.2194030, Time: 07_05_2022__13:48:23\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 2.1177273, Training accuracy: 0.2205882, Time: 07_05_2022__13:48:43\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 2.1139694, Training accuracy: 0.2223551, Time: 07_05_2022__13:49:04\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 2.1100534, Training accuracy: 0.2238214, Time: 07_05_2022__13:49:25\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 2.1063552, Training accuracy: 0.2252465, Time: 07_05_2022__13:49:45\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 2.1026394, Training accuracy: 0.2263889, Time: 07_05_2022__13:50:06\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 2.0986643, Training accuracy: 0.2280822, Time: 07_05_2022__13:50:26\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 2.0960491, Training accuracy: 0.2291892, Time: 07_05_2022__13:50:47\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 2.0932457, Training accuracy: 0.2299000, Time: 07_05_2022__13:51:07\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 2.0899311, Training accuracy: 0.2317105, Time: 07_05_2022__13:51:28\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 2.0869073, Training accuracy: 0.2327597, Time: 07_05_2022__13:51:48\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 2.0826474, Training accuracy: 0.2345513, Time: 07_05_2022__13:52:09\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 2.0790761, Training accuracy: 0.2357911, Time: 07_05_2022__13:52:29\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 2.0761599, Training accuracy: 0.2366250, Time: 07_05_2022__13:52:50\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 2.0728712, Training accuracy: 0.2375926, Time: 07_05_2022__13:53:11\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 2.0698159, Training accuracy: 0.2390549, Time: 07_05_2022__13:53:31\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 2.0663951, Training accuracy: 0.2402108, Time: 07_05_2022__13:53:52\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 2.0633865, Training accuracy: 0.2414881, Time: 07_05_2022__13:54:12\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 2.0597729, Training accuracy: 0.2430588, Time: 07_05_2022__13:54:33\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 2.0557639, Training accuracy: 0.2444477, Time: 07_05_2022__13:54:54\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 2.0532787, Training accuracy: 0.2456609, Time: 07_05_2022__13:55:14\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 2.0490710, Training accuracy: 0.2473864, Time: 07_05_2022__13:55:35\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 2.0458993, Training accuracy: 0.2485955, Time: 07_05_2022__13:55:55\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 2.0428527, Training accuracy: 0.2497500, Time: 07_05_2022__13:56:16\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 2.0396464, Training accuracy: 0.2508242, Time: 07_05_2022__13:56:37\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 2.0365845, Training accuracy: 0.2522554, Time: 07_05_2022__13:56:57\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 2.0328024, Training accuracy: 0.2533333, Time: 07_05_2022__13:57:18\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 2.0304240, Training accuracy: 0.2541223, Time: 07_05_2022__13:57:38\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 2.0284275, Training accuracy: 0.2550789, Time: 07_05_2022__13:57:59\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 2.0250542, Training accuracy: 0.2564063, Time: 07_05_2022__13:58:19\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 2.0209619, Training accuracy: 0.2577062, Time: 07_05_2022__13:58:40\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 2.0177006, Training accuracy: 0.2590816, Time: 07_05_2022__13:59:01\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 2.0149978, Training accuracy: 0.2600758, Time: 07_05_2022__13:59:21\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 2.0123276, Training accuracy: 0.2611250, Time: 07_05_2022__13:59:42\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 2.0100009, Training accuracy: 0.2619554, Time: 07_05_2022__14:00:02\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 2.0063748, Training accuracy: 0.2630637, Time: 07_05_2022__14:00:23\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 2.0029814, Training accuracy: 0.2643932, Time: 07_05_2022__14:00:44\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 1.9999213, Training accuracy: 0.2656010, Time: 07_05_2022__14:01:04\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 1.9975654, Training accuracy: 0.2665476, Time: 07_05_2022__14:01:25\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 1.9948601, Training accuracy: 0.2676179, Time: 07_05_2022__14:01:45\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 1.9918991, Training accuracy: 0.2685748, Time: 07_05_2022__14:02:06\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 1.9891102, Training accuracy: 0.2697222, Time: 07_05_2022__14:02:27\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 1.9871650, Training accuracy: 0.2703440, Time: 07_05_2022__14:02:47\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 1.9847669, Training accuracy: 0.2711591, Time: 07_05_2022__14:03:08\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 1.9811687, Training accuracy: 0.2723423, Time: 07_05_2022__14:03:28\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 1.9787273, Training accuracy: 0.2729464, Time: 07_05_2022__14:03:49\n","Epoch 1 of 5, Average training loss: 1.9778522, Average training accuracy: 0.2732667, Time: 07_05_2022__14:03:59\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8763dc389884a2baa867712da03bca9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.5645375, Validation accuracy: 0.4275000, Time: 07_05_2022__14:04:04 | Loss decreased from inf to 1.5624501 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.5546621, Validation accuracy: 0.4275000, Time: 07_05_2022__14:04:12 | Loss decreased from 1.5624501 to 1.5569202 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.5682002, Validation accuracy: 0.4150000, Time: 07_05_2022__14:04:19\n","Step: 400 of 1250, Validation loss: 1.5701949, Validation accuracy: 0.4143750, Time: 07_05_2022__14:04:25\n","Step: 500 of 1250, Validation loss: 1.5672463, Validation accuracy: 0.4155000, Time: 07_05_2022__14:04:30\n","Step: 600 of 1250, Validation loss: 1.5664483, Validation accuracy: 0.4150000, Time: 07_05_2022__14:04:35\n","Step: 700 of 1250, Validation loss: 1.5676195, Validation accuracy: 0.4150000, Time: 07_05_2022__14:04:40\n","Step: 800 of 1250, Validation loss: 1.5654964, Validation accuracy: 0.4159375, Time: 07_05_2022__14:04:45\n","Step: 900 of 1250, Validation loss: 1.5666301, Validation accuracy: 0.4166667, Time: 07_05_2022__14:04:50\n","Step: 1000 of 1250, Validation loss: 1.5716736, Validation accuracy: 0.4135000, Time: 07_05_2022__14:04:55\n","Step: 1100 of 1250, Validation loss: 1.5757025, Validation accuracy: 0.4131818, Time: 07_05_2022__14:05:01\n","Step: 1200 of 1250, Validation loss: 1.5727633, Validation accuracy: 0.4135417, Time: 07_05_2022__14:05:06\n","Average validation loss: 1.5725235, Average validation accuracy: 0.4118000, Time: 07_05_2022__14:05:08\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1e276799585476bb41ecebf66d3a04a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.5786554, Training accuracy: 0.4350000, Time: 07_05_2022__14:05:29\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.6105930, Training accuracy: 0.4150000, Time: 07_05_2022__14:05:49\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.6488711, Training accuracy: 0.3891667, Time: 07_05_2022__14:06:10\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.6373633, Training accuracy: 0.3856250, Time: 07_05_2022__14:06:31\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.6377143, Training accuracy: 0.3885000, Time: 07_05_2022__14:06:51\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.6324054, Training accuracy: 0.3904167, Time: 07_05_2022__14:07:12\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.6358841, Training accuracy: 0.3903571, Time: 07_05_2022__14:07:33\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.6327501, Training accuracy: 0.3896875, Time: 07_05_2022__14:07:53\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.6348372, Training accuracy: 0.3947222, Time: 07_05_2022__14:08:14\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.6310177, Training accuracy: 0.3997500, Time: 07_05_2022__14:08:35\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.6268653, Training accuracy: 0.4022727, Time: 07_05_2022__14:08:55\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.6265374, Training accuracy: 0.4014583, Time: 07_05_2022__14:09:16\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.6266915, Training accuracy: 0.4030769, Time: 07_05_2022__14:09:36\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.6216883, Training accuracy: 0.4041071, Time: 07_05_2022__14:09:57\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.6211412, Training accuracy: 0.4023333, Time: 07_05_2022__14:10:18\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.6212814, Training accuracy: 0.4004687, Time: 07_05_2022__14:10:38\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.6229271, Training accuracy: 0.4008824, Time: 07_05_2022__14:10:59\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.6212306, Training accuracy: 0.4013889, Time: 07_05_2022__14:11:20\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.6165827, Training accuracy: 0.4031579, Time: 07_05_2022__14:11:40\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.6144707, Training accuracy: 0.4042500, Time: 07_05_2022__14:12:01\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.6122726, Training accuracy: 0.4040476, Time: 07_05_2022__14:12:21\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.6125016, Training accuracy: 0.4035227, Time: 07_05_2022__14:12:42\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.6113866, Training accuracy: 0.4044565, Time: 07_05_2022__14:13:03\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.6074741, Training accuracy: 0.4054167, Time: 07_05_2022__14:13:23\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.6032396, Training accuracy: 0.4064000, Time: 07_05_2022__14:13:44\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.6011346, Training accuracy: 0.4086538, Time: 07_05_2022__14:14:04\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.5962227, Training accuracy: 0.4107407, Time: 07_05_2022__14:14:25\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.5950180, Training accuracy: 0.4120536, Time: 07_05_2022__14:14:46\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.5924988, Training accuracy: 0.4132759, Time: 07_05_2022__14:15:06\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.5912271, Training accuracy: 0.4130000, Time: 07_05_2022__14:15:27\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.5860711, Training accuracy: 0.4147581, Time: 07_05_2022__14:15:48\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.5833347, Training accuracy: 0.4156250, Time: 07_05_2022__14:16:08\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.5826407, Training accuracy: 0.4162879, Time: 07_05_2022__14:16:29\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.5808414, Training accuracy: 0.4166176, Time: 07_05_2022__14:16:49\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.5777523, Training accuracy: 0.4182143, Time: 07_05_2022__14:17:10\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.5768986, Training accuracy: 0.4186111, Time: 07_05_2022__14:17:31\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.5758417, Training accuracy: 0.4189865, Time: 07_05_2022__14:17:51\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.5742207, Training accuracy: 0.4198026, Time: 07_05_2022__14:18:12\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.5716054, Training accuracy: 0.4205128, Time: 07_05_2022__14:18:33\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.5690999, Training accuracy: 0.4218750, Time: 07_05_2022__14:18:53\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.5684991, Training accuracy: 0.4233537, Time: 07_05_2022__14:19:14\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.5633116, Training accuracy: 0.4254167, Time: 07_05_2022__14:19:35\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.5621035, Training accuracy: 0.4259884, Time: 07_05_2022__14:19:55\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.5586683, Training accuracy: 0.4267614, Time: 07_05_2022__14:20:16\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.5556451, Training accuracy: 0.4280556, Time: 07_05_2022__14:20:37\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.5535866, Training accuracy: 0.4292935, Time: 07_05_2022__14:20:57\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.5520290, Training accuracy: 0.4302660, Time: 07_05_2022__14:21:18\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.5506805, Training accuracy: 0.4309375, Time: 07_05_2022__14:21:38\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.5490735, Training accuracy: 0.4306633, Time: 07_05_2022__14:21:59\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.5470601, Training accuracy: 0.4320500, Time: 07_05_2022__14:22:20\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.5447888, Training accuracy: 0.4337745, Time: 07_05_2022__14:22:40\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.5443486, Training accuracy: 0.4347115, Time: 07_05_2022__14:23:01\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.5428748, Training accuracy: 0.4351887, Time: 07_05_2022__14:23:22\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.5409047, Training accuracy: 0.4356481, Time: 07_05_2022__14:23:42\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.5394324, Training accuracy: 0.4364091, Time: 07_05_2022__14:24:03\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.5380729, Training accuracy: 0.4366071, Time: 07_05_2022__14:24:24\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.5352471, Training accuracy: 0.4375439, Time: 07_05_2022__14:24:44\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.5339239, Training accuracy: 0.4379741, Time: 07_05_2022__14:25:05\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.5316774, Training accuracy: 0.4390678, Time: 07_05_2022__14:25:26\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.5303960, Training accuracy: 0.4392917, Time: 07_05_2022__14:25:46\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.5282800, Training accuracy: 0.4395492, Time: 07_05_2022__14:26:07\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.5257957, Training accuracy: 0.4406048, Time: 07_05_2022__14:26:28\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.5248533, Training accuracy: 0.4407540, Time: 07_05_2022__14:26:48\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.5240263, Training accuracy: 0.4410156, Time: 07_05_2022__14:27:09\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.5214990, Training accuracy: 0.4422692, Time: 07_05_2022__14:27:30\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.5199782, Training accuracy: 0.4431061, Time: 07_05_2022__14:27:50\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.5164676, Training accuracy: 0.4451119, Time: 07_05_2022__14:28:11\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.5151332, Training accuracy: 0.4460662, Time: 07_05_2022__14:28:31\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.5122623, Training accuracy: 0.4475000, Time: 07_05_2022__14:28:52\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.5099770, Training accuracy: 0.4482143, Time: 07_05_2022__14:29:13\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.5086360, Training accuracy: 0.4487676, Time: 07_05_2022__14:29:33\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.5063024, Training accuracy: 0.4499653, Time: 07_05_2022__14:29:54\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.5053486, Training accuracy: 0.4501370, Time: 07_05_2022__14:30:15\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.5028076, Training accuracy: 0.4510473, Time: 07_05_2022__14:30:35\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.5006020, Training accuracy: 0.4519333, Time: 07_05_2022__14:30:56\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.4978823, Training accuracy: 0.4532237, Time: 07_05_2022__14:31:17\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.4958247, Training accuracy: 0.4544805, Time: 07_05_2022__14:31:37\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.4931718, Training accuracy: 0.4554487, Time: 07_05_2022__14:31:58\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.4908295, Training accuracy: 0.4562975, Time: 07_05_2022__14:32:19\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.4883159, Training accuracy: 0.4569687, Time: 07_05_2022__14:32:39\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.4863791, Training accuracy: 0.4579012, Time: 07_05_2022__14:33:00\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.4845362, Training accuracy: 0.4586585, Time: 07_05_2022__14:33:21\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.4816710, Training accuracy: 0.4598193, Time: 07_05_2022__14:33:41\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.4801246, Training accuracy: 0.4604762, Time: 07_05_2022__14:34:02\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.4778502, Training accuracy: 0.4612941, Time: 07_05_2022__14:34:23\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.4758233, Training accuracy: 0.4618314, Time: 07_05_2022__14:34:43\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.4734399, Training accuracy: 0.4629310, Time: 07_05_2022__14:35:04\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.4702070, Training accuracy: 0.4643466, Time: 07_05_2022__14:35:25\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.4676995, Training accuracy: 0.4655899, Time: 07_05_2022__14:35:45\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.4652992, Training accuracy: 0.4664722, Time: 07_05_2022__14:36:06\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.4631078, Training accuracy: 0.4673352, Time: 07_05_2022__14:36:26\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.4605432, Training accuracy: 0.4683967, Time: 07_05_2022__14:36:47\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.4587470, Training accuracy: 0.4689785, Time: 07_05_2022__14:37:08\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.4571609, Training accuracy: 0.4696011, Time: 07_05_2022__14:37:28\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.4568663, Training accuracy: 0.4698684, Time: 07_05_2022__14:37:49\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.4535988, Training accuracy: 0.4711458, Time: 07_05_2022__14:38:10\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.4507177, Training accuracy: 0.4721649, Time: 07_05_2022__14:38:30\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.4481386, Training accuracy: 0.4730867, Time: 07_05_2022__14:38:51\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.4465968, Training accuracy: 0.4735859, Time: 07_05_2022__14:39:12\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.4442592, Training accuracy: 0.4746250, Time: 07_05_2022__14:39:32\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.4432547, Training accuracy: 0.4751733, Time: 07_05_2022__14:39:53\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.4412275, Training accuracy: 0.4760294, Time: 07_05_2022__14:40:14\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.4386514, Training accuracy: 0.4770631, Time: 07_05_2022__14:40:34\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.4364256, Training accuracy: 0.4782452, Time: 07_05_2022__14:40:55\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.4349040, Training accuracy: 0.4789762, Time: 07_05_2022__14:41:16\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.4330617, Training accuracy: 0.4794575, Time: 07_05_2022__14:41:36\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.4303504, Training accuracy: 0.4807477, Time: 07_05_2022__14:41:57\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.4282063, Training accuracy: 0.4817130, Time: 07_05_2022__14:42:18\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.4269951, Training accuracy: 0.4822477, Time: 07_05_2022__14:42:38\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.4244818, Training accuracy: 0.4830909, Time: 07_05_2022__14:42:59\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.4222219, Training accuracy: 0.4839414, Time: 07_05_2022__14:43:20\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.4203827, Training accuracy: 0.4844866, Time: 07_05_2022__14:43:40\n","Epoch 2 of 5, Average training loss: 1.4201281, Average training accuracy: 0.4846000, Time: 07_05_2022__14:43:51\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01765cbe201945ae84539f584847ace4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.1486205, Validation accuracy: 0.5825000, Time: 07_05_2022__14:43:56 | Loss decreased from 1.5569202 to 1.1500167 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.1565220, Validation accuracy: 0.5800000, Time: 07_05_2022__14:44:03\n","Step: 300 of 1250, Validation loss: 1.1927788, Validation accuracy: 0.5716667, Time: 07_05_2022__14:44:08\n","Step: 400 of 1250, Validation loss: 1.1995726, Validation accuracy: 0.5725000, Time: 07_05_2022__14:44:14\n","Step: 500 of 1250, Validation loss: 1.2073685, Validation accuracy: 0.5695000, Time: 07_05_2022__14:44:19\n","Step: 600 of 1250, Validation loss: 1.1985212, Validation accuracy: 0.5741667, Time: 07_05_2022__14:44:24\n","Step: 700 of 1250, Validation loss: 1.1944202, Validation accuracy: 0.5789286, Time: 07_05_2022__14:44:29\n","Step: 800 of 1250, Validation loss: 1.1869455, Validation accuracy: 0.5806250, Time: 07_05_2022__14:44:34\n","Step: 900 of 1250, Validation loss: 1.1850276, Validation accuracy: 0.5825000, Time: 07_05_2022__14:44:39\n","Step: 1000 of 1250, Validation loss: 1.1875110, Validation accuracy: 0.5797500, Time: 07_05_2022__14:44:44\n","Step: 1100 of 1250, Validation loss: 1.1916499, Validation accuracy: 0.5779545, Time: 07_05_2022__14:44:49\n","Step: 1200 of 1250, Validation loss: 1.1983963, Validation accuracy: 0.5743750, Time: 07_05_2022__14:44:55\n","Average validation loss: 1.1986861, Average validation accuracy: 0.5740000, Time: 07_05_2022__14:44:57\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa01ef68dd1e4ea399b4a5cd21076492"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.1326869, Training accuracy: 0.6025000, Time: 07_05_2022__14:45:18\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.1135921, Training accuracy: 0.6150000, Time: 07_05_2022__14:45:38\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.1346852, Training accuracy: 0.5966667, Time: 07_05_2022__14:45:59\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.1123591, Training accuracy: 0.6012500, Time: 07_05_2022__14:46:20\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.1123085, Training accuracy: 0.6025000, Time: 07_05_2022__14:46:40\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.1202662, Training accuracy: 0.6029167, Time: 07_05_2022__14:47:01\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.1369063, Training accuracy: 0.5989286, Time: 07_05_2022__14:47:22\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.1401319, Training accuracy: 0.5975000, Time: 07_05_2022__14:47:42\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.1457594, Training accuracy: 0.5969444, Time: 07_05_2022__14:48:03\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.1455271, Training accuracy: 0.5955000, Time: 07_05_2022__14:48:24\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.1464160, Training accuracy: 0.5934091, Time: 07_05_2022__14:48:44\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.1517666, Training accuracy: 0.5916667, Time: 07_05_2022__14:49:05\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.1487567, Training accuracy: 0.5928846, Time: 07_05_2022__14:49:26\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.1464495, Training accuracy: 0.5967857, Time: 07_05_2022__14:49:46\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.1507810, Training accuracy: 0.5951667, Time: 07_05_2022__14:50:07\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.1492155, Training accuracy: 0.5959375, Time: 07_05_2022__14:50:28\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.1519582, Training accuracy: 0.5966176, Time: 07_05_2022__14:50:48\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.1537630, Training accuracy: 0.5948611, Time: 07_05_2022__14:51:09\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.1518775, Training accuracy: 0.5968421, Time: 07_05_2022__14:51:30\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.1508016, Training accuracy: 0.5967500, Time: 07_05_2022__14:51:50\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.1434155, Training accuracy: 0.5997619, Time: 07_05_2022__14:52:11\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.1441909, Training accuracy: 0.5984091, Time: 07_05_2022__14:52:32\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.1448776, Training accuracy: 0.5989130, Time: 07_05_2022__14:52:52\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.1418539, Training accuracy: 0.5990625, Time: 07_05_2022__14:53:13\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.1410679, Training accuracy: 0.5989000, Time: 07_05_2022__14:53:34\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.1383152, Training accuracy: 0.6000000, Time: 07_05_2022__14:53:54\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.1326523, Training accuracy: 0.6012963, Time: 07_05_2022__14:54:15\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.1311497, Training accuracy: 0.6016071, Time: 07_05_2022__14:54:36\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.1285771, Training accuracy: 0.6018966, Time: 07_05_2022__14:54:56\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.1293928, Training accuracy: 0.6016667, Time: 07_05_2022__14:55:17\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.1252809, Training accuracy: 0.6027419, Time: 07_05_2022__14:55:38\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.1227454, Training accuracy: 0.6042188, Time: 07_05_2022__14:55:58\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.1235854, Training accuracy: 0.6031061, Time: 07_05_2022__14:56:19\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.1226220, Training accuracy: 0.6035294, Time: 07_05_2022__14:56:40\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.1208169, Training accuracy: 0.6039286, Time: 07_05_2022__14:57:00\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.1214195, Training accuracy: 0.6036806, Time: 07_05_2022__14:57:21\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.1192903, Training accuracy: 0.6043919, Time: 07_05_2022__14:57:42\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.1159700, Training accuracy: 0.6052632, Time: 07_05_2022__14:58:02\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.1147888, Training accuracy: 0.6053846, Time: 07_05_2022__14:58:23\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.1135689, Training accuracy: 0.6058750, Time: 07_05_2022__14:58:44\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.1157565, Training accuracy: 0.6054878, Time: 07_05_2022__14:59:04\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.1124666, Training accuracy: 0.6073214, Time: 07_05_2022__14:59:25\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.1104150, Training accuracy: 0.6081977, Time: 07_05_2022__14:59:46\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.1087752, Training accuracy: 0.6081818, Time: 07_05_2022__15:00:06\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.1091802, Training accuracy: 0.6084444, Time: 07_05_2022__15:00:27\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.1088420, Training accuracy: 0.6088587, Time: 07_05_2022__15:00:48\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.1078722, Training accuracy: 0.6094149, Time: 07_05_2022__15:01:08\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.1073788, Training accuracy: 0.6097396, Time: 07_05_2022__15:01:29\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.1072931, Training accuracy: 0.6095408, Time: 07_05_2022__15:01:50\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.1066770, Training accuracy: 0.6102000, Time: 07_05_2022__15:02:10\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.1054842, Training accuracy: 0.6102941, Time: 07_05_2022__15:02:31\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.1045116, Training accuracy: 0.6104327, Time: 07_05_2022__15:02:52\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.1031887, Training accuracy: 0.6107547, Time: 07_05_2022__15:03:12\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.1003787, Training accuracy: 0.6119444, Time: 07_05_2022__15:03:33\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.0990224, Training accuracy: 0.6130909, Time: 07_05_2022__15:03:54\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.0974655, Training accuracy: 0.6132589, Time: 07_05_2022__15:04:14\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.0961913, Training accuracy: 0.6136842, Time: 07_05_2022__15:04:35\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.0953275, Training accuracy: 0.6142672, Time: 07_05_2022__15:04:56\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.0936954, Training accuracy: 0.6149153, Time: 07_05_2022__15:05:16\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.0932850, Training accuracy: 0.6152917, Time: 07_05_2022__15:05:37\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.0929466, Training accuracy: 0.6156148, Time: 07_05_2022__15:05:58\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.0909468, Training accuracy: 0.6162903, Time: 07_05_2022__15:06:18\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.0905888, Training accuracy: 0.6165476, Time: 07_05_2022__15:06:39\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.0891125, Training accuracy: 0.6166406, Time: 07_05_2022__15:07:00\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.0883690, Training accuracy: 0.6167692, Time: 07_05_2022__15:07:20\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.0866486, Training accuracy: 0.6175000, Time: 07_05_2022__15:07:41\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.0851924, Training accuracy: 0.6181343, Time: 07_05_2022__15:08:02\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.0842683, Training accuracy: 0.6182353, Time: 07_05_2022__15:08:22\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.0828698, Training accuracy: 0.6188043, Time: 07_05_2022__15:08:43\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.0811947, Training accuracy: 0.6197500, Time: 07_05_2022__15:09:04\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.0807047, Training accuracy: 0.6201056, Time: 07_05_2022__15:09:24\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.0783804, Training accuracy: 0.6206944, Time: 07_05_2022__15:09:45\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.0773459, Training accuracy: 0.6208904, Time: 07_05_2022__15:10:06\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.0760613, Training accuracy: 0.6212838, Time: 07_05_2022__15:10:26\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.0743358, Training accuracy: 0.6221333, Time: 07_05_2022__15:10:47\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.0728146, Training accuracy: 0.6225987, Time: 07_05_2022__15:11:08\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.0720912, Training accuracy: 0.6230519, Time: 07_05_2022__15:11:28\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.0705021, Training accuracy: 0.6233974, Time: 07_05_2022__15:11:49\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.0687973, Training accuracy: 0.6240506, Time: 07_05_2022__15:12:10\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.0673620, Training accuracy: 0.6247187, Time: 07_05_2022__15:12:30\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.0664914, Training accuracy: 0.6251235, Time: 07_05_2022__15:12:51\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.0665626, Training accuracy: 0.6252744, Time: 07_05_2022__15:13:12\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.0649824, Training accuracy: 0.6254819, Time: 07_05_2022__15:13:32\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.0650506, Training accuracy: 0.6255357, Time: 07_05_2022__15:13:53\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.0640258, Training accuracy: 0.6258235, Time: 07_05_2022__15:14:14\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.0631187, Training accuracy: 0.6259593, Time: 07_05_2022__15:14:34\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.0622899, Training accuracy: 0.6262356, Time: 07_05_2022__15:14:55\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.0606693, Training accuracy: 0.6269318, Time: 07_05_2022__15:15:16\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 1.0582087, Training accuracy: 0.6276124, Time: 07_05_2022__15:15:36\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 1.0569008, Training accuracy: 0.6281667, Time: 07_05_2022__15:15:57\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 1.0565213, Training accuracy: 0.6284890, Time: 07_05_2022__15:16:18\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 1.0553402, Training accuracy: 0.6290489, Time: 07_05_2022__15:16:38\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 1.0540354, Training accuracy: 0.6295430, Time: 07_05_2022__15:16:59\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 1.0536611, Training accuracy: 0.6294149, Time: 07_05_2022__15:17:20\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 1.0538010, Training accuracy: 0.6297105, Time: 07_05_2022__15:17:40\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 1.0518079, Training accuracy: 0.6304167, Time: 07_05_2022__15:18:01\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 1.0494642, Training accuracy: 0.6309021, Time: 07_05_2022__15:18:22\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 1.0478145, Training accuracy: 0.6318878, Time: 07_05_2022__15:18:42\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 1.0468065, Training accuracy: 0.6322475, Time: 07_05_2022__15:19:03\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 1.0457088, Training accuracy: 0.6329000, Time: 07_05_2022__15:19:24\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 1.0451738, Training accuracy: 0.6327970, Time: 07_05_2022__15:19:44\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 1.0443972, Training accuracy: 0.6330147, Time: 07_05_2022__15:20:05\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 1.0428924, Training accuracy: 0.6336165, Time: 07_05_2022__15:20:26\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 1.0415576, Training accuracy: 0.6340625, Time: 07_05_2022__15:20:46\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 1.0404872, Training accuracy: 0.6346905, Time: 07_05_2022__15:21:07\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 1.0398566, Training accuracy: 0.6351651, Time: 07_05_2022__15:21:28\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 1.0378010, Training accuracy: 0.6359346, Time: 07_05_2022__15:21:48\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 1.0372843, Training accuracy: 0.6363657, Time: 07_05_2022__15:22:09\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 1.0367296, Training accuracy: 0.6368578, Time: 07_05_2022__15:22:30\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 1.0357735, Training accuracy: 0.6373636, Time: 07_05_2022__15:22:50\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 1.0340318, Training accuracy: 0.6378604, Time: 07_05_2022__15:23:11\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 1.0329538, Training accuracy: 0.6382813, Time: 07_05_2022__15:23:32\n","Epoch 3 of 5, Average training loss: 1.0326760, Average training accuracy: 0.6382889, Time: 07_05_2022__15:23:42\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc8c02a59d00495daf786e9e5b5e9379"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.8246061, Validation accuracy: 0.6975000, Time: 07_05_2022__15:23:47 | Loss decreased from 1.1500167 to 0.8261625 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.8487389, Validation accuracy: 0.6912500, Time: 07_05_2022__15:23:55\n","Step: 300 of 1250, Validation loss: 0.8725099, Validation accuracy: 0.6866667, Time: 07_05_2022__15:24:00\n","Step: 400 of 1250, Validation loss: 0.8708620, Validation accuracy: 0.6868750, Time: 07_05_2022__15:24:05\n","Step: 500 of 1250, Validation loss: 0.8814343, Validation accuracy: 0.6800000, Time: 07_05_2022__15:24:10\n","Step: 600 of 1250, Validation loss: 0.8751304, Validation accuracy: 0.6812500, Time: 07_05_2022__15:24:15\n","Step: 700 of 1250, Validation loss: 0.8729882, Validation accuracy: 0.6839286, Time: 07_05_2022__15:24:21\n","Step: 800 of 1250, Validation loss: 0.8550271, Validation accuracy: 0.6896875, Time: 07_05_2022__15:24:26\n","Step: 900 of 1250, Validation loss: 0.8576819, Validation accuracy: 0.6916667, Time: 07_05_2022__15:24:31\n","Step: 1000 of 1250, Validation loss: 0.8533272, Validation accuracy: 0.6932500, Time: 07_05_2022__15:24:36\n","Step: 1100 of 1250, Validation loss: 0.8544996, Validation accuracy: 0.6925000, Time: 07_05_2022__15:24:41\n","Step: 1200 of 1250, Validation loss: 0.8613108, Validation accuracy: 0.6895833, Time: 07_05_2022__15:24:46\n","Average validation loss: 0.8606399, Average validation accuracy: 0.6896000, Time: 07_05_2022__15:24:49\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26dfcf5956ee4841b6894b89cf70d948"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 0.7368421, Training accuracy: 0.7275000, Time: 07_05_2022__15:25:09\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 0.8232789, Training accuracy: 0.7037500, Time: 07_05_2022__15:25:30\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 0.8543692, Training accuracy: 0.6975000, Time: 07_05_2022__15:25:51\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 0.8351943, Training accuracy: 0.7043750, Time: 07_05_2022__15:26:12\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 0.8344452, Training accuracy: 0.6985000, Time: 07_05_2022__15:26:32\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 0.8444954, Training accuracy: 0.7000000, Time: 07_05_2022__15:26:53\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 0.8546035, Training accuracy: 0.6967857, Time: 07_05_2022__15:27:14\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 0.8532406, Training accuracy: 0.6975000, Time: 07_05_2022__15:27:34\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 0.8594177, Training accuracy: 0.6927778, Time: 07_05_2022__15:27:55\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 0.8518222, Training accuracy: 0.6942500, Time: 07_05_2022__15:28:16\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 0.8557768, Training accuracy: 0.6947727, Time: 07_05_2022__15:28:36\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 0.8669958, Training accuracy: 0.6900000, Time: 07_05_2022__15:28:57\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 0.8755196, Training accuracy: 0.6871154, Time: 07_05_2022__15:29:18\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 0.8754991, Training accuracy: 0.6889286, Time: 07_05_2022__15:29:38\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 0.8769950, Training accuracy: 0.6891667, Time: 07_05_2022__15:29:59\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 0.8774470, Training accuracy: 0.6900000, Time: 07_05_2022__15:30:20\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 0.8804161, Training accuracy: 0.6892647, Time: 07_05_2022__15:30:40\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 0.8866559, Training accuracy: 0.6865278, Time: 07_05_2022__15:31:01\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 0.8851920, Training accuracy: 0.6868421, Time: 07_05_2022__15:31:22\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 0.8861142, Training accuracy: 0.6871250, Time: 07_05_2022__15:31:42\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 0.8826119, Training accuracy: 0.6882143, Time: 07_05_2022__15:32:03\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 0.8806012, Training accuracy: 0.6902273, Time: 07_05_2022__15:32:24\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 0.8819018, Training accuracy: 0.6905435, Time: 07_05_2022__15:32:44\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 0.8791229, Training accuracy: 0.6923958, Time: 07_05_2022__15:33:05\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 0.8771715, Training accuracy: 0.6931000, Time: 07_05_2022__15:33:26\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 0.8764240, Training accuracy: 0.6933654, Time: 07_05_2022__15:33:46\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 0.8752332, Training accuracy: 0.6942593, Time: 07_05_2022__15:34:07\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 0.8762814, Training accuracy: 0.6942857, Time: 07_05_2022__15:34:28\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 0.8740912, Training accuracy: 0.6958621, Time: 07_05_2022__15:34:49\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 0.8752390, Training accuracy: 0.6950833, Time: 07_05_2022__15:35:09\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 0.8710536, Training accuracy: 0.6969355, Time: 07_05_2022__15:35:30\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 0.8665901, Training accuracy: 0.6980469, Time: 07_05_2022__15:35:51\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 0.8687080, Training accuracy: 0.6973485, Time: 07_05_2022__15:36:11\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 0.8669738, Training accuracy: 0.6983088, Time: 07_05_2022__15:36:32\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 0.8654361, Training accuracy: 0.6985714, Time: 07_05_2022__15:36:53\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 0.8656959, Training accuracy: 0.6984028, Time: 07_05_2022__15:37:13\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 0.8649861, Training accuracy: 0.6986486, Time: 07_05_2022__15:37:34\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 0.8633334, Training accuracy: 0.6982895, Time: 07_05_2022__15:37:55\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 0.8626361, Training accuracy: 0.6980128, Time: 07_05_2022__15:38:15\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 0.8614799, Training accuracy: 0.6985000, Time: 07_05_2022__15:38:36\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 0.8632254, Training accuracy: 0.6976829, Time: 07_05_2022__15:38:57\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 0.8595382, Training accuracy: 0.6988095, Time: 07_05_2022__15:39:17\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 0.8588732, Training accuracy: 0.6989535, Time: 07_05_2022__15:39:38\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 0.8587432, Training accuracy: 0.6989773, Time: 07_05_2022__15:39:59\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 0.8587317, Training accuracy: 0.6995556, Time: 07_05_2022__15:40:19\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 0.8590954, Training accuracy: 0.6997283, Time: 07_05_2022__15:40:40\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 0.8583410, Training accuracy: 0.7005319, Time: 07_05_2022__15:41:01\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 0.8578337, Training accuracy: 0.7005208, Time: 07_05_2022__15:41:21\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 0.8581247, Training accuracy: 0.7002041, Time: 07_05_2022__15:41:42\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 0.8574579, Training accuracy: 0.7008000, Time: 07_05_2022__15:42:03\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 0.8572950, Training accuracy: 0.7005882, Time: 07_05_2022__15:42:24\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 0.8565147, Training accuracy: 0.7010096, Time: 07_05_2022__15:42:44\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 0.8558438, Training accuracy: 0.7011321, Time: 07_05_2022__15:43:05\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 0.8556458, Training accuracy: 0.7012500, Time: 07_05_2022__15:43:26\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 0.8558942, Training accuracy: 0.7012727, Time: 07_05_2022__15:43:46\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 0.8553185, Training accuracy: 0.7015625, Time: 07_05_2022__15:44:07\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 0.8549539, Training accuracy: 0.7017982, Time: 07_05_2022__15:44:28\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 0.8546251, Training accuracy: 0.7015948, Time: 07_05_2022__15:44:48\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 0.8548912, Training accuracy: 0.7018220, Time: 07_05_2022__15:45:09\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 0.8547098, Training accuracy: 0.7024583, Time: 07_05_2022__15:45:30\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 0.8542819, Training accuracy: 0.7028689, Time: 07_05_2022__15:45:50\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 0.8529186, Training accuracy: 0.7032258, Time: 07_05_2022__15:46:11\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 0.8534316, Training accuracy: 0.7033730, Time: 07_05_2022__15:46:32\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 0.8528491, Training accuracy: 0.7035547, Time: 07_05_2022__15:46:52\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 0.8511785, Training accuracy: 0.7042308, Time: 07_05_2022__15:47:13\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 0.8495840, Training accuracy: 0.7050758, Time: 07_05_2022__15:47:34\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 0.8481018, Training accuracy: 0.7056716, Time: 07_05_2022__15:47:54\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 0.8476268, Training accuracy: 0.7059191, Time: 07_05_2022__15:48:15\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 0.8462209, Training accuracy: 0.7067754, Time: 07_05_2022__15:48:36\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 0.8448427, Training accuracy: 0.7073571, Time: 07_05_2022__15:48:57\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 0.8453351, Training accuracy: 0.7073592, Time: 07_05_2022__15:49:17\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 0.8443671, Training accuracy: 0.7074653, Time: 07_05_2022__15:49:38\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 0.8437864, Training accuracy: 0.7075342, Time: 07_05_2022__15:49:59\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 0.8439420, Training accuracy: 0.7077703, Time: 07_05_2022__15:50:19\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 0.8422920, Training accuracy: 0.7084000, Time: 07_05_2022__15:50:40\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 0.8407580, Training accuracy: 0.7089803, Time: 07_05_2022__15:51:01\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 0.8402875, Training accuracy: 0.7089935, Time: 07_05_2022__15:51:21\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 0.8398335, Training accuracy: 0.7091026, Time: 07_05_2022__15:51:42\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 0.8385632, Training accuracy: 0.7094620, Time: 07_05_2022__15:52:03\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 0.8374988, Training accuracy: 0.7095625, Time: 07_05_2022__15:52:23\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 0.8383881, Training accuracy: 0.7091975, Time: 07_05_2022__15:52:44\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 0.8384666, Training accuracy: 0.7093598, Time: 07_05_2022__15:53:05\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 0.8379470, Training accuracy: 0.7093976, Time: 07_05_2022__15:53:25\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 0.8384341, Training accuracy: 0.7089881, Time: 07_05_2022__15:53:46\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 0.8378205, Training accuracy: 0.7092647, Time: 07_05_2022__15:54:07\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 0.8372745, Training accuracy: 0.7094186, Time: 07_05_2022__15:54:27\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 0.8369438, Training accuracy: 0.7096552, Time: 07_05_2022__15:54:48\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 0.8359603, Training accuracy: 0.7101705, Time: 07_05_2022__15:55:09\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 0.8343794, Training accuracy: 0.7106742, Time: 07_05_2022__15:55:29\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 0.8337087, Training accuracy: 0.7108889, Time: 07_05_2022__15:55:50\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 0.8330819, Training accuracy: 0.7111264, Time: 07_05_2022__15:56:11\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 0.8326928, Training accuracy: 0.7110054, Time: 07_05_2022__15:56:31\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 0.8319275, Training accuracy: 0.7112097, Time: 07_05_2022__15:56:52\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 0.8318047, Training accuracy: 0.7111702, Time: 07_05_2022__15:57:13\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 0.8327991, Training accuracy: 0.7109737, Time: 07_05_2022__15:57:33\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 0.8314369, Training accuracy: 0.7114063, Time: 07_05_2022__15:57:54\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 0.8295169, Training accuracy: 0.7119845, Time: 07_05_2022__15:58:15\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 0.8282377, Training accuracy: 0.7125510, Time: 07_05_2022__15:58:35\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 0.8281878, Training accuracy: 0.7127273, Time: 07_05_2022__15:58:56\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 0.8277025, Training accuracy: 0.7129250, Time: 07_05_2022__15:59:17\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 0.8280277, Training accuracy: 0.7127475, Time: 07_05_2022__15:59:37\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 0.8268482, Training accuracy: 0.7129412, Time: 07_05_2022__15:59:58\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 0.8255018, Training accuracy: 0.7134466, Time: 07_05_2022__16:00:19\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 0.8242632, Training accuracy: 0.7140865, Time: 07_05_2022__16:00:39\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 0.8238646, Training accuracy: 0.7142143, Time: 07_05_2022__16:01:00\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 0.8236656, Training accuracy: 0.7143160, Time: 07_05_2022__16:01:21\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 0.8226212, Training accuracy: 0.7146729, Time: 07_05_2022__16:01:41\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 0.8222256, Training accuracy: 0.7146528, Time: 07_05_2022__16:02:02\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 0.8225442, Training accuracy: 0.7149083, Time: 07_05_2022__16:02:23\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 0.8217364, Training accuracy: 0.7151818, Time: 07_05_2022__16:02:43\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 0.8206140, Training accuracy: 0.7156306, Time: 07_05_2022__16:03:04\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 0.8198453, Training accuracy: 0.7158259, Time: 07_05_2022__16:03:25\n","Epoch 4 of 5, Average training loss: 0.8196295, Average training accuracy: 0.7158889, Time: 07_05_2022__16:03:35\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55c5d97ce1414f8689d5fc8fdf6cd43e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.7108235, Validation accuracy: 0.7275000, Time: 07_05_2022__16:03:40 | Loss decreased from 0.8261625 to 0.7125606 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.6967635, Validation accuracy: 0.7475000, Time: 07_05_2022__16:03:48 | Loss decreased from 0.7125606 to 0.6957443 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.7364248, Validation accuracy: 0.7408333, Time: 07_05_2022__16:03:55\n","Step: 400 of 1250, Validation loss: 0.7208364, Validation accuracy: 0.7431250, Time: 07_05_2022__16:04:01\n","Step: 500 of 1250, Validation loss: 0.7242588, Validation accuracy: 0.7445000, Time: 07_05_2022__16:04:06\n","Step: 600 of 1250, Validation loss: 0.7168857, Validation accuracy: 0.7425000, Time: 07_05_2022__16:04:11\n","Step: 700 of 1250, Validation loss: 0.7138070, Validation accuracy: 0.7442857, Time: 07_05_2022__16:04:16\n","Step: 800 of 1250, Validation loss: 0.6968773, Validation accuracy: 0.7515625, Time: 07_05_2022__16:04:21\n","Step: 900 of 1250, Validation loss: 0.7024268, Validation accuracy: 0.7513889, Time: 07_05_2022__16:04:26\n","Step: 1000 of 1250, Validation loss: 0.7003482, Validation accuracy: 0.7515000, Time: 07_05_2022__16:04:32\n","Step: 1100 of 1250, Validation loss: 0.7023569, Validation accuracy: 0.7502273, Time: 07_05_2022__16:04:37\n","Step: 1200 of 1250, Validation loss: 0.7099894, Validation accuracy: 0.7470833, Time: 07_05_2022__16:04:42\n","Average validation loss: 0.7111764, Average validation accuracy: 0.7462000, Time: 07_05_2022__16:04:44\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0005bdd06414fcab7d8932ca691ef54"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 0.7032167, Training accuracy: 0.7350000, Time: 07_05_2022__16:05:05\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 0.7149256, Training accuracy: 0.7425000, Time: 07_05_2022__16:05:26\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 0.7220436, Training accuracy: 0.7400000, Time: 07_05_2022__16:05:46\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 0.6861914, Training accuracy: 0.7543750, Time: 07_05_2022__16:06:07\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 0.6973303, Training accuracy: 0.7565000, Time: 07_05_2022__16:06:28\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 0.6949979, Training accuracy: 0.7608333, Time: 07_05_2022__16:06:49\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 0.7006862, Training accuracy: 0.7589286, Time: 07_05_2022__16:07:09\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 0.6942762, Training accuracy: 0.7618750, Time: 07_05_2022__16:07:30\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 0.7010728, Training accuracy: 0.7600000, Time: 07_05_2022__16:07:50\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 0.6996459, Training accuracy: 0.7607500, Time: 07_05_2022__16:08:11\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 0.7062742, Training accuracy: 0.7586364, Time: 07_05_2022__16:08:32\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 0.7105939, Training accuracy: 0.7566667, Time: 07_05_2022__16:08:53\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 0.7160617, Training accuracy: 0.7548077, Time: 07_05_2022__16:09:13\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 0.7205627, Training accuracy: 0.7544643, Time: 07_05_2022__16:09:34\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 0.7231728, Training accuracy: 0.7531667, Time: 07_05_2022__16:09:55\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 0.7214336, Training accuracy: 0.7534375, Time: 07_05_2022__16:10:15\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 0.7256115, Training accuracy: 0.7519118, Time: 07_05_2022__16:10:36\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 0.7285505, Training accuracy: 0.7497222, Time: 07_05_2022__16:10:57\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 0.7221391, Training accuracy: 0.7525000, Time: 07_05_2022__16:11:17\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 0.7225680, Training accuracy: 0.7520000, Time: 07_05_2022__16:11:38\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 0.7198840, Training accuracy: 0.7532143, Time: 07_05_2022__16:11:59\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 0.7173664, Training accuracy: 0.7529545, Time: 07_05_2022__16:12:19\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 0.7133940, Training accuracy: 0.7540217, Time: 07_05_2022__16:12:40\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 0.7110639, Training accuracy: 0.7548958, Time: 07_05_2022__16:13:01\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 0.7102904, Training accuracy: 0.7552000, Time: 07_05_2022__16:13:21\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 0.7078886, Training accuracy: 0.7557692, Time: 07_05_2022__16:13:42\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 0.7076719, Training accuracy: 0.7549074, Time: 07_05_2022__16:14:03\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 0.7093522, Training accuracy: 0.7543750, Time: 07_05_2022__16:14:23\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 0.7075297, Training accuracy: 0.7550000, Time: 07_05_2022__16:14:44\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 0.7073457, Training accuracy: 0.7546667, Time: 07_05_2022__16:15:05\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 0.7050613, Training accuracy: 0.7558871, Time: 07_05_2022__16:15:25\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 0.7037421, Training accuracy: 0.7564062, Time: 07_05_2022__16:15:46\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 0.7052106, Training accuracy: 0.7565909, Time: 07_05_2022__16:16:07\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 0.7048568, Training accuracy: 0.7572794, Time: 07_05_2022__16:16:27\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 0.7041266, Training accuracy: 0.7568571, Time: 07_05_2022__16:16:48\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 0.7045743, Training accuracy: 0.7565972, Time: 07_05_2022__16:17:09\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 0.7045646, Training accuracy: 0.7568243, Time: 07_05_2022__16:17:29\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 0.7025459, Training accuracy: 0.7573684, Time: 07_05_2022__16:17:50\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 0.7042377, Training accuracy: 0.7567949, Time: 07_05_2022__16:18:11\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 0.7030061, Training accuracy: 0.7570625, Time: 07_05_2022__16:18:32\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 0.7033448, Training accuracy: 0.7568902, Time: 07_05_2022__16:18:52\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 0.7007877, Training accuracy: 0.7577381, Time: 07_05_2022__16:19:13\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 0.6990548, Training accuracy: 0.7586047, Time: 07_05_2022__16:19:34\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 0.6990064, Training accuracy: 0.7589205, Time: 07_05_2022__16:19:54\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 0.7004375, Training accuracy: 0.7583333, Time: 07_05_2022__16:20:15\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 0.7018935, Training accuracy: 0.7582065, Time: 07_05_2022__16:20:36\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 0.7006732, Training accuracy: 0.7586702, Time: 07_05_2022__16:20:56\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 0.6999847, Training accuracy: 0.7588542, Time: 07_05_2022__16:21:17\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 0.6995266, Training accuracy: 0.7588265, Time: 07_05_2022__16:21:38\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 0.7003290, Training accuracy: 0.7586000, Time: 07_05_2022__16:21:59\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 0.7007200, Training accuracy: 0.7578431, Time: 07_05_2022__16:22:19\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 0.7001109, Training accuracy: 0.7578846, Time: 07_05_2022__16:22:40\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 0.7004236, Training accuracy: 0.7574528, Time: 07_05_2022__16:23:01\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 0.7000984, Training accuracy: 0.7577778, Time: 07_05_2022__16:23:22\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 0.7011097, Training accuracy: 0.7574091, Time: 07_05_2022__16:23:42\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 0.7010783, Training accuracy: 0.7572768, Time: 07_05_2022__16:24:03\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 0.7001790, Training accuracy: 0.7574123, Time: 07_05_2022__16:24:24\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 0.6994548, Training accuracy: 0.7576293, Time: 07_05_2022__16:24:44\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 0.7001916, Training accuracy: 0.7572881, Time: 07_05_2022__16:25:05\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 0.7008501, Training accuracy: 0.7569167, Time: 07_05_2022__16:25:26\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 0.7010367, Training accuracy: 0.7572131, Time: 07_05_2022__16:25:47\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 0.7002317, Training accuracy: 0.7575403, Time: 07_05_2022__16:26:07\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 0.7003027, Training accuracy: 0.7576587, Time: 07_05_2022__16:26:28\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 0.7003516, Training accuracy: 0.7577344, Time: 07_05_2022__16:26:49\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 0.6989982, Training accuracy: 0.7581923, Time: 07_05_2022__16:27:10\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 0.6978435, Training accuracy: 0.7583333, Time: 07_05_2022__16:27:30\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 0.6979202, Training accuracy: 0.7583582, Time: 07_05_2022__16:27:51\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 0.6971305, Training accuracy: 0.7587500, Time: 07_05_2022__16:28:12\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 0.6962177, Training accuracy: 0.7593116, Time: 07_05_2022__16:28:32\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 0.6950193, Training accuracy: 0.7596786, Time: 07_05_2022__16:28:53\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 0.6943827, Training accuracy: 0.7599296, Time: 07_05_2022__16:29:14\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 0.6931897, Training accuracy: 0.7601042, Time: 07_05_2022__16:29:35\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 0.6925471, Training accuracy: 0.7603767, Time: 07_05_2022__16:29:55\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 0.6921446, Training accuracy: 0.7605405, Time: 07_05_2022__16:30:16\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 0.6905690, Training accuracy: 0.7611333, Time: 07_05_2022__16:30:37\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 0.6890530, Training accuracy: 0.7615132, Time: 07_05_2022__16:30:57\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 0.6889363, Training accuracy: 0.7614935, Time: 07_05_2022__16:31:18\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 0.6891192, Training accuracy: 0.7610256, Time: 07_05_2022__16:31:39\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 0.6880279, Training accuracy: 0.7614873, Time: 07_05_2022__16:32:00\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 0.6872874, Training accuracy: 0.7614688, Time: 07_05_2022__16:32:20\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 0.6881349, Training accuracy: 0.7611111, Time: 07_05_2022__16:32:41\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 0.6876816, Training accuracy: 0.7612500, Time: 07_05_2022__16:33:02\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 0.6871233, Training accuracy: 0.7614157, Time: 07_05_2022__16:33:22\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 0.6877328, Training accuracy: 0.7611607, Time: 07_05_2022__16:33:43\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 0.6880558, Training accuracy: 0.7608824, Time: 07_05_2022__16:34:04\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 0.6874032, Training accuracy: 0.7610465, Time: 07_05_2022__16:34:25\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 0.6880002, Training accuracy: 0.7608046, Time: 07_05_2022__16:34:45\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 0.6867280, Training accuracy: 0.7614489, Time: 07_05_2022__16:35:06\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 0.6862639, Training accuracy: 0.7616292, Time: 07_05_2022__16:35:27\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 0.6854444, Training accuracy: 0.7619444, Time: 07_05_2022__16:35:48\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 0.6861508, Training accuracy: 0.7619231, Time: 07_05_2022__16:36:08\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 0.6852221, Training accuracy: 0.7622011, Time: 07_05_2022__16:36:29\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 0.6850401, Training accuracy: 0.7622581, Time: 07_05_2022__16:36:50\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 0.6849677, Training accuracy: 0.7623404, Time: 07_05_2022__16:37:10\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 0.6854625, Training accuracy: 0.7621316, Time: 07_05_2022__16:37:31\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 0.6842277, Training accuracy: 0.7625260, Time: 07_05_2022__16:37:52\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 0.6828089, Training accuracy: 0.7630928, Time: 07_05_2022__16:38:13\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 0.6822020, Training accuracy: 0.7634184, Time: 07_05_2022__16:38:33\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 0.6822037, Training accuracy: 0.7633838, Time: 07_05_2022__16:38:54\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 0.6814571, Training accuracy: 0.7635750, Time: 07_05_2022__16:39:15\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 0.6814685, Training accuracy: 0.7636386, Time: 07_05_2022__16:39:36\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 0.6813873, Training accuracy: 0.7635539, Time: 07_05_2022__16:39:56\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 0.6802408, Training accuracy: 0.7639078, Time: 07_05_2022__16:40:17\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 0.6790439, Training accuracy: 0.7643269, Time: 07_05_2022__16:40:38\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 0.6780551, Training accuracy: 0.7646429, Time: 07_05_2022__16:40:58\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 0.6786334, Training accuracy: 0.7644575, Time: 07_05_2022__16:41:19\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 0.6774688, Training accuracy: 0.7649766, Time: 07_05_2022__16:41:40\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 0.6771570, Training accuracy: 0.7652778, Time: 07_05_2022__16:42:01\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 0.6772795, Training accuracy: 0.7652752, Time: 07_05_2022__16:42:21\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 0.6772362, Training accuracy: 0.7651364, Time: 07_05_2022__16:42:42\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 0.6765996, Training accuracy: 0.7654054, Time: 07_05_2022__16:43:03\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 0.6762992, Training accuracy: 0.7654688, Time: 07_05_2022__16:43:23\n","Epoch 5 of 5, Average training loss: 0.6764384, Average training accuracy: 0.7652667, Time: 07_05_2022__16:43:34\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1157c68c520c4da386aa8bbf9d21d402"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.6584327, Validation accuracy: 0.7775000, Time: 07_05_2022__16:43:39 | Loss decreased from 0.6957443 to 0.6644012 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.6607173, Validation accuracy: 0.7687500, Time: 07_05_2022__16:43:47 | Loss decreased from 0.6644012 to 0.6597506 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.6846228, Validation accuracy: 0.7625000, Time: 07_05_2022__16:43:54\n","Step: 400 of 1250, Validation loss: 0.6617003, Validation accuracy: 0.7706250, Time: 07_05_2022__16:44:00\n","Step: 500 of 1250, Validation loss: 0.6632414, Validation accuracy: 0.7735000, Time: 07_05_2022__16:44:05\n","Step: 600 of 1250, Validation loss: 0.6629209, Validation accuracy: 0.7733333, Time: 07_05_2022__16:44:10\n","Step: 700 of 1250, Validation loss: 0.6548703, Validation accuracy: 0.7771429, Time: 07_05_2022__16:44:15 | Loss decreased from 0.6597506 to 0.6539805 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.6439357, Validation accuracy: 0.7784375, Time: 07_05_2022__16:44:23 | Loss decreased from 0.6539805 to 0.6431587 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.6445857, Validation accuracy: 0.7805556, Time: 07_05_2022__16:44:31\n","Step: 1000 of 1250, Validation loss: 0.6431703, Validation accuracy: 0.7800000, Time: 07_05_2022__16:44:36 | Loss decreased from 0.6431587 to 0.6431401 .... Saving the model\n","Step: 1100 of 1250, Validation loss: 0.6431829, Validation accuracy: 0.7815909, Time: 07_05_2022__16:44:44\n","Step: 1200 of 1250, Validation loss: 0.6520338, Validation accuracy: 0.7781250, Time: 07_05_2022__16:44:49\n","Average validation loss: 0.6494149, Average validation accuracy: 0.7788000, Time: 07_05_2022__16:44:52\n","###################### Testing vgg19_batch_norm SGD, lr_0.01, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eedf6372946c4ac3bf28d373c5ce5513"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.8050000, Time: 07_05_2022__16:45:05\n","Step: 200 of 2500, Test accuracy: 0.7912500, Time: 07_05_2022__16:45:10\n","Step: 300 of 2500, Test accuracy: 0.7941667, Time: 07_05_2022__16:45:15\n","Step: 400 of 2500, Test accuracy: 0.7875000, Time: 07_05_2022__16:45:20\n","Step: 500 of 2500, Test accuracy: 0.7790000, Time: 07_05_2022__16:45:25\n","Step: 600 of 2500, Test accuracy: 0.7745833, Time: 07_05_2022__16:45:30\n","Step: 700 of 2500, Test accuracy: 0.7721429, Time: 07_05_2022__16:45:36\n","Step: 800 of 2500, Test accuracy: 0.7734375, Time: 07_05_2022__16:45:41\n","Step: 900 of 2500, Test accuracy: 0.7719444, Time: 07_05_2022__16:45:46\n","Step: 1000 of 2500, Test accuracy: 0.7707500, Time: 07_05_2022__16:45:51\n","Step: 1100 of 2500, Test accuracy: 0.7752273, Time: 07_05_2022__16:45:56\n","Step: 1200 of 2500, Test accuracy: 0.7766667, Time: 07_05_2022__16:46:01\n","Step: 1300 of 2500, Test accuracy: 0.7786538, Time: 07_05_2022__16:46:07\n","Step: 1400 of 2500, Test accuracy: 0.7789286, Time: 07_05_2022__16:46:12\n","Step: 1500 of 2500, Test accuracy: 0.7771667, Time: 07_05_2022__16:46:17\n","Step: 1600 of 2500, Test accuracy: 0.7771875, Time: 07_05_2022__16:46:22\n","Step: 1700 of 2500, Test accuracy: 0.7766176, Time: 07_05_2022__16:46:27\n","Step: 1800 of 2500, Test accuracy: 0.7748611, Time: 07_05_2022__16:46:32\n","Step: 1900 of 2500, Test accuracy: 0.7753947, Time: 07_05_2022__16:46:37\n","Step: 2000 of 2500, Test accuracy: 0.7753750, Time: 07_05_2022__16:46:43\n","Step: 2100 of 2500, Test accuracy: 0.7748810, Time: 07_05_2022__16:46:48\n","Step: 2200 of 2500, Test accuracy: 0.7738636, Time: 07_05_2022__16:46:53\n","Step: 2300 of 2500, Test accuracy: 0.7735870, Time: 07_05_2022__16:46:58\n","Step: 2400 of 2500, Test accuracy: 0.7737500, Time: 07_05_2022__16:47:03\n","Step: 2500 of 2500, Test accuracy: 0.7735000, Time: 07_05_2022__16:47:08\n","Average testing accuracy: 0.7735000, Time: 07_05_2022__16:47:08\n","###################### Training vgg19_batch_norm SGD, lr_0.01, momentum_0.9 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"100e8f71d8464f59a4b1fcaae7dace89"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 9.3646668, Training accuracy: 0.0900000, Time: 07_05_2022__16:47:31\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 6.1634971, Training accuracy: 0.0962500, Time: 07_05_2022__16:47:52\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 4.9412201, Training accuracy: 0.1025000, Time: 07_05_2022__16:48:12\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 4.2926239, Training accuracy: 0.1075000, Time: 07_05_2022__16:48:33\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 3.9022607, Training accuracy: 0.1045000, Time: 07_05_2022__16:48:54\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 3.6389700, Training accuracy: 0.1050000, Time: 07_05_2022__16:49:14\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 3.4491776, Training accuracy: 0.1064286, Time: 07_05_2022__16:49:35\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 3.3079495, Training accuracy: 0.1021875, Time: 07_05_2022__16:49:55\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 3.1965136, Training accuracy: 0.0997222, Time: 07_05_2022__16:50:15\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 3.1074279, Training accuracy: 0.0990000, Time: 07_05_2022__16:50:35\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 3.0346871, Training accuracy: 0.1006818, Time: 07_05_2022__16:50:55\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.9737601, Training accuracy: 0.0997917, Time: 07_05_2022__16:51:15\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.9220934, Training accuracy: 0.1007692, Time: 07_05_2022__16:51:35\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.8780569, Training accuracy: 0.1017857, Time: 07_05_2022__16:51:55\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.8397132, Training accuracy: 0.1015000, Time: 07_05_2022__16:52:15\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.8061728, Training accuracy: 0.1010937, Time: 07_05_2022__16:52:34\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.7765157, Training accuracy: 0.1004412, Time: 07_05_2022__16:52:54\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.7504391, Training accuracy: 0.0995833, Time: 07_05_2022__16:53:14\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.7268705, Training accuracy: 0.0990789, Time: 07_05_2022__16:53:33\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.7056758, Training accuracy: 0.0990000, Time: 07_05_2022__16:53:53\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.6864639, Training accuracy: 0.0979762, Time: 07_05_2022__16:54:13\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.6687645, Training accuracy: 0.0990909, Time: 07_05_2022__16:54:33\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.6531408, Training accuracy: 0.0997826, Time: 07_05_2022__16:54:53\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.6386078, Training accuracy: 0.0998958, Time: 07_05_2022__16:55:13\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.6251233, Training accuracy: 0.0993000, Time: 07_05_2022__16:55:33\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.6127835, Training accuracy: 0.0988462, Time: 07_05_2022__16:55:52\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.6012546, Training accuracy: 0.0996296, Time: 07_05_2022__16:56:12\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.5906228, Training accuracy: 0.0999107, Time: 07_05_2022__16:56:32\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.5805497, Training accuracy: 0.1000000, Time: 07_05_2022__16:56:52\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.5715067, Training accuracy: 0.0997500, Time: 07_05_2022__16:57:12\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.5627739, Training accuracy: 0.0995161, Time: 07_05_2022__16:57:32\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.5542652, Training accuracy: 0.1006250, Time: 07_05_2022__16:57:52\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.5467212, Training accuracy: 0.1006061, Time: 07_05_2022__16:58:12\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.5395413, Training accuracy: 0.1003676, Time: 07_05_2022__16:58:32\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.5328890, Training accuracy: 0.0995714, Time: 07_05_2022__16:58:52\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.5264335, Training accuracy: 0.0996528, Time: 07_05_2022__16:59:12\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.5204182, Training accuracy: 0.0996622, Time: 07_05_2022__16:59:32\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.5148368, Training accuracy: 0.0998026, Time: 07_05_2022__16:59:51\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.5095256, Training accuracy: 0.1000641, Time: 07_05_2022__17:00:11\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.5043843, Training accuracy: 0.0997500, Time: 07_05_2022__17:00:31\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.4994568, Training accuracy: 0.1001829, Time: 07_05_2022__17:00:51\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.4947567, Training accuracy: 0.1004762, Time: 07_05_2022__17:01:11\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.4902828, Training accuracy: 0.0999419, Time: 07_05_2022__17:01:31\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.4857405, Training accuracy: 0.1011364, Time: 07_05_2022__17:01:52\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.4816679, Training accuracy: 0.1013333, Time: 07_05_2022__17:02:12\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.4778002, Training accuracy: 0.1011413, Time: 07_05_2022__17:02:31\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.4741194, Training accuracy: 0.1013830, Time: 07_05_2022__17:02:51\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 2.4705532, Training accuracy: 0.1011458, Time: 07_05_2022__17:03:11\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 2.4672529, Training accuracy: 0.1008163, Time: 07_05_2022__17:03:31\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 2.4640349, Training accuracy: 0.1010500, Time: 07_05_2022__17:03:51\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 2.4608758, Training accuracy: 0.1008333, Time: 07_05_2022__17:04:11\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 2.4578518, Training accuracy: 0.1007692, Time: 07_05_2022__17:04:30\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 2.4548817, Training accuracy: 0.1006132, Time: 07_05_2022__17:04:50\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 2.4516981, Training accuracy: 0.1012500, Time: 07_05_2022__17:05:10\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 2.4489611, Training accuracy: 0.1010909, Time: 07_05_2022__17:05:30\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 2.4461790, Training accuracy: 0.1015625, Time: 07_05_2022__17:05:50\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 2.4436967, Training accuracy: 0.1014035, Time: 07_05_2022__17:06:10\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 2.4411971, Training accuracy: 0.1017241, Time: 07_05_2022__17:06:30\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 2.4389950, Training accuracy: 0.1019492, Time: 07_05_2022__17:06:49\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 2.4367801, Training accuracy: 0.1018750, Time: 07_05_2022__17:07:10\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 2.4345737, Training accuracy: 0.1019672, Time: 07_05_2022__17:07:29\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 2.4323870, Training accuracy: 0.1025403, Time: 07_05_2022__17:07:49\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 2.4302845, Training accuracy: 0.1026190, Time: 07_05_2022__17:08:09\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 2.4283843, Training accuracy: 0.1025391, Time: 07_05_2022__17:08:29\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 2.4264261, Training accuracy: 0.1027308, Time: 07_05_2022__17:08:49\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 2.4244801, Training accuracy: 0.1032576, Time: 07_05_2022__17:09:09\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 2.4226357, Training accuracy: 0.1037313, Time: 07_05_2022__17:09:29\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 2.4210034, Training accuracy: 0.1034559, Time: 07_05_2022__17:09:49\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 2.4193400, Training accuracy: 0.1031159, Time: 07_05_2022__17:10:09\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 2.4177479, Training accuracy: 0.1033214, Time: 07_05_2022__17:10:30\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 2.4161118, Training accuracy: 0.1033451, Time: 07_05_2022__17:10:50\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 2.4143440, Training accuracy: 0.1034722, Time: 07_05_2022__17:11:10\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 2.4129088, Training accuracy: 0.1032192, Time: 07_05_2022__17:11:30\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 2.4113927, Training accuracy: 0.1034797, Time: 07_05_2022__17:11:50\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 2.4097941, Training accuracy: 0.1037667, Time: 07_05_2022__17:12:10\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 2.4085194, Training accuracy: 0.1036184, Time: 07_05_2022__17:12:30\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 2.4071652, Training accuracy: 0.1035390, Time: 07_05_2022__17:12:50\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 2.4058267, Training accuracy: 0.1033974, Time: 07_05_2022__17:13:10\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 2.4045286, Training accuracy: 0.1034177, Time: 07_05_2022__17:13:30\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 2.4032694, Training accuracy: 0.1030313, Time: 07_05_2022__17:13:50\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 2.4019824, Training accuracy: 0.1033025, Time: 07_05_2022__17:14:10\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 2.4008094, Training accuracy: 0.1033841, Time: 07_05_2022__17:14:30\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 2.3996497, Training accuracy: 0.1032530, Time: 07_05_2022__17:14:50\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 2.3985263, Training accuracy: 0.1028869, Time: 07_05_2022__17:15:10\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 2.3973932, Training accuracy: 0.1031471, Time: 07_05_2022__17:15:30\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 2.3963026, Training accuracy: 0.1032267, Time: 07_05_2022__17:15:49\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 2.3952460, Training accuracy: 0.1030460, Time: 07_05_2022__17:16:09\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 2.3942039, Training accuracy: 0.1030398, Time: 07_05_2022__17:16:29\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 2.3931206, Training accuracy: 0.1034831, Time: 07_05_2022__17:16:49\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 2.3921436, Training accuracy: 0.1034167, Time: 07_05_2022__17:17:09\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 2.3911746, Training accuracy: 0.1032418, Time: 07_05_2022__17:17:28\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 2.3900711, Training accuracy: 0.1034239, Time: 07_05_2022__17:17:48\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 2.3891165, Training accuracy: 0.1036022, Time: 07_05_2022__17:18:08\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 2.3881603, Training accuracy: 0.1039096, Time: 07_05_2022__17:18:29\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 2.3873356, Training accuracy: 0.1038158, Time: 07_05_2022__17:18:48\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 2.3864399, Training accuracy: 0.1038281, Time: 07_05_2022__17:19:08\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 2.3855979, Training accuracy: 0.1037887, Time: 07_05_2022__17:19:28\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 2.3847105, Training accuracy: 0.1036990, Time: 07_05_2022__17:19:48\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 2.3838861, Training accuracy: 0.1036111, Time: 07_05_2022__17:20:08\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 2.3830779, Training accuracy: 0.1038000, Time: 07_05_2022__17:20:28\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 2.3823644, Training accuracy: 0.1039356, Time: 07_05_2022__17:20:48\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 2.3815202, Training accuracy: 0.1042157, Time: 07_05_2022__17:21:08\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 2.3807248, Training accuracy: 0.1040291, Time: 07_05_2022__17:21:28\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 2.3799835, Training accuracy: 0.1038942, Time: 07_05_2022__17:21:48\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 2.3792518, Training accuracy: 0.1038571, Time: 07_05_2022__17:22:08\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 2.3786253, Training accuracy: 0.1042689, Time: 07_05_2022__17:22:28\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 2.3779447, Training accuracy: 0.1042757, Time: 07_05_2022__17:22:48\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 2.3772633, Training accuracy: 0.1041435, Time: 07_05_2022__17:23:09\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 2.3765058, Training accuracy: 0.1041514, Time: 07_05_2022__17:23:29\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 2.3757649, Training accuracy: 0.1046136, Time: 07_05_2022__17:23:49\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 2.3750412, Training accuracy: 0.1049550, Time: 07_05_2022__17:24:09\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 2.3742759, Training accuracy: 0.1050223, Time: 07_05_2022__17:24:29\n","Epoch 1 of 5, Average training loss: 2.3739862, Average training accuracy: 0.1050444, Time: 07_05_2022__17:24:39\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"072b2976f64148329937c1feef91aa8b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 2.2901630, Validation accuracy: 0.1375000, Time: 07_05_2022__17:24:44 | Loss decreased from inf to 2.2904818 .... Saving the model\n","Step: 200 of 1250, Validation loss: 2.2890869, Validation accuracy: 0.1262500, Time: 07_05_2022__17:24:52 | Loss decreased from 2.2904818 to 2.2881739 .... Saving the model\n","Step: 300 of 1250, Validation loss: 2.2848468, Validation accuracy: 0.1383333, Time: 07_05_2022__17:25:00 | Loss decreased from 2.2881739 to 2.2846566 .... Saving the model\n","Step: 400 of 1250, Validation loss: 2.2936846, Validation accuracy: 0.1337500, Time: 07_05_2022__17:25:08\n","Step: 500 of 1250, Validation loss: 2.2921453, Validation accuracy: 0.1370000, Time: 07_05_2022__17:25:13\n","Step: 600 of 1250, Validation loss: 2.2899925, Validation accuracy: 0.1400000, Time: 07_05_2022__17:25:19\n","Step: 700 of 1250, Validation loss: 2.2976570, Validation accuracy: 0.1403571, Time: 07_05_2022__17:25:24\n","Step: 800 of 1250, Validation loss: 2.2963931, Validation accuracy: 0.1384375, Time: 07_05_2022__17:25:29\n","Step: 900 of 1250, Validation loss: 2.2944850, Validation accuracy: 0.1372222, Time: 07_05_2022__17:25:34\n","Step: 1000 of 1250, Validation loss: 2.2944274, Validation accuracy: 0.1365000, Time: 07_05_2022__17:25:39\n","Step: 1100 of 1250, Validation loss: 2.2925770, Validation accuracy: 0.1354545, Time: 07_05_2022__17:25:44\n","Step: 1200 of 1250, Validation loss: 2.2944837, Validation accuracy: 0.1354167, Time: 07_05_2022__17:25:50\n","Average validation loss: 2.2949186, Average validation accuracy: 0.1362000, Time: 07_05_2022__17:25:52\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89ae773cccc4487991539b8cda005baa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 2.2980932, Training accuracy: 0.0950000, Time: 07_05_2022__17:26:12\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 2.2995910, Training accuracy: 0.1162500, Time: 07_05_2022__17:26:32\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 2.2992220, Training accuracy: 0.1225000, Time: 07_05_2022__17:26:52\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 2.2986441, Training accuracy: 0.1250000, Time: 07_05_2022__17:27:13\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 2.2975374, Training accuracy: 0.1230000, Time: 07_05_2022__17:27:33\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 2.2976122, Training accuracy: 0.1225000, Time: 07_05_2022__17:27:53\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 2.2983985, Training accuracy: 0.1217857, Time: 07_05_2022__17:28:13\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 2.2980509, Training accuracy: 0.1200000, Time: 07_05_2022__17:28:33\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 2.2969968, Training accuracy: 0.1194444, Time: 07_05_2022__17:28:54\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 2.2979619, Training accuracy: 0.1180000, Time: 07_05_2022__17:29:14\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 2.2978939, Training accuracy: 0.1181818, Time: 07_05_2022__17:29:34\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 2.2973460, Training accuracy: 0.1164583, Time: 07_05_2022__17:29:55\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 2.2971468, Training accuracy: 0.1153846, Time: 07_05_2022__17:30:15\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 2.2960741, Training accuracy: 0.1169643, Time: 07_05_2022__17:30:36\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 2.2967358, Training accuracy: 0.1176667, Time: 07_05_2022__17:30:56\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 2.2968830, Training accuracy: 0.1171875, Time: 07_05_2022__17:31:17\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 2.2962061, Training accuracy: 0.1176471, Time: 07_05_2022__17:31:37\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 2.2958803, Training accuracy: 0.1177778, Time: 07_05_2022__17:31:57\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 2.2960763, Training accuracy: 0.1177632, Time: 07_05_2022__17:32:18\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 2.2960771, Training accuracy: 0.1178750, Time: 07_05_2022__17:32:38\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 2.2956636, Training accuracy: 0.1180952, Time: 07_05_2022__17:32:59\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 2.2958014, Training accuracy: 0.1182955, Time: 07_05_2022__17:33:20\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 2.2954261, Training accuracy: 0.1188043, Time: 07_05_2022__17:33:40\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 2.2954485, Training accuracy: 0.1189583, Time: 07_05_2022__17:34:01\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 2.2954183, Training accuracy: 0.1189000, Time: 07_05_2022__17:34:21\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 2.2956612, Training accuracy: 0.1200962, Time: 07_05_2022__17:34:42\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 2.2956463, Training accuracy: 0.1201852, Time: 07_05_2022__17:35:02\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 2.2950433, Training accuracy: 0.1211607, Time: 07_05_2022__17:35:22\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 2.2951138, Training accuracy: 0.1206034, Time: 07_05_2022__17:35:43\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 2.2950475, Training accuracy: 0.1205833, Time: 07_05_2022__17:36:03\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 2.2952588, Training accuracy: 0.1205645, Time: 07_05_2022__17:36:23\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 2.2946344, Training accuracy: 0.1207031, Time: 07_05_2022__17:36:44\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 2.2944399, Training accuracy: 0.1206061, Time: 07_05_2022__17:37:04\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 2.2940391, Training accuracy: 0.1202941, Time: 07_05_2022__17:37:25\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 2.2943391, Training accuracy: 0.1204286, Time: 07_05_2022__17:37:45\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 2.2940447, Training accuracy: 0.1195833, Time: 07_05_2022__17:38:06\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 2.2938495, Training accuracy: 0.1197973, Time: 07_05_2022__17:38:26\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 2.2937033, Training accuracy: 0.1194079, Time: 07_05_2022__17:38:47\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 2.2934952, Training accuracy: 0.1194872, Time: 07_05_2022__17:39:07\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 2.2928475, Training accuracy: 0.1195000, Time: 07_05_2022__17:39:28\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 2.2922697, Training accuracy: 0.1201220, Time: 07_05_2022__17:39:48\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 2.2920682, Training accuracy: 0.1202976, Time: 07_05_2022__17:40:09\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 2.2919859, Training accuracy: 0.1211047, Time: 07_05_2022__17:40:30\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 2.2910959, Training accuracy: 0.1223864, Time: 07_05_2022__17:40:50\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 2.2905195, Training accuracy: 0.1231667, Time: 07_05_2022__17:41:11\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 2.2898780, Training accuracy: 0.1239674, Time: 07_05_2022__17:41:31\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 2.2893081, Training accuracy: 0.1243085, Time: 07_05_2022__17:41:52\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 2.2881023, Training accuracy: 0.1252604, Time: 07_05_2022__17:42:12\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 2.2876520, Training accuracy: 0.1254082, Time: 07_05_2022__17:42:33\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 2.2871120, Training accuracy: 0.1256000, Time: 07_05_2022__17:42:54\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 2.2864180, Training accuracy: 0.1265196, Time: 07_05_2022__17:43:14\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 2.2855354, Training accuracy: 0.1275962, Time: 07_05_2022__17:43:35\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 2.2848444, Training accuracy: 0.1283962, Time: 07_05_2022__17:43:55\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 2.2835185, Training accuracy: 0.1290741, Time: 07_05_2022__17:44:16\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 2.2824634, Training accuracy: 0.1294545, Time: 07_05_2022__17:44:37\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 2.2814470, Training accuracy: 0.1298661, Time: 07_05_2022__17:44:57\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 2.2803241, Training accuracy: 0.1301754, Time: 07_05_2022__17:45:18\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 2.2791676, Training accuracy: 0.1306466, Time: 07_05_2022__17:45:38\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 2.2783187, Training accuracy: 0.1309746, Time: 07_05_2022__17:45:59\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 2.2765810, Training accuracy: 0.1318333, Time: 07_05_2022__17:46:19\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 2.2757771, Training accuracy: 0.1324590, Time: 07_05_2022__17:46:40\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 2.2742286, Training accuracy: 0.1333468, Time: 07_05_2022__17:47:01\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 2.2728060, Training accuracy: 0.1337302, Time: 07_05_2022__17:47:21\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 2.2714433, Training accuracy: 0.1345703, Time: 07_05_2022__17:47:42\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 2.2681475, Training accuracy: 0.1360769, Time: 07_05_2022__17:48:02\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 2.2671795, Training accuracy: 0.1374242, Time: 07_05_2022__17:48:23\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 2.2654206, Training accuracy: 0.1383209, Time: 07_05_2022__17:48:43\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 2.2643484, Training accuracy: 0.1387500, Time: 07_05_2022__17:49:04\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 2.2627186, Training accuracy: 0.1395290, Time: 07_05_2022__17:49:25\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 2.2606516, Training accuracy: 0.1403571, Time: 07_05_2022__17:49:45\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 2.2595164, Training accuracy: 0.1407746, Time: 07_05_2022__17:50:06\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 2.2573126, Training accuracy: 0.1416319, Time: 07_05_2022__17:50:26\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 2.2557491, Training accuracy: 0.1422945, Time: 07_05_2022__17:50:47\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 2.2544337, Training accuracy: 0.1431081, Time: 07_05_2022__17:51:07\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 2.2529669, Training accuracy: 0.1438333, Time: 07_05_2022__17:51:28\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 2.2511161, Training accuracy: 0.1448026, Time: 07_05_2022__17:51:48\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 2.2500141, Training accuracy: 0.1458117, Time: 07_05_2022__17:52:09\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 2.2480629, Training accuracy: 0.1469872, Time: 07_05_2022__17:52:30\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 2.2460156, Training accuracy: 0.1483861, Time: 07_05_2022__17:52:50\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 2.2444219, Training accuracy: 0.1491875, Time: 07_05_2022__17:53:11\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 2.2428296, Training accuracy: 0.1496296, Time: 07_05_2022__17:53:31\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 2.2411260, Training accuracy: 0.1502439, Time: 07_05_2022__17:53:52\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 2.2391011, Training accuracy: 0.1511145, Time: 07_05_2022__17:54:12\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 2.2367183, Training accuracy: 0.1524405, Time: 07_05_2022__17:54:33\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 2.2353469, Training accuracy: 0.1530294, Time: 07_05_2022__17:54:54\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 2.2338422, Training accuracy: 0.1536919, Time: 07_05_2022__17:55:14\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 2.2320432, Training accuracy: 0.1543103, Time: 07_05_2022__17:55:35\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 2.2295217, Training accuracy: 0.1551420, Time: 07_05_2022__17:55:56\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 2.2273857, Training accuracy: 0.1562079, Time: 07_05_2022__17:56:16\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 2.2261053, Training accuracy: 0.1568889, Time: 07_05_2022__17:56:37\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 2.2246013, Training accuracy: 0.1575824, Time: 07_05_2022__17:56:57\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 2.2227037, Training accuracy: 0.1590217, Time: 07_05_2022__17:57:18\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 2.2212273, Training accuracy: 0.1597849, Time: 07_05_2022__17:57:38\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 2.2198948, Training accuracy: 0.1607713, Time: 07_05_2022__17:57:59\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 2.2186147, Training accuracy: 0.1616316, Time: 07_05_2022__17:58:19\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 2.2170026, Training accuracy: 0.1625260, Time: 07_05_2022__17:58:40\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 2.2152698, Training accuracy: 0.1632990, Time: 07_05_2022__17:59:01\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 2.2127484, Training accuracy: 0.1641837, Time: 07_05_2022__17:59:21\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 2.2114721, Training accuracy: 0.1648990, Time: 07_05_2022__17:59:42\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 2.2104548, Training accuracy: 0.1657500, Time: 07_05_2022__18:00:02\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 2.2090004, Training accuracy: 0.1663119, Time: 07_05_2022__18:00:23\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 2.2075545, Training accuracy: 0.1670833, Time: 07_05_2022__18:00:43\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 2.2061894, Training accuracy: 0.1681068, Time: 07_05_2022__18:01:04\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 2.2045742, Training accuracy: 0.1691587, Time: 07_05_2022__18:01:24\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 2.2033758, Training accuracy: 0.1698095, Time: 07_05_2022__18:01:45\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 2.2019363, Training accuracy: 0.1706840, Time: 07_05_2022__18:02:06\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 2.2003963, Training accuracy: 0.1711215, Time: 07_05_2022__18:02:26\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 2.1986645, Training accuracy: 0.1721759, Time: 07_05_2022__18:02:47\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 2.1974624, Training accuracy: 0.1727064, Time: 07_05_2022__18:03:07\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 2.1960462, Training accuracy: 0.1735000, Time: 07_05_2022__18:03:28\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 2.1941330, Training accuracy: 0.1744595, Time: 07_05_2022__18:03:48\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 2.1923858, Training accuracy: 0.1749554, Time: 07_05_2022__18:04:09\n","Epoch 2 of 5, Average training loss: 2.1918351, Average training accuracy: 0.1752444, Time: 07_05_2022__18:04:19\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"689b8b5da5d9490c91c722574d9dff69"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.8836384, Validation accuracy: 0.3125000, Time: 07_05_2022__18:04:25 | Loss decreased from 2.2846566 to 1.8868663 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.8881453, Validation accuracy: 0.3037500, Time: 07_05_2022__18:04:32\n","Step: 300 of 1250, Validation loss: 1.8730568, Validation accuracy: 0.3116667, Time: 07_05_2022__18:04:37 | Loss decreased from 1.8868663 to 1.8725691 .... Saving the model\n","Step: 400 of 1250, Validation loss: 1.8818596, Validation accuracy: 0.3150000, Time: 07_05_2022__18:04:45\n","Step: 500 of 1250, Validation loss: 1.8968042, Validation accuracy: 0.3040000, Time: 07_05_2022__18:04:50\n","Step: 600 of 1250, Validation loss: 1.8904550, Validation accuracy: 0.3083333, Time: 07_05_2022__18:04:56\n","Step: 700 of 1250, Validation loss: 1.8828837, Validation accuracy: 0.3096429, Time: 07_05_2022__18:05:01\n","Step: 800 of 1250, Validation loss: 1.8788871, Validation accuracy: 0.3131250, Time: 07_05_2022__18:05:06\n","Step: 900 of 1250, Validation loss: 1.8785368, Validation accuracy: 0.3150000, Time: 07_05_2022__18:05:11\n","Step: 1000 of 1250, Validation loss: 1.8793407, Validation accuracy: 0.3122500, Time: 07_05_2022__18:05:16\n","Step: 1100 of 1250, Validation loss: 1.8788161, Validation accuracy: 0.3115909, Time: 07_05_2022__18:05:21\n","Step: 1200 of 1250, Validation loss: 1.8807699, Validation accuracy: 0.3108333, Time: 07_05_2022__18:05:26\n","Average validation loss: 1.8804914, Average validation accuracy: 0.3118000, Time: 07_05_2022__18:05:29\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d60e3b48fdb94610a269f44cb9c200e1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.9063077, Training accuracy: 0.3075000, Time: 07_05_2022__18:05:49\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.9434400, Training accuracy: 0.2925000, Time: 07_05_2022__18:06:10\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.9690724, Training accuracy: 0.2883333, Time: 07_05_2022__18:06:30\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.9793429, Training accuracy: 0.2856250, Time: 07_05_2022__18:06:51\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.9854018, Training accuracy: 0.2825000, Time: 07_05_2022__18:07:12\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.9819994, Training accuracy: 0.2808333, Time: 07_05_2022__18:07:32\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.9827457, Training accuracy: 0.2817857, Time: 07_05_2022__18:07:53\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.9797403, Training accuracy: 0.2809375, Time: 07_05_2022__18:08:13\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.9766444, Training accuracy: 0.2836111, Time: 07_05_2022__18:08:34\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.9725980, Training accuracy: 0.2852500, Time: 07_05_2022__18:08:54\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.9714495, Training accuracy: 0.2875000, Time: 07_05_2022__18:09:15\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.9677136, Training accuracy: 0.2860417, Time: 07_05_2022__18:09:36\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.9616969, Training accuracy: 0.2901923, Time: 07_05_2022__18:09:56\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.9590089, Training accuracy: 0.2923214, Time: 07_05_2022__18:10:17\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.9590673, Training accuracy: 0.2911667, Time: 07_05_2022__18:10:37\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.9612883, Training accuracy: 0.2910937, Time: 07_05_2022__18:10:58\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.9572097, Training accuracy: 0.2932353, Time: 07_05_2022__18:11:18\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.9503608, Training accuracy: 0.2943056, Time: 07_05_2022__18:11:39\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.9455213, Training accuracy: 0.2965789, Time: 07_05_2022__18:11:59\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.9438650, Training accuracy: 0.2977500, Time: 07_05_2022__18:12:20\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.9403744, Training accuracy: 0.2990476, Time: 07_05_2022__18:12:41\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.9403877, Training accuracy: 0.2976136, Time: 07_05_2022__18:13:01\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.9362247, Training accuracy: 0.2983696, Time: 07_05_2022__18:13:22\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.9320112, Training accuracy: 0.2988542, Time: 07_05_2022__18:13:42\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.9280122, Training accuracy: 0.3011000, Time: 07_05_2022__18:14:03\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.9254387, Training accuracy: 0.3017308, Time: 07_05_2022__18:14:24\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.9216739, Training accuracy: 0.3034259, Time: 07_05_2022__18:14:44\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.9188120, Training accuracy: 0.3043750, Time: 07_05_2022__18:15:05\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.9147329, Training accuracy: 0.3066379, Time: 07_05_2022__18:15:25\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.9135774, Training accuracy: 0.3062500, Time: 07_05_2022__18:15:46\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.9085661, Training accuracy: 0.3078226, Time: 07_05_2022__18:16:06\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.9048256, Training accuracy: 0.3101563, Time: 07_05_2022__18:16:27\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.9049627, Training accuracy: 0.3096212, Time: 07_05_2022__18:16:47\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.9028963, Training accuracy: 0.3086765, Time: 07_05_2022__18:17:08\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.9018743, Training accuracy: 0.3098571, Time: 07_05_2022__18:17:29\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.9006035, Training accuracy: 0.3097222, Time: 07_05_2022__18:17:49\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.8991311, Training accuracy: 0.3102703, Time: 07_05_2022__18:18:10\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.8968749, Training accuracy: 0.3107895, Time: 07_05_2022__18:18:30\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.8946028, Training accuracy: 0.3109615, Time: 07_05_2022__18:18:51\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.8925920, Training accuracy: 0.3115000, Time: 07_05_2022__18:19:11\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.8913416, Training accuracy: 0.3115854, Time: 07_05_2022__18:19:32\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.8885033, Training accuracy: 0.3127381, Time: 07_05_2022__18:19:53\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.8867306, Training accuracy: 0.3134302, Time: 07_05_2022__18:20:13\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.8835063, Training accuracy: 0.3151705, Time: 07_05_2022__18:20:34\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.8806431, Training accuracy: 0.3157222, Time: 07_05_2022__18:20:54\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.8781333, Training accuracy: 0.3161413, Time: 07_05_2022__18:21:15\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.8756958, Training accuracy: 0.3170213, Time: 07_05_2022__18:21:36\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.8753515, Training accuracy: 0.3174479, Time: 07_05_2022__18:21:56\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.8737738, Training accuracy: 0.3177041, Time: 07_05_2022__18:22:17\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.8737585, Training accuracy: 0.3183000, Time: 07_05_2022__18:22:37\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.8713032, Training accuracy: 0.3193627, Time: 07_05_2022__18:22:58\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.8709419, Training accuracy: 0.3192308, Time: 07_05_2022__18:23:19\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.8687126, Training accuracy: 0.3207075, Time: 07_05_2022__18:23:39\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.8665281, Training accuracy: 0.3215278, Time: 07_05_2022__18:24:00\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.8645073, Training accuracy: 0.3220000, Time: 07_05_2022__18:24:20\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.8629377, Training accuracy: 0.3224554, Time: 07_05_2022__18:24:41\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.8611593, Training accuracy: 0.3230702, Time: 07_05_2022__18:25:02\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.8595472, Training accuracy: 0.3237069, Time: 07_05_2022__18:25:22\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.8569266, Training accuracy: 0.3251271, Time: 07_05_2022__18:25:43\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.8541597, Training accuracy: 0.3265000, Time: 07_05_2022__18:26:03\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.8533369, Training accuracy: 0.3265984, Time: 07_05_2022__18:26:24\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.8515988, Training accuracy: 0.3277016, Time: 07_05_2022__18:26:45\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.8493278, Training accuracy: 0.3282540, Time: 07_05_2022__18:27:05\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.8472694, Training accuracy: 0.3285156, Time: 07_05_2022__18:27:26\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.8439548, Training accuracy: 0.3301154, Time: 07_05_2022__18:27:46\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.8430678, Training accuracy: 0.3306439, Time: 07_05_2022__18:28:07\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.8409024, Training accuracy: 0.3312687, Time: 07_05_2022__18:28:27\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.8392459, Training accuracy: 0.3320221, Time: 07_05_2022__18:28:48\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.8383272, Training accuracy: 0.3324275, Time: 07_05_2022__18:29:09\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.8360988, Training accuracy: 0.3330714, Time: 07_05_2022__18:29:29\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.8354247, Training accuracy: 0.3336620, Time: 07_05_2022__18:29:50\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.8328864, Training accuracy: 0.3345486, Time: 07_05_2022__18:30:11\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.8316783, Training accuracy: 0.3347945, Time: 07_05_2022__18:30:31\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.8308290, Training accuracy: 0.3348649, Time: 07_05_2022__18:30:52\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.8293500, Training accuracy: 0.3354333, Time: 07_05_2022__18:31:12\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.8271903, Training accuracy: 0.3364803, Time: 07_05_2022__18:31:33\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.8261200, Training accuracy: 0.3369481, Time: 07_05_2022__18:31:53\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.8245081, Training accuracy: 0.3376923, Time: 07_05_2022__18:32:14\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.8231701, Training accuracy: 0.3380696, Time: 07_05_2022__18:32:35\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.8214582, Training accuracy: 0.3390000, Time: 07_05_2022__18:32:55\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.8203601, Training accuracy: 0.3389506, Time: 07_05_2022__18:33:16\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.8189418, Training accuracy: 0.3396037, Time: 07_05_2022__18:33:37\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.8168082, Training accuracy: 0.3405723, Time: 07_05_2022__18:33:57\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.8155600, Training accuracy: 0.3406845, Time: 07_05_2022__18:34:18\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.8137392, Training accuracy: 0.3413529, Time: 07_05_2022__18:34:38\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.8117994, Training accuracy: 0.3419477, Time: 07_05_2022__18:34:59\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.8096008, Training accuracy: 0.3428161, Time: 07_05_2022__18:35:19\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.8068169, Training accuracy: 0.3441761, Time: 07_05_2022__18:35:40\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 1.8050540, Training accuracy: 0.3448876, Time: 07_05_2022__18:36:01\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 1.8036817, Training accuracy: 0.3454722, Time: 07_05_2022__18:36:21\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 1.8023177, Training accuracy: 0.3454945, Time: 07_05_2022__18:36:42\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 1.8003402, Training accuracy: 0.3461957, Time: 07_05_2022__18:37:02\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 1.7984445, Training accuracy: 0.3467742, Time: 07_05_2022__18:37:23\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 1.7968059, Training accuracy: 0.3471809, Time: 07_05_2022__18:37:44\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 1.7962417, Training accuracy: 0.3473684, Time: 07_05_2022__18:38:04\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 1.7940511, Training accuracy: 0.3479427, Time: 07_05_2022__18:38:25\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 1.7917826, Training accuracy: 0.3486340, Time: 07_05_2022__18:38:46\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 1.7894233, Training accuracy: 0.3492092, Time: 07_05_2022__18:39:06\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 1.7878408, Training accuracy: 0.3496212, Time: 07_05_2022__18:39:27\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 1.7870987, Training accuracy: 0.3498500, Time: 07_05_2022__18:39:47\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 1.7858886, Training accuracy: 0.3504455, Time: 07_05_2022__18:40:08\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 1.7842403, Training accuracy: 0.3511765, Time: 07_05_2022__18:40:29\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 1.7829061, Training accuracy: 0.3519417, Time: 07_05_2022__18:40:49\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 1.7813701, Training accuracy: 0.3521635, Time: 07_05_2022__18:41:10\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 1.7808244, Training accuracy: 0.3523095, Time: 07_05_2022__18:41:30\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 1.7791835, Training accuracy: 0.3526651, Time: 07_05_2022__18:41:51\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 1.7774462, Training accuracy: 0.3529907, Time: 07_05_2022__18:42:12\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 1.7751790, Training accuracy: 0.3539815, Time: 07_05_2022__18:42:32\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 1.7741887, Training accuracy: 0.3543807, Time: 07_05_2022__18:42:53\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 1.7728963, Training accuracy: 0.3546591, Time: 07_05_2022__18:43:13\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 1.7705741, Training accuracy: 0.3552027, Time: 07_05_2022__18:43:34\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 1.7696654, Training accuracy: 0.3551339, Time: 07_05_2022__18:43:55\n","Epoch 3 of 5, Average training loss: 1.7692682, Average training accuracy: 0.3551333, Time: 07_05_2022__18:44:05\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8803f9a49af8413cbb2e2c64d2f42b13"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.4491002, Validation accuracy: 0.4775000, Time: 07_05_2022__18:44:10 | Loss decreased from 1.8725691 to 1.4440256 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.4591101, Validation accuracy: 0.4687500, Time: 07_05_2022__18:44:17\n","Step: 300 of 1250, Validation loss: 1.4850099, Validation accuracy: 0.4641667, Time: 07_05_2022__18:44:23\n","Step: 400 of 1250, Validation loss: 1.4849333, Validation accuracy: 0.4662500, Time: 07_05_2022__18:44:28\n","Step: 500 of 1250, Validation loss: 1.4938311, Validation accuracy: 0.4570000, Time: 07_05_2022__18:44:33\n","Step: 600 of 1250, Validation loss: 1.4908643, Validation accuracy: 0.4562500, Time: 07_05_2022__18:44:38\n","Step: 700 of 1250, Validation loss: 1.4786771, Validation accuracy: 0.4642857, Time: 07_05_2022__18:44:44\n","Step: 800 of 1250, Validation loss: 1.4687403, Validation accuracy: 0.4656250, Time: 07_05_2022__18:44:49\n","Step: 900 of 1250, Validation loss: 1.4738740, Validation accuracy: 0.4647222, Time: 07_05_2022__18:44:54\n","Step: 1000 of 1250, Validation loss: 1.4796211, Validation accuracy: 0.4592500, Time: 07_05_2022__18:44:59\n","Step: 1100 of 1250, Validation loss: 1.4829556, Validation accuracy: 0.4615909, Time: 07_05_2022__18:45:04\n","Step: 1200 of 1250, Validation loss: 1.4864567, Validation accuracy: 0.4575000, Time: 07_05_2022__18:45:09\n","Average validation loss: 1.4861227, Average validation accuracy: 0.4574000, Time: 07_05_2022__18:45:12\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcac1741e9b240e998ac6e426047afbe"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 1.4966901, Training accuracy: 0.4625000, Time: 07_05_2022__18:45:32\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 1.5369191, Training accuracy: 0.4425000, Time: 07_05_2022__18:45:53\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 1.5694981, Training accuracy: 0.4275000, Time: 07_05_2022__18:46:14\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 1.5696200, Training accuracy: 0.4312500, Time: 07_05_2022__18:46:34\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 1.5821799, Training accuracy: 0.4270000, Time: 07_05_2022__18:46:55\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 1.5863421, Training accuracy: 0.4266667, Time: 07_05_2022__18:47:15\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 1.5944496, Training accuracy: 0.4228571, Time: 07_05_2022__18:47:36\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 1.5940575, Training accuracy: 0.4218750, Time: 07_05_2022__18:47:57\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 1.5876135, Training accuracy: 0.4241667, Time: 07_05_2022__18:48:17\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 1.5825960, Training accuracy: 0.4265000, Time: 07_05_2022__18:48:38\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 1.5742345, Training accuracy: 0.4293182, Time: 07_05_2022__18:48:59\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 1.5791959, Training accuracy: 0.4254167, Time: 07_05_2022__18:49:19\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 1.5771979, Training accuracy: 0.4271154, Time: 07_05_2022__18:49:40\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 1.5713327, Training accuracy: 0.4300000, Time: 07_05_2022__18:50:00\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 1.5699776, Training accuracy: 0.4306667, Time: 07_05_2022__18:50:21\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 1.5705854, Training accuracy: 0.4289062, Time: 07_05_2022__18:50:42\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 1.5694643, Training accuracy: 0.4295588, Time: 07_05_2022__18:51:02\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 1.5663397, Training accuracy: 0.4305556, Time: 07_05_2022__18:51:23\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 1.5637061, Training accuracy: 0.4297368, Time: 07_05_2022__18:51:44\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 1.5614215, Training accuracy: 0.4313750, Time: 07_05_2022__18:52:04\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 1.5609081, Training accuracy: 0.4319048, Time: 07_05_2022__18:52:25\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 1.5591626, Training accuracy: 0.4339773, Time: 07_05_2022__18:52:45\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 1.5585620, Training accuracy: 0.4340217, Time: 07_05_2022__18:53:06\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 1.5579778, Training accuracy: 0.4333333, Time: 07_05_2022__18:53:27\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 1.5573040, Training accuracy: 0.4341000, Time: 07_05_2022__18:53:47\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 1.5567383, Training accuracy: 0.4345192, Time: 07_05_2022__18:54:08\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 1.5553074, Training accuracy: 0.4333333, Time: 07_05_2022__18:54:28\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 1.5524796, Training accuracy: 0.4345536, Time: 07_05_2022__18:54:49\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 1.5498606, Training accuracy: 0.4351724, Time: 07_05_2022__18:55:10\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 1.5503965, Training accuracy: 0.4347500, Time: 07_05_2022__18:55:30\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 1.5464139, Training accuracy: 0.4354839, Time: 07_05_2022__18:55:51\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 1.5409740, Training accuracy: 0.4385938, Time: 07_05_2022__18:56:12\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 1.5409535, Training accuracy: 0.4381061, Time: 07_05_2022__18:56:32\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 1.5403201, Training accuracy: 0.4376471, Time: 07_05_2022__18:56:53\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 1.5419472, Training accuracy: 0.4362857, Time: 07_05_2022__18:57:13\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 1.5430605, Training accuracy: 0.4359028, Time: 07_05_2022__18:57:34\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 1.5415455, Training accuracy: 0.4366892, Time: 07_05_2022__18:57:55\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 1.5390394, Training accuracy: 0.4384868, Time: 07_05_2022__18:58:15\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 1.5388648, Training accuracy: 0.4394872, Time: 07_05_2022__18:58:36\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 1.5373731, Training accuracy: 0.4403750, Time: 07_05_2022__18:58:56\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 1.5379176, Training accuracy: 0.4409146, Time: 07_05_2022__18:59:17\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 1.5333178, Training accuracy: 0.4427381, Time: 07_05_2022__18:59:38\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 1.5314619, Training accuracy: 0.4436047, Time: 07_05_2022__18:59:58\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 1.5294496, Training accuracy: 0.4446591, Time: 07_05_2022__19:00:19\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 1.5267635, Training accuracy: 0.4457778, Time: 07_05_2022__19:00:40\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 1.5249271, Training accuracy: 0.4464130, Time: 07_05_2022__19:01:00\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 1.5241516, Training accuracy: 0.4466489, Time: 07_05_2022__19:01:21\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 1.5220233, Training accuracy: 0.4478125, Time: 07_05_2022__19:01:41\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 1.5220355, Training accuracy: 0.4476020, Time: 07_05_2022__19:02:02\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 1.5217812, Training accuracy: 0.4478000, Time: 07_05_2022__19:02:23\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 1.5200308, Training accuracy: 0.4487745, Time: 07_05_2022__19:02:43\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 1.5204938, Training accuracy: 0.4483654, Time: 07_05_2022__19:03:04\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 1.5211944, Training accuracy: 0.4484434, Time: 07_05_2022__19:03:25\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 1.5199827, Training accuracy: 0.4493056, Time: 07_05_2022__19:03:45\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 1.5188794, Training accuracy: 0.4495455, Time: 07_05_2022__19:04:06\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 1.5174257, Training accuracy: 0.4495089, Time: 07_05_2022__19:04:26\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 1.5158287, Training accuracy: 0.4501316, Time: 07_05_2022__19:04:47\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 1.5152228, Training accuracy: 0.4500862, Time: 07_05_2022__19:05:08\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 1.5143241, Training accuracy: 0.4503390, Time: 07_05_2022__19:05:28\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 1.5132732, Training accuracy: 0.4502917, Time: 07_05_2022__19:05:49\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 1.5125498, Training accuracy: 0.4502459, Time: 07_05_2022__19:06:10\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 1.5104028, Training accuracy: 0.4509274, Time: 07_05_2022__19:06:30\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 1.5094209, Training accuracy: 0.4514286, Time: 07_05_2022__19:06:51\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 1.5073599, Training accuracy: 0.4525781, Time: 07_05_2022__19:07:11\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 1.5062213, Training accuracy: 0.4530769, Time: 07_05_2022__19:07:32\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 1.5051194, Training accuracy: 0.4540909, Time: 07_05_2022__19:07:53\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 1.5039681, Training accuracy: 0.4542537, Time: 07_05_2022__19:08:13\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 1.5031429, Training accuracy: 0.4547794, Time: 07_05_2022__19:08:34\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 1.5018829, Training accuracy: 0.4554710, Time: 07_05_2022__19:08:55\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 1.5000238, Training accuracy: 0.4564643, Time: 07_05_2022__19:09:15\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 1.5003076, Training accuracy: 0.4565493, Time: 07_05_2022__19:09:36\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 1.4982609, Training accuracy: 0.4574306, Time: 07_05_2022__19:09:57\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 1.4969666, Training accuracy: 0.4580479, Time: 07_05_2022__19:10:17\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 1.4962413, Training accuracy: 0.4580405, Time: 07_05_2022__19:10:38\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 1.4958218, Training accuracy: 0.4583333, Time: 07_05_2022__19:10:59\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 1.4930983, Training accuracy: 0.4591447, Time: 07_05_2022__19:11:19\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 1.4922871, Training accuracy: 0.4596429, Time: 07_05_2022__19:11:40\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 1.4903905, Training accuracy: 0.4604808, Time: 07_05_2022__19:12:00\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 1.4893494, Training accuracy: 0.4610127, Time: 07_05_2022__19:12:21\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 1.4878832, Training accuracy: 0.4618125, Time: 07_05_2022__19:12:42\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 1.4864433, Training accuracy: 0.4623148, Time: 07_05_2022__19:13:02\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 1.4852159, Training accuracy: 0.4629268, Time: 07_05_2022__19:13:23\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 1.4833454, Training accuracy: 0.4636747, Time: 07_05_2022__19:13:44\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 1.4829133, Training accuracy: 0.4640774, Time: 07_05_2022__19:14:04\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 1.4818193, Training accuracy: 0.4648529, Time: 07_05_2022__19:14:25\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 1.4809048, Training accuracy: 0.4651744, Time: 07_05_2022__19:14:46\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 1.4792488, Training accuracy: 0.4659770, Time: 07_05_2022__19:15:06\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 1.4767600, Training accuracy: 0.4670455, Time: 07_05_2022__19:15:27\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 1.4750072, Training accuracy: 0.4679775, Time: 07_05_2022__19:15:47\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 1.4735687, Training accuracy: 0.4685833, Time: 07_05_2022__19:16:08\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 1.4724906, Training accuracy: 0.4689560, Time: 07_05_2022__19:16:29\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 1.4707601, Training accuracy: 0.4698370, Time: 07_05_2022__19:16:49\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 1.4702264, Training accuracy: 0.4698118, Time: 07_05_2022__19:17:10\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 1.4689415, Training accuracy: 0.4702394, Time: 07_05_2022__19:17:31\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 1.4690106, Training accuracy: 0.4705263, Time: 07_05_2022__19:17:51\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 1.4666664, Training accuracy: 0.4712500, Time: 07_05_2022__19:18:12\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 1.4647031, Training accuracy: 0.4721649, Time: 07_05_2022__19:18:32\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 1.4629707, Training accuracy: 0.4729592, Time: 07_05_2022__19:18:53\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 1.4617917, Training accuracy: 0.4734343, Time: 07_05_2022__19:19:14\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 1.4606691, Training accuracy: 0.4738750, Time: 07_05_2022__19:19:34\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 1.4601051, Training accuracy: 0.4742327, Time: 07_05_2022__19:19:55\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 1.4583097, Training accuracy: 0.4750735, Time: 07_05_2022__19:20:16\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 1.4573321, Training accuracy: 0.4755340, Time: 07_05_2022__19:20:36\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 1.4556829, Training accuracy: 0.4762019, Time: 07_05_2022__19:20:57\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 1.4546585, Training accuracy: 0.4767143, Time: 07_05_2022__19:21:17\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 1.4533266, Training accuracy: 0.4774057, Time: 07_05_2022__19:21:38\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 1.4515988, Training accuracy: 0.4782243, Time: 07_05_2022__19:21:59\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 1.4500038, Training accuracy: 0.4788889, Time: 07_05_2022__19:22:19\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 1.4490047, Training accuracy: 0.4789450, Time: 07_05_2022__19:22:40\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 1.4480335, Training accuracy: 0.4795000, Time: 07_05_2022__19:23:01\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 1.4460363, Training accuracy: 0.4800901, Time: 07_05_2022__19:23:21\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 1.4444033, Training accuracy: 0.4804018, Time: 07_05_2022__19:23:42\n","Epoch 4 of 5, Average training loss: 1.4442431, Average training accuracy: 0.4805556, Time: 07_05_2022__19:23:52\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93cb7ba95f034b71ad1b9d745d30d5c9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.1389449, Validation accuracy: 0.5825000, Time: 07_05_2022__19:23:57 | Loss decreased from 1.4440256 to 1.1298723 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.1726810, Validation accuracy: 0.5700000, Time: 07_05_2022__19:24:05\n","Step: 300 of 1250, Validation loss: 1.1927682, Validation accuracy: 0.5775000, Time: 07_05_2022__19:24:10\n","Step: 400 of 1250, Validation loss: 1.2001509, Validation accuracy: 0.5825000, Time: 07_05_2022__19:24:16\n","Step: 500 of 1250, Validation loss: 1.2105322, Validation accuracy: 0.5755000, Time: 07_05_2022__19:24:21\n","Step: 600 of 1250, Validation loss: 1.1986499, Validation accuracy: 0.5791667, Time: 07_05_2022__19:24:26\n","Step: 700 of 1250, Validation loss: 1.1896017, Validation accuracy: 0.5821429, Time: 07_05_2022__19:24:31\n","Step: 800 of 1250, Validation loss: 1.1806287, Validation accuracy: 0.5843750, Time: 07_05_2022__19:24:36\n","Step: 900 of 1250, Validation loss: 1.1799205, Validation accuracy: 0.5847222, Time: 07_05_2022__19:24:41\n","Step: 1000 of 1250, Validation loss: 1.1809466, Validation accuracy: 0.5822500, Time: 07_05_2022__19:24:46\n","Step: 1100 of 1250, Validation loss: 1.1819754, Validation accuracy: 0.5804545, Time: 07_05_2022__19:24:52\n","Step: 1200 of 1250, Validation loss: 1.1840835, Validation accuracy: 0.5810417, Time: 07_05_2022__19:24:57\n","Average validation loss: 1.1852298, Average validation accuracy: 0.5798000, Time: 07_05_2022__19:24:59\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d696b25acce45e498e6435c7dd3e3a7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 1.1819633, Training accuracy: 0.5825000, Time: 07_05_2022__19:25:20\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 1.2306964, Training accuracy: 0.5600000, Time: 07_05_2022__19:25:40\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 1.2682988, Training accuracy: 0.5458333, Time: 07_05_2022__19:26:01\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 1.2407408, Training accuracy: 0.5568750, Time: 07_05_2022__19:26:22\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 1.2487418, Training accuracy: 0.5520000, Time: 07_05_2022__19:26:42\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 1.2584894, Training accuracy: 0.5458333, Time: 07_05_2022__19:27:03\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 1.2587920, Training accuracy: 0.5446429, Time: 07_05_2022__19:27:24\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 1.2546452, Training accuracy: 0.5459375, Time: 07_05_2022__19:27:44\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 1.2520488, Training accuracy: 0.5505556, Time: 07_05_2022__19:28:05\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 1.2480754, Training accuracy: 0.5530000, Time: 07_05_2022__19:28:26\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 1.2444490, Training accuracy: 0.5534091, Time: 07_05_2022__19:28:46\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 1.2506766, Training accuracy: 0.5502083, Time: 07_05_2022__19:29:07\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 1.2473338, Training accuracy: 0.5532692, Time: 07_05_2022__19:29:27\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 1.2485323, Training accuracy: 0.5544643, Time: 07_05_2022__19:29:48\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 1.2540153, Training accuracy: 0.5515000, Time: 07_05_2022__19:30:09\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 1.2483084, Training accuracy: 0.5534375, Time: 07_05_2022__19:30:29\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 1.2494001, Training accuracy: 0.5535294, Time: 07_05_2022__19:30:50\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 1.2465726, Training accuracy: 0.5536111, Time: 07_05_2022__19:31:11\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 1.2455409, Training accuracy: 0.5542105, Time: 07_05_2022__19:31:31\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 1.2438838, Training accuracy: 0.5547500, Time: 07_05_2022__19:31:52\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 1.2395498, Training accuracy: 0.5566667, Time: 07_05_2022__19:32:13\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 1.2378671, Training accuracy: 0.5578409, Time: 07_05_2022__19:32:33\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 1.2361637, Training accuracy: 0.5593478, Time: 07_05_2022__19:32:54\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 1.2311455, Training accuracy: 0.5611458, Time: 07_05_2022__19:33:15\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 1.2295793, Training accuracy: 0.5625000, Time: 07_05_2022__19:33:35\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 1.2301184, Training accuracy: 0.5628846, Time: 07_05_2022__19:33:56\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 1.2291057, Training accuracy: 0.5637963, Time: 07_05_2022__19:34:17\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 1.2287883, Training accuracy: 0.5638393, Time: 07_05_2022__19:34:37\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 1.2280493, Training accuracy: 0.5648276, Time: 07_05_2022__19:34:58\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 1.2268191, Training accuracy: 0.5645833, Time: 07_05_2022__19:35:18\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 1.2248180, Training accuracy: 0.5655645, Time: 07_05_2022__19:35:39\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 1.2204754, Training accuracy: 0.5669531, Time: 07_05_2022__19:36:00\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 1.2218103, Training accuracy: 0.5660606, Time: 07_05_2022__19:36:20\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 1.2216890, Training accuracy: 0.5662500, Time: 07_05_2022__19:36:41\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 1.2202363, Training accuracy: 0.5665000, Time: 07_05_2022__19:37:02\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 1.2216402, Training accuracy: 0.5663889, Time: 07_05_2022__19:37:22\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 1.2207585, Training accuracy: 0.5671622, Time: 07_05_2022__19:37:43\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 1.2201860, Training accuracy: 0.5678947, Time: 07_05_2022__19:38:04\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 1.2181979, Training accuracy: 0.5698077, Time: 07_05_2022__19:38:24\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 1.2163008, Training accuracy: 0.5705000, Time: 07_05_2022__19:38:45\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 1.2166398, Training accuracy: 0.5707927, Time: 07_05_2022__19:39:06\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 1.2127031, Training accuracy: 0.5723214, Time: 07_05_2022__19:39:26\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 1.2109446, Training accuracy: 0.5732558, Time: 07_05_2022__19:39:47\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 1.2093716, Training accuracy: 0.5738636, Time: 07_05_2022__19:40:08\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 1.2088770, Training accuracy: 0.5749444, Time: 07_05_2022__19:40:28\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 1.2090880, Training accuracy: 0.5747826, Time: 07_05_2022__19:40:49\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 1.2085420, Training accuracy: 0.5751064, Time: 07_05_2022__19:41:10\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 1.2066324, Training accuracy: 0.5758854, Time: 07_05_2022__19:41:30\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 1.2061526, Training accuracy: 0.5758673, Time: 07_05_2022__19:41:51\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 1.2052770, Training accuracy: 0.5766000, Time: 07_05_2022__19:42:12\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 1.2054923, Training accuracy: 0.5769118, Time: 07_05_2022__19:42:32\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 1.2047122, Training accuracy: 0.5768269, Time: 07_05_2022__19:42:53\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 1.2047974, Training accuracy: 0.5769340, Time: 07_05_2022__19:43:14\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 1.2030524, Training accuracy: 0.5775000, Time: 07_05_2022__19:43:34\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 1.2025114, Training accuracy: 0.5778636, Time: 07_05_2022__19:43:55\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 1.2014794, Training accuracy: 0.5777232, Time: 07_05_2022__19:44:16\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 1.2005033, Training accuracy: 0.5776316, Time: 07_05_2022__19:44:36\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 1.1995322, Training accuracy: 0.5775862, Time: 07_05_2022__19:44:57\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 1.1991211, Training accuracy: 0.5780508, Time: 07_05_2022__19:45:17\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 1.1987346, Training accuracy: 0.5783750, Time: 07_05_2022__19:45:38\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 1.1980921, Training accuracy: 0.5789754, Time: 07_05_2022__19:45:59\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 1.1960139, Training accuracy: 0.5799194, Time: 07_05_2022__19:46:20\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 1.1954320, Training accuracy: 0.5800000, Time: 07_05_2022__19:46:40\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 1.1938593, Training accuracy: 0.5805469, Time: 07_05_2022__19:47:01\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 1.1921473, Training accuracy: 0.5811538, Time: 07_05_2022__19:47:21\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 1.1906346, Training accuracy: 0.5816288, Time: 07_05_2022__19:47:42\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 1.1894793, Training accuracy: 0.5819403, Time: 07_05_2022__19:48:03\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 1.1879681, Training accuracy: 0.5824265, Time: 07_05_2022__19:48:23\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 1.1859932, Training accuracy: 0.5831159, Time: 07_05_2022__19:48:44\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 1.1845588, Training accuracy: 0.5840714, Time: 07_05_2022__19:49:05\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 1.1851461, Training accuracy: 0.5841197, Time: 07_05_2022__19:49:25\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 1.1837759, Training accuracy: 0.5844097, Time: 07_05_2022__19:49:46\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 1.1830183, Training accuracy: 0.5845548, Time: 07_05_2022__19:50:07\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 1.1816192, Training accuracy: 0.5849662, Time: 07_05_2022__19:50:27\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 1.1801597, Training accuracy: 0.5857000, Time: 07_05_2022__19:50:48\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 1.1784094, Training accuracy: 0.5863158, Time: 07_05_2022__19:51:09\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 1.1784338, Training accuracy: 0.5864610, Time: 07_05_2022__19:51:29\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 1.1779958, Training accuracy: 0.5868590, Time: 07_05_2022__19:51:50\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 1.1761483, Training accuracy: 0.5875949, Time: 07_05_2022__19:52:11\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 1.1746084, Training accuracy: 0.5879062, Time: 07_05_2022__19:52:31\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 1.1737518, Training accuracy: 0.5883642, Time: 07_05_2022__19:52:52\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 1.1732311, Training accuracy: 0.5887805, Time: 07_05_2022__19:53:13\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 1.1716025, Training accuracy: 0.5892470, Time: 07_05_2022__19:53:33\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 1.1719243, Training accuracy: 0.5888690, Time: 07_05_2022__19:53:54\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 1.1712172, Training accuracy: 0.5890588, Time: 07_05_2022__19:54:15\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 1.1709330, Training accuracy: 0.5894477, Time: 07_05_2022__19:54:35\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 1.1702801, Training accuracy: 0.5897701, Time: 07_05_2022__19:54:56\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 1.1681638, Training accuracy: 0.5907386, Time: 07_05_2022__19:55:17\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 1.1660890, Training accuracy: 0.5915169, Time: 07_05_2022__19:55:37\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 1.1641633, Training accuracy: 0.5924167, Time: 07_05_2022__19:55:58\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 1.1630485, Training accuracy: 0.5929945, Time: 07_05_2022__19:56:18\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 1.1616295, Training accuracy: 0.5937228, Time: 07_05_2022__19:56:39\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 1.1608480, Training accuracy: 0.5943280, Time: 07_05_2022__19:57:00\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 1.1605979, Training accuracy: 0.5944149, Time: 07_05_2022__19:57:20\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 1.1609785, Training accuracy: 0.5947105, Time: 07_05_2022__19:57:41\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 1.1589849, Training accuracy: 0.5954948, Time: 07_05_2022__19:58:02\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 1.1567536, Training accuracy: 0.5963402, Time: 07_05_2022__19:58:22\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 1.1548135, Training accuracy: 0.5969898, Time: 07_05_2022__19:58:43\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 1.1543331, Training accuracy: 0.5970960, Time: 07_05_2022__19:59:04\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 1.1537331, Training accuracy: 0.5975500, Time: 07_05_2022__19:59:24\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 1.1534262, Training accuracy: 0.5975000, Time: 07_05_2022__19:59:45\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 1.1522354, Training accuracy: 0.5977206, Time: 07_05_2022__20:00:06\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 1.1505862, Training accuracy: 0.5982767, Time: 07_05_2022__20:00:26\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 1.1497517, Training accuracy: 0.5985096, Time: 07_05_2022__20:00:47\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 1.1488265, Training accuracy: 0.5991429, Time: 07_05_2022__20:01:08\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 1.1479648, Training accuracy: 0.5994340, Time: 07_05_2022__20:01:28\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 1.1461849, Training accuracy: 0.6000234, Time: 07_05_2022__20:01:49\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 1.1449507, Training accuracy: 0.6005556, Time: 07_05_2022__20:02:10\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 1.1443007, Training accuracy: 0.6009174, Time: 07_05_2022__20:02:30\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 1.1429471, Training accuracy: 0.6012955, Time: 07_05_2022__20:02:51\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 1.1409547, Training accuracy: 0.6020270, Time: 07_05_2022__20:03:12\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 1.1398117, Training accuracy: 0.6024330, Time: 07_05_2022__20:03:32\n","Epoch 5 of 5, Average training loss: 1.1400679, Average training accuracy: 0.6023778, Time: 07_05_2022__20:03:43\n","###################### Validating vgg19_batch_norm SGD, lr_0.01, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ce5038050a24edfb4cdecda31d22f50"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.9180337, Validation accuracy: 0.6775000, Time: 07_05_2022__20:03:48 | Loss decreased from 1.1298723 to 0.9115967 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.9282786, Validation accuracy: 0.6775000, Time: 07_05_2022__20:03:55\n","Step: 300 of 1250, Validation loss: 0.9408072, Validation accuracy: 0.6808333, Time: 07_05_2022__20:04:01\n","Step: 400 of 1250, Validation loss: 0.9425576, Validation accuracy: 0.6850000, Time: 07_05_2022__20:04:06\n","Step: 500 of 1250, Validation loss: 0.9506088, Validation accuracy: 0.6820000, Time: 07_05_2022__20:04:11\n","Step: 600 of 1250, Validation loss: 0.9470497, Validation accuracy: 0.6808333, Time: 07_05_2022__20:04:16\n","Step: 700 of 1250, Validation loss: 0.9384666, Validation accuracy: 0.6828571, Time: 07_05_2022__20:04:21\n","Step: 800 of 1250, Validation loss: 0.9269408, Validation accuracy: 0.6853125, Time: 07_05_2022__20:04:26\n","Step: 900 of 1250, Validation loss: 0.9336310, Validation accuracy: 0.6844444, Time: 07_05_2022__20:04:31\n","Step: 1000 of 1250, Validation loss: 0.9376958, Validation accuracy: 0.6815000, Time: 07_05_2022__20:04:36\n","Step: 1100 of 1250, Validation loss: 0.9374700, Validation accuracy: 0.6815909, Time: 07_05_2022__20:04:42\n","Step: 1200 of 1250, Validation loss: 0.9433658, Validation accuracy: 0.6800000, Time: 07_05_2022__20:04:47\n","Average validation loss: 0.9398120, Average validation accuracy: 0.6816000, Time: 07_05_2022__20:04:49\n","###################### Testing vgg19_batch_norm SGD, lr_0.01, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aa07520f53c4d1aa7530837e17088d7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.6875000, Time: 07_05_2022__20:05:03\n","Step: 200 of 2500, Test accuracy: 0.6862500, Time: 07_05_2022__20:05:08\n","Step: 300 of 2500, Test accuracy: 0.6850000, Time: 07_05_2022__20:05:13\n","Step: 400 of 2500, Test accuracy: 0.6750000, Time: 07_05_2022__20:05:18\n","Step: 500 of 2500, Test accuracy: 0.6680000, Time: 07_05_2022__20:05:23\n","Step: 600 of 2500, Test accuracy: 0.6675000, Time: 07_05_2022__20:05:28\n","Step: 700 of 2500, Test accuracy: 0.6660714, Time: 07_05_2022__20:05:34\n","Step: 800 of 2500, Test accuracy: 0.6681250, Time: 07_05_2022__20:05:39\n","Step: 900 of 2500, Test accuracy: 0.6666667, Time: 07_05_2022__20:05:44\n","Step: 1000 of 2500, Test accuracy: 0.6680000, Time: 07_05_2022__20:05:49\n","Step: 1100 of 2500, Test accuracy: 0.6715909, Time: 07_05_2022__20:05:54\n","Step: 1200 of 2500, Test accuracy: 0.6741667, Time: 07_05_2022__20:05:59\n","Step: 1300 of 2500, Test accuracy: 0.6761538, Time: 07_05_2022__20:06:04\n","Step: 1400 of 2500, Test accuracy: 0.6758929, Time: 07_05_2022__20:06:09\n","Step: 1500 of 2500, Test accuracy: 0.6761667, Time: 07_05_2022__20:06:14\n","Step: 1600 of 2500, Test accuracy: 0.6756250, Time: 07_05_2022__20:06:20\n","Step: 1700 of 2500, Test accuracy: 0.6776471, Time: 07_05_2022__20:06:25\n","Step: 1800 of 2500, Test accuracy: 0.6769444, Time: 07_05_2022__20:06:30\n","Step: 1900 of 2500, Test accuracy: 0.6773684, Time: 07_05_2022__20:06:35\n","Step: 2000 of 2500, Test accuracy: 0.6766250, Time: 07_05_2022__20:06:40\n","Step: 2100 of 2500, Test accuracy: 0.6757143, Time: 07_05_2022__20:06:45\n","Step: 2200 of 2500, Test accuracy: 0.6754545, Time: 07_05_2022__20:06:50\n","Step: 2300 of 2500, Test accuracy: 0.6766304, Time: 07_05_2022__20:06:55\n","Step: 2400 of 2500, Test accuracy: 0.6766667, Time: 07_05_2022__20:07:01\n","Step: 2500 of 2500, Test accuracy: 0.6752000, Time: 07_05_2022__20:07:06\n","Average testing accuracy: 0.6752000, Time: 07_05_2022__20:07:06\n","###################### Training vgg19_batch_norm SGD, lr_0.001, momentum_0 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9931f939ac14045a2979a0f8b114c53"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 2.4943796, Training accuracy: 0.1000000, Time: 07_05_2022__20:07:27\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 2.4559565, Training accuracy: 0.1125000, Time: 07_05_2022__20:07:47\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 2.4331661, Training accuracy: 0.1208333, Time: 07_05_2022__20:08:07\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 2.4002925, Training accuracy: 0.1437500, Time: 07_05_2022__20:08:26\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 2.3725303, Training accuracy: 0.1505000, Time: 07_05_2022__20:08:46\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 2.3560750, Training accuracy: 0.1533333, Time: 07_05_2022__20:09:06\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.3351648, Training accuracy: 0.1603571, Time: 07_05_2022__20:09:25\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.3172936, Training accuracy: 0.1618750, Time: 07_05_2022__20:09:45\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.3069272, Training accuracy: 0.1655556, Time: 07_05_2022__20:10:04\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.2954851, Training accuracy: 0.1672500, Time: 07_05_2022__20:10:24\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.2812137, Training accuracy: 0.1722727, Time: 07_05_2022__20:10:44\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.2659617, Training accuracy: 0.1783333, Time: 07_05_2022__20:11:03\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.2509886, Training accuracy: 0.1842308, Time: 07_05_2022__20:11:23\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.2355223, Training accuracy: 0.1871429, Time: 07_05_2022__20:11:42\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.2264556, Training accuracy: 0.1903333, Time: 07_05_2022__20:12:02\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.2171841, Training accuracy: 0.1926563, Time: 07_05_2022__20:12:22\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.2048611, Training accuracy: 0.1967647, Time: 07_05_2022__20:12:41\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.1927441, Training accuracy: 0.2018056, Time: 07_05_2022__20:13:01\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.1810302, Training accuracy: 0.2061842, Time: 07_05_2022__20:13:20\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.1717671, Training accuracy: 0.2101250, Time: 07_05_2022__20:13:40\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.1608465, Training accuracy: 0.2133333, Time: 07_05_2022__20:14:00\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.1513157, Training accuracy: 0.2165909, Time: 07_05_2022__20:14:19\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.1408846, Training accuracy: 0.2208696, Time: 07_05_2022__20:14:39\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.1296140, Training accuracy: 0.2250000, Time: 07_05_2022__20:14:58\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.1190435, Training accuracy: 0.2284000, Time: 07_05_2022__20:15:18\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.1086704, Training accuracy: 0.2324038, Time: 07_05_2022__20:15:38\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.0989907, Training accuracy: 0.2360185, Time: 07_05_2022__20:15:57\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.0906054, Training accuracy: 0.2395536, Time: 07_05_2022__20:16:17\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.0840422, Training accuracy: 0.2409483, Time: 07_05_2022__20:16:36\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.0758924, Training accuracy: 0.2437500, Time: 07_05_2022__20:16:56\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.0659682, Training accuracy: 0.2466129, Time: 07_05_2022__20:17:16\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.0576002, Training accuracy: 0.2489844, Time: 07_05_2022__20:17:35\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.0534249, Training accuracy: 0.2507576, Time: 07_05_2022__20:17:55\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.0469975, Training accuracy: 0.2520588, Time: 07_05_2022__20:18:14\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.0406420, Training accuracy: 0.2546429, Time: 07_05_2022__20:18:34\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.0355614, Training accuracy: 0.2560417, Time: 07_05_2022__20:18:54\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.0313100, Training accuracy: 0.2577703, Time: 07_05_2022__20:19:13\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.0257727, Training accuracy: 0.2596711, Time: 07_05_2022__20:19:33\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.0205254, Training accuracy: 0.2616667, Time: 07_05_2022__20:19:52\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.0158206, Training accuracy: 0.2638125, Time: 07_05_2022__20:20:12\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.0117004, Training accuracy: 0.2651220, Time: 07_05_2022__20:20:32\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.0050401, Training accuracy: 0.2678571, Time: 07_05_2022__20:20:51\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 1.9998368, Training accuracy: 0.2696512, Time: 07_05_2022__20:21:11\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 1.9931953, Training accuracy: 0.2715909, Time: 07_05_2022__20:21:30\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 1.9868530, Training accuracy: 0.2735556, Time: 07_05_2022__20:21:50\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 1.9822772, Training accuracy: 0.2750543, Time: 07_05_2022__20:22:09\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 1.9771888, Training accuracy: 0.2765426, Time: 07_05_2022__20:22:29\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 1.9732784, Training accuracy: 0.2785417, Time: 07_05_2022__20:22:49\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 1.9694774, Training accuracy: 0.2798469, Time: 07_05_2022__20:23:08\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 1.9662727, Training accuracy: 0.2814000, Time: 07_05_2022__20:23:28\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 1.9605818, Training accuracy: 0.2831373, Time: 07_05_2022__20:23:47\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 1.9581671, Training accuracy: 0.2842788, Time: 07_05_2022__20:24:07\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 1.9547986, Training accuracy: 0.2858491, Time: 07_05_2022__20:24:27\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 1.9511493, Training accuracy: 0.2872222, Time: 07_05_2022__20:24:46\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 1.9467821, Training accuracy: 0.2890455, Time: 07_05_2022__20:25:06\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 1.9437645, Training accuracy: 0.2900000, Time: 07_05_2022__20:25:25\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 1.9395704, Training accuracy: 0.2917544, Time: 07_05_2022__20:25:45\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 1.9366375, Training accuracy: 0.2928448, Time: 07_05_2022__20:26:05\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 1.9331814, Training accuracy: 0.2949153, Time: 07_05_2022__20:26:24\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 1.9289183, Training accuracy: 0.2962083, Time: 07_05_2022__20:26:44\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 1.9258916, Training accuracy: 0.2972131, Time: 07_05_2022__20:27:03\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 1.9218507, Training accuracy: 0.2982661, Time: 07_05_2022__20:27:23\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 1.9181304, Training accuracy: 0.2995635, Time: 07_05_2022__20:27:43\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 1.9152358, Training accuracy: 0.3005078, Time: 07_05_2022__20:28:02\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 1.9106620, Training accuracy: 0.3021538, Time: 07_05_2022__20:28:22\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 1.9081575, Training accuracy: 0.3031818, Time: 07_05_2022__20:28:41\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 1.9047863, Training accuracy: 0.3042537, Time: 07_05_2022__20:29:01\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 1.9024538, Training accuracy: 0.3052574, Time: 07_05_2022__20:29:20\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 1.8990019, Training accuracy: 0.3065580, Time: 07_05_2022__20:29:40\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 1.8951913, Training accuracy: 0.3077857, Time: 07_05_2022__20:30:00\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 1.8922224, Training accuracy: 0.3086268, Time: 07_05_2022__20:30:19\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 1.8887101, Training accuracy: 0.3097917, Time: 07_05_2022__20:30:39\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 1.8858480, Training accuracy: 0.3104795, Time: 07_05_2022__20:30:58\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 1.8837502, Training accuracy: 0.3116554, Time: 07_05_2022__20:31:18\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 1.8815440, Training accuracy: 0.3121333, Time: 07_05_2022__20:31:38\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 1.8793142, Training accuracy: 0.3130263, Time: 07_05_2022__20:31:57\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 1.8761618, Training accuracy: 0.3144481, Time: 07_05_2022__20:32:17\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 1.8727300, Training accuracy: 0.3155769, Time: 07_05_2022__20:32:36\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 1.8700783, Training accuracy: 0.3164241, Time: 07_05_2022__20:32:56\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 1.8672349, Training accuracy: 0.3174375, Time: 07_05_2022__20:33:15\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 1.8647018, Training accuracy: 0.3182407, Time: 07_05_2022__20:33:35\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 1.8629871, Training accuracy: 0.3189939, Time: 07_05_2022__20:33:55\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 1.8595494, Training accuracy: 0.3203916, Time: 07_05_2022__20:34:14\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 1.8569811, Training accuracy: 0.3214286, Time: 07_05_2022__20:34:34\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 1.8543873, Training accuracy: 0.3224118, Time: 07_05_2022__20:34:53\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 1.8511239, Training accuracy: 0.3236919, Time: 07_05_2022__20:35:13\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 1.8488946, Training accuracy: 0.3244828, Time: 07_05_2022__20:35:33\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 1.8453431, Training accuracy: 0.3258807, Time: 07_05_2022__20:35:52\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 1.8427587, Training accuracy: 0.3268539, Time: 07_05_2022__20:36:12\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 1.8403688, Training accuracy: 0.3276944, Time: 07_05_2022__20:36:32\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 1.8379231, Training accuracy: 0.3285989, Time: 07_05_2022__20:36:51\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 1.8349410, Training accuracy: 0.3298641, Time: 07_05_2022__20:37:11\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 1.8327142, Training accuracy: 0.3307527, Time: 07_05_2022__20:37:30\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 1.8310623, Training accuracy: 0.3313564, Time: 07_05_2022__20:37:50\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 1.8301671, Training accuracy: 0.3318947, Time: 07_05_2022__20:38:09\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 1.8274454, Training accuracy: 0.3328646, Time: 07_05_2022__20:38:29\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 1.8235758, Training accuracy: 0.3344845, Time: 07_05_2022__20:38:49\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 1.8207053, Training accuracy: 0.3356122, Time: 07_05_2022__20:39:08\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 1.8188766, Training accuracy: 0.3363131, Time: 07_05_2022__20:39:28\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 1.8170218, Training accuracy: 0.3371250, Time: 07_05_2022__20:39:47\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 1.8157362, Training accuracy: 0.3377228, Time: 07_05_2022__20:40:07\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 1.8137238, Training accuracy: 0.3385539, Time: 07_05_2022__20:40:27\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 1.8114731, Training accuracy: 0.3395388, Time: 07_05_2022__20:40:46\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 1.8087146, Training accuracy: 0.3406010, Time: 07_05_2022__20:41:06\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 1.8071481, Training accuracy: 0.3414048, Time: 07_05_2022__20:41:25\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 1.8052221, Training accuracy: 0.3418396, Time: 07_05_2022__20:41:45\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 1.8033185, Training accuracy: 0.3423598, Time: 07_05_2022__20:42:05\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 1.8009831, Training accuracy: 0.3434028, Time: 07_05_2022__20:42:24\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 1.7998499, Training accuracy: 0.3439450, Time: 07_05_2022__20:42:44\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 1.7981204, Training accuracy: 0.3445000, Time: 07_05_2022__20:43:03\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 1.7955394, Training accuracy: 0.3455405, Time: 07_05_2022__20:43:23\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 1.7943176, Training accuracy: 0.3458929, Time: 07_05_2022__20:43:43\n","Epoch 1 of 5, Average training loss: 1.7935851, Average training accuracy: 0.3460444, Time: 07_05_2022__20:43:52\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4cfa05b8fe64d32816fbe3143dc3798"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.4568086, Validation accuracy: 0.4775000, Time: 07_05_2022__20:43:58 | Loss decreased from inf to 1.4565268 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.4466892, Validation accuracy: 0.4762500, Time: 07_05_2022__20:44:05 | Loss decreased from 1.4565268 to 1.4494065 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.4721930, Validation accuracy: 0.4575000, Time: 07_05_2022__20:44:12\n","Step: 400 of 1250, Validation loss: 1.4652821, Validation accuracy: 0.4631250, Time: 07_05_2022__20:44:18\n","Step: 500 of 1250, Validation loss: 1.4661676, Validation accuracy: 0.4680000, Time: 07_05_2022__20:44:23\n","Step: 600 of 1250, Validation loss: 1.4586979, Validation accuracy: 0.4700000, Time: 07_05_2022__20:44:28\n","Step: 700 of 1250, Validation loss: 1.4509881, Validation accuracy: 0.4800000, Time: 07_05_2022__20:44:33\n","Step: 800 of 1250, Validation loss: 1.4404687, Validation accuracy: 0.4856250, Time: 07_05_2022__20:44:39 | Loss decreased from 1.4494065 to 1.4414845 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.4427277, Validation accuracy: 0.4861111, Time: 07_05_2022__20:44:46\n","Step: 1000 of 1250, Validation loss: 1.4463085, Validation accuracy: 0.4825000, Time: 07_05_2022__20:44:52\n","Step: 1100 of 1250, Validation loss: 1.4493410, Validation accuracy: 0.4797727, Time: 07_05_2022__20:44:57\n","Step: 1200 of 1250, Validation loss: 1.4522838, Validation accuracy: 0.4783333, Time: 07_05_2022__20:45:02\n","Average validation loss: 1.4517681, Average validation accuracy: 0.4784000, Time: 07_05_2022__20:45:05\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bf44792175d4dea8788fce8a478216c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.5088709, Training accuracy: 0.4600000, Time: 07_05_2022__20:45:24\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.5490343, Training accuracy: 0.4437500, Time: 07_05_2022__20:45:44\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.5568463, Training accuracy: 0.4391667, Time: 07_05_2022__20:46:03\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.5469770, Training accuracy: 0.4443750, Time: 07_05_2022__20:46:23\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.5498705, Training accuracy: 0.4415000, Time: 07_05_2022__20:46:43\n"]}],"source":["#-- Parameters\n","epochs = 5\n","\n","for learning_rate in [0.1, 0.01, 0.001, 0.0001]:\n","  for mom in [0, 0.3, 0.6, 0.9]:\n","    #-- Freeze the randomness\n","    seed()\n","    model = vgg19_bn(pretrained=False)\n","    model_name = 'vgg19_batch_norm'\n","\n","    lr = learning_rate\n","    momentum = mom\n","    parameters = 'SGD, lr_{}, momentum_{}'.format(lr, momentum)\n","\n","    #-- Initiating a tensorboard writer that contains all logs for training, validation, and testing\n","    tb_writer = SummaryWriter('./models/CIFAR/runs', filename_suffix='_'+model_name+'_'+parameters)\n","\n","    #-- Create the model's critrion loss function and a optimization function \n","    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","\n","    #-- Train and valiate the model\n","    model, model_save_path = model_train(model, model_name, lr, momentum, optimizer, epochs, tb_writer, parameters)\n","\n","    #-- Load the best saved model for testing\n","    model.load_state_dict(torch.load(model_save_path))\n","    model.to(device)\n","\n","    #-- Set the model mode to evaluation to prepare for testing\n","    model.eval()\n","    model_test(model, model_name, tb_writer, parameters) \n","\n","    #-- Close the Tensoboard writer\n","    tb_writer.close()\n","\n","    #-- Delete the model\n","    del model"]},{"cell_type":"markdown","source":["## Part 3"],"metadata":{"id":"aLakPbHTLjwU"},"id":"aLakPbHTLjwU"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["245239c786314c19bd027d2fff05282d","426be35f61424af2a36c3ddab83c4e85","e91f6d818fbb462eb864618ae2cdfc0b","0a520bcbcd8d4cabae3bd3a4d3c5e654","da49d404f01e43378327ea409e066c06","b513fc79696b4fdca457d75a3b2b55af","869d44bff5bf4c7886076b97c0549c06","400c677f1e534aa3bfbfb3aca71fb65d","b1e6cd0e328541c78e171a662f6e0eee","6394175b99fa4725babee4d94160e0e7","cb8d01ef5e0c4666983701599ec8fea8","96bc5d7068f94b40b22b49f2412405d7","a665e2fc537d4d118a6d89ee47998b68","2c20d6110de4436fa51fa4454c0f0c13","d672a3eff71049178c719016795fb29a","10a14791f0f14c5bbcf167f3e6e1d507","d8c1eb62e5d14058b354b9b8d62fbdd5","bc09199419264af295238041e378c2a5","671858cff7ed406c9575219a9cb59bca","92b9dcbbedc04f5aa88bcf31b4d92a34","3e76a1d57c2b42baab5fc3e0c0b8a71f","847a16ef6176467785200f0a2b5d6084","0e7d864df1ad4a0f8cf93655d6e3cfe0","449ef27281a343588ffbe04b48881810","676269416c5a4106815de43d886eb97c","7fdb48b8c0014e5895abf4889fb0ba2c","12103cd95df342d39aeda80ca6732434","addf07fbce8243c0b5da686f1650d3ac","755123156d6c40248db8af4674f9a770","a53fb47e110c49a294a4261604fb2969","f9de3af4885f481fad62725b5109d8b7","c52fd9395ab446d9b484adfb3ee71978","da46faa0abfc4d3fae8668677b4cae31","a88403a3640d48b2994c77351c85b7d4","9cf32867b75f4220841e02645f548a48","ebd5521b2b394d8c92f0d4ee8add2d3d","36933f815d1f484c96d2d0ad28ad019f","fa5e42b4037348a69312b134bdb7f338","217e9f7c7446468d83a373def6af4312","25284b0f879042b38008452fb3e73660","6990795dc86c499a8a523f1f5f6dd5c5","4f66a65955444df2b0007f9798ec1379","5f3a7a3b61ef4a19b14678a2617e7deb","587e9d4e691e44359a75e8e640b317e3","22a3e587ca604996a5a16fd0ab937b2b","f1f3f818158b478491e421712eb16e83","6d4abbc9345c4a6084a448d91a02fda9","bb37e99178314f4386751070fc5d8b3e","011584cf6b4441b180a8992d4f7660ff","4325c207af504f2cacc2b75d5e24bdde","21b90e2b2887465089cee9e368f0872e","5ec165beb955423aa58744704ff1d277","9433f72ffa5c49688a091aa85e765d0a","05e799f2e6d24ca286bbeb2f51ade629","7690613364334148b4d7870357e6de69","e0846d20f867408aae16d2120f5163fd","36ed31de641649d5a4fb4c971a4b70c8","74e92a6e29794a96b3ef2aa00ce8992f","a781984173bc4900b78cac323a91da9f","14f4fbdd99ad4abbbc5c0228cf91027e","33221bb5347744cb9e8b8dfaa6eef5e2","233926e219c244299d1449e7e455798a","c1cf9259024048d7866fbb8010f01bcd","823e4fd51aed4b1aaf43aa5ab49431b9","8a010939cc3d4f7292ed7e000f7d3bc8","f4b97198055e4f429a007e8215afb754","b5be73bcaba241fc871da0a5299e2f87","9bf84eae03fc4208931b37ae60cceacc","90267246c41448a9aa00f9de0b323b9e","d154533fec894ec192f9bbae815294e0","0018275773ce40338932e0ebe1fe3a98","b4372b6947824511b17a92ff4301b6f2","0ad5207ab3274581814c3f752987c030","5b04a1b841b040b49d54a8909f75edee","aa0c928ddca74f84ba983ad1cd69ff01","9f37c32871dc46deb68023ff152a7508","31c9d4ccd7bd413e853dbdd5d14fec29","49f22b7371b045db80c5ac93f066ba25","04adb26a464141a499eb932476d8ad0f","7d430486b46a439ca24d6f5232eb6063","908fd9491b054e2cbfca992e99758a4d","fde745ccb5a84f39a4199863bcb680a8","4c3fa1d0d48c420f83a40fca38e04c1e","68ae924f3c3349808c3af17254849903","f330d5a32ba4443e861cb65903733fff","acabd71c08bc461a8e5fd54d59de55f6","df3a0b6180cf48c491a764dc84da1f87","97757ea7bf1f48d9a915f20ddd822a50","b7eede6a5f624c59962803af1fc83384","5888c484fae14cde9a0759071afc34e3","d998d961b37c47e28821e4412ddf6757","77354059391347d29f495c7a70def69b","a4f27db6589647fca9c9ac8809d048cf","92c734ec55d5418290c76e138910f268","46e9dbd87aa548ec9ed99e6bc07e2e12","977589dc2c1b482fbe5506d99d4054c8","b336c71a9a9a42e5909af7c39d12a677","747f7fc8562444039a099f6e3ebc1c0c","3800c050eb9a42e0bd22b425c1c2c5a0","5a3c867f2d9241ce84a06407bf6554cc","069a9020a8d54dbaa0990895eaa9ce6d","68cd6d7ec57345b7ac3524e08a0ebadc","2d69d475fb1246c18247c6d86fb1d75f","6642026ed07f4fbba7f47de9a2d5740c","6a16a7b53ec6484e9e4a4ebf2b6275e7","4e2d49467b7a4852818c37a67ea5d686","6904b66e9094494790ab81c60ac4a11b","26167b0b342b4e38a57e10c08dc9f514","80844747f8a145729a2afdddf911474b","75390fabf0e34fd398196e257cc964a2","b0cdf6a173954b48a4b87a2f6a84f854","5c48127158b345408135facc7677a44c","dff2bfb30de44916898fb60d0fddf688","9c92971476434faa8bc653ea71e42ed0","d738ab3ef8814506865c138615547d0b","578c5aaa059749beaedce566d656498d","cb0fbd3598cb4fe99518659f11aa29b8","cca696418e82478bb931e156373af48d","2f6e34bd23f34abc8280c36d8034a254","7389dd1a47f94e84add0ff150e77e490","5f5826e2f1cb43af85a76932215909f9","c4100af50e864948b88cfb4152e6c7dd","014deb7bd88348a88db825323f16137e","5a9ec8bd4b094e13a4899316cfbeb5d1","367bcb74ca85491298144edd19f50d0b","ea93de2b8b79420b8e6044d60a81a052","f81a6afaeb2240cbbe0d4753818060c5","e7a157bcda82471c81017ddd275bc93b","7f1ab31215c64c68a9f6f4c40ddba1ac","5fafe9717d7c40598a87829997ebfa0e","7982dad4f22c433696cb7855bcb1cef8","1197b25891984864a50f5797c460d609","18a114f5dfa849158e81699b82e7b805","76e83eceb3454883975c06593d19d1c6","8bc7471c2fe745a7aa34d88ce248b9a0","e592832b622445a8856cbb9e953aba8c","08d765faa28a44e7bb95b85129fe8170","1fe50e44febf47ee817eb424018cab14","451bafeca48e4b079584ac097a75332b","b582831dd3fe405dbf0c26067d64eb68","bfe18b7b831d49aeb1c69e59e319bfdf","44a4f3608f0b41f99fe157f4c3a04bf3","9a286535b37346ce8dd3ef1caeb6b79d","5b90ede8d7b1477d86036fdd4c228b4f","a6aa550ed1ee4889a7c3045c5aaa2714","d5909ff71f1444ebaa263df58dd92887","5eff4f3a74474a1fb93cd4cd7951d368","e758dc45e46840549031e619176e2446","737e42f2010049b88e54fa4d608f4b04","08f3bdeb26f34887a4470e667bde63ad","c92338d72eb549cd83bc1037d3b573cf","665dcb9606eb4fa79824ae7394d3c5da","dfe0894c3c3b46e692a420957efe9ef1","3b040f9a616a474089b17dfe8ff1ad4a","fd9b7c94487e4074bdab0c04aa6ff235","c6ccb595620346aca5aee23698878862","30bdde789e9045deb7873258609da5c6","968780c519b3434ca3f91c72b58f64bf","dc743152513b4a759a142a3483e194b5","24427c075df54ce09dce884d1777d7e5","60fdac62e5d84fcaa56b86a771bd519d","dbda11fc7464434cb8998ef04cc2fba4","e0ebc7bcfe6044a7ab6e0d87b7b458d9","85c8fd79caa344cdafba86321880583b","3ec82932384546c485a26740553054db","c559d53b3a2a4941b9113c10e7c83537","f84d64380b9f4ac4a9e9d4af71c4b02e","a91f2fd654364032b61a33b8d56658b8","7c9bcbf1fde84c29b366f9f22da695c2","4b81eb7ce53b44e08df73b9617079086","dafb385a2f0d45cfa4a87b5d2b4a7a81","38eba219d8bf42b7805a7f5b98156c67","631dbea5bfa1486a872ac6cb74da5c25","e4dac93c1d3d4e489398851bcb23c024","ee5d656723c143f6a911216e86cce12d","750f216822ea4b5993ce01849d244119","6da00a3ceda14880a7f213fcbcf1ff26","15f5c5fd69fa4492bdf52e83d6e1c46c","477bcf2514b444bdbff1304bce4706c3","b4a315bd3cb44d6fb98ad0c8deff038f","88c89d31e6d94d5f82f2f21495ae2774","92ae6b1dc99746fba98000e62899efab","cb4685f31bf142628c3bbfb596ff0e70","ebcdda3c2bf44c5b984dab15203a51e5","0576b683e892400495f25e9c2e0af577","3a6b78680e7545e7825ded0aa98ee81f","c47c7dbd91ab4ea4aa2c0913d71224da","31c4331189244b3c9d119e31ff4edf54","7d34937476e34a519806676550c7b8f8","d727661ec0b549bfa022584b0decbc19","a7942891e4164c27b1b70e635e46a965","815d01a3088a4a5bb321881738585f64","f81ef582d5f24e7aa55c4dd16085547e","9ff7aa891dd34a8691bd1d46362123be","d903018068fb43c88fbbdc91245c5a00","2327764c891a4aad830e05cfee0b6c9e","e458201735ad4c21b0346ee085d26bdc","ed99d90dbd104cf390af795872ca5345","af4b63424da745ada7fe0ed9b9d7fc62","c532f698976e4e3abea98305cddedafe","5a2841c78e8045cc84c07356a07ac9fd","309136225fa8439eadcda8378a819bad","c9b83d112c6148a39a17d517b2b97eec","85b2489cc6374b5192b5f056915166fd","7c9dc9b5825341549e8c498f77b8a857","ebf16b1de36f4fa09d7f52c69ae631a6","a0c316ef529344049930e57b5adfcfc6","31e767623395487f89e327c81f2c99a5","ead469c91b3d475d925dadee4ec558ba","3a9eafd14f01461d8b904d8be2922133","d67881a4ca294aefb880006683ecb8b2","9848cf79f1ac4b80ae6492ac903d23b0","09e06ba010e74000b905d5c535aaefc5","f45236e14f094650a648136993e64336","99ac8bf52da841d397e465dcbc7f6371","f795f84abd154a9481938ab5cd8a843d","51748c03c0544a68ba5a1ea65fa279c9","a343d9e7b35d4297a021b41c44a5c06c","c88d83d1ecf746fdb88723e2f83c42da","9dfdf5bcb6654712ad496a34e0b74fd1","8296f42d49e944839e751d23059451ab","bbfcee2aa925431aab65f3b535ba6cad","5089696d3fdc4eebbe4ff9928726ac9d","1b3fdff48a1d4b7e96d6d904c23634f3","9cf7ae76b49941d3bf21982dcb9927ea","93e31364fff14310a42052048370626e","b76ffc2d2ddf4a2a97fe4549113e0ca0","3807caf887714a8a8d36f34bc8f5a253","9c6c0823432b469c85300e158323ad22","f2bc8d702b9846aabfbcd6a2c6b6840d","d86672f980b84941bb5d49ab13f4e622","938ffe7f6d8c4241af5dc96e042441b8","c5d6309143154d16be679e7464c18e3b","f123cb78c4e04ee89dff9f16226be098","3d521645c5d943a6ac12b5db755665ed","4351270026fd4d68a7603a898e71cb17","b63516c8ef7a42e9a98024384faa965a","fdb9a91682274f468aaf67aadb190df0","b5acf08929d64899995ae581df53546c","6e1eed253163427994cea4ee03d996ae","1a3fcf41e67c440093cb3faf656b1ce2","ee0b6933d7c64a6abe5cbf6174b70b0e","a1ad81bd6be34f2994039fa00638bc3a","ff3823efc06e4b5381309d5bb40c6d98","2dc890cda2c945c597e7439d0fd17fbd","6c413df2020748d1a7b7caa83ccdf8aa","6aca87a3d6eb4e53ad9b1946dc4ad06e","16ad85b06f6f49b2a81fb62d84c97df2","2b43b6e3da0e41d088ab0f53e9d83c5c","fb5d648052164cc18c1e7b4a4facad18","9dd921cdda0345d485adf972a1d19e7e","b2327e6575a44b1ebf44612aa6ee5076","19ce991831a74421a5db81e856bbfe45","846fdfd338b0437e89a1d69b86ddd635","23d1a9d970134a6f9a74f2fd89660340","6905724127f74d79bef36ab6e2fc6712","19b323b5926a48a0ba654360b72d4ade","49518f1a408645e8a554b2e8dce3beef","16cea954823643a1920450447ccba2ef","14c9e5a05117489a8993e6c2354f3d1b","aab0727f779d4d08a8f46b8e1b4f3875","56edd53a6cdc4f1e8c4eb0dc81a1f484","2f35d0d3560e4e56b1b35f903c044b22","9cc2ccf7a0fd4c1f80d67846d63b9e00","b26015df75ba4f43989dc1ca9296a3d7","a2e86ada25d043c38e9a91b5b8049b5f","e30585ee171b44499c34b211f89f64b7","277810918d444eb8bf41e8d64ed572c7","6762cad0e4454349beba2fd0007530b0","fe8fc08003494b71b59616dc7e8ad3de","393a283e66cd4110911282aadac11fe2","d1a4062e176a410c9da12e1554d349a4","da6ed3cfbf314ab9bcf8d328339dda52","ad2298b5151e411eb1249a49dbe5c4c6","5c4ae1acb04545488163061882650682","1e95533cfc3545ff9b51eb1f8175f6cc","e9773710eaeb4d0faf41523ba7d428ba","b5c1fa6576f242dd858fb6320beeb5a3","cfe03b5c61fc44b8b696b78e2f7c6f87","f9808fe426724596a20bdc48f8692527","ae4e066806e549d29d537a2f727da6a7","8b89a761dd8747d7a7faef0c7360a43d","5e92c1108e37422fb9a35c13c0ad75f8","9564204836894bac8553aa09e42a68ff","6c8b67446fa0421baf7aa8fe3582a796","1117e7563333470c8861a2afdcb434a3","25bbb5dfd5fe4a9f8cbf9373238965f1","d514f79a072e42d59a2af3b8728fd462","8c634482adb04737bf21634f97035337","20c3d6cc0d5a4d27b009f44b01a9c7b4","a12c1d6ec6424d56af963b83fe7c64ed","466f5d982dfa41b791998864a9996292","5a908c0efd884fa9a3c9bf88027e383f","f37465256d7348268b46065127ad45ec","ce9f4d68c7a6449f8f68ae83e73c6ec9","d2a6a5bb5e754779a74c5b84dd0f967e","896cc42479904f29a5e57220db5f2c21","4fa40b034bb1472ba1ee4fd634760db8","a4580d62987f42e3985a4ee551201cb4","9c5c5e0a4a5b4bdb9332cf3bb374c6ac","0e66e1d7161d430b9ad225eca072f149","6f5606da322f446dbe4776db706890a2","0327da421c0d450cb8dd7ca721e13ca4","2e8c51931c9e490589aab6c55cc551a6","5611e9d96ef24d26a078cfb6d792d767","68cdb60147294f5ba75ac198dc18015a","878f51d6888d48848c984d88840b5319","bd9d1c8877eb4f34ae1ac8bc36d69431","90ddd3e20e0843f2b8af6087f9edbf6d","52145d0823f04490b0584bad5824a6d8","c909522d55b642c7ba6dc16523a33a81","aabba49fb0054115b739c0ed20904c7c","374af04103564d54806697d5b62d871c","9589b2a82590467ea303da08fee3cdf9","9fcfef6e9c6f45b8bf25399e1bba0e36","5258551f7c2f4ce3932bafafcf3d8cd8","3b28ff6f052f49c18ef357c93065b5a4","342a4f22e9334d94a7754b42538d02ce","7d0539cd5e2a4673826869a75cb31131","9a584744a84541a4b153f5aa421a3c42","aa51fd6570414c548337bc554752ef8b","11e3a4f1a43b4a1587948cd45a8ab28a","3cf0f62174cb44b499c064420085cf17","b347930abcc9450f889c73c08d497e85","7cf10c5267694d36bedaf1f4fccaca1b","86d49a97be8c496d80237c2be16739d0","a93b511956e648cb9e4aa3d8f6b93bee","fa0e5ef56cca4a62978482d9a414ab81","db7176cb80094fbbab5f7cb01d7cb4e2","36de572d1b134ef2b4581732a1e32f90","a5efde3f24754c249486b25e0a90cf43","6de0cf0e27df48dcb762c617a01dbc6a","5d321299aec9420f88c106a716939733","85eaa71160194ffabfe671edbf62f162","32e06966f9ca4c3d991e49519e24f07e","d5361bb31a4d44a8ad65823558368c18","ad528eeb23e043269d999ab1af87f226","13c3587cc44a435383b0963ae69f6655","4085ecd5749e44faad0f1204aa8f5b68","77d608322e364fceabd02101e32a7bcd","9d37920bf7b64ca2bd4e0b48e0d65bed","36e9b8debc144e80abba333d094ed5d4","e382261b2dce445f844ddd60f3aa1611","69f883060783442382f8ce18f9b08d1d","a1f7e2b81d2343af80009a079f852052","b5c9d010371b4ac6adf45b9c3925f57b","8505473265e14e9fad4bc44355daa7ef","7c005d339f1647e0acd5ba81aa9ac03b","4510f50bf8414e2789a27271067f6287","e7778a5cc7c9418b8f2e9526fbeaee3c","a4fc8a06aea04611bd4e02d9f0705d82","8d92ae1f797a408aa40f8b8db1bd4d04","a13cfc4d134c4bd780b3b4a7f1b33631","3d622daf97ea46599a702867de578f19","24927958d1184d50998a11349b846a91","c9ffe3e5f5fc493e8da57fa47b99fdaf","315f317470ff4ec7b67f3a7cd43e9efe","b993082e53a048ea95e8736f0240b9d6","56c62508ae334d089373fdb61fe0a4d3","583d2a373f3f47c6914caffe9520573c","b476f5c55a76436bb682ad58fc83c4a0","318d2492361d41e8afd07f2c1940fe31","3c230352e024408983eecee705320c70","4b214598214e49ac90e52ecfc824a528","94550cae88a8472e9522e9992a622310","71ff15e5837346c4a6747760e24f56b9","3e19aa6a1f85480ba2125dcbdef75c11","ac8dc7b6773c40bf821371e8389f478d","d86fadde70f847c7a7d55d1c3ea17cfa","31137a24eaad48c1a2cfaf0af9668030","3b1b0e89552c4be5a0754fcd97e9735c","bbc387ae4065486998e83a20f99104e2","22a0e2004df546bb8b694c6996bf3680","82208743ea5b446ab906b4918fdce664","2c105bda548349148637fd6ba4670e66","4b51f3d2d4844a1ab2920e4fa769e5c4","02f1a6288575401f912b57cc646be5b8","08a5da8abf714895b8a4e9562b11099d","e02ff5ac9d2b45d291375e0cf77e99ec","4f3df0d3782047cb95696ae4496d7758","4a891bf9f0fa4d06892428d856096acf","dcc40edf867344c08b20aa4cb07c2eb3","eed063e9cd014676863ff9fc12014d4d","c1c0e499f8974156aab38d50fd5ba04f","f1b54999e5c141739a46cf1009ba78bc","afc67279b76a4db1bbe60e11931382bc","083a3b2919f749819294d07b70a01f5d","daf0c5601f134146bdf7304aa4646224","da1ed6b64283449292c86f20d974ddcf","b48a1c51e4e14d3594f65e37f4db0aae","f057e7d08de14d7f9a3f7d4888760b11","d2f37f8d99f8407cb73523da477fe05d","3616bc698a9c4ab994ae30d5a8951c8f","52be2e0c94644e51ab223ee3d61d15ff","987c31de180c4f40baf5bed8b3b1bbd9","caf680972e1940c3ab241b1d4a1908f2","8bf6598f9879411f9fa72e339b88ee5f","0bb984723223483ba269935e62d99c6e","ab60cf8910e64324bb4ffe1c70e929f7","524dfa591a88484483e497c4ca689a02","85b9384a86434f9d9cd4e965a997cc85","880cca144f7b4826821f2ee77d57917c","b4c9ba0054fa49f4922e3c46dc7635f1","c62089a8f85d4e4bbf5274dfbd7c7037","01e57688b7f04786b569f18a82872fdf","baaccd56344a41239cd494ae4a28c484","163daf50522d47f2aa562fe2cf60ac51","53ea92ba074c4af8aea1b4fbf779c99b","68872fccea8e48769a68448911709b5e","17b9bec8952e434592aeb3a604f6ccb4","0f704ce60de842bf9eca5bbede4cc64f","9c4bb7e633444a70acbbd4540425a74a","f7256a0ddbd04228b30f9574761c6041","7feed98b3ce24157be8ea3a4b2c43d0c","9fe91020dde44d12bd971d155d240cb2","49d88f559e9c476cb13737801e0b50f3","4167c6ec3be04bc3ab0d7a4cb3a23654","74fc472c392d4be3abbf9f5445653751","7c9e7182f90f44d984fbcf9ecf2ac40e","9855d6500db445869a3f6c319e408316","2cbb482117794a37bcf3b90ed91d51f7","f0ea3dcbe7cd4278a3e42b7446006a1a","19218ad863dd4eb0b3baf1097bb62d57","017013d83a8247359124037187513538","0365a47dbb924b54b88ac4b1560dd2c6","142aa9c4de3b4463acf47bc7db9e3654","ccc6f4d4a82e41cda6e02b55da937e9d","c7eba174eff047b9a78ed23d7246439c","99c2cb111d9342e9ae9200cd617141f0","25346fcd747b456f8a82eb3fd9f91f8e","294bb05e6b9d449a83cffdb42b4fba3b","c17b819a1c9b4a2da3451258ac9144fd","ef2e6a23917a4dad89147861e6004b08","7d659a05e59a497cabc30929ac963ef6","ffe8723dea624782befea95c178eae74","97c9b13ba206481c8eece6c355f6d249","fd75b3f6d6fe40238f1493c50df79da4","2b67113d22ec45a3ac5d98252bede7f2","980ea583adc04003839f5b145a9b1afe","a181cdcb20c14d538a3b641552a3d79f","1339154ab8934984acf669e0d981921e","c97a9bd58de449a192400a9c44892570","ae161a1b8d7047dea82567e1b4cd030e","21dc6ee59148497496fe222430ef30ec","fb6b81129dea4b4380ca12c95787d976","2a7395a245114b318a2e40674a5b3fa7","f739a844fd4c4627af31f1942d82208f","ac838cdf956b4313b83c5f3dda4f18d0","2035b2cd6d5e42cc8f44697112e96867","320614a483674760aac85e37c8c4534c","1ec93b85892c45beb96d5f958bcb8c35","f4975a0614104d638f7fc0b3c0897720","b049704733a74d1ab31f43b54ecb30b5","9dfaa017e8ab4801bf7a2d96c15bab3a","d184ce22d9b74e70935e0ce67f398f18","2e68272a4d274d46b0fb078882024e51","a230c1e699014a24a97609a09c1a4b4a","09a736ec98484c5e89792961bcdcc19e","cabdd9c89bcd4f4bb2e0a5a328db8778","72344bcd39c8492d86d9b9610bae0b21","1e00f609391d462489a1cd416b03607c","8728c16fae564d04a89f0ce83333b3a5","2bb2a8346fed4466b0583cfe5c6dcb35","9ebd2a91630d4ccfb583caf05783a1d5","5d81338a9edd446085e345d677ca097e","7ff27ed90b034d1d87c48df1863519a8","e94945ab957343b69e14cb1fbd86eba7","b974ea994fd64b949554d0c2cf6e071b","b46dd0cf6ef14f64920961eb922589b9","9c0ad96f16b44ced934bde37d8b8ee74","ced59e52c48e43d1b8c9ec8198bd170c","20d6d3b524ed414e870d708814ead605","61196f016d6d42dcbe17d4bfd029188c","a082951c66f649fd993527057e09db2e","ed2e967b2fb74d928c96f0a2fe59dbb3","7c1b74a5405f42598a8684d6e0c21ada","3746c6e12f5c4c10999c93ecb548c567","e266d10b786c4f98b6c8a9a87130fd44","aa894230d02c466694eb0ee85e3b7ea2","90a9a2bfa3124e549991c0a3c7169b3d","22c97b6fd714453a9abb18974fad532e","e2f5eb6e05c8480998a637e341a67293","da15ac8e0e89433cb6dba2734e2866d8","ccb4fcd7900d47568e504d120cbd729b","8d0f7bd0395d448cb0f9cb46d3e02b35","e10a6c1d2d9e48868bcaa072202cd1e6","f8ee43dabab3467db2829f2e8cae63b3","ab11972a829d4989a8301ece1f321ad6","64dae83e8ee9487a99ccab3253009820","e0f9b24ba60f43a7b8c5582e180f9d6c","6b1bef92577e42d093022b9a35bd6aef","ff8ea34e044d4a14a420e7a66bf7636b","6eaebacc2e734d259368fbc6817dc39b","5a3fcb5ce246440e93d508ca8b9f5759","1064fa909d804763bc63d0138abe5a98","c4a9b66b26b2472ea00a565f53ce6bd5","9069fb8e4efd424192fc1131bf4ef2fe","b7f4bcca64f347cc88fb5633e08b785c","d71c44be4f5f45929632fc891099f562","2dda106eeb704aed905d7c41a8a198a2","93554f58c8c94bb7b8282769e7cf127e","0f0da4b2dd7b45f39a452b5e312ffb99","4d8719e80e944c47a5d7f01a3149ef5b","e20bd4dcbb254ec3a5776d33c09f1557","b784736dc91b4957a35edd5fa6c88c00","3867da53fb5e41419383da8ea1bc2b8a","d4c3ad914afd4da28d4e9045403788c6","2d8ee2401ab74fe4a5c77d65c593996b","0f1a1b31a9f74b39813245f05f4ed92c","a78beb8ac9b344958bce153a5910f06e","7e21f538e4f6479596d69738e5a08ab2","6c7bdaaa77f048d28871228b77c8761d","d96c5215bcb649b0bcac2d8c1efaa2ef","fdf142f6e8374f7e9ef7a4b15b140dc0","c90312939458481885bfea63de702170","388df34cfbf94c2f91760d078d9262cc","ad4aca128b794d5fbd37c09e7533839d","38104948a0e44921b9c09517829018b7","a3d8c60f8abd401b9a38875bd5f1681a","bd66211a1101404c9aeb6e30070db6e8","75e356aae3e247378c5962a03d776f9c","1d8c231f066c43ef9c01b9a16a1f61bf","1e767fca34b34a5fb76da51df22b44d1","4c6dc84c7a6941db9fe749de256babf5","0d31d82ae32e40968483009b510d431f","a0f50438ad96493a937486b1fc931fc3","4bb74f46a2a9457aabc260173a2f8d62","c576e5e55599445c9973e88a936ed951","5b2531d57899420d830cc702959356dd","effa60151463432abed725682e40dec6","fa312ba7e4a04bc2ad1d2efaee9560cc","be90f10f7104468487335711d7e29a75","7a07e724f8bd448c8170bbd2152bb192","ef52fa630db24af2b8dac839a65c81cf","b7db183d782a428da5f4008ea2d708f2","6207977fc9e54eeea8bf4705bc26fd88","845ba58826a443e8a2635cc9343e91da","63a9aeaee3e741558565297d0687fa8e","8c912a897a1d4797ab28037d7dab1fde","04e71f616b8f4a849987fa37213cc16e","97b431bd90f441a79ae29c146ad3edf6","02216954d948488c9e3e369359dbf147","843516a8690848179134b5b4089593ad","f408a6113e6d4305a4c3299d327f5f58","5ca661c7840d4bc2b2ea810dbf60f0bc","a2c24c1d7d1b4a2a95e6f6b20a18d7b6","b1c35de69d044fdfa760f6171682d85c","6840931fa5364285b6f01a431fb17ba3","66d8db3e15bb4cd98e20a82cbc75ac8b","4d3d8ffe04af42e98df1402b97771ba7","c6dc8647f6ec45528ba81ca446a925e4","a82d6cbbcab94b8f999bc61c58552b0c","235d1fd2c8ce4db9bb4e56a143dbb3b7","e04917f1abc34aed91bddd028c735f5e","34080ea9d63e4a4486d66c214d6385ca","f5a431232698469bafa38215ae67efae","368a6709a4864622a29214c4fe173a50","c3a40e3035184fa3ad2b9856b3fee3f0","e52ed631478f4356919a694b27cc9274","680d96b6713e41349b67399c11658082","d095d3eb710043d39abb1da56790a660","cf422f85e6054c3aa9c7a2f2304ebb78","42dd948c64d841718d73b086f1bb7b88","7def8825b9134072bb45f0b7047eb281","94e14ac439ea4294b7376c7cad11f4f0","761f54c32cfa482190af85c56f61bc3a","dbfe2c5dc8284457ae8ff1a6faff0eea","66e3b2586cbb4b6e82ea91c3645f53e4","4cae13d3f4d64ec5a40fb7baab3834a4","6d76165f362a45aa82896d63e5237f44","96706ea5c54b4337bd2e180ae2ef26a5","df8699ab08b94718ac64b27faf777d3b","fa10f6cb10fe4279b5d7e788d369772f","76e28ec4442a42b7a876849554e0335c","212f43ef740e402dac257fafdf492b75","2e805f312d2f455295e930237df0ce1b","71be581b8a4240db9220ccb4f882705a","7413337e692642f3a4c0bf0efa574ee5","80449bf0a6d54724bc2fa35ffa0cb173","e05d55ab82bf4fe88d0c39d3dd3267c8","cf3b025c85a742d39d0f7b698fd0d9cf","c3505c1bf28b45d4983ba6c0ec996b9c","2877e3ce16784c0cb4334c79066be31b","75fd52d7d8964e28bf3fee7a38c25591","02f84a9cecc64fb98767b9bc4e6040cd","f1d1b6653e794cde80f3e29ce3e11597","99ba2c119c2047d79f21af20388b8b82","4f229fd60ea143c19608fe2534aaeb42","7dd8b7f752114dce9f5192c13b38e5e4","0a79bf00e1294268aad119d1ece1c092","242b4cee0d87418bac9041968be4910a","09fd354cf8bc45aab118cb24e94e8c03","3f8d77b559bf4000b8b4325751c25ad1","73326d669c9f4c778c6125670464ed63","4bb194932b0741c1a839ff7c60e2bf9a","36d6b209a63f4848835a6f03d9e69bcb","d593d7e9658a4c73ae396b45827961b5","b22e807d85aa413a9c8dab2e351a7ed8","6201b61605f342dcac0a61d4fad782f4","9f2be8f1b35e4602b2ac0887e858d13d","a8ef9be4f4da46098f1f65431de89588","5774713bbb08405a97bbff6310a2b74d","8940b7491ed84131bb46fb3047393621","eabf1b27c4c1430aa2695bdc212008e6","4aa5b2b491b549baa0f9c821e316db6a","ec67a36b5b78402d932b8ef1fa159857","1733916b6a1047f58d8a96e069527557","99cca1d084324437bd4e0964696e4b52","7abeafe5b469472184bb2b5bcf857cf5","cdbe2d91c29b40a68486b266094f309d","da02bcefd5174e02a7a7624a3a079ebd","f75d1fd04fd042eca14181d2bf43a289","90a1a0eae7b24c1289a8c25cfab69606","41523d0a2d5f497fbb9fa54b61c63342","f0723bd4fb164a10882e8a65c59b7354","a86902bb19c1477cb0d4f24eb697ac8e","7b1d295a87f14e81899eb2985d0833a9","6d5671a8e9e84445a20459562168b2a0","d937276632f848c89242872f0d39c9a6","e68cd472af6648339ec04c74e023b727","130eecfaefe246c39595b23634365c6d","ac1616d8e0444d56af6d55d9b7c42593","260b5cb1dc7f45129c6646b3ae488aa8","628ab43ad74e46ec88a752944ad607e8","c8de038c5a1c4db0af0b9c2c9074fd0c","cdedbc761b4a43aa81f78c473ccd734b","1f34a7189ac54b5f81f81721afe5867d","be3b2bf0ba8b4c178074ec14dbdd3dfe","c2a2dc4a40614165b5c16fb36b07640f","52c914a46b8e4fdaba766023bba08595","b6632ddd6c9c4e058b2618f17675aa90","0034f0a086524ecb9217901e2959f7ea","ee3cea931afc4a5bab9abe1537df8162","5075e3f56d224d47974b07349448f937","2109d3747bed40f0840467ae77c6e762","77d4cd2a22e749c1816f1b752cbeff5d","b3882e92f230435eb05cee1ae9089b4f","8d284336f14d46ff91e3150143088335","b11743b4c5754e3d8c954b93082e7b73","cb97d93522624141a299fea29c1ba553","dcdac117a7594f9ca333e2f8a068db2a","82947de600b24e3597944bf700036c4d","c5932cf43c6a4071a1516d35261aa94d","bd6a1a1f5dac437a842d085b0290ef50","d5b0074cc73542068db5ac98e32d7469","b305632baa1b45d88258cf3831ecc4f3","05507f81c5ec493c98c0061a909d1f2b","0c9746201aba4cbb95deb1e73107327b","114e9c8f0ab1404f8f20aa42c3af9797","3b5c3645f433411e881c40973a725697","7b98c2d91c644fc999bec37868c4e28e","cd67fc08982c46edacd6660409a57944","ee17d851c37645389ce6f66d37a2e9ca","ed61f95bcdb74ad383743e40e42d0d7b","71db3d09e8034609aa1d5104639d8781","45ba1c36758741c186ad33e72025d72e","b507788f91414bb9a9e41e3ee44c2a1a","8dd80b78949d4fa9b0429d5713034a20","664f2776194f425195e78b31d5eb8216","8c2d1c3a4cc641899f7d1a169156d8b5","df55a6f6d4644f6a882d4ce6762c89a3","35da1b01b5a04d009aba93f8f139737b","70678f91f4694b0dbbf5d60a3764ba5e","9a0cc2c469834033981f8e4122994ec7","e70c8f9bf8c24d539a12ef5123511f6d","5bc636dc74074770bf717aa2fceb3bde","07b1c64bf5d3495982c7885bdc75790c","f8eb81e1f3254d04a61b46247740c9f1","46d84420e20943afbda4d8a2a5238643","d0919411242f4c52a325463c84e1766f","5d7c8fcfb45242968fd66bb7f8d6dce2","f71884cc8b7e4c70b151a5081627926b","d397e15e8aa940b29bbd37b221fed0fb","2113c60d337b4d06bccc2b3587b6cb63","2da7a4e1f69d419ca5619ad11e9f9928","21ece3ea015f4280962009a0c778145d","90990fceff824578a6f5902486626609","5883b46d452e4aedb5a8bd1ddc200c6f","02cfc1864d3a4b2c85c4039b91e9a019","aeb7bd35334742b4a4cee8a359f2ec45","44e430ccfa69481fa6e4e426d32d2de4","5676861dac4542c49e9958831e154756","cbce709588074412b0bf8265b905f098","06d2ea6195034254be3005ed22ceec94","97febf99080e4476ab06c34152831c2a","0215b17e98134bc1a99625527eb59c21","e94eabb2bf23492eb703756177a95210","f54e8bf09fa3489da45daf508d0bdcb1","85e25326849d4f348340b79f83030bb7","f5fd2ae939854a90b576db6cb683ab3c","516d13bcfd1046caa0d8f2be02da60a8","4bae5e9456f7463bbb44364f32873ff9","e809d69bfce846cbb0debeb16beabd52","060cfaef6eb2492aab15e41f6bea90e4","b5a004550e864344b3354a8fc8bc8882","aa3daea8a1e648c7b2f377314f4f1ae3","b7fc122c85354dfcb6b3b850a2c245a7","1e6ca3e3ae9d43bdb8c683a4a875aa2b","59992c07670640a595081e1ba8c4f126","9c8a8c55e57a48b2a935ffb7d7d27a65","9f3bc7e1123246f9bf93b24fc90ebec4","5e4d0dc2d8064d1a8eed9c5f327c75d6","73bfaed0cdbe4947b4efafba841b37ec","6e21d3a09bdf4605ae81334fb5e222ad","56c6090e3a464d46a99f8e8b4f603538","f06a662d05a7450a9004d4ea4a9b8dd5","6ecb8f6b8d3242758a42f0d284b5ad8e","deb4f3f3cf32402089b94f68b4d448f7","f9c1870367a14b69842b8b330f290cb3","87092d1e566d4ac89208591cdbdd0d84","81671d89f4b1499cb07183168dc82500","ef3dd8ad107f4377842cb348907cb695","d218dd208404480d9545a27d98c4b9e8","e4a710918f9f4b4684d5d94d77b34e58","e0a9115dafa549ba8b3dceb2fe25b5f6","dabd6b2acd70417b90a517c19de95bae","3a8e36edc76c48b5bb065a093ab6d162","ef23808a48d94a4994c6533602ceabd7","54e35e99782d4a0f8ab29aa28cd6eafe","de9c2b9907b648108308f74a48283006","13f89bcc996a4a12aad74af15d5a131e","8274495a4a8d4b9e8978621bdeeee08b","420de015ea484cf2b09cb3311748a674","298cbc6227e54eb2b1ebeb3b83014f50","238d2632336f4171919f71dc2cbc0d8d","973dbb94571b41bcb94721d796a7d988","6c80750836ad465d846009a69e5d37b1","5871cb6c503f48e8acf1d8b12b547dfc","aa8d46b514854757a0b523fc10b239a0","0a6b018703c14e00a8be8970280e8fb4","0f0fad505f3e4f02b8e182bef1584508","efb5e51bb76c4881b132d71290d5c74f","5682e383851b47bb80c0c8ea7fc5bcdf","1ff481f0ff794b63b3b3f952453d36f9","8bad322423914c3a8fa0739df21a8e64","40aa04cb09e14ec98cdd35d49eb0c0c2","ceb12e65aae340e58a4600a080fa30ee","eb06464af0004628a2745e54b653aac4","38625aa2c4d64b4da8cb801155f0eb37","79604541d22b4337b2f1638b2d6f33f4","5486fac0ab1840669610fb9ab32afa8b","a974ae6cf3dd4044ba8e0ca1431a720c","e1ad52bcb4bb4c3e83ed5e05d860b884","838cf312b6f646968c1fbf5c959a3d1e","dcfb64b1988b448d8f95c4be308824d8","7e3c2efd0e1745ae808899391e453b05","cb139c78f07f41798be59032a46f1a1a","7185b4083f7246a8929b6b7f526e7971","dbf48a82935c442392bf528f6551dafa","74b443bf938742bc9eab7d3a76bc4187","72370e97d4f74622accc45979117f45a","bbf5429a47564ff291bed17d42143a73","64d75cec768b4ff3895f38b45abcd155","014da33809a744aab78fc8d6ed35f78b","aa2e60eec4f245f68aec8948b06b0dbf","8d30f80adff745f18b1edc0795b69c3a","54e55a251611438596c3e95a7a5a5fd5","f6376a7e3f6245369f97c6502626c37f","7159d255b50942be959b9f043b3cbfd6","bedf703e512a401e9f3c5f104dcb3b1b","c2766225471c473ba6f473d7a0fca0c8","2f69c26e661245d3ad53fa6ea4f00229","9e8d8d22f0d84c55b1a65fd177641e14","95788b79ff1147068f2f9f25608d5091","b60c2e78bed646ecbca8b5f6dd4f2011","ae109605f30f4d47acbc23ae6e341bd5","ec6933d23a6c40ac939cc8931816f6e7","4dd9641b71f048079c140d87950b4915","b11acc78f3be4f7eae895abeedf350c6","bed94a856b8b4b08992887c981e696d6","12fb751cbe6b45a8aa72d783e32acd8f","45d06029a8db43adb5ca333a6560e084","d3cb4dad4f0c488ab2e0b188d3f7ba38","55cd5dee6d8748b08b14e69fdc063ffc","f3147d5bb4074332bc349ac664dbc382","98a603437e1842eabe5aa98ceaf4d110","f6d059e797b349ea9fdab96d6c9e06b8","59373754f30844b7a65f83f82b4b1e2f","e73a99bbf1aa40f495e9135e9eb13b41","32484960dd1e48d4b1017e166054213e","c068f60b56dc460883e44ad052dee28b","f43a910cd9a34aec93395e1c464aa448","3b969e4ab3954bfab38cfb6e3158d3f8","cf9b4e84d46c445c9e420f7d9a77d4de","fcce93fceeba49a39d1dddda98e85421","bba50ae13b314756ab7af100ad2c33cc","5ac8699165814cb6ad539c18e805c60c","259bc29a51a840b8955d04fff659b3f9","ab5f8e1718c94f928b64258b98740769","93dd970da233483aa79f2e577c150402","5763c0f04d2d4ecd89ce826f9804be53","e4a0606a571746fdb280c1a77033d107","830e8af7072e4e30a64da627c1d74e06","6d1ecedc35ea4408964de8a63398e46b","c721cb7fcabf43c4a3a18b1570516c70","ca9f80455c484db4b4bb1895a9dc424a","e0126abe51fc4e0c8a40a50095494e84","a906955999534c8fbe2a6897f7b65487","a9fecd5599454880b95cc664ac135c52","a3a4a9fdd558403dabfa9c10b8783f51","d566bee383bc4bbb9f162ae1695cd101","e3c4b1ccf3d448b49ae0375faa9cd5bd","5111bd774cfb48b89670369ca08340d9","29ac7b12b7044ca58b3ca711dbfc1e2f","db86be85cad94607b07d4551c44c65ff","ece3f0524bd24266948ef21f7affb463","2fcd9b85cc51489787c3484d57a7ceee","d631978c9a414767af9649831b4c12ce","5e4f2e940633400b9232fd25e9555563","793388a537e64070987213835f73822b","331ca0c83c2c43dc998452742fb08fb7","605ee90f555d4d6b831a0a31f3be1c80","3b43931821f04630a1a1c85222a2bab5","fda6614e8fb24520b3ee1363407cfc2d","8f639999fa254eb1af618b7d10596fa5","e48fdece6c0c48bf82bfacff8bfdeced","6e2b0c6a4c514cb7baa2f8af63646748","24127d6458564a4686e98663aa74604f","7df324485dcb4be3a1dbe55585c4a8ff","9eb32569efe44e1c8b23846e0d75ec51","c0ca20e0b48943edbe3afc4028ac1877","3217273e35804be5b0278c17cc5a7093","584d92dc38814bfb90100103eaebec0c","197e91a6549f4a85ab3a14e1239d8712","02a5bdda375e4a41b35fe73191633b7c","16f81a44a442453095e687223154ecde","1105a39546f3429895072e0988c3fbac","25e154d837e44162a6e6bf831f82b15c","d6f29b717f734b93b5726ab7c23a942d","59331ad199114cffb5a0f0599a84da83","929d9e6ba412488c8b7ba61ad6e9e158","ca0ffca31adc464d812b798c855cf624","97d3f34b6b4441509afe1ffea12c50a1","6cc829ac8c794061bd62a6ce13c9874b","01463058d25243dcb5c2314df90672c8","2427ca00bbdc4e4f893f88c4f7a0ebca","7136f2d2d2d34a7cabfb83caa4c822d8","7dee9ac3f86d4036af8eaebc22c695e9","44bc012055cb497eb12ceafd0d971014","b3cdb2974fd3468eb456e75ae8726a37","d2acc8f4fa7e4a99aed1a2e431ecce73","e5f43f613cd3485dbec49dc579e480a4","788af66b51fd4eacab5d87e59879ce35","08cb47602a74482a850d02f83a8e43fc","5676bc21613d4d4eb72e4d430110c7ab","0b5b7e0e95f649a18874d0ecc9ad5174","54935cc6458a40f6aa946bdab5c603a8"]},"outputId":"adcf5c15-0aae-476f-efcd-00113a297ada","executionInfo":{"status":"ok","timestamp":1652058330647,"user_tz":-60,"elapsed":45834776,"user":{"displayName":"Ziyad Moraished","userId":"09734916932076943331"}},"id":"6wfRoiUOKBdD"},"outputs":[{"output_type":"stream","name":"stdout","text":["###################### Training vgg19_batch_norm SGD, lr_0.001, momentum_0.3 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"245239c786314c19bd027d2fff05282d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 2.4975640, Training accuracy: 0.0950000, Time: 08_05_2022__12:22:01\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 2.4752028, Training accuracy: 0.1112500, Time: 08_05_2022__12:22:12\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 2.4464085, Training accuracy: 0.1158333, Time: 08_05_2022__12:22:23\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 2.4117174, Training accuracy: 0.1262500, Time: 08_05_2022__12:22:34\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 2.3815575, Training accuracy: 0.1345000, Time: 08_05_2022__12:22:45\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 2.3607387, Training accuracy: 0.1429167, Time: 08_05_2022__12:22:56\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.3381120, Training accuracy: 0.1503571, Time: 08_05_2022__12:23:06\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.3141232, Training accuracy: 0.1571875, Time: 08_05_2022__12:23:17\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.3007561, Training accuracy: 0.1627778, Time: 08_05_2022__12:23:28\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.2865021, Training accuracy: 0.1645000, Time: 08_05_2022__12:23:39\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.2737949, Training accuracy: 0.1686364, Time: 08_05_2022__12:23:50\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.2615251, Training accuracy: 0.1743750, Time: 08_05_2022__12:24:01\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.2464542, Training accuracy: 0.1792308, Time: 08_05_2022__12:24:12\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.2299198, Training accuracy: 0.1860714, Time: 08_05_2022__12:24:23\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.2218415, Training accuracy: 0.1906667, Time: 08_05_2022__12:24:34\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.2128770, Training accuracy: 0.1942187, Time: 08_05_2022__12:24:44\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.2024992, Training accuracy: 0.1972059, Time: 08_05_2022__12:24:55\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.1875566, Training accuracy: 0.2040278, Time: 08_05_2022__12:25:06\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.1733770, Training accuracy: 0.2089474, Time: 08_05_2022__12:25:17\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.1620572, Training accuracy: 0.2130000, Time: 08_05_2022__12:25:28\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.1497542, Training accuracy: 0.2172619, Time: 08_05_2022__12:25:39\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.1402245, Training accuracy: 0.2205682, Time: 08_05_2022__12:25:50\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.1293296, Training accuracy: 0.2231522, Time: 08_05_2022__12:26:01\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.1170724, Training accuracy: 0.2276042, Time: 08_05_2022__12:26:12\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.1056323, Training accuracy: 0.2326000, Time: 08_05_2022__12:26:23\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.0944718, Training accuracy: 0.2375000, Time: 08_05_2022__12:26:33\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.0855978, Training accuracy: 0.2407407, Time: 08_05_2022__12:26:44\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.0783193, Training accuracy: 0.2427679, Time: 08_05_2022__12:26:55\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.0713061, Training accuracy: 0.2431897, Time: 08_05_2022__12:27:06\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.0644978, Training accuracy: 0.2455833, Time: 08_05_2022__12:27:17\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.0549019, Training accuracy: 0.2495968, Time: 08_05_2022__12:27:28\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.0466828, Training accuracy: 0.2525781, Time: 08_05_2022__12:27:39\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.0418603, Training accuracy: 0.2535606, Time: 08_05_2022__12:27:50\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.0357516, Training accuracy: 0.2554412, Time: 08_05_2022__12:28:01\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.0291588, Training accuracy: 0.2580714, Time: 08_05_2022__12:28:11\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.0241410, Training accuracy: 0.2597222, Time: 08_05_2022__12:28:22\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.0201676, Training accuracy: 0.2610811, Time: 08_05_2022__12:28:33\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.0134027, Training accuracy: 0.2636842, Time: 08_05_2022__12:28:44\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.0073029, Training accuracy: 0.2665385, Time: 08_05_2022__12:28:55\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.0032183, Training accuracy: 0.2682500, Time: 08_05_2022__12:29:06\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 1.9992117, Training accuracy: 0.2696951, Time: 08_05_2022__12:29:17\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 1.9919008, Training accuracy: 0.2730952, Time: 08_05_2022__12:29:28\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 1.9870339, Training accuracy: 0.2746512, Time: 08_05_2022__12:29:39\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 1.9811967, Training accuracy: 0.2768182, Time: 08_05_2022__12:29:49\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 1.9748613, Training accuracy: 0.2792222, Time: 08_05_2022__12:30:00\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 1.9699580, Training accuracy: 0.2807609, Time: 08_05_2022__12:30:11\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 1.9644073, Training accuracy: 0.2820213, Time: 08_05_2022__12:30:22\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 1.9605241, Training accuracy: 0.2838542, Time: 08_05_2022__12:30:33\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 1.9559153, Training accuracy: 0.2857653, Time: 08_05_2022__12:30:44\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 1.9520554, Training accuracy: 0.2870000, Time: 08_05_2022__12:30:55\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 1.9463212, Training accuracy: 0.2889216, Time: 08_05_2022__12:31:06\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 1.9436137, Training accuracy: 0.2903846, Time: 08_05_2022__12:31:17\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 1.9395456, Training accuracy: 0.2918396, Time: 08_05_2022__12:31:27\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 1.9365604, Training accuracy: 0.2929630, Time: 08_05_2022__12:31:38\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 1.9328471, Training accuracy: 0.2949091, Time: 08_05_2022__12:31:49\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 1.9286391, Training accuracy: 0.2966964, Time: 08_05_2022__12:32:00\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 1.9248994, Training accuracy: 0.2985965, Time: 08_05_2022__12:32:11\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 1.9212999, Training accuracy: 0.2996121, Time: 08_05_2022__12:32:22\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 1.9175135, Training accuracy: 0.3016525, Time: 08_05_2022__12:32:33\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 1.9132992, Training accuracy: 0.3031250, Time: 08_05_2022__12:32:44\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 1.9104426, Training accuracy: 0.3041803, Time: 08_05_2022__12:32:54\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 1.9059862, Training accuracy: 0.3058468, Time: 08_05_2022__12:33:05\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 1.9016196, Training accuracy: 0.3067857, Time: 08_05_2022__12:33:16\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 1.8986708, Training accuracy: 0.3077344, Time: 08_05_2022__12:33:27\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 1.8940415, Training accuracy: 0.3099615, Time: 08_05_2022__12:33:38\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 1.8907100, Training accuracy: 0.3111364, Time: 08_05_2022__12:33:49\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 1.8871856, Training accuracy: 0.3116791, Time: 08_05_2022__12:34:00\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 1.8845035, Training accuracy: 0.3128309, Time: 08_05_2022__12:34:11\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 1.8809547, Training accuracy: 0.3138406, Time: 08_05_2022__12:34:22\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 1.8770592, Training accuracy: 0.3151786, Time: 08_05_2022__12:34:32\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 1.8738052, Training accuracy: 0.3161620, Time: 08_05_2022__12:34:43\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 1.8704492, Training accuracy: 0.3173264, Time: 08_05_2022__12:34:54\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 1.8671188, Training accuracy: 0.3184589, Time: 08_05_2022__12:35:05\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 1.8648823, Training accuracy: 0.3191554, Time: 08_05_2022__12:35:16\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 1.8621689, Training accuracy: 0.3201667, Time: 08_05_2022__12:35:27\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 1.8593538, Training accuracy: 0.3210855, Time: 08_05_2022__12:35:38\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 1.8561714, Training accuracy: 0.3222078, Time: 08_05_2022__12:35:49\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 1.8526174, Training accuracy: 0.3233654, Time: 08_05_2022__12:35:59\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 1.8495620, Training accuracy: 0.3245886, Time: 08_05_2022__12:36:10\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 1.8473614, Training accuracy: 0.3253437, Time: 08_05_2022__12:36:21\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 1.8444830, Training accuracy: 0.3264198, Time: 08_05_2022__12:36:32\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 1.8420271, Training accuracy: 0.3275915, Time: 08_05_2022__12:36:43\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 1.8384767, Training accuracy: 0.3293976, Time: 08_05_2022__12:36:54\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 1.8355765, Training accuracy: 0.3303571, Time: 08_05_2022__12:37:05\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 1.8324821, Training accuracy: 0.3314412, Time: 08_05_2022__12:37:16\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 1.8289842, Training accuracy: 0.3329942, Time: 08_05_2022__12:37:27\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 1.8261651, Training accuracy: 0.3340517, Time: 08_05_2022__12:37:37\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 1.8226704, Training accuracy: 0.3352841, Time: 08_05_2022__12:37:48\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 1.8198058, Training accuracy: 0.3360955, Time: 08_05_2022__12:37:59\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 1.8176714, Training accuracy: 0.3369722, Time: 08_05_2022__12:38:10\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 1.8150349, Training accuracy: 0.3379121, Time: 08_05_2022__12:38:21\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 1.8118629, Training accuracy: 0.3391848, Time: 08_05_2022__12:38:32\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 1.8096644, Training accuracy: 0.3398656, Time: 08_05_2022__12:38:43\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 1.8075476, Training accuracy: 0.3407447, Time: 08_05_2022__12:38:54\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 1.8065611, Training accuracy: 0.3410789, Time: 08_05_2022__12:39:05\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 1.8034103, Training accuracy: 0.3421615, Time: 08_05_2022__12:39:15\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 1.7999254, Training accuracy: 0.3435309, Time: 08_05_2022__12:39:26\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 1.7973603, Training accuracy: 0.3443112, Time: 08_05_2022__12:39:37\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 1.7953211, Training accuracy: 0.3450000, Time: 08_05_2022__12:39:48\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 1.7932667, Training accuracy: 0.3458500, Time: 08_05_2022__12:39:59\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 1.7916919, Training accuracy: 0.3466584, Time: 08_05_2022__12:40:10\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 1.7898920, Training accuracy: 0.3473775, Time: 08_05_2022__12:40:21\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 1.7877178, Training accuracy: 0.3483010, Time: 08_05_2022__12:40:32\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 1.7851677, Training accuracy: 0.3494952, Time: 08_05_2022__12:40:42\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 1.7835696, Training accuracy: 0.3501190, Time: 08_05_2022__12:40:53\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 1.7814136, Training accuracy: 0.3508019, Time: 08_05_2022__12:41:04\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 1.7791914, Training accuracy: 0.3513785, Time: 08_05_2022__12:41:15\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 1.7766032, Training accuracy: 0.3525000, Time: 08_05_2022__12:41:26\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 1.7752272, Training accuracy: 0.3533945, Time: 08_05_2022__12:41:37\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 1.7733218, Training accuracy: 0.3541364, Time: 08_05_2022__12:41:48\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 1.7700766, Training accuracy: 0.3555631, Time: 08_05_2022__12:41:59\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 1.7684883, Training accuracy: 0.3561384, Time: 08_05_2022__12:42:10\n","Epoch 1 of 5, Average training loss: 1.7677056, Average training accuracy: 0.3564444, Time: 08_05_2022__12:42:15\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96bc5d7068f94b40b22b49f2412405d7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.4237943, Validation accuracy: 0.4850000, Time: 08_05_2022__12:42:19 | Loss decreased from inf to 1.4247893 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.4252489, Validation accuracy: 0.4912500, Time: 08_05_2022__12:42:25\n","Step: 300 of 1250, Validation loss: 1.4436732, Validation accuracy: 0.4750000, Time: 08_05_2022__12:42:29\n","Step: 400 of 1250, Validation loss: 1.4403692, Validation accuracy: 0.4768750, Time: 08_05_2022__12:42:32\n","Step: 500 of 1250, Validation loss: 1.4386434, Validation accuracy: 0.4825000, Time: 08_05_2022__12:42:36\n","Step: 600 of 1250, Validation loss: 1.4307907, Validation accuracy: 0.4825000, Time: 08_05_2022__12:42:40\n","Step: 700 of 1250, Validation loss: 1.4195108, Validation accuracy: 0.4871429, Time: 08_05_2022__12:42:43 | Loss decreased from 1.4247893 to 1.4197062 .... Saving the model\n","Step: 800 of 1250, Validation loss: 1.4101916, Validation accuracy: 0.4896875, Time: 08_05_2022__12:42:49 | Loss decreased from 1.4197062 to 1.4112183 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.4112180, Validation accuracy: 0.4900000, Time: 08_05_2022__12:42:55 | Loss decreased from 1.4112183 to 1.4104512 .... Saving the model\n","Step: 1000 of 1250, Validation loss: 1.4146316, Validation accuracy: 0.4870000, Time: 08_05_2022__12:43:01\n","Step: 1100 of 1250, Validation loss: 1.4147277, Validation accuracy: 0.4865909, Time: 08_05_2022__12:43:04\n","Step: 1200 of 1250, Validation loss: 1.4170475, Validation accuracy: 0.4845833, Time: 08_05_2022__12:43:08\n","Average validation loss: 1.4156017, Average validation accuracy: 0.4848000, Time: 08_05_2022__12:43:10\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e7d864df1ad4a0f8cf93655d6e3cfe0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.4515967, Training accuracy: 0.5100000, Time: 08_05_2022__12:43:21\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.4992730, Training accuracy: 0.4787500, Time: 08_05_2022__12:43:32\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.5135267, Training accuracy: 0.4608333, Time: 08_05_2022__12:43:43\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.5065296, Training accuracy: 0.4568750, Time: 08_05_2022__12:43:54\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.5092604, Training accuracy: 0.4490000, Time: 08_05_2022__12:44:04\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.5051653, Training accuracy: 0.4508333, Time: 08_05_2022__12:44:15\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.5220868, Training accuracy: 0.4425000, Time: 08_05_2022__12:44:26\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.5226042, Training accuracy: 0.4431250, Time: 08_05_2022__12:44:37\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.5227483, Training accuracy: 0.4480556, Time: 08_05_2022__12:44:48\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.5182340, Training accuracy: 0.4470000, Time: 08_05_2022__12:44:59\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.5122427, Training accuracy: 0.4502273, Time: 08_05_2022__12:45:10\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.5118421, Training accuracy: 0.4487500, Time: 08_05_2022__12:45:21\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.5104485, Training accuracy: 0.4501923, Time: 08_05_2022__12:45:32\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.5027928, Training accuracy: 0.4544643, Time: 08_05_2022__12:45:43\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.5021980, Training accuracy: 0.4545000, Time: 08_05_2022__12:45:53\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.5014240, Training accuracy: 0.4548437, Time: 08_05_2022__12:46:04\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.5031974, Training accuracy: 0.4536765, Time: 08_05_2022__12:46:15\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.5029425, Training accuracy: 0.4525000, Time: 08_05_2022__12:46:26\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.5000778, Training accuracy: 0.4542105, Time: 08_05_2022__12:46:37\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.4978382, Training accuracy: 0.4556250, Time: 08_05_2022__12:46:48\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.4967618, Training accuracy: 0.4561905, Time: 08_05_2022__12:46:59\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.4936126, Training accuracy: 0.4577273, Time: 08_05_2022__12:47:10\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.4915008, Training accuracy: 0.4575000, Time: 08_05_2022__12:47:21\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.4879046, Training accuracy: 0.4588542, Time: 08_05_2022__12:47:31\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.4841202, Training accuracy: 0.4600000, Time: 08_05_2022__12:47:42\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.4843675, Training accuracy: 0.4602885, Time: 08_05_2022__12:47:53\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.4823679, Training accuracy: 0.4599074, Time: 08_05_2022__12:48:04\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.4823751, Training accuracy: 0.4598214, Time: 08_05_2022__12:48:15\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.4818702, Training accuracy: 0.4593103, Time: 08_05_2022__12:48:26\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.4808065, Training accuracy: 0.4595000, Time: 08_05_2022__12:48:37\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.4770771, Training accuracy: 0.4606452, Time: 08_05_2022__12:48:48\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.4733770, Training accuracy: 0.4617969, Time: 08_05_2022__12:48:59\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.4742874, Training accuracy: 0.4621212, Time: 08_05_2022__12:49:10\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.4744419, Training accuracy: 0.4625735, Time: 08_05_2022__12:49:20\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.4724013, Training accuracy: 0.4635714, Time: 08_05_2022__12:49:31\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.4717102, Training accuracy: 0.4636111, Time: 08_05_2022__12:49:42\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.4711091, Training accuracy: 0.4634459, Time: 08_05_2022__12:49:53\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.4695125, Training accuracy: 0.4636842, Time: 08_05_2022__12:50:04\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.4676903, Training accuracy: 0.4642308, Time: 08_05_2022__12:50:15\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.4663654, Training accuracy: 0.4653750, Time: 08_05_2022__12:50:26\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.4672361, Training accuracy: 0.4655488, Time: 08_05_2022__12:50:37\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.4638913, Training accuracy: 0.4673810, Time: 08_05_2022__12:50:48\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.4632671, Training accuracy: 0.4677326, Time: 08_05_2022__12:50:59\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.4605252, Training accuracy: 0.4680114, Time: 08_05_2022__12:51:09\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.4578614, Training accuracy: 0.4693889, Time: 08_05_2022__12:51:20\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.4563512, Training accuracy: 0.4702174, Time: 08_05_2022__12:51:31\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.4551841, Training accuracy: 0.4710638, Time: 08_05_2022__12:51:42\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.4536213, Training accuracy: 0.4719792, Time: 08_05_2022__12:51:53\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.4522760, Training accuracy: 0.4724490, Time: 08_05_2022__12:52:04\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.4521769, Training accuracy: 0.4728000, Time: 08_05_2022__12:52:15\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.4497720, Training accuracy: 0.4740686, Time: 08_05_2022__12:52:26\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.4504644, Training accuracy: 0.4743750, Time: 08_05_2022__12:52:37\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.4488993, Training accuracy: 0.4751887, Time: 08_05_2022__12:52:48\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.4483144, Training accuracy: 0.4756944, Time: 08_05_2022__12:52:58\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.4480421, Training accuracy: 0.4764091, Time: 08_05_2022__12:53:09\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.4472495, Training accuracy: 0.4767411, Time: 08_05_2022__12:53:20\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.4460256, Training accuracy: 0.4768421, Time: 08_05_2022__12:53:31\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.4450917, Training accuracy: 0.4772414, Time: 08_05_2022__12:53:42\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.4443440, Training accuracy: 0.4776695, Time: 08_05_2022__12:53:53\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.4429613, Training accuracy: 0.4782917, Time: 08_05_2022__12:54:04\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.4427801, Training accuracy: 0.4787295, Time: 08_05_2022__12:54:15\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.4403626, Training accuracy: 0.4797581, Time: 08_05_2022__12:54:26\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.4399933, Training accuracy: 0.4798016, Time: 08_05_2022__12:54:37\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.4386376, Training accuracy: 0.4803906, Time: 08_05_2022__12:54:47\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.4366544, Training accuracy: 0.4808846, Time: 08_05_2022__12:54:58\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.4360603, Training accuracy: 0.4810985, Time: 08_05_2022__12:55:09\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.4346331, Training accuracy: 0.4814179, Time: 08_05_2022__12:55:20\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.4352172, Training accuracy: 0.4814338, Time: 08_05_2022__12:55:31\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.4336493, Training accuracy: 0.4821014, Time: 08_05_2022__12:55:42\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.4316144, Training accuracy: 0.4830357, Time: 08_05_2022__12:55:53\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.4308895, Training accuracy: 0.4829930, Time: 08_05_2022__12:56:04\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.4297091, Training accuracy: 0.4834028, Time: 08_05_2022__12:56:15\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.4295015, Training accuracy: 0.4836644, Time: 08_05_2022__12:56:26\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.4288575, Training accuracy: 0.4838514, Time: 08_05_2022__12:56:36\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.4275955, Training accuracy: 0.4839667, Time: 08_05_2022__12:56:47\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.4264081, Training accuracy: 0.4841776, Time: 08_05_2022__12:56:58\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.4257751, Training accuracy: 0.4849351, Time: 08_05_2022__12:57:09\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.4234077, Training accuracy: 0.4857051, Time: 08_05_2022__12:57:20\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.4216896, Training accuracy: 0.4860443, Time: 08_05_2022__12:57:31\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.4202312, Training accuracy: 0.4868438, Time: 08_05_2022__12:57:42\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.4199207, Training accuracy: 0.4869753, Time: 08_05_2022__12:57:53\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.4194938, Training accuracy: 0.4869207, Time: 08_05_2022__12:58:04\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.4184129, Training accuracy: 0.4875000, Time: 08_05_2022__12:58:15\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.4174702, Training accuracy: 0.4879464, Time: 08_05_2022__12:58:25\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.4164717, Training accuracy: 0.4884118, Time: 08_05_2022__12:58:36\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.4154861, Training accuracy: 0.4888081, Time: 08_05_2022__12:58:47\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.4139787, Training accuracy: 0.4893103, Time: 08_05_2022__12:58:58\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.4119316, Training accuracy: 0.4900852, Time: 08_05_2022__12:59:09\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.4098102, Training accuracy: 0.4906742, Time: 08_05_2022__12:59:20\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.4096210, Training accuracy: 0.4910278, Time: 08_05_2022__12:59:31\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.4084143, Training accuracy: 0.4913736, Time: 08_05_2022__12:59:42\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.4064643, Training accuracy: 0.4922826, Time: 08_05_2022__12:59:53\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.4053706, Training accuracy: 0.4928495, Time: 08_05_2022__13:00:04\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.4045140, Training accuracy: 0.4933511, Time: 08_05_2022__13:00:15\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.4054111, Training accuracy: 0.4929474, Time: 08_05_2022__13:00:25\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.4040868, Training accuracy: 0.4932292, Time: 08_05_2022__13:00:36\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.4015682, Training accuracy: 0.4940464, Time: 08_05_2022__13:00:47\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.4001517, Training accuracy: 0.4945153, Time: 08_05_2022__13:00:58\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.3994523, Training accuracy: 0.4948737, Time: 08_05_2022__13:01:09\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.3982402, Training accuracy: 0.4954000, Time: 08_05_2022__13:01:20\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.3984286, Training accuracy: 0.4955941, Time: 08_05_2022__13:01:31\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.3976378, Training accuracy: 0.4958333, Time: 08_05_2022__13:01:42\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.3963596, Training accuracy: 0.4964806, Time: 08_05_2022__13:01:53\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.3948293, Training accuracy: 0.4969231, Time: 08_05_2022__13:02:04\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.3942368, Training accuracy: 0.4972857, Time: 08_05_2022__13:02:15\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.3934775, Training accuracy: 0.4978066, Time: 08_05_2022__13:02:25\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.3920664, Training accuracy: 0.4981776, Time: 08_05_2022__13:02:36\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.3909895, Training accuracy: 0.4986111, Time: 08_05_2022__13:02:47\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.3908634, Training accuracy: 0.4989220, Time: 08_05_2022__13:02:58\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.3901703, Training accuracy: 0.4992500, Time: 08_05_2022__13:03:09\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.3889312, Training accuracy: 0.4995045, Time: 08_05_2022__13:03:20\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.3881747, Training accuracy: 0.4999330, Time: 08_05_2022__13:03:31\n","Epoch 2 of 5, Average training loss: 1.3877416, Average training accuracy: 0.5000222, Time: 08_05_2022__13:03:36\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a88403a3640d48b2994c77351c85b7d4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.1690689, Validation accuracy: 0.5725000, Time: 08_05_2022__13:03:40 | Loss decreased from 1.4104512 to 1.1667290 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.1607486, Validation accuracy: 0.5700000, Time: 08_05_2022__13:03:46 | Loss decreased from 1.1667290 to 1.1624369 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.1719542, Validation accuracy: 0.5566667, Time: 08_05_2022__13:03:52\n","Step: 400 of 1250, Validation loss: 1.1834821, Validation accuracy: 0.5581250, Time: 08_05_2022__13:03:55\n","Step: 500 of 1250, Validation loss: 1.1888356, Validation accuracy: 0.5600000, Time: 08_05_2022__13:03:59\n","Step: 600 of 1250, Validation loss: 1.1767098, Validation accuracy: 0.5662500, Time: 08_05_2022__13:04:03\n","Step: 700 of 1250, Validation loss: 1.1608875, Validation accuracy: 0.5721429, Time: 08_05_2022__13:04:07 | Loss decreased from 1.1624369 to 1.1613068 .... Saving the model\n","Step: 800 of 1250, Validation loss: 1.1594239, Validation accuracy: 0.5756250, Time: 08_05_2022__13:04:12 | Loss decreased from 1.1613068 to 1.1598325 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.1613217, Validation accuracy: 0.5738889, Time: 08_05_2022__13:04:18\n","Step: 1000 of 1250, Validation loss: 1.1715323, Validation accuracy: 0.5672500, Time: 08_05_2022__13:04:22\n","Step: 1100 of 1250, Validation loss: 1.1734444, Validation accuracy: 0.5670455, Time: 08_05_2022__13:04:25\n","Step: 1200 of 1250, Validation loss: 1.1785926, Validation accuracy: 0.5664583, Time: 08_05_2022__13:04:29\n","Average validation loss: 1.1791070, Average validation accuracy: 0.5664000, Time: 08_05_2022__13:04:31\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22a3e587ca604996a5a16fd0ab937b2b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.2021809, Training accuracy: 0.5700000, Time: 08_05_2022__13:04:42\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.2303120, Training accuracy: 0.5662500, Time: 08_05_2022__13:04:53\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.2530369, Training accuracy: 0.5616667, Time: 08_05_2022__13:05:04\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.2341895, Training accuracy: 0.5593750, Time: 08_05_2022__13:05:15\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.2371415, Training accuracy: 0.5530000, Time: 08_05_2022__13:05:25\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.2425557, Training accuracy: 0.5525000, Time: 08_05_2022__13:05:36\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.2608953, Training accuracy: 0.5446429, Time: 08_05_2022__13:05:47\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.2608883, Training accuracy: 0.5425000, Time: 08_05_2022__13:05:58\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.2604520, Training accuracy: 0.5455556, Time: 08_05_2022__13:06:09\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.2548834, Training accuracy: 0.5482500, Time: 08_05_2022__13:06:20\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.2512121, Training accuracy: 0.5502273, Time: 08_05_2022__13:06:31\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.2559730, Training accuracy: 0.5489583, Time: 08_05_2022__13:06:42\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.2559180, Training accuracy: 0.5488462, Time: 08_05_2022__13:06:53\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.2520872, Training accuracy: 0.5498214, Time: 08_05_2022__13:07:04\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.2525065, Training accuracy: 0.5495000, Time: 08_05_2022__13:07:15\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.2519184, Training accuracy: 0.5496875, Time: 08_05_2022__13:07:26\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.2516404, Training accuracy: 0.5498529, Time: 08_05_2022__13:07:37\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.2527217, Training accuracy: 0.5494444, Time: 08_05_2022__13:07:47\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.2493028, Training accuracy: 0.5489474, Time: 08_05_2022__13:07:58\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.2503776, Training accuracy: 0.5483750, Time: 08_05_2022__13:08:09\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.2472301, Training accuracy: 0.5491667, Time: 08_05_2022__13:08:20\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.2450686, Training accuracy: 0.5503409, Time: 08_05_2022__13:08:31\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.2427603, Training accuracy: 0.5507609, Time: 08_05_2022__13:08:42\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.2391743, Training accuracy: 0.5514583, Time: 08_05_2022__13:08:53\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.2362056, Training accuracy: 0.5515000, Time: 08_05_2022__13:09:04\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.2356734, Training accuracy: 0.5524038, Time: 08_05_2022__13:09:15\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.2323737, Training accuracy: 0.5529630, Time: 08_05_2022__13:09:26\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.2339584, Training accuracy: 0.5526786, Time: 08_05_2022__13:09:37\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.2346816, Training accuracy: 0.5525862, Time: 08_05_2022__13:09:48\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.2347932, Training accuracy: 0.5528333, Time: 08_05_2022__13:09:59\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.2313831, Training accuracy: 0.5542742, Time: 08_05_2022__13:10:09\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.2273788, Training accuracy: 0.5563281, Time: 08_05_2022__13:10:20\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.2281483, Training accuracy: 0.5564394, Time: 08_05_2022__13:10:31\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.2273251, Training accuracy: 0.5568382, Time: 08_05_2022__13:10:42\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.2266511, Training accuracy: 0.5565714, Time: 08_05_2022__13:10:53\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.2274516, Training accuracy: 0.5570139, Time: 08_05_2022__13:11:04\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.2275801, Training accuracy: 0.5568919, Time: 08_05_2022__13:11:15\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.2265311, Training accuracy: 0.5570395, Time: 08_05_2022__13:11:26\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.2257534, Training accuracy: 0.5573718, Time: 08_05_2022__13:11:37\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.2245130, Training accuracy: 0.5581875, Time: 08_05_2022__13:11:48\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.2263373, Training accuracy: 0.5575610, Time: 08_05_2022__13:11:59\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.2220125, Training accuracy: 0.5594643, Time: 08_05_2022__13:12:10\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.2203133, Training accuracy: 0.5595930, Time: 08_05_2022__13:12:20\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.2173451, Training accuracy: 0.5610227, Time: 08_05_2022__13:12:31\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.2159386, Training accuracy: 0.5617778, Time: 08_05_2022__13:12:42\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.2151350, Training accuracy: 0.5623913, Time: 08_05_2022__13:12:53\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.2140883, Training accuracy: 0.5635106, Time: 08_05_2022__13:13:04\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.2122836, Training accuracy: 0.5643229, Time: 08_05_2022__13:13:15\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.2111515, Training accuracy: 0.5642857, Time: 08_05_2022__13:13:26\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.2099912, Training accuracy: 0.5648500, Time: 08_05_2022__13:13:37\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.2082337, Training accuracy: 0.5654902, Time: 08_05_2022__13:13:48\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.2083164, Training accuracy: 0.5650481, Time: 08_05_2022__13:13:59\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.2075678, Training accuracy: 0.5651887, Time: 08_05_2022__13:14:10\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.2060762, Training accuracy: 0.5655556, Time: 08_05_2022__13:14:21\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.2059781, Training accuracy: 0.5657727, Time: 08_05_2022__13:14:32\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.2055698, Training accuracy: 0.5662054, Time: 08_05_2022__13:14:42\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.2052756, Training accuracy: 0.5659649, Time: 08_05_2022__13:14:53\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.2055254, Training accuracy: 0.5662069, Time: 08_05_2022__13:15:04\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.2043206, Training accuracy: 0.5667373, Time: 08_05_2022__13:15:15\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.2034296, Training accuracy: 0.5671667, Time: 08_05_2022__13:15:26\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.2034359, Training accuracy: 0.5670082, Time: 08_05_2022__13:15:37\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.2021423, Training accuracy: 0.5679839, Time: 08_05_2022__13:15:48\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.2026133, Training accuracy: 0.5677381, Time: 08_05_2022__13:15:59\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.2018987, Training accuracy: 0.5676172, Time: 08_05_2022__13:16:10\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.2013150, Training accuracy: 0.5678462, Time: 08_05_2022__13:16:21\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.2006744, Training accuracy: 0.5684091, Time: 08_05_2022__13:16:32\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.1996829, Training accuracy: 0.5688433, Time: 08_05_2022__13:16:43\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.1995598, Training accuracy: 0.5691176, Time: 08_05_2022__13:16:54\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.1989178, Training accuracy: 0.5695290, Time: 08_05_2022__13:17:04\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.1973185, Training accuracy: 0.5703214, Time: 08_05_2022__13:17:15\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.1964683, Training accuracy: 0.5705282, Time: 08_05_2022__13:17:26\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.1951293, Training accuracy: 0.5712500, Time: 08_05_2022__13:17:37\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.1937749, Training accuracy: 0.5719521, Time: 08_05_2022__13:17:48\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.1928071, Training accuracy: 0.5721284, Time: 08_05_2022__13:17:59\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.1913325, Training accuracy: 0.5725333, Time: 08_05_2022__13:18:10\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.1905270, Training accuracy: 0.5728618, Time: 08_05_2022__13:18:21\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.1892136, Training accuracy: 0.5734091, Time: 08_05_2022__13:18:32\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.1878682, Training accuracy: 0.5740705, Time: 08_05_2022__13:18:43\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.1866062, Training accuracy: 0.5745570, Time: 08_05_2022__13:18:54\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.1857829, Training accuracy: 0.5746250, Time: 08_05_2022__13:19:05\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.1857562, Training accuracy: 0.5744753, Time: 08_05_2022__13:19:16\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.1859591, Training accuracy: 0.5741768, Time: 08_05_2022__13:19:26\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.1848443, Training accuracy: 0.5745181, Time: 08_05_2022__13:19:37\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.1850126, Training accuracy: 0.5742857, Time: 08_05_2022__13:19:48\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.1838808, Training accuracy: 0.5748235, Time: 08_05_2022__13:19:59\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.1830676, Training accuracy: 0.5754070, Time: 08_05_2022__13:20:10\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.1823759, Training accuracy: 0.5754885, Time: 08_05_2022__13:20:21\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.1802254, Training accuracy: 0.5762784, Time: 08_05_2022__13:20:32\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 1.1786486, Training accuracy: 0.5771348, Time: 08_05_2022__13:20:43\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 1.1779644, Training accuracy: 0.5775833, Time: 08_05_2022__13:20:54\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 1.1777378, Training accuracy: 0.5778022, Time: 08_05_2022__13:21:05\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 1.1760988, Training accuracy: 0.5783967, Time: 08_05_2022__13:21:16\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 1.1755758, Training accuracy: 0.5789516, Time: 08_05_2022__13:21:27\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 1.1751633, Training accuracy: 0.5792287, Time: 08_05_2022__13:21:38\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 1.1756120, Training accuracy: 0.5788947, Time: 08_05_2022__13:21:48\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 1.1738477, Training accuracy: 0.5796094, Time: 08_05_2022__13:21:59\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 1.1718810, Training accuracy: 0.5804381, Time: 08_05_2022__13:22:10\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 1.1704057, Training accuracy: 0.5812245, Time: 08_05_2022__13:22:21\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 1.1697345, Training accuracy: 0.5815909, Time: 08_05_2022__13:22:32\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 1.1686042, Training accuracy: 0.5821750, Time: 08_05_2022__13:22:43\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 1.1690117, Training accuracy: 0.5821287, Time: 08_05_2022__13:22:54\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 1.1679638, Training accuracy: 0.5826961, Time: 08_05_2022__13:23:05\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 1.1669067, Training accuracy: 0.5832039, Time: 08_05_2022__13:23:16\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 1.1652113, Training accuracy: 0.5837740, Time: 08_05_2022__13:23:27\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 1.1646647, Training accuracy: 0.5840238, Time: 08_05_2022__13:23:38\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 1.1643702, Training accuracy: 0.5841274, Time: 08_05_2022__13:23:49\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 1.1631340, Training accuracy: 0.5844626, Time: 08_05_2022__13:23:59\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 1.1622049, Training accuracy: 0.5850926, Time: 08_05_2022__13:24:10\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 1.1620800, Training accuracy: 0.5849771, Time: 08_05_2022__13:24:21\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 1.1613463, Training accuracy: 0.5853636, Time: 08_05_2022__13:24:32\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 1.1599552, Training accuracy: 0.5859685, Time: 08_05_2022__13:24:43\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 1.1596622, Training accuracy: 0.5860268, Time: 08_05_2022__13:24:54\n","Epoch 3 of 5, Average training loss: 1.1592362, Average training accuracy: 0.5861778, Time: 08_05_2022__13:25:00\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0846d20f867408aae16d2120f5163fd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.0183265, Validation accuracy: 0.6350000, Time: 08_05_2022__13:25:03 | Loss decreased from 1.1598325 to 1.0220242 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.0122545, Validation accuracy: 0.6300000, Time: 08_05_2022__13:25:09 | Loss decreased from 1.0220242 to 1.0145320 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.0332339, Validation accuracy: 0.6216667, Time: 08_05_2022__13:25:15\n","Step: 400 of 1250, Validation loss: 1.0305093, Validation accuracy: 0.6275000, Time: 08_05_2022__13:25:18\n","Step: 500 of 1250, Validation loss: 1.0408813, Validation accuracy: 0.6230000, Time: 08_05_2022__13:25:22\n","Step: 600 of 1250, Validation loss: 1.0250069, Validation accuracy: 0.6300000, Time: 08_05_2022__13:25:26\n","Step: 700 of 1250, Validation loss: 1.0128296, Validation accuracy: 0.6346429, Time: 08_05_2022__13:25:29 | Loss decreased from 1.0145320 to 1.0132239 .... Saving the model\n","Step: 800 of 1250, Validation loss: 1.0073494, Validation accuracy: 0.6353125, Time: 08_05_2022__13:25:35 | Loss decreased from 1.0132239 to 1.0075914 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.0162949, Validation accuracy: 0.6316667, Time: 08_05_2022__13:25:41\n","Step: 1000 of 1250, Validation loss: 1.0218565, Validation accuracy: 0.6307500, Time: 08_05_2022__13:25:44\n","Step: 1100 of 1250, Validation loss: 1.0214728, Validation accuracy: 0.6315909, Time: 08_05_2022__13:25:48\n","Step: 1200 of 1250, Validation loss: 1.0315820, Validation accuracy: 0.6293750, Time: 08_05_2022__13:25:52\n","Average validation loss: 1.0332164, Average validation accuracy: 0.6290000, Time: 08_05_2022__13:25:54\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5be73bcaba241fc871da0a5299e2f87"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 0.9301282, Training accuracy: 0.6575000, Time: 08_05_2022__13:26:05\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 0.9859749, Training accuracy: 0.6362500, Time: 08_05_2022__13:26:16\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 1.0263487, Training accuracy: 0.6250000, Time: 08_05_2022__13:26:27\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 1.0111477, Training accuracy: 0.6300000, Time: 08_05_2022__13:26:37\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 1.0168618, Training accuracy: 0.6280000, Time: 08_05_2022__13:26:48\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 1.0116027, Training accuracy: 0.6354167, Time: 08_05_2022__13:26:59\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 1.0271638, Training accuracy: 0.6307143, Time: 08_05_2022__13:27:10\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 1.0330490, Training accuracy: 0.6275000, Time: 08_05_2022__13:27:21\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 1.0361043, Training accuracy: 0.6266667, Time: 08_05_2022__13:27:32\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 1.0338881, Training accuracy: 0.6282500, Time: 08_05_2022__13:27:43\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 1.0360412, Training accuracy: 0.6286364, Time: 08_05_2022__13:27:54\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 1.0424620, Training accuracy: 0.6260417, Time: 08_05_2022__13:28:05\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 1.0465661, Training accuracy: 0.6251923, Time: 08_05_2022__13:28:16\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 1.0456718, Training accuracy: 0.6253571, Time: 08_05_2022__13:28:27\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 1.0461385, Training accuracy: 0.6256667, Time: 08_05_2022__13:28:37\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 1.0426955, Training accuracy: 0.6281250, Time: 08_05_2022__13:28:48\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 1.0447515, Training accuracy: 0.6270588, Time: 08_05_2022__13:28:59\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 1.0489439, Training accuracy: 0.6247222, Time: 08_05_2022__13:29:10\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 1.0458271, Training accuracy: 0.6247368, Time: 08_05_2022__13:29:21\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 1.0453380, Training accuracy: 0.6235000, Time: 08_05_2022__13:29:32\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 1.0433794, Training accuracy: 0.6252381, Time: 08_05_2022__13:29:43\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 1.0411431, Training accuracy: 0.6269318, Time: 08_05_2022__13:29:54\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 1.0391610, Training accuracy: 0.6277174, Time: 08_05_2022__13:30:05\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 1.0363608, Training accuracy: 0.6282292, Time: 08_05_2022__13:30:16\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 1.0341414, Training accuracy: 0.6291000, Time: 08_05_2022__13:30:27\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 1.0344504, Training accuracy: 0.6281731, Time: 08_05_2022__13:30:37\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 1.0308936, Training accuracy: 0.6300000, Time: 08_05_2022__13:30:48\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 1.0326639, Training accuracy: 0.6294643, Time: 08_05_2022__13:30:59\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 1.0311221, Training accuracy: 0.6309483, Time: 08_05_2022__13:31:10\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 1.0315129, Training accuracy: 0.6308333, Time: 08_05_2022__13:31:21\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 1.0287379, Training accuracy: 0.6316129, Time: 08_05_2022__13:31:32\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 1.0238337, Training accuracy: 0.6335937, Time: 08_05_2022__13:31:43\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 1.0255793, Training accuracy: 0.6334091, Time: 08_05_2022__13:31:54\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 1.0256711, Training accuracy: 0.6333088, Time: 08_05_2022__13:32:05\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 1.0260734, Training accuracy: 0.6331429, Time: 08_05_2022__13:32:16\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 1.0260248, Training accuracy: 0.6327083, Time: 08_05_2022__13:32:27\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 1.0253442, Training accuracy: 0.6329054, Time: 08_05_2022__13:32:38\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 1.0217824, Training accuracy: 0.6338158, Time: 08_05_2022__13:32:49\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 1.0211836, Training accuracy: 0.6336538, Time: 08_05_2022__13:32:59\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 1.0208331, Training accuracy: 0.6340000, Time: 08_05_2022__13:33:10\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 1.0231400, Training accuracy: 0.6329878, Time: 08_05_2022__13:33:21\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 1.0190421, Training accuracy: 0.6344048, Time: 08_05_2022__13:33:32\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 1.0161380, Training accuracy: 0.6355233, Time: 08_05_2022__13:33:43\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 1.0142939, Training accuracy: 0.6360227, Time: 08_05_2022__13:33:54\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 1.0139562, Training accuracy: 0.6365000, Time: 08_05_2022__13:34:05\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 1.0144567, Training accuracy: 0.6365761, Time: 08_05_2022__13:34:16\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 1.0128265, Training accuracy: 0.6376596, Time: 08_05_2022__13:34:27\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 1.0120365, Training accuracy: 0.6377083, Time: 08_05_2022__13:34:38\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 1.0115528, Training accuracy: 0.6376020, Time: 08_05_2022__13:34:49\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 1.0117635, Training accuracy: 0.6382000, Time: 08_05_2022__13:34:59\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 1.0109409, Training accuracy: 0.6386765, Time: 08_05_2022__13:35:10\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 1.0099259, Training accuracy: 0.6388942, Time: 08_05_2022__13:35:21\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 1.0105791, Training accuracy: 0.6384434, Time: 08_05_2022__13:35:32\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 1.0093779, Training accuracy: 0.6388426, Time: 08_05_2022__13:35:43\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 1.0097051, Training accuracy: 0.6387273, Time: 08_05_2022__13:35:54\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 1.0087574, Training accuracy: 0.6390625, Time: 08_05_2022__13:36:05\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 1.0085135, Training accuracy: 0.6389474, Time: 08_05_2022__13:36:16\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 1.0079334, Training accuracy: 0.6387931, Time: 08_05_2022__13:36:27\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 1.0077704, Training accuracy: 0.6386864, Time: 08_05_2022__13:36:38\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 1.0074148, Training accuracy: 0.6388333, Time: 08_05_2022__13:36:49\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 1.0073366, Training accuracy: 0.6390164, Time: 08_05_2022__13:37:00\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 1.0064808, Training accuracy: 0.6391935, Time: 08_05_2022__13:37:11\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 1.0063255, Training accuracy: 0.6392460, Time: 08_05_2022__13:37:21\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 1.0050808, Training accuracy: 0.6396875, Time: 08_05_2022__13:37:32\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 1.0042630, Training accuracy: 0.6399231, Time: 08_05_2022__13:37:43\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 1.0041641, Training accuracy: 0.6402652, Time: 08_05_2022__13:37:54\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 1.0030670, Training accuracy: 0.6403731, Time: 08_05_2022__13:38:05\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 1.0026909, Training accuracy: 0.6405147, Time: 08_05_2022__13:38:16\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 1.0016362, Training accuracy: 0.6409058, Time: 08_05_2022__13:38:27\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 1.0001170, Training accuracy: 0.6415714, Time: 08_05_2022__13:38:38\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 1.0002825, Training accuracy: 0.6413732, Time: 08_05_2022__13:38:49\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 0.9988289, Training accuracy: 0.6420833, Time: 08_05_2022__13:39:00\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 0.9975600, Training accuracy: 0.6426370, Time: 08_05_2022__13:39:11\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 0.9969003, Training accuracy: 0.6429730, Time: 08_05_2022__13:39:22\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 0.9957669, Training accuracy: 0.6431333, Time: 08_05_2022__13:39:32\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 0.9946953, Training accuracy: 0.6436842, Time: 08_05_2022__13:39:43\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 0.9946722, Training accuracy: 0.6438312, Time: 08_05_2022__13:39:54\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 0.9934053, Training accuracy: 0.6439744, Time: 08_05_2022__13:40:05\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 0.9921130, Training accuracy: 0.6443038, Time: 08_05_2022__13:40:16\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 0.9906558, Training accuracy: 0.6445625, Time: 08_05_2022__13:40:27\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 0.9903115, Training accuracy: 0.6450309, Time: 08_05_2022__13:40:38\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 0.9905889, Training accuracy: 0.6450000, Time: 08_05_2022__13:40:49\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 0.9899944, Training accuracy: 0.6450301, Time: 08_05_2022__13:41:00\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 0.9905942, Training accuracy: 0.6449702, Time: 08_05_2022__13:41:11\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 0.9902661, Training accuracy: 0.6452059, Time: 08_05_2022__13:41:22\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 0.9900295, Training accuracy: 0.6453488, Time: 08_05_2022__13:41:33\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 0.9895509, Training accuracy: 0.6455747, Time: 08_05_2022__13:41:44\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 0.9879543, Training accuracy: 0.6463920, Time: 08_05_2022__13:41:54\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 0.9866052, Training accuracy: 0.6469382, Time: 08_05_2022__13:42:05\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 0.9863022, Training accuracy: 0.6472222, Time: 08_05_2022__13:42:16\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 0.9866476, Training accuracy: 0.6472802, Time: 08_05_2022__13:42:27\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 0.9854079, Training accuracy: 0.6479348, Time: 08_05_2022__13:42:38\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 0.9848984, Training accuracy: 0.6482258, Time: 08_05_2022__13:42:49\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 0.9847178, Training accuracy: 0.6482713, Time: 08_05_2022__13:43:00\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 0.9851125, Training accuracy: 0.6480789, Time: 08_05_2022__13:43:11\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 0.9838515, Training accuracy: 0.6484375, Time: 08_05_2022__13:43:22\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 0.9818514, Training accuracy: 0.6493299, Time: 08_05_2022__13:43:33\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 0.9804186, Training accuracy: 0.6501531, Time: 08_05_2022__13:43:44\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 0.9802381, Training accuracy: 0.6502273, Time: 08_05_2022__13:43:55\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 0.9801111, Training accuracy: 0.6504250, Time: 08_05_2022__13:44:06\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 0.9809798, Training accuracy: 0.6502228, Time: 08_05_2022__13:44:16\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 0.9803145, Training accuracy: 0.6506127, Time: 08_05_2022__13:44:27\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 0.9796603, Training accuracy: 0.6510194, Time: 08_05_2022__13:44:38\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 0.9784698, Training accuracy: 0.6514663, Time: 08_05_2022__13:44:49\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 0.9779636, Training accuracy: 0.6518095, Time: 08_05_2022__13:45:00\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 0.9786162, Training accuracy: 0.6518868, Time: 08_05_2022__13:45:11\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 0.9775580, Training accuracy: 0.6521729, Time: 08_05_2022__13:45:22\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 0.9767618, Training accuracy: 0.6524537, Time: 08_05_2022__13:45:33\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 0.9769418, Training accuracy: 0.6524541, Time: 08_05_2022__13:45:44\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 0.9766173, Training accuracy: 0.6525909, Time: 08_05_2022__13:45:55\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 0.9751360, Training accuracy: 0.6532207, Time: 08_05_2022__13:46:06\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 0.9749450, Training accuracy: 0.6531027, Time: 08_05_2022__13:46:17\n","Epoch 4 of 5, Average training loss: 0.9748051, Average training accuracy: 0.6531556, Time: 08_05_2022__13:46:22\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49f22b7371b045db80c5ac93f066ba25"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.8959466, Validation accuracy: 0.6750000, Time: 08_05_2022__13:46:26 | Loss decreased from 1.0075914 to 0.8969658 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.8895172, Validation accuracy: 0.6862500, Time: 08_05_2022__13:46:31 | Loss decreased from 0.8969658 to 0.8924369 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.9189814, Validation accuracy: 0.6733333, Time: 08_05_2022__13:46:37\n","Step: 400 of 1250, Validation loss: 0.9151894, Validation accuracy: 0.6737500, Time: 08_05_2022__13:46:41\n","Step: 500 of 1250, Validation loss: 0.9258617, Validation accuracy: 0.6700000, Time: 08_05_2022__13:46:44\n","Step: 600 of 1250, Validation loss: 0.9119851, Validation accuracy: 0.6758333, Time: 08_05_2022__13:46:48\n","Step: 700 of 1250, Validation loss: 0.9016556, Validation accuracy: 0.6814286, Time: 08_05_2022__13:46:52\n","Step: 800 of 1250, Validation loss: 0.8866077, Validation accuracy: 0.6856250, Time: 08_05_2022__13:46:55 | Loss decreased from 0.8924369 to 0.8861485 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.8902592, Validation accuracy: 0.6841667, Time: 08_05_2022__13:47:01\n","Step: 1000 of 1250, Validation loss: 0.8939283, Validation accuracy: 0.6810000, Time: 08_05_2022__13:47:05\n","Step: 1100 of 1250, Validation loss: 0.8951623, Validation accuracy: 0.6827273, Time: 08_05_2022__13:47:08\n","Step: 1200 of 1250, Validation loss: 0.9060391, Validation accuracy: 0.6789583, Time: 08_05_2022__13:47:12\n","Average validation loss: 0.9079832, Average validation accuracy: 0.6780000, Time: 08_05_2022__13:47:14\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7eede6a5f624c59962803af1fc83384"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 0.8211750, Training accuracy: 0.7075000, Time: 08_05_2022__13:47:25\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 0.8460605, Training accuracy: 0.7000000, Time: 08_05_2022__13:47:36\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 0.8734870, Training accuracy: 0.6858333, Time: 08_05_2022__13:47:47\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 0.8409588, Training accuracy: 0.6950000, Time: 08_05_2022__13:47:58\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 0.8490186, Training accuracy: 0.6920000, Time: 08_05_2022__13:48:09\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 0.8523571, Training accuracy: 0.6925000, Time: 08_05_2022__13:48:20\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 0.8654047, Training accuracy: 0.6907143, Time: 08_05_2022__13:48:31\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 0.8683842, Training accuracy: 0.6890625, Time: 08_05_2022__13:48:42\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 0.8751558, Training accuracy: 0.6875000, Time: 08_05_2022__13:48:52\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 0.8753617, Training accuracy: 0.6880000, Time: 08_05_2022__13:49:03\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 0.8797368, Training accuracy: 0.6859091, Time: 08_05_2022__13:49:14\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 0.8853074, Training accuracy: 0.6831250, Time: 08_05_2022__13:49:25\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 0.8904578, Training accuracy: 0.6809615, Time: 08_05_2022__13:49:36\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 0.8905647, Training accuracy: 0.6825000, Time: 08_05_2022__13:49:47\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 0.8951761, Training accuracy: 0.6811667, Time: 08_05_2022__13:49:58\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 0.8911404, Training accuracy: 0.6832812, Time: 08_05_2022__13:50:09\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 0.8941760, Training accuracy: 0.6822059, Time: 08_05_2022__13:50:20\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 0.8989154, Training accuracy: 0.6797222, Time: 08_05_2022__13:50:31\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 0.8943283, Training accuracy: 0.6817105, Time: 08_05_2022__13:50:42\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 0.8939343, Training accuracy: 0.6817500, Time: 08_05_2022__13:50:53\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 0.8899769, Training accuracy: 0.6835714, Time: 08_05_2022__13:51:04\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 0.8900739, Training accuracy: 0.6850000, Time: 08_05_2022__13:51:15\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 0.8874763, Training accuracy: 0.6857609, Time: 08_05_2022__13:51:26\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 0.8830540, Training accuracy: 0.6860417, Time: 08_05_2022__13:51:37\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 0.8810250, Training accuracy: 0.6865000, Time: 08_05_2022__13:51:47\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 0.8810614, Training accuracy: 0.6862500, Time: 08_05_2022__13:51:58\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 0.8790026, Training accuracy: 0.6875000, Time: 08_05_2022__13:52:09\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 0.8786880, Training accuracy: 0.6875893, Time: 08_05_2022__13:52:20\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 0.8777338, Training accuracy: 0.6889655, Time: 08_05_2022__13:52:31\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 0.8775199, Training accuracy: 0.6875833, Time: 08_05_2022__13:52:42\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 0.8751973, Training accuracy: 0.6883871, Time: 08_05_2022__13:52:53\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 0.8722658, Training accuracy: 0.6895313, Time: 08_05_2022__13:53:04\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 0.8734034, Training accuracy: 0.6891667, Time: 08_05_2022__13:53:15\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 0.8733671, Training accuracy: 0.6896324, Time: 08_05_2022__13:53:26\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 0.8728654, Training accuracy: 0.6899286, Time: 08_05_2022__13:53:37\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 0.8738167, Training accuracy: 0.6897917, Time: 08_05_2022__13:53:48\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 0.8739210, Training accuracy: 0.6893243, Time: 08_05_2022__13:53:59\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 0.8721528, Training accuracy: 0.6901316, Time: 08_05_2022__13:54:10\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 0.8719151, Training accuracy: 0.6898718, Time: 08_05_2022__13:54:21\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 0.8702382, Training accuracy: 0.6900000, Time: 08_05_2022__13:54:31\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 0.8716716, Training accuracy: 0.6896951, Time: 08_05_2022__13:54:42\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 0.8680376, Training accuracy: 0.6910119, Time: 08_05_2022__13:54:53\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 0.8651256, Training accuracy: 0.6924419, Time: 08_05_2022__13:55:04\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 0.8635647, Training accuracy: 0.6930682, Time: 08_05_2022__13:55:15\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 0.8633459, Training accuracy: 0.6935556, Time: 08_05_2022__13:55:26\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 0.8646121, Training accuracy: 0.6934783, Time: 08_05_2022__13:55:37\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 0.8640577, Training accuracy: 0.6942021, Time: 08_05_2022__13:55:48\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 0.8644158, Training accuracy: 0.6939062, Time: 08_05_2022__13:55:59\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 0.8637999, Training accuracy: 0.6942347, Time: 08_05_2022__13:56:10\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 0.8639619, Training accuracy: 0.6944500, Time: 08_05_2022__13:56:21\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 0.8637100, Training accuracy: 0.6939216, Time: 08_05_2022__13:56:32\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 0.8636425, Training accuracy: 0.6939423, Time: 08_05_2022__13:56:43\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 0.8644169, Training accuracy: 0.6934906, Time: 08_05_2022__13:56:54\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 0.8635671, Training accuracy: 0.6937500, Time: 08_05_2022__13:57:05\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 0.8645707, Training accuracy: 0.6940000, Time: 08_05_2022__13:57:15\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 0.8641369, Training accuracy: 0.6935714, Time: 08_05_2022__13:57:26\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 0.8631647, Training accuracy: 0.6940351, Time: 08_05_2022__13:57:37\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 0.8634295, Training accuracy: 0.6938793, Time: 08_05_2022__13:57:48\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 0.8634614, Training accuracy: 0.6941525, Time: 08_05_2022__13:57:59\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 0.8639530, Training accuracy: 0.6939583, Time: 08_05_2022__13:58:10\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 0.8642824, Training accuracy: 0.6934426, Time: 08_05_2022__13:58:21\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 0.8637976, Training accuracy: 0.6935081, Time: 08_05_2022__13:58:32\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 0.8633016, Training accuracy: 0.6935317, Time: 08_05_2022__13:58:43\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 0.8626757, Training accuracy: 0.6939062, Time: 08_05_2022__13:58:54\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 0.8620048, Training accuracy: 0.6943462, Time: 08_05_2022__13:59:05\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 0.8620546, Training accuracy: 0.6945076, Time: 08_05_2022__13:59:16\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 0.8608699, Training accuracy: 0.6948134, Time: 08_05_2022__13:59:27\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 0.8602807, Training accuracy: 0.6945956, Time: 08_05_2022__13:59:38\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 0.8593214, Training accuracy: 0.6948551, Time: 08_05_2022__13:59:48\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 0.8575958, Training accuracy: 0.6955714, Time: 08_05_2022__13:59:59\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 0.8579110, Training accuracy: 0.6955282, Time: 08_05_2022__14:00:10\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 0.8561271, Training accuracy: 0.6957986, Time: 08_05_2022__14:00:21\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 0.8547161, Training accuracy: 0.6963356, Time: 08_05_2022__14:00:32\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 0.8541794, Training accuracy: 0.6963514, Time: 08_05_2022__14:00:43\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 0.8529891, Training accuracy: 0.6966667, Time: 08_05_2022__14:00:54\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 0.8521790, Training accuracy: 0.6968750, Time: 08_05_2022__14:01:05\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 0.8524177, Training accuracy: 0.6971104, Time: 08_05_2022__14:01:16\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 0.8517328, Training accuracy: 0.6971795, Time: 08_05_2022__14:01:27\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 0.8508457, Training accuracy: 0.6974367, Time: 08_05_2022__14:01:38\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 0.8494439, Training accuracy: 0.6978125, Time: 08_05_2022__14:01:49\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 0.8492528, Training accuracy: 0.6980864, Time: 08_05_2022__14:02:00\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 0.8494121, Training accuracy: 0.6983232, Time: 08_05_2022__14:02:11\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 0.8489792, Training accuracy: 0.6984337, Time: 08_05_2022__14:02:22\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 0.8498205, Training accuracy: 0.6981845, Time: 08_05_2022__14:02:33\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 0.8492332, Training accuracy: 0.6985588, Time: 08_05_2022__14:02:44\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 0.8491425, Training accuracy: 0.6985174, Time: 08_05_2022__14:02:54\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 0.8489947, Training accuracy: 0.6985345, Time: 08_05_2022__14:03:05\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 0.8479030, Training accuracy: 0.6992045, Time: 08_05_2022__14:03:16\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 0.8473742, Training accuracy: 0.6994663, Time: 08_05_2022__14:03:27\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 0.8466819, Training accuracy: 0.7000000, Time: 08_05_2022__14:03:38\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 0.8466643, Training accuracy: 0.6997802, Time: 08_05_2022__14:03:49\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 0.8455570, Training accuracy: 0.7003533, Time: 08_05_2022__14:04:00\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 0.8456830, Training accuracy: 0.7003495, Time: 08_05_2022__14:04:11\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 0.8451361, Training accuracy: 0.7005319, Time: 08_05_2022__14:04:22\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 0.8458139, Training accuracy: 0.7003947, Time: 08_05_2022__14:04:33\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 0.8447633, Training accuracy: 0.7009896, Time: 08_05_2022__14:04:44\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 0.8432219, Training accuracy: 0.7013918, Time: 08_05_2022__14:04:55\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 0.8427241, Training accuracy: 0.7018112, Time: 08_05_2022__14:05:06\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 0.8422410, Training accuracy: 0.7019697, Time: 08_05_2022__14:05:17\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 0.8421082, Training accuracy: 0.7022750, Time: 08_05_2022__14:05:28\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 0.8423268, Training accuracy: 0.7022277, Time: 08_05_2022__14:05:39\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 0.8420940, Training accuracy: 0.7026225, Time: 08_05_2022__14:05:49\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 0.8413994, Training accuracy: 0.7030340, Time: 08_05_2022__14:06:00\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 0.8405014, Training accuracy: 0.7036058, Time: 08_05_2022__14:06:11\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 0.8397559, Training accuracy: 0.7041429, Time: 08_05_2022__14:06:22\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 0.8401318, Training accuracy: 0.7039858, Time: 08_05_2022__14:06:33\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 0.8388603, Training accuracy: 0.7045794, Time: 08_05_2022__14:06:44\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 0.8382305, Training accuracy: 0.7051389, Time: 08_05_2022__14:06:55\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 0.8386945, Training accuracy: 0.7050688, Time: 08_05_2022__14:07:06\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 0.8383877, Training accuracy: 0.7051591, Time: 08_05_2022__14:07:17\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 0.8371592, Training accuracy: 0.7054955, Time: 08_05_2022__14:07:28\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 0.8368763, Training accuracy: 0.7054464, Time: 08_05_2022__14:07:39\n","Epoch 5 of 5, Average training loss: 0.8367880, Average training accuracy: 0.7054000, Time: 08_05_2022__14:07:44\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a3c867f2d9241ce84a06407bf6554cc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.8483295, Validation accuracy: 0.6975000, Time: 08_05_2022__14:07:48 | Loss decreased from 0.8861485 to 0.8508583 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.8254942, Validation accuracy: 0.7037500, Time: 08_05_2022__14:07:54 | Loss decreased from 0.8508583 to 0.8275675 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.8608945, Validation accuracy: 0.6966667, Time: 08_05_2022__14:07:59\n","Step: 400 of 1250, Validation loss: 0.8404831, Validation accuracy: 0.7093750, Time: 08_05_2022__14:08:03\n","Step: 500 of 1250, Validation loss: 0.8462901, Validation accuracy: 0.7080000, Time: 08_05_2022__14:08:07\n","Step: 600 of 1250, Validation loss: 0.8335999, Validation accuracy: 0.7141667, Time: 08_05_2022__14:08:10\n","Step: 700 of 1250, Validation loss: 0.8290187, Validation accuracy: 0.7150000, Time: 08_05_2022__14:08:14\n","Step: 800 of 1250, Validation loss: 0.8141014, Validation accuracy: 0.7196875, Time: 08_05_2022__14:08:18 | Loss decreased from 0.8275675 to 0.8131998 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.8148561, Validation accuracy: 0.7200000, Time: 08_05_2022__14:08:23\n","Step: 1000 of 1250, Validation loss: 0.8147015, Validation accuracy: 0.7192500, Time: 08_05_2022__14:08:27\n","Step: 1100 of 1250, Validation loss: 0.8152913, Validation accuracy: 0.7186364, Time: 08_05_2022__14:08:31\n","Step: 1200 of 1250, Validation loss: 0.8275070, Validation accuracy: 0.7143750, Time: 08_05_2022__14:08:34\n","Average validation loss: 0.8297392, Average validation accuracy: 0.7142000, Time: 08_05_2022__14:08:36\n","###################### Testing vgg19_batch_norm SGD, lr_0.001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0cdf6a173954b48a4b87a2f6a84f854"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.7300000, Time: 08_05_2022__14:08:50\n","Step: 200 of 2500, Test accuracy: 0.7250000, Time: 08_05_2022__14:08:54\n","Step: 300 of 2500, Test accuracy: 0.7241667, Time: 08_05_2022__14:08:58\n","Step: 400 of 2500, Test accuracy: 0.7131250, Time: 08_05_2022__14:09:01\n","Step: 500 of 2500, Test accuracy: 0.7085000, Time: 08_05_2022__14:09:05\n","Step: 600 of 2500, Test accuracy: 0.7091667, Time: 08_05_2022__14:09:09\n","Step: 700 of 2500, Test accuracy: 0.7085714, Time: 08_05_2022__14:09:12\n","Step: 800 of 2500, Test accuracy: 0.7128125, Time: 08_05_2022__14:09:16\n","Step: 900 of 2500, Test accuracy: 0.7094444, Time: 08_05_2022__14:09:20\n","Step: 1000 of 2500, Test accuracy: 0.7045000, Time: 08_05_2022__14:09:23\n","Step: 1100 of 2500, Test accuracy: 0.7054545, Time: 08_05_2022__14:09:27\n","Step: 1200 of 2500, Test accuracy: 0.7064583, Time: 08_05_2022__14:09:31\n","Step: 1300 of 2500, Test accuracy: 0.7050000, Time: 08_05_2022__14:09:34\n","Step: 1400 of 2500, Test accuracy: 0.7060714, Time: 08_05_2022__14:09:38\n","Step: 1500 of 2500, Test accuracy: 0.7065000, Time: 08_05_2022__14:09:42\n","Step: 1600 of 2500, Test accuracy: 0.7073438, Time: 08_05_2022__14:09:45\n","Step: 1700 of 2500, Test accuracy: 0.7069118, Time: 08_05_2022__14:09:49\n","Step: 1800 of 2500, Test accuracy: 0.7062500, Time: 08_05_2022__14:09:53\n","Step: 1900 of 2500, Test accuracy: 0.7082895, Time: 08_05_2022__14:09:56\n","Step: 2000 of 2500, Test accuracy: 0.7075000, Time: 08_05_2022__14:10:00\n","Step: 2100 of 2500, Test accuracy: 0.7063095, Time: 08_05_2022__14:10:04\n","Step: 2200 of 2500, Test accuracy: 0.7053409, Time: 08_05_2022__14:10:08\n","Step: 2300 of 2500, Test accuracy: 0.7054348, Time: 08_05_2022__14:10:11\n","Step: 2400 of 2500, Test accuracy: 0.7047917, Time: 08_05_2022__14:10:15\n","Step: 2500 of 2500, Test accuracy: 0.7036000, Time: 08_05_2022__14:10:19\n","Average testing accuracy: 0.7036000, Time: 08_05_2022__14:10:19\n","###################### Training vgg19_batch_norm SGD, lr_0.001, momentum_0.6 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4100af50e864948b88cfb4152e6c7dd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 2.5546833, Training accuracy: 0.1125000, Time: 08_05_2022__14:10:32\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 2.4674044, Training accuracy: 0.1350000, Time: 08_05_2022__14:10:43\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 2.4310407, Training accuracy: 0.1516667, Time: 08_05_2022__14:10:54\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 2.3928803, Training accuracy: 0.1612500, Time: 08_05_2022__14:11:04\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 2.3530852, Training accuracy: 0.1695000, Time: 08_05_2022__14:11:15\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 2.3284906, Training accuracy: 0.1737500, Time: 08_05_2022__14:11:26\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.3044660, Training accuracy: 0.1800000, Time: 08_05_2022__14:11:37\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.2790395, Training accuracy: 0.1853125, Time: 08_05_2022__14:11:48\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.2640969, Training accuracy: 0.1908333, Time: 08_05_2022__14:11:59\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.2430486, Training accuracy: 0.1937500, Time: 08_05_2022__14:12:10\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.2220190, Training accuracy: 0.2025000, Time: 08_05_2022__14:12:21\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.2073206, Training accuracy: 0.2058333, Time: 08_05_2022__14:12:32\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.1858380, Training accuracy: 0.2126923, Time: 08_05_2022__14:12:43\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.1690984, Training accuracy: 0.2175000, Time: 08_05_2022__14:12:54\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.1586161, Training accuracy: 0.2226667, Time: 08_05_2022__14:13:05\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.1501199, Training accuracy: 0.2250000, Time: 08_05_2022__14:13:16\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.1374283, Training accuracy: 0.2269118, Time: 08_05_2022__14:13:27\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.1204865, Training accuracy: 0.2333333, Time: 08_05_2022__14:13:38\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.1074465, Training accuracy: 0.2384211, Time: 08_05_2022__14:13:49\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.0989414, Training accuracy: 0.2417500, Time: 08_05_2022__14:14:00\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.0889976, Training accuracy: 0.2455952, Time: 08_05_2022__14:14:11\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.0778038, Training accuracy: 0.2487500, Time: 08_05_2022__14:14:22\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.0683689, Training accuracy: 0.2511957, Time: 08_05_2022__14:14:33\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.0565713, Training accuracy: 0.2550000, Time: 08_05_2022__14:14:43\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.0447483, Training accuracy: 0.2591000, Time: 08_05_2022__14:14:54\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.0359572, Training accuracy: 0.2635577, Time: 08_05_2022__14:15:05\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.0252414, Training accuracy: 0.2682407, Time: 08_05_2022__14:15:16\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.0175826, Training accuracy: 0.2707143, Time: 08_05_2022__14:15:27\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.0109243, Training accuracy: 0.2730172, Time: 08_05_2022__14:15:38\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.0065576, Training accuracy: 0.2745000, Time: 08_05_2022__14:15:49\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 1.9971008, Training accuracy: 0.2777419, Time: 08_05_2022__14:16:00\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 1.9892997, Training accuracy: 0.2804687, Time: 08_05_2022__14:16:11\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 1.9831660, Training accuracy: 0.2834091, Time: 08_05_2022__14:16:22\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 1.9755895, Training accuracy: 0.2859559, Time: 08_05_2022__14:16:33\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 1.9682839, Training accuracy: 0.2894286, Time: 08_05_2022__14:16:44\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 1.9639260, Training accuracy: 0.2901389, Time: 08_05_2022__14:16:55\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 1.9599063, Training accuracy: 0.2919595, Time: 08_05_2022__14:17:06\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 1.9536664, Training accuracy: 0.2942105, Time: 08_05_2022__14:17:17\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 1.9486567, Training accuracy: 0.2959615, Time: 08_05_2022__14:17:28\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 1.9438015, Training accuracy: 0.2981250, Time: 08_05_2022__14:17:39\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 1.9397544, Training accuracy: 0.2996341, Time: 08_05_2022__14:17:50\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 1.9314625, Training accuracy: 0.3029167, Time: 08_05_2022__14:18:01\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 1.9269699, Training accuracy: 0.3036628, Time: 08_05_2022__14:18:12\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 1.9197616, Training accuracy: 0.3057955, Time: 08_05_2022__14:18:23\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 1.9135780, Training accuracy: 0.3076667, Time: 08_05_2022__14:18:34\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 1.9076162, Training accuracy: 0.3095652, Time: 08_05_2022__14:18:45\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 1.9033868, Training accuracy: 0.3111702, Time: 08_05_2022__14:18:56\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 1.8997903, Training accuracy: 0.3122917, Time: 08_05_2022__14:19:06\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 1.8959161, Training accuracy: 0.3140816, Time: 08_05_2022__14:19:17\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 1.8931058, Training accuracy: 0.3152000, Time: 08_05_2022__14:19:28\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 1.8879642, Training accuracy: 0.3169608, Time: 08_05_2022__14:19:39\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 1.8853242, Training accuracy: 0.3188462, Time: 08_05_2022__14:19:50\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 1.8805330, Training accuracy: 0.3206132, Time: 08_05_2022__14:20:01\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 1.8776313, Training accuracy: 0.3217130, Time: 08_05_2022__14:20:12\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 1.8738093, Training accuracy: 0.3231818, Time: 08_05_2022__14:20:23\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 1.8698263, Training accuracy: 0.3241518, Time: 08_05_2022__14:20:34\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 1.8658516, Training accuracy: 0.3257895, Time: 08_05_2022__14:20:45\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 1.8626261, Training accuracy: 0.3265948, Time: 08_05_2022__14:20:56\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 1.8583868, Training accuracy: 0.3283051, Time: 08_05_2022__14:21:07\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 1.8543105, Training accuracy: 0.3294583, Time: 08_05_2022__14:21:18\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 1.8519647, Training accuracy: 0.3303279, Time: 08_05_2022__14:21:29\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 1.8478919, Training accuracy: 0.3317742, Time: 08_05_2022__14:21:40\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 1.8441030, Training accuracy: 0.3331746, Time: 08_05_2022__14:21:51\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 1.8412190, Training accuracy: 0.3339453, Time: 08_05_2022__14:22:02\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 1.8367258, Training accuracy: 0.3357308, Time: 08_05_2022__14:22:13\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 1.8339974, Training accuracy: 0.3365530, Time: 08_05_2022__14:22:24\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 1.8302296, Training accuracy: 0.3373881, Time: 08_05_2022__14:22:35\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 1.8277672, Training accuracy: 0.3380882, Time: 08_05_2022__14:22:46\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 1.8241727, Training accuracy: 0.3396739, Time: 08_05_2022__14:22:56\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 1.8203324, Training accuracy: 0.3408214, Time: 08_05_2022__14:23:07\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 1.8175054, Training accuracy: 0.3415141, Time: 08_05_2022__14:23:18\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 1.8146470, Training accuracy: 0.3421181, Time: 08_05_2022__14:23:29\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 1.8120881, Training accuracy: 0.3430822, Time: 08_05_2022__14:23:40\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 1.8096723, Training accuracy: 0.3437162, Time: 08_05_2022__14:23:51\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 1.8075217, Training accuracy: 0.3444000, Time: 08_05_2022__14:24:02\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 1.8049111, Training accuracy: 0.3456579, Time: 08_05_2022__14:24:13\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 1.8018071, Training accuracy: 0.3466558, Time: 08_05_2022__14:24:24\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 1.7979005, Training accuracy: 0.3481410, Time: 08_05_2022__14:24:35\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 1.7954112, Training accuracy: 0.3488291, Time: 08_05_2022__14:24:46\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 1.7930820, Training accuracy: 0.3493750, Time: 08_05_2022__14:24:57\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 1.7908172, Training accuracy: 0.3497222, Time: 08_05_2022__14:25:08\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 1.7889301, Training accuracy: 0.3505183, Time: 08_05_2022__14:25:19\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 1.7855393, Training accuracy: 0.3516867, Time: 08_05_2022__14:25:30\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 1.7833491, Training accuracy: 0.3524702, Time: 08_05_2022__14:25:41\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 1.7804932, Training accuracy: 0.3535294, Time: 08_05_2022__14:25:52\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 1.7775819, Training accuracy: 0.3547384, Time: 08_05_2022__14:26:03\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 1.7745057, Training accuracy: 0.3560920, Time: 08_05_2022__14:26:14\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 1.7707050, Training accuracy: 0.3577273, Time: 08_05_2022__14:26:25\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 1.7677351, Training accuracy: 0.3587640, Time: 08_05_2022__14:26:36\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 1.7653286, Training accuracy: 0.3595556, Time: 08_05_2022__14:26:47\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 1.7626723, Training accuracy: 0.3605769, Time: 08_05_2022__14:26:58\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 1.7595225, Training accuracy: 0.3620109, Time: 08_05_2022__14:27:08\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 1.7572853, Training accuracy: 0.3628495, Time: 08_05_2022__14:27:19\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 1.7549566, Training accuracy: 0.3636702, Time: 08_05_2022__14:27:30\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 1.7540075, Training accuracy: 0.3639737, Time: 08_05_2022__14:27:41\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 1.7508927, Training accuracy: 0.3649219, Time: 08_05_2022__14:27:52\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 1.7472525, Training accuracy: 0.3663402, Time: 08_05_2022__14:28:03\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 1.7447135, Training accuracy: 0.3673724, Time: 08_05_2022__14:28:14\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 1.7431731, Training accuracy: 0.3679293, Time: 08_05_2022__14:28:25\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 1.7407017, Training accuracy: 0.3689750, Time: 08_05_2022__14:28:36\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 1.7395628, Training accuracy: 0.3693812, Time: 08_05_2022__14:28:47\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 1.7376511, Training accuracy: 0.3700980, Time: 08_05_2022__14:28:58\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 1.7349413, Training accuracy: 0.3712379, Time: 08_05_2022__14:29:09\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 1.7320702, Training accuracy: 0.3716587, Time: 08_05_2022__14:29:20\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 1.7302831, Training accuracy: 0.3725714, Time: 08_05_2022__14:29:31\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 1.7285124, Training accuracy: 0.3732783, Time: 08_05_2022__14:29:42\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 1.7260550, Training accuracy: 0.3740654, Time: 08_05_2022__14:29:53\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 1.7236999, Training accuracy: 0.3749306, Time: 08_05_2022__14:30:04\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 1.7225355, Training accuracy: 0.3754128, Time: 08_05_2022__14:30:15\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 1.7204191, Training accuracy: 0.3761136, Time: 08_05_2022__14:30:26\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 1.7177753, Training accuracy: 0.3771847, Time: 08_05_2022__14:30:37\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 1.7163770, Training accuracy: 0.3777009, Time: 08_05_2022__14:30:48\n","Epoch 1 of 5, Average training loss: 1.7153918, Average training accuracy: 0.3780667, Time: 08_05_2022__14:30:53\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18a114f5dfa849158e81699b82e7b805"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.3509817, Validation accuracy: 0.5325000, Time: 08_05_2022__14:30:57 | Loss decreased from inf to 1.3490623 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.3331132, Validation accuracy: 0.5325000, Time: 08_05_2022__14:31:04 | Loss decreased from 1.3490623 to 1.3359384 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.3473198, Validation accuracy: 0.5083333, Time: 08_05_2022__14:31:10\n","Step: 400 of 1250, Validation loss: 1.3443018, Validation accuracy: 0.5112500, Time: 08_05_2022__14:31:13\n","Step: 500 of 1250, Validation loss: 1.3480477, Validation accuracy: 0.5085000, Time: 08_05_2022__14:31:17\n","Step: 600 of 1250, Validation loss: 1.3362334, Validation accuracy: 0.5179167, Time: 08_05_2022__14:31:21\n","Step: 700 of 1250, Validation loss: 1.3308521, Validation accuracy: 0.5203571, Time: 08_05_2022__14:31:25 | Loss decreased from 1.3359384 to 1.3313407 .... Saving the model\n","Step: 800 of 1250, Validation loss: 1.3287313, Validation accuracy: 0.5212500, Time: 08_05_2022__14:31:30 | Loss decreased from 1.3313407 to 1.3297040 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.3294179, Validation accuracy: 0.5219444, Time: 08_05_2022__14:31:36 | Loss decreased from 1.3297040 to 1.3292370 .... Saving the model\n","Step: 1000 of 1250, Validation loss: 1.3347887, Validation accuracy: 0.5177500, Time: 08_05_2022__14:31:42\n","Step: 1100 of 1250, Validation loss: 1.3355949, Validation accuracy: 0.5156818, Time: 08_05_2022__14:31:46\n","Step: 1200 of 1250, Validation loss: 1.3361815, Validation accuracy: 0.5147917, Time: 08_05_2022__14:31:50\n","Average validation loss: 1.3345085, Average validation accuracy: 0.5160000, Time: 08_05_2022__14:31:51\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b90ede8d7b1477d86036fdd4c228b4f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.4051531, Training accuracy: 0.5150000, Time: 08_05_2022__14:32:03\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.4400530, Training accuracy: 0.4975000, Time: 08_05_2022__14:32:13\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.4682496, Training accuracy: 0.4683333, Time: 08_05_2022__14:32:24\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.4530700, Training accuracy: 0.4706250, Time: 08_05_2022__14:32:35\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.4580888, Training accuracy: 0.4665000, Time: 08_05_2022__14:32:46\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.4518289, Training accuracy: 0.4700000, Time: 08_05_2022__14:32:57\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.4620214, Training accuracy: 0.4642857, Time: 08_05_2022__14:33:08\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.4604694, Training accuracy: 0.4665625, Time: 08_05_2022__14:33:19\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.4596491, Training accuracy: 0.4672222, Time: 08_05_2022__14:33:30\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.4576761, Training accuracy: 0.4712500, Time: 08_05_2022__14:33:41\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.4526960, Training accuracy: 0.4722727, Time: 08_05_2022__14:33:52\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.4536911, Training accuracy: 0.4691667, Time: 08_05_2022__14:34:03\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.4515920, Training accuracy: 0.4717308, Time: 08_05_2022__14:34:14\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.4438586, Training accuracy: 0.4762500, Time: 08_05_2022__14:34:25\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.4447218, Training accuracy: 0.4771667, Time: 08_05_2022__14:34:36\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.4415856, Training accuracy: 0.4781250, Time: 08_05_2022__14:34:47\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.4408732, Training accuracy: 0.4782353, Time: 08_05_2022__14:34:58\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.4394322, Training accuracy: 0.4791667, Time: 08_05_2022__14:35:09\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.4369303, Training accuracy: 0.4800000, Time: 08_05_2022__14:35:20\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.4353905, Training accuracy: 0.4810000, Time: 08_05_2022__14:35:31\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.4311643, Training accuracy: 0.4814286, Time: 08_05_2022__14:35:42\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.4285114, Training accuracy: 0.4832955, Time: 08_05_2022__14:35:53\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.4263901, Training accuracy: 0.4843478, Time: 08_05_2022__14:36:04\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.4213042, Training accuracy: 0.4860417, Time: 08_05_2022__14:36:15\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.4167698, Training accuracy: 0.4876000, Time: 08_05_2022__14:36:25\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.4173110, Training accuracy: 0.4877885, Time: 08_05_2022__14:36:36\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.4149420, Training accuracy: 0.4872222, Time: 08_05_2022__14:36:47\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.4142586, Training accuracy: 0.4868750, Time: 08_05_2022__14:36:58\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.4140054, Training accuracy: 0.4870690, Time: 08_05_2022__14:37:09\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.4132897, Training accuracy: 0.4880000, Time: 08_05_2022__14:37:20\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.4109201, Training accuracy: 0.4890323, Time: 08_05_2022__14:37:31\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.4054373, Training accuracy: 0.4915625, Time: 08_05_2022__14:37:42\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.4062840, Training accuracy: 0.4906818, Time: 08_05_2022__14:37:53\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.4058564, Training accuracy: 0.4905882, Time: 08_05_2022__14:38:04\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.4029324, Training accuracy: 0.4914286, Time: 08_05_2022__14:38:15\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.4027580, Training accuracy: 0.4909028, Time: 08_05_2022__14:38:26\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.4018134, Training accuracy: 0.4912838, Time: 08_05_2022__14:38:37\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.3995435, Training accuracy: 0.4928947, Time: 08_05_2022__14:38:48\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.3963958, Training accuracy: 0.4942949, Time: 08_05_2022__14:38:59\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.3943326, Training accuracy: 0.4951875, Time: 08_05_2022__14:39:10\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.3950088, Training accuracy: 0.4955488, Time: 08_05_2022__14:39:21\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.3918950, Training accuracy: 0.4968452, Time: 08_05_2022__14:39:32\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.3895873, Training accuracy: 0.4969767, Time: 08_05_2022__14:39:43\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.3873290, Training accuracy: 0.4970455, Time: 08_05_2022__14:39:54\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.3854082, Training accuracy: 0.4972778, Time: 08_05_2022__14:40:05\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.3846227, Training accuracy: 0.4976087, Time: 08_05_2022__14:40:16\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.3832650, Training accuracy: 0.4988298, Time: 08_05_2022__14:40:27\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.3815596, Training accuracy: 0.4994792, Time: 08_05_2022__14:40:37\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.3793133, Training accuracy: 0.5007653, Time: 08_05_2022__14:40:48\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.3787912, Training accuracy: 0.5013500, Time: 08_05_2022__14:40:59\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.3765641, Training accuracy: 0.5025490, Time: 08_05_2022__14:41:10\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.3769777, Training accuracy: 0.5024038, Time: 08_05_2022__14:41:21\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.3752946, Training accuracy: 0.5028774, Time: 08_05_2022__14:41:32\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.3733353, Training accuracy: 0.5036111, Time: 08_05_2022__14:41:43\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.3723229, Training accuracy: 0.5035455, Time: 08_05_2022__14:41:54\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.3697794, Training accuracy: 0.5044196, Time: 08_05_2022__14:42:05\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.3689195, Training accuracy: 0.5044298, Time: 08_05_2022__14:42:16\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.3684361, Training accuracy: 0.5049569, Time: 08_05_2022__14:42:27\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.3672385, Training accuracy: 0.5050000, Time: 08_05_2022__14:42:38\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.3664026, Training accuracy: 0.5056250, Time: 08_05_2022__14:42:49\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.3658251, Training accuracy: 0.5060246, Time: 08_05_2022__14:43:00\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.3630460, Training accuracy: 0.5074597, Time: 08_05_2022__14:43:11\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.3625909, Training accuracy: 0.5074603, Time: 08_05_2022__14:43:22\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.3616100, Training accuracy: 0.5074219, Time: 08_05_2022__14:43:33\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.3600639, Training accuracy: 0.5080769, Time: 08_05_2022__14:43:44\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.3585876, Training accuracy: 0.5089015, Time: 08_05_2022__14:43:55\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.3564247, Training accuracy: 0.5095522, Time: 08_05_2022__14:44:06\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.3569386, Training accuracy: 0.5093015, Time: 08_05_2022__14:44:17\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.3549939, Training accuracy: 0.5101449, Time: 08_05_2022__14:44:28\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.3529098, Training accuracy: 0.5108214, Time: 08_05_2022__14:44:39\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.3524144, Training accuracy: 0.5109859, Time: 08_05_2022__14:44:50\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.3505876, Training accuracy: 0.5116667, Time: 08_05_2022__14:45:00\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.3497998, Training accuracy: 0.5122260, Time: 08_05_2022__14:45:11\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.3479575, Training accuracy: 0.5128378, Time: 08_05_2022__14:45:22\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.3462456, Training accuracy: 0.5136000, Time: 08_05_2022__14:45:33\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.3443250, Training accuracy: 0.5143092, Time: 08_05_2022__14:45:44\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.3432263, Training accuracy: 0.5148052, Time: 08_05_2022__14:45:55\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.3404143, Training accuracy: 0.5158013, Time: 08_05_2022__14:46:06\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.3382406, Training accuracy: 0.5166456, Time: 08_05_2022__14:46:17\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.3364880, Training accuracy: 0.5170625, Time: 08_05_2022__14:46:28\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.3358245, Training accuracy: 0.5170370, Time: 08_05_2022__14:46:39\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.3350322, Training accuracy: 0.5169817, Time: 08_05_2022__14:46:50\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.3333127, Training accuracy: 0.5174699, Time: 08_05_2022__14:47:01\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.3321314, Training accuracy: 0.5179464, Time: 08_05_2022__14:47:12\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.3304709, Training accuracy: 0.5187941, Time: 08_05_2022__14:47:23\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.3294391, Training accuracy: 0.5192733, Time: 08_05_2022__14:47:34\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.3276938, Training accuracy: 0.5196264, Time: 08_05_2022__14:47:45\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.3253279, Training accuracy: 0.5211080, Time: 08_05_2022__14:47:56\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.3232038, Training accuracy: 0.5217697, Time: 08_05_2022__14:48:07\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.3220987, Training accuracy: 0.5220833, Time: 08_05_2022__14:48:18\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.3208707, Training accuracy: 0.5228571, Time: 08_05_2022__14:48:29\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.3182677, Training accuracy: 0.5240217, Time: 08_05_2022__14:48:40\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.3175542, Training accuracy: 0.5245161, Time: 08_05_2022__14:48:51\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.3159705, Training accuracy: 0.5251330, Time: 08_05_2022__14:49:02\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.3162841, Training accuracy: 0.5248684, Time: 08_05_2022__14:49:13\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.3144906, Training accuracy: 0.5257812, Time: 08_05_2022__14:49:24\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.3119625, Training accuracy: 0.5266237, Time: 08_05_2022__14:49:35\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.3103577, Training accuracy: 0.5273724, Time: 08_05_2022__14:49:46\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.3094709, Training accuracy: 0.5278535, Time: 08_05_2022__14:49:57\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.3079156, Training accuracy: 0.5285000, Time: 08_05_2022__14:50:07\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.3077893, Training accuracy: 0.5286386, Time: 08_05_2022__14:50:18\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.3064524, Training accuracy: 0.5292157, Time: 08_05_2022__14:50:29\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.3042668, Training accuracy: 0.5300971, Time: 08_05_2022__14:50:40\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.3023018, Training accuracy: 0.5305529, Time: 08_05_2022__14:50:51\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.3013766, Training accuracy: 0.5310000, Time: 08_05_2022__14:51:02\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.3001849, Training accuracy: 0.5316509, Time: 08_05_2022__14:51:13\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.2978278, Training accuracy: 0.5324065, Time: 08_05_2022__14:51:24\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.2965122, Training accuracy: 0.5330556, Time: 08_05_2022__14:51:35\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.2959259, Training accuracy: 0.5333028, Time: 08_05_2022__14:51:46\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.2947884, Training accuracy: 0.5336591, Time: 08_05_2022__14:51:57\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.2931691, Training accuracy: 0.5344369, Time: 08_05_2022__14:52:08\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.2924660, Training accuracy: 0.5347098, Time: 08_05_2022__14:52:19\n","Epoch 2 of 5, Average training loss: 1.2918252, Average training accuracy: 0.5348222, Time: 08_05_2022__14:52:24\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd9b7c94487e4074bdab0c04aa6ff235"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.0549797, Validation accuracy: 0.6300000, Time: 08_05_2022__14:52:28 | Loss decreased from 1.3292370 to 1.0547670 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.0295397, Validation accuracy: 0.6262500, Time: 08_05_2022__14:52:34 | Loss decreased from 1.0547670 to 1.0312487 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.0517711, Validation accuracy: 0.6225000, Time: 08_05_2022__14:52:40\n","Step: 400 of 1250, Validation loss: 1.0443144, Validation accuracy: 0.6256250, Time: 08_05_2022__14:52:43\n","Step: 500 of 1250, Validation loss: 1.0528727, Validation accuracy: 0.6165000, Time: 08_05_2022__14:52:47\n","Step: 600 of 1250, Validation loss: 1.0442366, Validation accuracy: 0.6187500, Time: 08_05_2022__14:52:51\n","Step: 700 of 1250, Validation loss: 1.0339072, Validation accuracy: 0.6242857, Time: 08_05_2022__14:52:54\n","Step: 800 of 1250, Validation loss: 1.0281119, Validation accuracy: 0.6259375, Time: 08_05_2022__14:52:58 | Loss decreased from 1.0312487 to 1.0289423 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.0331164, Validation accuracy: 0.6230556, Time: 08_05_2022__14:53:04\n","Step: 1000 of 1250, Validation loss: 1.0391420, Validation accuracy: 0.6192500, Time: 08_05_2022__14:53:08\n","Step: 1100 of 1250, Validation loss: 1.0407531, Validation accuracy: 0.6200000, Time: 08_05_2022__14:53:11\n","Step: 1200 of 1250, Validation loss: 1.0461851, Validation accuracy: 0.6193750, Time: 08_05_2022__14:53:15\n","Average validation loss: 1.0453842, Average validation accuracy: 0.6194000, Time: 08_05_2022__14:53:17\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c559d53b3a2a4941b9113c10e7c83537"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.0378194, Training accuracy: 0.6250000, Time: 08_05_2022__14:53:28\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.0683744, Training accuracy: 0.6175000, Time: 08_05_2022__14:53:39\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.0913064, Training accuracy: 0.6066667, Time: 08_05_2022__14:53:50\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.0652050, Training accuracy: 0.6200000, Time: 08_05_2022__14:54:01\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.0777436, Training accuracy: 0.6155000, Time: 08_05_2022__14:54:12\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.0778020, Training accuracy: 0.6150000, Time: 08_05_2022__14:54:23\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.1084657, Training accuracy: 0.6078571, Time: 08_05_2022__14:54:34\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.1065196, Training accuracy: 0.6106250, Time: 08_05_2022__14:54:45\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.1064175, Training accuracy: 0.6125000, Time: 08_05_2022__14:54:56\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.1024415, Training accuracy: 0.6130000, Time: 08_05_2022__14:55:07\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.1054522, Training accuracy: 0.6127273, Time: 08_05_2022__14:55:18\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.1126951, Training accuracy: 0.6085417, Time: 08_05_2022__14:55:29\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.1169026, Training accuracy: 0.6096154, Time: 08_05_2022__14:55:40\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.1162114, Training accuracy: 0.6126786, Time: 08_05_2022__14:55:51\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.1179825, Training accuracy: 0.6123333, Time: 08_05_2022__14:56:02\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.1165106, Training accuracy: 0.6123437, Time: 08_05_2022__14:56:13\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.1154305, Training accuracy: 0.6114706, Time: 08_05_2022__14:56:24\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.1160516, Training accuracy: 0.6113889, Time: 08_05_2022__14:56:35\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.1118628, Training accuracy: 0.6130263, Time: 08_05_2022__14:56:45\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.1117392, Training accuracy: 0.6127500, Time: 08_05_2022__14:56:56\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.1070953, Training accuracy: 0.6133333, Time: 08_05_2022__14:57:07\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.1054939, Training accuracy: 0.6135227, Time: 08_05_2022__14:57:18\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.1015121, Training accuracy: 0.6142391, Time: 08_05_2022__14:57:29\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.1000645, Training accuracy: 0.6150000, Time: 08_05_2022__14:57:40\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.0985290, Training accuracy: 0.6145000, Time: 08_05_2022__14:57:51\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.0969030, Training accuracy: 0.6143269, Time: 08_05_2022__14:58:02\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.0929021, Training accuracy: 0.6151852, Time: 08_05_2022__14:58:13\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.0944586, Training accuracy: 0.6141071, Time: 08_05_2022__14:58:24\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.0937284, Training accuracy: 0.6138793, Time: 08_05_2022__14:58:35\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.0939307, Training accuracy: 0.6130000, Time: 08_05_2022__14:58:46\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.0909994, Training accuracy: 0.6129839, Time: 08_05_2022__14:58:57\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.0871844, Training accuracy: 0.6149219, Time: 08_05_2022__14:59:08\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.0898234, Training accuracy: 0.6153030, Time: 08_05_2022__14:59:19\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.0893747, Training accuracy: 0.6155882, Time: 08_05_2022__14:59:30\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.0872501, Training accuracy: 0.6159286, Time: 08_05_2022__14:59:41\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.0870275, Training accuracy: 0.6165278, Time: 08_05_2022__14:59:52\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.0859340, Training accuracy: 0.6166892, Time: 08_05_2022__15:00:03\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.0838108, Training accuracy: 0.6170395, Time: 08_05_2022__15:00:14\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.0804789, Training accuracy: 0.6178846, Time: 08_05_2022__15:00:25\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.0795033, Training accuracy: 0.6183125, Time: 08_05_2022__15:00:36\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.0806678, Training accuracy: 0.6189024, Time: 08_05_2022__15:00:47\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.0767442, Training accuracy: 0.6203571, Time: 08_05_2022__15:00:58\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.0742411, Training accuracy: 0.6209884, Time: 08_05_2022__15:01:09\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.0723069, Training accuracy: 0.6219318, Time: 08_05_2022__15:01:20\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.0712533, Training accuracy: 0.6227222, Time: 08_05_2022__15:01:31\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.0702585, Training accuracy: 0.6235326, Time: 08_05_2022__15:01:42\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.0685491, Training accuracy: 0.6239894, Time: 08_05_2022__15:01:53\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.0678029, Training accuracy: 0.6242708, Time: 08_05_2022__15:02:04\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.0673822, Training accuracy: 0.6244898, Time: 08_05_2022__15:02:15\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.0672417, Training accuracy: 0.6246000, Time: 08_05_2022__15:02:26\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.0659425, Training accuracy: 0.6248039, Time: 08_05_2022__15:02:37\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.0646866, Training accuracy: 0.6257212, Time: 08_05_2022__15:02:48\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.0642380, Training accuracy: 0.6256132, Time: 08_05_2022__15:02:58\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.0626692, Training accuracy: 0.6262963, Time: 08_05_2022__15:03:09\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.0615075, Training accuracy: 0.6267273, Time: 08_05_2022__15:03:20\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.0610484, Training accuracy: 0.6264286, Time: 08_05_2022__15:03:31\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.0607110, Training accuracy: 0.6260088, Time: 08_05_2022__15:03:42\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.0610264, Training accuracy: 0.6256034, Time: 08_05_2022__15:03:53\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.0607790, Training accuracy: 0.6255508, Time: 08_05_2022__15:04:04\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.0593567, Training accuracy: 0.6264583, Time: 08_05_2022__15:04:15\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.0597636, Training accuracy: 0.6263934, Time: 08_05_2022__15:04:26\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.0580344, Training accuracy: 0.6267339, Time: 08_05_2022__15:04:37\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.0574751, Training accuracy: 0.6268254, Time: 08_05_2022__15:04:48\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.0565255, Training accuracy: 0.6271484, Time: 08_05_2022__15:04:59\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.0562242, Training accuracy: 0.6271154, Time: 08_05_2022__15:05:10\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.0557258, Training accuracy: 0.6272348, Time: 08_05_2022__15:05:21\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.0541841, Training accuracy: 0.6276119, Time: 08_05_2022__15:05:32\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.0542367, Training accuracy: 0.6272059, Time: 08_05_2022__15:05:43\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.0531697, Training accuracy: 0.6275000, Time: 08_05_2022__15:05:54\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.0515346, Training accuracy: 0.6280714, Time: 08_05_2022__15:06:05\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.0514562, Training accuracy: 0.6280986, Time: 08_05_2022__15:06:16\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.0499072, Training accuracy: 0.6287500, Time: 08_05_2022__15:06:27\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.0487115, Training accuracy: 0.6292123, Time: 08_05_2022__15:06:38\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.0475205, Training accuracy: 0.6296622, Time: 08_05_2022__15:06:49\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.0457867, Training accuracy: 0.6301333, Time: 08_05_2022__15:07:00\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.0445613, Training accuracy: 0.6305263, Time: 08_05_2022__15:07:11\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.0435981, Training accuracy: 0.6308117, Time: 08_05_2022__15:07:22\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.0424032, Training accuracy: 0.6312500, Time: 08_05_2022__15:07:33\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.0414490, Training accuracy: 0.6316456, Time: 08_05_2022__15:07:44\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.0401311, Training accuracy: 0.6319687, Time: 08_05_2022__15:07:55\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.0396534, Training accuracy: 0.6321914, Time: 08_05_2022__15:08:06\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.0396156, Training accuracy: 0.6325305, Time: 08_05_2022__15:08:17\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.0388561, Training accuracy: 0.6325000, Time: 08_05_2022__15:08:28\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.0391350, Training accuracy: 0.6323512, Time: 08_05_2022__15:08:39\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.0383152, Training accuracy: 0.6324412, Time: 08_05_2022__15:08:50\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.0380331, Training accuracy: 0.6324709, Time: 08_05_2022__15:09:01\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.0368925, Training accuracy: 0.6329023, Time: 08_05_2022__15:09:12\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.0348620, Training accuracy: 0.6336364, Time: 08_05_2022__15:09:23\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 1.0334128, Training accuracy: 0.6339888, Time: 08_05_2022__15:09:34\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 1.0325168, Training accuracy: 0.6342222, Time: 08_05_2022__15:09:45\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 1.0325719, Training accuracy: 0.6343681, Time: 08_05_2022__15:09:56\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 1.0312485, Training accuracy: 0.6347283, Time: 08_05_2022__15:10:07\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 1.0308958, Training accuracy: 0.6348118, Time: 08_05_2022__15:10:18\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 1.0304123, Training accuracy: 0.6348670, Time: 08_05_2022__15:10:29\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 1.0309587, Training accuracy: 0.6346579, Time: 08_05_2022__15:10:40\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 1.0292464, Training accuracy: 0.6354167, Time: 08_05_2022__15:10:51\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 1.0272725, Training accuracy: 0.6362629, Time: 08_05_2022__15:11:02\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 1.0254609, Training accuracy: 0.6369643, Time: 08_05_2022__15:11:13\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 1.0251453, Training accuracy: 0.6371717, Time: 08_05_2022__15:11:24\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 1.0242150, Training accuracy: 0.6377000, Time: 08_05_2022__15:11:35\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 1.0240087, Training accuracy: 0.6378960, Time: 08_05_2022__15:11:46\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 1.0232544, Training accuracy: 0.6382598, Time: 08_05_2022__15:11:57\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 1.0220985, Training accuracy: 0.6385922, Time: 08_05_2022__15:12:08\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 1.0206233, Training accuracy: 0.6390144, Time: 08_05_2022__15:12:19\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 1.0201183, Training accuracy: 0.6394524, Time: 08_05_2022__15:12:30\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 1.0199058, Training accuracy: 0.6396226, Time: 08_05_2022__15:12:41\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 1.0182801, Training accuracy: 0.6402103, Time: 08_05_2022__15:12:52\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 1.0179180, Training accuracy: 0.6405324, Time: 08_05_2022__15:13:03\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 1.0177198, Training accuracy: 0.6404587, Time: 08_05_2022__15:13:13\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 1.0167994, Training accuracy: 0.6408636, Time: 08_05_2022__15:13:24\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 1.0152698, Training accuracy: 0.6415541, Time: 08_05_2022__15:13:35\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 1.0145382, Training accuracy: 0.6417857, Time: 08_05_2022__15:13:46\n","Epoch 3 of 5, Average training loss: 1.0142766, Average training accuracy: 0.6418889, Time: 08_05_2022__15:13:52\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6da00a3ceda14880a7f213fcbcf1ff26"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.8745167, Validation accuracy: 0.6900000, Time: 08_05_2022__15:13:56 | Loss decreased from 1.0289423 to 0.8743206 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.8655991, Validation accuracy: 0.6875000, Time: 08_05_2022__15:14:01 | Loss decreased from 0.8743206 to 0.8668253 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.8882301, Validation accuracy: 0.6850000, Time: 08_05_2022__15:14:07\n","Step: 400 of 1250, Validation loss: 0.8755549, Validation accuracy: 0.6850000, Time: 08_05_2022__15:14:11\n","Step: 500 of 1250, Validation loss: 0.8817418, Validation accuracy: 0.6795000, Time: 08_05_2022__15:14:14\n","Step: 600 of 1250, Validation loss: 0.8694808, Validation accuracy: 0.6858333, Time: 08_05_2022__15:14:18\n","Step: 700 of 1250, Validation loss: 0.8589349, Validation accuracy: 0.6917857, Time: 08_05_2022__15:14:22 | Loss decreased from 0.8668253 to 0.8579347 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.8483737, Validation accuracy: 0.6946875, Time: 08_05_2022__15:14:28 | Loss decreased from 0.8579347 to 0.8475973 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.8568150, Validation accuracy: 0.6958333, Time: 08_05_2022__15:14:33\n","Step: 1000 of 1250, Validation loss: 0.8575890, Validation accuracy: 0.6940000, Time: 08_05_2022__15:14:37\n","Step: 1100 of 1250, Validation loss: 0.8576048, Validation accuracy: 0.6963636, Time: 08_05_2022__15:14:41\n","Step: 1200 of 1250, Validation loss: 0.8668165, Validation accuracy: 0.6950000, Time: 08_05_2022__15:14:45\n","Average validation loss: 0.8673879, Average validation accuracy: 0.6960000, Time: 08_05_2022__15:14:46\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31c4331189244b3c9d119e31ff4edf54"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 0.8026429, Training accuracy: 0.6900000, Time: 08_05_2022__15:14:58\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 0.8282978, Training accuracy: 0.6887500, Time: 08_05_2022__15:15:08\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 0.8442556, Training accuracy: 0.6916667, Time: 08_05_2022__15:15:19\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 0.8176980, Training accuracy: 0.7012500, Time: 08_05_2022__15:15:30\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 0.8249143, Training accuracy: 0.6965000, Time: 08_05_2022__15:15:41\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 0.8271176, Training accuracy: 0.6962500, Time: 08_05_2022__15:15:52\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 0.8425878, Training accuracy: 0.6932143, Time: 08_05_2022__15:16:03\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 0.8486704, Training accuracy: 0.6937500, Time: 08_05_2022__15:16:14\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 0.8552963, Training accuracy: 0.6941667, Time: 08_05_2022__15:16:25\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 0.8537049, Training accuracy: 0.6962500, Time: 08_05_2022__15:16:36\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 0.8583658, Training accuracy: 0.6959091, Time: 08_05_2022__15:16:47\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 0.8650853, Training accuracy: 0.6929167, Time: 08_05_2022__15:16:58\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 0.8712938, Training accuracy: 0.6915385, Time: 08_05_2022__15:17:09\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 0.8764635, Training accuracy: 0.6917857, Time: 08_05_2022__15:17:20\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 0.8798118, Training accuracy: 0.6895000, Time: 08_05_2022__15:17:31\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 0.8793923, Training accuracy: 0.6896875, Time: 08_05_2022__15:17:42\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 0.8801051, Training accuracy: 0.6894118, Time: 08_05_2022__15:17:53\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 0.8855201, Training accuracy: 0.6876389, Time: 08_05_2022__15:18:04\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 0.8847912, Training accuracy: 0.6881579, Time: 08_05_2022__15:18:15\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 0.8853651, Training accuracy: 0.6872500, Time: 08_05_2022__15:18:26\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 0.8816641, Training accuracy: 0.6878571, Time: 08_05_2022__15:18:37\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 0.8831403, Training accuracy: 0.6869318, Time: 08_05_2022__15:18:48\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 0.8825554, Training accuracy: 0.6869565, Time: 08_05_2022__15:18:59\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 0.8796976, Training accuracy: 0.6871875, Time: 08_05_2022__15:19:10\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 0.8779184, Training accuracy: 0.6880000, Time: 08_05_2022__15:19:21\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 0.8764068, Training accuracy: 0.6877885, Time: 08_05_2022__15:19:32\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 0.8741363, Training accuracy: 0.6881481, Time: 08_05_2022__15:19:43\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 0.8744103, Training accuracy: 0.6882143, Time: 08_05_2022__15:19:54\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 0.8738025, Training accuracy: 0.6895690, Time: 08_05_2022__15:20:05\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 0.8741861, Training accuracy: 0.6895833, Time: 08_05_2022__15:20:16\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 0.8721557, Training accuracy: 0.6904839, Time: 08_05_2022__15:20:27\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 0.8698455, Training accuracy: 0.6910156, Time: 08_05_2022__15:20:38\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 0.8720866, Training accuracy: 0.6906061, Time: 08_05_2022__15:20:49\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 0.8706838, Training accuracy: 0.6911029, Time: 08_05_2022__15:21:00\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 0.8704544, Training accuracy: 0.6915000, Time: 08_05_2022__15:21:11\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 0.8693385, Training accuracy: 0.6917361, Time: 08_05_2022__15:21:22\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 0.8684638, Training accuracy: 0.6921622, Time: 08_05_2022__15:21:33\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 0.8678762, Training accuracy: 0.6928289, Time: 08_05_2022__15:21:44\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 0.8657281, Training accuracy: 0.6928846, Time: 08_05_2022__15:21:55\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 0.8643536, Training accuracy: 0.6930625, Time: 08_05_2022__15:22:06\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 0.8662271, Training accuracy: 0.6926220, Time: 08_05_2022__15:22:16\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 0.8628538, Training accuracy: 0.6939881, Time: 08_05_2022__15:22:27\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 0.8620437, Training accuracy: 0.6938953, Time: 08_05_2022__15:22:38\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 0.8603517, Training accuracy: 0.6946023, Time: 08_05_2022__15:22:49\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 0.8596522, Training accuracy: 0.6952222, Time: 08_05_2022__15:23:00\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 0.8606744, Training accuracy: 0.6950543, Time: 08_05_2022__15:23:11\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 0.8591606, Training accuracy: 0.6959574, Time: 08_05_2022__15:23:22\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 0.8595940, Training accuracy: 0.6957292, Time: 08_05_2022__15:23:33\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 0.8591613, Training accuracy: 0.6958673, Time: 08_05_2022__15:23:44\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 0.8595645, Training accuracy: 0.6961000, Time: 08_05_2022__15:23:55\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 0.8584981, Training accuracy: 0.6968137, Time: 08_05_2022__15:24:06\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 0.8578521, Training accuracy: 0.6971154, Time: 08_05_2022__15:24:17\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 0.8583556, Training accuracy: 0.6966981, Time: 08_05_2022__15:24:28\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 0.8576267, Training accuracy: 0.6967593, Time: 08_05_2022__15:24:39\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 0.8581223, Training accuracy: 0.6968636, Time: 08_05_2022__15:24:50\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 0.8579907, Training accuracy: 0.6966964, Time: 08_05_2022__15:25:01\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 0.8569826, Training accuracy: 0.6967105, Time: 08_05_2022__15:25:12\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 0.8567091, Training accuracy: 0.6967672, Time: 08_05_2022__15:25:23\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 0.8575471, Training accuracy: 0.6963559, Time: 08_05_2022__15:25:34\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 0.8578277, Training accuracy: 0.6962083, Time: 08_05_2022__15:25:45\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 0.8581422, Training accuracy: 0.6962705, Time: 08_05_2022__15:25:56\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 0.8574733, Training accuracy: 0.6963306, Time: 08_05_2022__15:26:07\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 0.8577261, Training accuracy: 0.6965079, Time: 08_05_2022__15:26:18\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 0.8570322, Training accuracy: 0.6968750, Time: 08_05_2022__15:26:29\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 0.8560587, Training accuracy: 0.6970385, Time: 08_05_2022__15:26:40\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 0.8566537, Training accuracy: 0.6970076, Time: 08_05_2022__15:26:51\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 0.8557081, Training accuracy: 0.6974627, Time: 08_05_2022__15:27:02\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 0.8563620, Training accuracy: 0.6971691, Time: 08_05_2022__15:27:13\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 0.8550520, Training accuracy: 0.6972826, Time: 08_05_2022__15:27:24\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 0.8534512, Training accuracy: 0.6980357, Time: 08_05_2022__15:27:35\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 0.8538665, Training accuracy: 0.6980986, Time: 08_05_2022__15:27:46\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 0.8522762, Training accuracy: 0.6987153, Time: 08_05_2022__15:27:57\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 0.8515319, Training accuracy: 0.6989726, Time: 08_05_2022__15:28:08\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 0.8506928, Training accuracy: 0.6992905, Time: 08_05_2022__15:28:19\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 0.8494916, Training accuracy: 0.6996667, Time: 08_05_2022__15:28:30\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 0.8487598, Training accuracy: 0.6998355, Time: 08_05_2022__15:28:41\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 0.8489066, Training accuracy: 0.6996429, Time: 08_05_2022__15:28:52\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 0.8481564, Training accuracy: 0.6998077, Time: 08_05_2022__15:29:03\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 0.8468722, Training accuracy: 0.7001899, Time: 08_05_2022__15:29:14\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 0.8458064, Training accuracy: 0.7004063, Time: 08_05_2022__15:29:25\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 0.8464392, Training accuracy: 0.7002160, Time: 08_05_2022__15:29:36\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 0.8464372, Training accuracy: 0.7003049, Time: 08_05_2022__15:29:47\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 0.8463564, Training accuracy: 0.7005422, Time: 08_05_2022__15:29:58\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 0.8472959, Training accuracy: 0.7000893, Time: 08_05_2022__15:30:09\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 0.8469246, Training accuracy: 0.7002941, Time: 08_05_2022__15:30:20\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 0.8473759, Training accuracy: 0.7001453, Time: 08_05_2022__15:30:31\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 0.8469189, Training accuracy: 0.7005460, Time: 08_05_2022__15:30:42\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 0.8457887, Training accuracy: 0.7013352, Time: 08_05_2022__15:30:53\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 0.8445679, Training accuracy: 0.7017135, Time: 08_05_2022__15:31:04\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 0.8438836, Training accuracy: 0.7020833, Time: 08_05_2022__15:31:15\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 0.8435108, Training accuracy: 0.7019780, Time: 08_05_2022__15:31:26\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 0.8426074, Training accuracy: 0.7022011, Time: 08_05_2022__15:31:37\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 0.8420476, Training accuracy: 0.7026344, Time: 08_05_2022__15:31:48\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 0.8414959, Training accuracy: 0.7028191, Time: 08_05_2022__15:31:59\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 0.8426935, Training accuracy: 0.7025789, Time: 08_05_2022__15:32:10\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 0.8419312, Training accuracy: 0.7027083, Time: 08_05_2022__15:32:21\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 0.8399892, Training accuracy: 0.7034021, Time: 08_05_2022__15:32:32\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 0.8388646, Training accuracy: 0.7041837, Time: 08_05_2022__15:32:43\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 0.8392439, Training accuracy: 0.7040909, Time: 08_05_2022__15:32:54\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 0.8391350, Training accuracy: 0.7041750, Time: 08_05_2022__15:33:05\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 0.8393981, Training accuracy: 0.7042822, Time: 08_05_2022__15:33:16\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 0.8389884, Training accuracy: 0.7044363, Time: 08_05_2022__15:33:27\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 0.8380433, Training accuracy: 0.7048301, Time: 08_05_2022__15:33:38\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 0.8365367, Training accuracy: 0.7053846, Time: 08_05_2022__15:33:49\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 0.8357727, Training accuracy: 0.7058333, Time: 08_05_2022__15:34:00\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 0.8360187, Training accuracy: 0.7059434, Time: 08_05_2022__15:34:11\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 0.8352724, Training accuracy: 0.7064252, Time: 08_05_2022__15:34:22\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 0.8351200, Training accuracy: 0.7065741, Time: 08_05_2022__15:34:33\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 0.8351045, Training accuracy: 0.7066514, Time: 08_05_2022__15:34:44\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 0.8345725, Training accuracy: 0.7067045, Time: 08_05_2022__15:34:55\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 0.8332637, Training accuracy: 0.7071847, Time: 08_05_2022__15:35:06\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 0.8332487, Training accuracy: 0.7074330, Time: 08_05_2022__15:35:17\n","Epoch 4 of 5, Average training loss: 0.8335107, Average training accuracy: 0.7073333, Time: 08_05_2022__15:35:23\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af4b63424da745ada7fe0ed9b9d7fc62"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.7363627, Validation accuracy: 0.7375000, Time: 08_05_2022__15:35:26 | Loss decreased from 0.8475973 to 0.7358283 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.7312048, Validation accuracy: 0.7325000, Time: 08_05_2022__15:35:32 | Loss decreased from 0.7358283 to 0.7316477 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.7752744, Validation accuracy: 0.7250000, Time: 08_05_2022__15:35:38\n","Step: 400 of 1250, Validation loss: 0.7538988, Validation accuracy: 0.7381250, Time: 08_05_2022__15:35:41\n","Step: 500 of 1250, Validation loss: 0.7547351, Validation accuracy: 0.7420000, Time: 08_05_2022__15:35:45\n","Step: 600 of 1250, Validation loss: 0.7477266, Validation accuracy: 0.7445833, Time: 08_05_2022__15:35:49\n","Step: 700 of 1250, Validation loss: 0.7407424, Validation accuracy: 0.7457143, Time: 08_05_2022__15:35:53\n","Step: 800 of 1250, Validation loss: 0.7270914, Validation accuracy: 0.7475000, Time: 08_05_2022__15:35:56 | Loss decreased from 0.7316477 to 0.7258825 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.7311243, Validation accuracy: 0.7458333, Time: 08_05_2022__15:36:02\n","Step: 1000 of 1250, Validation loss: 0.7308405, Validation accuracy: 0.7455000, Time: 08_05_2022__15:36:06\n","Step: 1100 of 1250, Validation loss: 0.7316486, Validation accuracy: 0.7436364, Time: 08_05_2022__15:36:09\n","Step: 1200 of 1250, Validation loss: 0.7398641, Validation accuracy: 0.7391667, Time: 08_05_2022__15:36:13\n","Average validation loss: 0.7440425, Average validation accuracy: 0.7376000, Time: 08_05_2022__15:36:15\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a9eafd14f01461d8b904d8be2922133"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 0.6685455, Training accuracy: 0.7500000, Time: 08_05_2022__15:36:26\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 0.6829907, Training accuracy: 0.7500000, Time: 08_05_2022__15:36:37\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 0.7066202, Training accuracy: 0.7458333, Time: 08_05_2022__15:36:48\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 0.6862966, Training accuracy: 0.7525000, Time: 08_05_2022__15:36:59\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 0.6953359, Training accuracy: 0.7500000, Time: 08_05_2022__15:37:10\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 0.6974662, Training accuracy: 0.7525000, Time: 08_05_2022__15:37:21\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 0.7125870, Training accuracy: 0.7492857, Time: 08_05_2022__15:37:32\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 0.7174818, Training accuracy: 0.7443750, Time: 08_05_2022__15:37:43\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 0.7300260, Training accuracy: 0.7402778, Time: 08_05_2022__15:37:54\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 0.7239380, Training accuracy: 0.7435000, Time: 08_05_2022__15:38:05\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 0.7298328, Training accuracy: 0.7397727, Time: 08_05_2022__15:38:16\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 0.7334682, Training accuracy: 0.7368750, Time: 08_05_2022__15:38:27\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 0.7396686, Training accuracy: 0.7350000, Time: 08_05_2022__15:38:38\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 0.7455744, Training accuracy: 0.7342857, Time: 08_05_2022__15:38:49\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 0.7494064, Training accuracy: 0.7330000, Time: 08_05_2022__15:39:00\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 0.7457668, Training accuracy: 0.7362500, Time: 08_05_2022__15:39:11\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 0.7471043, Training accuracy: 0.7363235, Time: 08_05_2022__15:39:22\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 0.7504269, Training accuracy: 0.7352778, Time: 08_05_2022__15:39:33\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 0.7493400, Training accuracy: 0.7368421, Time: 08_05_2022__15:39:44\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 0.7491686, Training accuracy: 0.7376250, Time: 08_05_2022__15:39:55\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 0.7485721, Training accuracy: 0.7382143, Time: 08_05_2022__15:40:06\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 0.7493138, Training accuracy: 0.7376136, Time: 08_05_2022__15:40:17\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 0.7460941, Training accuracy: 0.7388043, Time: 08_05_2022__15:40:28\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 0.7442125, Training accuracy: 0.7394792, Time: 08_05_2022__15:40:39\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 0.7426418, Training accuracy: 0.7406000, Time: 08_05_2022__15:40:50\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 0.7412003, Training accuracy: 0.7410577, Time: 08_05_2022__15:41:01\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 0.7405416, Training accuracy: 0.7405556, Time: 08_05_2022__15:41:12\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 0.7408343, Training accuracy: 0.7400893, Time: 08_05_2022__15:41:23\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 0.7410636, Training accuracy: 0.7404310, Time: 08_05_2022__15:41:34\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 0.7402687, Training accuracy: 0.7401667, Time: 08_05_2022__15:41:45\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 0.7381243, Training accuracy: 0.7404839, Time: 08_05_2022__15:41:56\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 0.7359834, Training accuracy: 0.7406250, Time: 08_05_2022__15:42:07\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 0.7383229, Training accuracy: 0.7393939, Time: 08_05_2022__15:42:18\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 0.7388075, Training accuracy: 0.7399265, Time: 08_05_2022__15:42:29\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 0.7385433, Training accuracy: 0.7405000, Time: 08_05_2022__15:42:40\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 0.7381884, Training accuracy: 0.7406250, Time: 08_05_2022__15:42:51\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 0.7373985, Training accuracy: 0.7402027, Time: 08_05_2022__15:43:02\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 0.7365118, Training accuracy: 0.7407237, Time: 08_05_2022__15:43:13\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 0.7360552, Training accuracy: 0.7398718, Time: 08_05_2022__15:43:24\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 0.7342750, Training accuracy: 0.7403750, Time: 08_05_2022__15:43:35\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 0.7360070, Training accuracy: 0.7402439, Time: 08_05_2022__15:43:46\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 0.7341295, Training accuracy: 0.7410119, Time: 08_05_2022__15:43:57\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 0.7326970, Training accuracy: 0.7415698, Time: 08_05_2022__15:44:08\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 0.7321374, Training accuracy: 0.7415909, Time: 08_05_2022__15:44:19\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 0.7328425, Training accuracy: 0.7413889, Time: 08_05_2022__15:44:30\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 0.7322196, Training accuracy: 0.7420109, Time: 08_05_2022__15:44:41\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 0.7313348, Training accuracy: 0.7425000, Time: 08_05_2022__15:44:52\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 0.7312446, Training accuracy: 0.7423437, Time: 08_05_2022__15:45:03\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 0.7305081, Training accuracy: 0.7426531, Time: 08_05_2022__15:45:14\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 0.7312013, Training accuracy: 0.7429000, Time: 08_05_2022__15:45:25\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 0.7305348, Training accuracy: 0.7429902, Time: 08_05_2022__15:45:36\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 0.7293479, Training accuracy: 0.7435577, Time: 08_05_2022__15:45:47\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 0.7300798, Training accuracy: 0.7429717, Time: 08_05_2022__15:45:58\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 0.7292105, Training accuracy: 0.7432407, Time: 08_05_2022__15:46:09\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 0.7301009, Training accuracy: 0.7433182, Time: 08_05_2022__15:46:20\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 0.7305339, Training accuracy: 0.7429911, Time: 08_05_2022__15:46:31\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 0.7294924, Training accuracy: 0.7434649, Time: 08_05_2022__15:46:42\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 0.7292865, Training accuracy: 0.7436207, Time: 08_05_2022__15:46:53\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 0.7304321, Training accuracy: 0.7435593, Time: 08_05_2022__15:47:04\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 0.7312803, Training accuracy: 0.7435000, Time: 08_05_2022__15:47:15\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 0.7319573, Training accuracy: 0.7436475, Time: 08_05_2022__15:47:26\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 0.7320106, Training accuracy: 0.7435081, Time: 08_05_2022__15:47:37\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 0.7322213, Training accuracy: 0.7434921, Time: 08_05_2022__15:47:48\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 0.7320352, Training accuracy: 0.7435156, Time: 08_05_2022__15:47:59\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 0.7318944, Training accuracy: 0.7433846, Time: 08_05_2022__15:48:10\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 0.7315247, Training accuracy: 0.7435985, Time: 08_05_2022__15:48:21\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 0.7309655, Training accuracy: 0.7434328, Time: 08_05_2022__15:48:32\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 0.7309283, Training accuracy: 0.7436397, Time: 08_05_2022__15:48:43\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 0.7295472, Training accuracy: 0.7443841, Time: 08_05_2022__15:48:54\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 0.7282508, Training accuracy: 0.7448929, Time: 08_05_2022__15:49:05\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 0.7283144, Training accuracy: 0.7447183, Time: 08_05_2022__15:49:16\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 0.7270360, Training accuracy: 0.7453472, Time: 08_05_2022__15:49:27\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 0.7260459, Training accuracy: 0.7459247, Time: 08_05_2022__15:49:38\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 0.7252503, Training accuracy: 0.7461149, Time: 08_05_2022__15:49:49\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 0.7238402, Training accuracy: 0.7465333, Time: 08_05_2022__15:50:00\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 0.7230777, Training accuracy: 0.7465461, Time: 08_05_2022__15:50:11\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 0.7232397, Training accuracy: 0.7467208, Time: 08_05_2022__15:50:22\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 0.7224686, Training accuracy: 0.7469551, Time: 08_05_2022__15:50:33\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 0.7209971, Training accuracy: 0.7475633, Time: 08_05_2022__15:50:44\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 0.7202410, Training accuracy: 0.7477812, Time: 08_05_2022__15:50:55\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 0.7208720, Training accuracy: 0.7475926, Time: 08_05_2022__15:51:06\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 0.7204943, Training accuracy: 0.7480183, Time: 08_05_2022__15:51:17\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 0.7202266, Training accuracy: 0.7481024, Time: 08_05_2022__15:51:28\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 0.7209337, Training accuracy: 0.7477976, Time: 08_05_2022__15:51:39\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 0.7208617, Training accuracy: 0.7476765, Time: 08_05_2022__15:51:50\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 0.7202283, Training accuracy: 0.7478488, Time: 08_05_2022__15:52:01\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 0.7206327, Training accuracy: 0.7477011, Time: 08_05_2022__15:52:12\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 0.7193811, Training accuracy: 0.7483807, Time: 08_05_2022__15:52:23\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 0.7184625, Training accuracy: 0.7485955, Time: 08_05_2022__15:52:34\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 0.7179986, Training accuracy: 0.7485833, Time: 08_05_2022__15:52:45\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 0.7185452, Training accuracy: 0.7484341, Time: 08_05_2022__15:52:56\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 0.7177258, Training accuracy: 0.7489130, Time: 08_05_2022__15:53:07\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 0.7174392, Training accuracy: 0.7490323, Time: 08_05_2022__15:53:18\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 0.7172197, Training accuracy: 0.7488830, Time: 08_05_2022__15:53:29\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 0.7181134, Training accuracy: 0.7486316, Time: 08_05_2022__15:53:40\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 0.7168958, Training accuracy: 0.7491667, Time: 08_05_2022__15:53:51\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 0.7157556, Training accuracy: 0.7496392, Time: 08_05_2022__15:54:02\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 0.7148364, Training accuracy: 0.7499745, Time: 08_05_2022__15:54:13\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 0.7151231, Training accuracy: 0.7498232, Time: 08_05_2022__15:54:24\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 0.7147491, Training accuracy: 0.7499750, Time: 08_05_2022__15:54:35\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 0.7150790, Training accuracy: 0.7500000, Time: 08_05_2022__15:54:46\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 0.7150889, Training accuracy: 0.7502206, Time: 08_05_2022__15:54:57\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 0.7146056, Training accuracy: 0.7503883, Time: 08_05_2022__15:55:08\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 0.7137779, Training accuracy: 0.7507212, Time: 08_05_2022__15:55:19\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 0.7129774, Training accuracy: 0.7510476, Time: 08_05_2022__15:55:30\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 0.7130781, Training accuracy: 0.7508491, Time: 08_05_2022__15:55:41\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 0.7121208, Training accuracy: 0.7511449, Time: 08_05_2022__15:55:52\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 0.7118462, Training accuracy: 0.7512731, Time: 08_05_2022__15:56:03\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 0.7118885, Training accuracy: 0.7512844, Time: 08_05_2022__15:56:14\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 0.7117510, Training accuracy: 0.7514318, Time: 08_05_2022__15:56:25\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 0.7108732, Training accuracy: 0.7519144, Time: 08_05_2022__15:56:36\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 0.7108479, Training accuracy: 0.7518973, Time: 08_05_2022__15:56:47\n","Epoch 5 of 5, Average training loss: 0.7110630, Average training accuracy: 0.7517333, Time: 08_05_2022__15:56:53\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8296f42d49e944839e751d23059451ab"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.6950534, Validation accuracy: 0.7650000, Time: 08_05_2022__15:56:56 | Loss decreased from 0.7258825 to 0.6998064 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.6694103, Validation accuracy: 0.7550000, Time: 08_05_2022__15:57:02 | Loss decreased from 0.6998064 to 0.6696077 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.7080961, Validation accuracy: 0.7475000, Time: 08_05_2022__15:57:08\n","Step: 400 of 1250, Validation loss: 0.6907874, Validation accuracy: 0.7587500, Time: 08_05_2022__15:57:12\n","Step: 500 of 1250, Validation loss: 0.6922384, Validation accuracy: 0.7580000, Time: 08_05_2022__15:57:15\n","Step: 600 of 1250, Validation loss: 0.6834554, Validation accuracy: 0.7637500, Time: 08_05_2022__15:57:19\n","Step: 700 of 1250, Validation loss: 0.6745222, Validation accuracy: 0.7646429, Time: 08_05_2022__15:57:23\n","Step: 800 of 1250, Validation loss: 0.6693429, Validation accuracy: 0.7656250, Time: 08_05_2022__15:57:27 | Loss decreased from 0.6696077 to 0.6677532 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.6676321, Validation accuracy: 0.7672222, Time: 08_05_2022__15:57:33 | Loss decreased from 0.6677532 to 0.6675875 .... Saving the model\n","Step: 1000 of 1250, Validation loss: 0.6632422, Validation accuracy: 0.7667500, Time: 08_05_2022__15:57:39 | Loss decreased from 0.6675875 to 0.6631034 .... Saving the model\n","Step: 1100 of 1250, Validation loss: 0.6646622, Validation accuracy: 0.7647727, Time: 08_05_2022__15:57:44\n","Step: 1200 of 1250, Validation loss: 0.6720452, Validation accuracy: 0.7635417, Time: 08_05_2022__15:57:48\n","Average validation loss: 0.6713601, Average validation accuracy: 0.7646000, Time: 08_05_2022__15:57:50\n","###################### Testing vgg19_batch_norm SGD, lr_0.001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"938ffe7f6d8c4241af5dc96e042441b8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.7725000, Time: 08_05_2022__15:58:03\n","Step: 200 of 2500, Test accuracy: 0.7750000, Time: 08_05_2022__15:58:07\n","Step: 300 of 2500, Test accuracy: 0.7775000, Time: 08_05_2022__15:58:11\n","Step: 400 of 2500, Test accuracy: 0.7718750, Time: 08_05_2022__15:58:14\n","Step: 500 of 2500, Test accuracy: 0.7655000, Time: 08_05_2022__15:58:18\n","Step: 600 of 2500, Test accuracy: 0.7612500, Time: 08_05_2022__15:58:22\n","Step: 700 of 2500, Test accuracy: 0.7585714, Time: 08_05_2022__15:58:26\n","Step: 800 of 2500, Test accuracy: 0.7634375, Time: 08_05_2022__15:58:29\n","Step: 900 of 2500, Test accuracy: 0.7611111, Time: 08_05_2022__15:58:33\n","Step: 1000 of 2500, Test accuracy: 0.7585000, Time: 08_05_2022__15:58:37\n","Step: 1100 of 2500, Test accuracy: 0.7611364, Time: 08_05_2022__15:58:41\n","Step: 1200 of 2500, Test accuracy: 0.7620833, Time: 08_05_2022__15:58:45\n","Step: 1300 of 2500, Test accuracy: 0.7626923, Time: 08_05_2022__15:58:48\n","Step: 1400 of 2500, Test accuracy: 0.7621429, Time: 08_05_2022__15:58:52\n","Step: 1500 of 2500, Test accuracy: 0.7618333, Time: 08_05_2022__15:58:56\n","Step: 1600 of 2500, Test accuracy: 0.7609375, Time: 08_05_2022__15:59:00\n","Step: 1700 of 2500, Test accuracy: 0.7611765, Time: 08_05_2022__15:59:03\n","Step: 1800 of 2500, Test accuracy: 0.7611111, Time: 08_05_2022__15:59:07\n","Step: 1900 of 2500, Test accuracy: 0.7621053, Time: 08_05_2022__15:59:11\n","Step: 2000 of 2500, Test accuracy: 0.7631250, Time: 08_05_2022__15:59:15\n","Step: 2100 of 2500, Test accuracy: 0.7625000, Time: 08_05_2022__15:59:18\n","Step: 2200 of 2500, Test accuracy: 0.7618182, Time: 08_05_2022__15:59:22\n","Step: 2300 of 2500, Test accuracy: 0.7627174, Time: 08_05_2022__15:59:26\n","Step: 2400 of 2500, Test accuracy: 0.7632292, Time: 08_05_2022__15:59:30\n","Step: 2500 of 2500, Test accuracy: 0.7626000, Time: 08_05_2022__15:59:34\n","Average testing accuracy: 0.7626000, Time: 08_05_2022__15:59:34\n","###################### Training vgg19_batch_norm SGD, lr_0.001, momentum_0.9 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1ad81bd6be34f2994039fa00638bc3a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 2.9653623, Training accuracy: 0.1050000, Time: 08_05_2022__15:59:47\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 2.7967214, Training accuracy: 0.1325000, Time: 08_05_2022__15:59:58\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 2.6907273, Training accuracy: 0.1383333, Time: 08_05_2022__16:00:09\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 2.6138638, Training accuracy: 0.1387500, Time: 08_05_2022__16:00:20\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 2.5527010, Training accuracy: 0.1430000, Time: 08_05_2022__16:00:31\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 2.5098893, Training accuracy: 0.1504167, Time: 08_05_2022__16:00:42\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.4702107, Training accuracy: 0.1485714, Time: 08_05_2022__16:00:53\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.4364688, Training accuracy: 0.1521875, Time: 08_05_2022__16:01:04\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.4116004, Training accuracy: 0.1577778, Time: 08_05_2022__16:01:15\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.3867848, Training accuracy: 0.1612500, Time: 08_05_2022__16:01:26\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.3661945, Training accuracy: 0.1650000, Time: 08_05_2022__16:01:37\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.3430878, Training accuracy: 0.1662500, Time: 08_05_2022__16:01:48\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.3194838, Training accuracy: 0.1715385, Time: 08_05_2022__16:01:59\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.2992925, Training accuracy: 0.1767857, Time: 08_05_2022__16:02:10\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.2823924, Training accuracy: 0.1828333, Time: 08_05_2022__16:02:21\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.2670159, Training accuracy: 0.1870313, Time: 08_05_2022__16:02:32\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.2555792, Training accuracy: 0.1904412, Time: 08_05_2022__16:02:43\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.2374151, Training accuracy: 0.1973611, Time: 08_05_2022__16:02:54\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.2225352, Training accuracy: 0.2026316, Time: 08_05_2022__16:03:05\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.2108006, Training accuracy: 0.2065000, Time: 08_05_2022__16:03:16\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.1985744, Training accuracy: 0.2091667, Time: 08_05_2022__16:03:27\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.1889173, Training accuracy: 0.2112500, Time: 08_05_2022__16:03:38\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.1790475, Training accuracy: 0.2133696, Time: 08_05_2022__16:03:49\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.1661183, Training accuracy: 0.2176042, Time: 08_05_2022__16:04:00\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.1545857, Training accuracy: 0.2214000, Time: 08_05_2022__16:04:11\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.1440880, Training accuracy: 0.2253846, Time: 08_05_2022__16:04:23\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.1345577, Training accuracy: 0.2288889, Time: 08_05_2022__16:04:34\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.1252479, Training accuracy: 0.2314286, Time: 08_05_2022__16:04:45\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.1178120, Training accuracy: 0.2345690, Time: 08_05_2022__16:04:56\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.1111312, Training accuracy: 0.2357500, Time: 08_05_2022__16:05:07\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.1025638, Training accuracy: 0.2389516, Time: 08_05_2022__16:05:18\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.0949666, Training accuracy: 0.2425000, Time: 08_05_2022__16:05:29\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.0886356, Training accuracy: 0.2438636, Time: 08_05_2022__16:05:40\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.0810751, Training accuracy: 0.2463235, Time: 08_05_2022__16:05:51\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.0737574, Training accuracy: 0.2481429, Time: 08_05_2022__16:06:02\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.0686407, Training accuracy: 0.2494444, Time: 08_05_2022__16:06:13\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.0643255, Training accuracy: 0.2514865, Time: 08_05_2022__16:06:24\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.0568772, Training accuracy: 0.2546053, Time: 08_05_2022__16:06:35\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.0497044, Training accuracy: 0.2575641, Time: 08_05_2022__16:06:46\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.0443252, Training accuracy: 0.2595625, Time: 08_05_2022__16:06:57\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.0399950, Training accuracy: 0.2608537, Time: 08_05_2022__16:07:08\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.0319225, Training accuracy: 0.2638095, Time: 08_05_2022__16:07:19\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.0267618, Training accuracy: 0.2656977, Time: 08_05_2022__16:07:30\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.0200057, Training accuracy: 0.2678977, Time: 08_05_2022__16:07:41\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.0139557, Training accuracy: 0.2702778, Time: 08_05_2022__16:07:52\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.0076212, Training accuracy: 0.2727717, Time: 08_05_2022__16:08:03\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.0019595, Training accuracy: 0.2750532, Time: 08_05_2022__16:08:14\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 1.9975537, Training accuracy: 0.2762500, Time: 08_05_2022__16:08:25\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 1.9932075, Training accuracy: 0.2776531, Time: 08_05_2022__16:08:36\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 1.9902881, Training accuracy: 0.2785500, Time: 08_05_2022__16:08:47\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 1.9844774, Training accuracy: 0.2800000, Time: 08_05_2022__16:08:58\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 1.9812530, Training accuracy: 0.2812981, Time: 08_05_2022__16:09:09\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 1.9764403, Training accuracy: 0.2827358, Time: 08_05_2022__16:09:20\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 1.9727945, Training accuracy: 0.2839815, Time: 08_05_2022__16:09:32\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 1.9689331, Training accuracy: 0.2853182, Time: 08_05_2022__16:09:43\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 1.9651606, Training accuracy: 0.2862054, Time: 08_05_2022__16:09:54\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 1.9602991, Training accuracy: 0.2876754, Time: 08_05_2022__16:10:05\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 1.9557486, Training accuracy: 0.2889224, Time: 08_05_2022__16:10:16\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 1.9515587, Training accuracy: 0.2906356, Time: 08_05_2022__16:10:27\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 1.9477045, Training accuracy: 0.2917917, Time: 08_05_2022__16:10:38\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 1.9444928, Training accuracy: 0.2924590, Time: 08_05_2022__16:10:49\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 1.9401839, Training accuracy: 0.2939516, Time: 08_05_2022__16:11:00\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 1.9354535, Training accuracy: 0.2951190, Time: 08_05_2022__16:11:11\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 1.9327863, Training accuracy: 0.2958984, Time: 08_05_2022__16:11:22\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 1.9280577, Training accuracy: 0.2978846, Time: 08_05_2022__16:11:33\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 1.9251259, Training accuracy: 0.2988258, Time: 08_05_2022__16:11:44\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 1.9211846, Training accuracy: 0.2999627, Time: 08_05_2022__16:11:55\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 1.9181775, Training accuracy: 0.3011029, Time: 08_05_2022__16:12:06\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 1.9146714, Training accuracy: 0.3027174, Time: 08_05_2022__16:12:17\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 1.9105602, Training accuracy: 0.3040714, Time: 08_05_2022__16:12:28\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 1.9083949, Training accuracy: 0.3046831, Time: 08_05_2022__16:12:39\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 1.9046000, Training accuracy: 0.3058333, Time: 08_05_2022__16:12:50\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 1.9008189, Training accuracy: 0.3075000, Time: 08_05_2022__16:13:01\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 1.8979691, Training accuracy: 0.3085811, Time: 08_05_2022__16:13:12\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 1.8950382, Training accuracy: 0.3097333, Time: 08_05_2022__16:13:23\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 1.8910764, Training accuracy: 0.3112171, Time: 08_05_2022__16:13:34\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 1.8884363, Training accuracy: 0.3124675, Time: 08_05_2022__16:13:45\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 1.8844681, Training accuracy: 0.3141346, Time: 08_05_2022__16:13:56\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 1.8812942, Training accuracy: 0.3147785, Time: 08_05_2022__16:14:07\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 1.8782500, Training accuracy: 0.3157500, Time: 08_05_2022__16:14:18\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 1.8752789, Training accuracy: 0.3167284, Time: 08_05_2022__16:14:29\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 1.8720808, Training accuracy: 0.3179573, Time: 08_05_2022__16:14:40\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 1.8679758, Training accuracy: 0.3195181, Time: 08_05_2022__16:14:51\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 1.8644813, Training accuracy: 0.3207440, Time: 08_05_2022__16:15:02\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 1.8616554, Training accuracy: 0.3218235, Time: 08_05_2022__16:15:13\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 1.8583345, Training accuracy: 0.3232558, Time: 08_05_2022__16:15:24\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 1.8552351, Training accuracy: 0.3243103, Time: 08_05_2022__16:15:36\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 1.8510007, Training accuracy: 0.3257955, Time: 08_05_2022__16:15:47\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 1.8479431, Training accuracy: 0.3266292, Time: 08_05_2022__16:15:58\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 1.8448637, Training accuracy: 0.3275556, Time: 08_05_2022__16:16:09\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 1.8421761, Training accuracy: 0.3283516, Time: 08_05_2022__16:16:20\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 1.8387781, Training accuracy: 0.3299457, Time: 08_05_2022__16:16:31\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 1.8357384, Training accuracy: 0.3310753, Time: 08_05_2022__16:16:42\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 1.8334125, Training accuracy: 0.3321543, Time: 08_05_2022__16:16:53\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 1.8319453, Training accuracy: 0.3323421, Time: 08_05_2022__16:17:04\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 1.8278298, Training accuracy: 0.3338021, Time: 08_05_2022__16:17:15\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 1.8243198, Training accuracy: 0.3350258, Time: 08_05_2022__16:17:26\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 1.8213765, Training accuracy: 0.3360969, Time: 08_05_2022__16:17:37\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 1.8193118, Training accuracy: 0.3368182, Time: 08_05_2022__16:17:48\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 1.8169308, Training accuracy: 0.3377250, Time: 08_05_2022__16:17:59\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 1.8149487, Training accuracy: 0.3386634, Time: 08_05_2022__16:18:10\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 1.8122556, Training accuracy: 0.3395343, Time: 08_05_2022__16:18:21\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 1.8090346, Training accuracy: 0.3408252, Time: 08_05_2022__16:18:32\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 1.8060188, Training accuracy: 0.3418750, Time: 08_05_2022__16:18:43\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 1.8040215, Training accuracy: 0.3427381, Time: 08_05_2022__16:18:54\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 1.8012490, Training accuracy: 0.3436557, Time: 08_05_2022__16:19:05\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 1.7985730, Training accuracy: 0.3444393, Time: 08_05_2022__16:19:16\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 1.7956869, Training accuracy: 0.3457176, Time: 08_05_2022__16:19:27\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 1.7936490, Training accuracy: 0.3464908, Time: 08_05_2022__16:19:38\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 1.7907875, Training accuracy: 0.3477045, Time: 08_05_2022__16:19:49\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 1.7878334, Training accuracy: 0.3490541, Time: 08_05_2022__16:20:00\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 1.7857983, Training accuracy: 0.3498884, Time: 08_05_2022__16:20:11\n","Epoch 1 of 5, Average training loss: 1.7847500, Average training accuracy: 0.3502000, Time: 08_05_2022__16:20:17\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"846fdfd338b0437e89a1d69b86ddd635"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.3484195, Validation accuracy: 0.5350000, Time: 08_05_2022__16:20:21 | Loss decreased from inf to 1.3505618 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.3441419, Validation accuracy: 0.5187500, Time: 08_05_2022__16:20:27 | Loss decreased from 1.3505618 to 1.3470745 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.3387435, Validation accuracy: 0.5141667, Time: 08_05_2022__16:20:33 | Loss decreased from 1.3470745 to 1.3371542 .... Saving the model\n","Step: 400 of 1250, Validation loss: 1.3395297, Validation accuracy: 0.5156250, Time: 08_05_2022__16:20:39\n","Step: 500 of 1250, Validation loss: 1.3416374, Validation accuracy: 0.5135000, Time: 08_05_2022__16:20:43\n","Step: 600 of 1250, Validation loss: 1.3367728, Validation accuracy: 0.5179167, Time: 08_05_2022__16:20:47 | Loss decreased from 1.3371542 to 1.3370062 .... Saving the model\n","Step: 700 of 1250, Validation loss: 1.3277906, Validation accuracy: 0.5217857, Time: 08_05_2022__16:20:53 | Loss decreased from 1.3370062 to 1.3278267 .... Saving the model\n","Step: 800 of 1250, Validation loss: 1.3212580, Validation accuracy: 0.5209375, Time: 08_05_2022__16:20:59 | Loss decreased from 1.3278267 to 1.3219000 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.3250204, Validation accuracy: 0.5197222, Time: 08_05_2022__16:21:05\n","Step: 1000 of 1250, Validation loss: 1.3275728, Validation accuracy: 0.5172500, Time: 08_05_2022__16:21:09\n","Step: 1100 of 1250, Validation loss: 1.3254948, Validation accuracy: 0.5200000, Time: 08_05_2022__16:21:12\n","Step: 1200 of 1250, Validation loss: 1.3265385, Validation accuracy: 0.5185417, Time: 08_05_2022__16:21:16\n","Average validation loss: 1.3257050, Average validation accuracy: 0.5190000, Time: 08_05_2022__16:21:18\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b26015df75ba4f43989dc1ca9296a3d7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.3825979, Training accuracy: 0.4975000, Time: 08_05_2022__16:21:30\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.3972476, Training accuracy: 0.5012500, Time: 08_05_2022__16:21:41\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.4446205, Training accuracy: 0.4775000, Time: 08_05_2022__16:21:52\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.4292442, Training accuracy: 0.4837500, Time: 08_05_2022__16:22:03\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.4384624, Training accuracy: 0.4820000, Time: 08_05_2022__16:22:14\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.4449954, Training accuracy: 0.4758333, Time: 08_05_2022__16:22:25\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.4597675, Training accuracy: 0.4689286, Time: 08_05_2022__16:22:36\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.4527410, Training accuracy: 0.4768750, Time: 08_05_2022__16:22:48\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.4492922, Training accuracy: 0.4786111, Time: 08_05_2022__16:22:59\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.4421547, Training accuracy: 0.4812500, Time: 08_05_2022__16:23:10\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.4432740, Training accuracy: 0.4815909, Time: 08_05_2022__16:23:21\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.4420296, Training accuracy: 0.4827083, Time: 08_05_2022__16:23:32\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.4381807, Training accuracy: 0.4850000, Time: 08_05_2022__16:23:43\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.4332396, Training accuracy: 0.4869643, Time: 08_05_2022__16:23:54\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.4337631, Training accuracy: 0.4886667, Time: 08_05_2022__16:24:05\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.4341522, Training accuracy: 0.4882812, Time: 08_05_2022__16:24:16\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.4351921, Training accuracy: 0.4867647, Time: 08_05_2022__16:24:28\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.4327473, Training accuracy: 0.4870833, Time: 08_05_2022__16:24:39\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.4305067, Training accuracy: 0.4884211, Time: 08_05_2022__16:24:50\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.4267611, Training accuracy: 0.4900000, Time: 08_05_2022__16:25:01\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.4212421, Training accuracy: 0.4900000, Time: 08_05_2022__16:25:12\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.4189493, Training accuracy: 0.4914773, Time: 08_05_2022__16:25:23\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.4148626, Training accuracy: 0.4931522, Time: 08_05_2022__16:25:34\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.4103249, Training accuracy: 0.4940625, Time: 08_05_2022__16:25:45\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.4070371, Training accuracy: 0.4952000, Time: 08_05_2022__16:25:57\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.4055971, Training accuracy: 0.4964423, Time: 08_05_2022__16:26:08\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.4003032, Training accuracy: 0.4985185, Time: 08_05_2022__16:26:19\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.3985721, Training accuracy: 0.4991964, Time: 08_05_2022__16:26:30\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.3957110, Training accuracy: 0.5001724, Time: 08_05_2022__16:26:41\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.3956535, Training accuracy: 0.4998333, Time: 08_05_2022__16:26:52\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.3903659, Training accuracy: 0.5019355, Time: 08_05_2022__16:27:03\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.3877114, Training accuracy: 0.5035156, Time: 08_05_2022__16:27:15\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.3863285, Training accuracy: 0.5038636, Time: 08_05_2022__16:27:26\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.3848885, Training accuracy: 0.5046324, Time: 08_05_2022__16:27:37\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.3824139, Training accuracy: 0.5056429, Time: 08_05_2022__16:27:48\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.3822233, Training accuracy: 0.5050694, Time: 08_05_2022__16:27:59\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.3805333, Training accuracy: 0.5057432, Time: 08_05_2022__16:28:10\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.3783620, Training accuracy: 0.5067105, Time: 08_05_2022__16:28:21\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.3753018, Training accuracy: 0.5079487, Time: 08_05_2022__16:28:33\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.3725274, Training accuracy: 0.5089375, Time: 08_05_2022__16:28:44\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.3729587, Training accuracy: 0.5096341, Time: 08_05_2022__16:28:55\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.3687715, Training accuracy: 0.5111310, Time: 08_05_2022__16:29:06\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.3668775, Training accuracy: 0.5114535, Time: 08_05_2022__16:29:17\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.3646393, Training accuracy: 0.5118750, Time: 08_05_2022__16:29:28\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.3625067, Training accuracy: 0.5125000, Time: 08_05_2022__16:29:39\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.3610092, Training accuracy: 0.5131522, Time: 08_05_2022__16:29:50\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.3586202, Training accuracy: 0.5142553, Time: 08_05_2022__16:30:02\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.3566096, Training accuracy: 0.5148958, Time: 08_05_2022__16:30:13\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.3542860, Training accuracy: 0.5153571, Time: 08_05_2022__16:30:24\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.3536708, Training accuracy: 0.5166500, Time: 08_05_2022__16:30:35\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.3509569, Training accuracy: 0.5175490, Time: 08_05_2022__16:30:46\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.3493233, Training accuracy: 0.5184615, Time: 08_05_2022__16:30:57\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.3488872, Training accuracy: 0.5188208, Time: 08_05_2022__16:31:08\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.3472489, Training accuracy: 0.5196759, Time: 08_05_2022__16:31:20\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.3457149, Training accuracy: 0.5203636, Time: 08_05_2022__16:31:31\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.3445438, Training accuracy: 0.5209375, Time: 08_05_2022__16:31:42\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.3435954, Training accuracy: 0.5213158, Time: 08_05_2022__16:31:53\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.3422942, Training accuracy: 0.5214655, Time: 08_05_2022__16:32:04\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.3408338, Training accuracy: 0.5220339, Time: 08_05_2022__16:32:15\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.3399353, Training accuracy: 0.5219583, Time: 08_05_2022__16:32:26\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.3387337, Training accuracy: 0.5226639, Time: 08_05_2022__16:32:37\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.3367768, Training accuracy: 0.5233065, Time: 08_05_2022__16:32:49\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.3362260, Training accuracy: 0.5235317, Time: 08_05_2022__16:33:00\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.3337981, Training accuracy: 0.5246484, Time: 08_05_2022__16:33:11\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.3315263, Training accuracy: 0.5252308, Time: 08_05_2022__16:33:22\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.3296528, Training accuracy: 0.5258712, Time: 08_05_2022__16:33:33\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.3275439, Training accuracy: 0.5269403, Time: 08_05_2022__16:33:44\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.3266866, Training accuracy: 0.5272426, Time: 08_05_2022__16:33:55\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.3249501, Training accuracy: 0.5280435, Time: 08_05_2022__16:34:06\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.3227245, Training accuracy: 0.5289643, Time: 08_05_2022__16:34:18\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.3223955, Training accuracy: 0.5289437, Time: 08_05_2022__16:34:29\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.3200447, Training accuracy: 0.5300000, Time: 08_05_2022__16:34:40\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.3190599, Training accuracy: 0.5307192, Time: 08_05_2022__16:34:51\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.3171901, Training accuracy: 0.5312500, Time: 08_05_2022__16:35:02\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.3158596, Training accuracy: 0.5319000, Time: 08_05_2022__16:35:13\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.3127255, Training accuracy: 0.5327961, Time: 08_05_2022__16:35:24\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.3121560, Training accuracy: 0.5333117, Time: 08_05_2022__16:35:35\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.3110015, Training accuracy: 0.5341667, Time: 08_05_2022__16:35:47\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.3093202, Training accuracy: 0.5346835, Time: 08_05_2022__16:35:58\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.3076906, Training accuracy: 0.5353125, Time: 08_05_2022__16:36:09\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.3070623, Training accuracy: 0.5354630, Time: 08_05_2022__16:36:20\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.3062549, Training accuracy: 0.5358841, Time: 08_05_2022__16:36:31\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.3050351, Training accuracy: 0.5362048, Time: 08_05_2022__16:36:42\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.3039247, Training accuracy: 0.5364881, Time: 08_05_2022__16:36:53\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.3025037, Training accuracy: 0.5370588, Time: 08_05_2022__16:37:04\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.3007229, Training accuracy: 0.5376163, Time: 08_05_2022__16:37:16\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.2995382, Training accuracy: 0.5379885, Time: 08_05_2022__16:37:27\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.2972292, Training accuracy: 0.5388068, Time: 08_05_2022__16:37:38\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.2947198, Training accuracy: 0.5397472, Time: 08_05_2022__16:37:49\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.2928199, Training accuracy: 0.5404722, Time: 08_05_2022__16:38:00\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.2917134, Training accuracy: 0.5405220, Time: 08_05_2022__16:38:11\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.2891485, Training accuracy: 0.5414674, Time: 08_05_2022__16:38:22\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.2882731, Training accuracy: 0.5414516, Time: 08_05_2022__16:38:34\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.2867830, Training accuracy: 0.5418883, Time: 08_05_2022__16:38:45\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.2863502, Training accuracy: 0.5422895, Time: 08_05_2022__16:38:56\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.2843402, Training accuracy: 0.5429688, Time: 08_05_2022__16:39:07\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.2811881, Training accuracy: 0.5438402, Time: 08_05_2022__16:39:18\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.2795222, Training accuracy: 0.5446684, Time: 08_05_2022__16:39:29\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.2778836, Training accuracy: 0.5451010, Time: 08_05_2022__16:39:40\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.2769239, Training accuracy: 0.5454250, Time: 08_05_2022__16:39:51\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.2761876, Training accuracy: 0.5457178, Time: 08_05_2022__16:40:03\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.2745552, Training accuracy: 0.5464216, Time: 08_05_2022__16:40:14\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.2725073, Training accuracy: 0.5472573, Time: 08_05_2022__16:40:25\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.2700568, Training accuracy: 0.5480769, Time: 08_05_2022__16:40:36\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.2690508, Training accuracy: 0.5486905, Time: 08_05_2022__16:40:47\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.2678659, Training accuracy: 0.5491745, Time: 08_05_2022__16:40:58\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.2660867, Training accuracy: 0.5495561, Time: 08_05_2022__16:41:09\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.2643939, Training accuracy: 0.5503704, Time: 08_05_2022__16:41:20\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.2635399, Training accuracy: 0.5508486, Time: 08_05_2022__16:41:32\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.2620767, Training accuracy: 0.5512500, Time: 08_05_2022__16:41:43\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.2599703, Training accuracy: 0.5520721, Time: 08_05_2022__16:41:54\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.2590945, Training accuracy: 0.5522545, Time: 08_05_2022__16:42:05\n","Epoch 2 of 5, Average training loss: 1.2589461, Average training accuracy: 0.5523778, Time: 08_05_2022__16:42:11\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e95533cfc3545ff9b51eb1f8175f6cc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.0686316, Validation accuracy: 0.6400000, Time: 08_05_2022__16:42:14 | Loss decreased from 1.3219000 to 1.0728727 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.0341913, Validation accuracy: 0.6362500, Time: 08_05_2022__16:42:20 | Loss decreased from 1.0728727 to 1.0365081 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.0412886, Validation accuracy: 0.6375000, Time: 08_05_2022__16:42:26\n","Step: 400 of 1250, Validation loss: 1.0340543, Validation accuracy: 0.6456250, Time: 08_05_2022__16:42:30 | Loss decreased from 1.0365081 to 1.0345004 .... Saving the model\n","Step: 500 of 1250, Validation loss: 1.0404231, Validation accuracy: 0.6390000, Time: 08_05_2022__16:42:35\n","Step: 600 of 1250, Validation loss: 1.0294243, Validation accuracy: 0.6445833, Time: 08_05_2022__16:42:39 | Loss decreased from 1.0345004 to 1.0295740 .... Saving the model\n","Step: 700 of 1250, Validation loss: 1.0176611, Validation accuracy: 0.6446429, Time: 08_05_2022__16:42:45 | Loss decreased from 1.0295740 to 1.0171035 .... Saving the model\n","Step: 800 of 1250, Validation loss: 1.0093727, Validation accuracy: 0.6478125, Time: 08_05_2022__16:42:51 | Loss decreased from 1.0171035 to 1.0090519 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.0135071, Validation accuracy: 0.6488889, Time: 08_05_2022__16:42:57\n","Step: 1000 of 1250, Validation loss: 1.0177676, Validation accuracy: 0.6480000, Time: 08_05_2022__16:43:00\n","Step: 1100 of 1250, Validation loss: 1.0168574, Validation accuracy: 0.6479545, Time: 08_05_2022__16:43:04\n","Step: 1200 of 1250, Validation loss: 1.0232521, Validation accuracy: 0.6427083, Time: 08_05_2022__16:43:08\n","Average validation loss: 1.0220536, Average validation accuracy: 0.6444000, Time: 08_05_2022__16:43:10\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25bbb5dfd5fe4a9f8cbf9373238965f1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 0.9772837, Training accuracy: 0.6525000, Time: 08_05_2022__16:43:21\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.0146202, Training accuracy: 0.6400000, Time: 08_05_2022__16:43:32\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.0426395, Training accuracy: 0.6250000, Time: 08_05_2022__16:43:43\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.0206167, Training accuracy: 0.6281250, Time: 08_05_2022__16:43:54\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.0376320, Training accuracy: 0.6230000, Time: 08_05_2022__16:44:05\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.0525706, Training accuracy: 0.6241667, Time: 08_05_2022__16:44:17\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.0613865, Training accuracy: 0.6267857, Time: 08_05_2022__16:44:28\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.0570583, Training accuracy: 0.6303125, Time: 08_05_2022__16:44:39\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.0635604, Training accuracy: 0.6294444, Time: 08_05_2022__16:44:50\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.0602955, Training accuracy: 0.6305000, Time: 08_05_2022__16:45:01\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.0685459, Training accuracy: 0.6270455, Time: 08_05_2022__16:45:12\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.0669119, Training accuracy: 0.6277083, Time: 08_05_2022__16:45:23\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.0628633, Training accuracy: 0.6288462, Time: 08_05_2022__16:45:34\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.0605236, Training accuracy: 0.6294643, Time: 08_05_2022__16:45:45\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.0668646, Training accuracy: 0.6293333, Time: 08_05_2022__16:45:56\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.0676659, Training accuracy: 0.6285937, Time: 08_05_2022__16:46:07\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.0701612, Training accuracy: 0.6275000, Time: 08_05_2022__16:46:18\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.0698830, Training accuracy: 0.6279167, Time: 08_05_2022__16:46:29\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.0674251, Training accuracy: 0.6278947, Time: 08_05_2022__16:46:40\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.0653959, Training accuracy: 0.6290000, Time: 08_05_2022__16:46:51\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.0615732, Training accuracy: 0.6303571, Time: 08_05_2022__16:47:02\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.0606388, Training accuracy: 0.6306818, Time: 08_05_2022__16:47:14\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.0579098, Training accuracy: 0.6305435, Time: 08_05_2022__16:47:25\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.0555571, Training accuracy: 0.6308333, Time: 08_05_2022__16:47:36\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.0522214, Training accuracy: 0.6323000, Time: 08_05_2022__16:47:47\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.0497037, Training accuracy: 0.6338462, Time: 08_05_2022__16:47:58\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.0472432, Training accuracy: 0.6351852, Time: 08_05_2022__16:48:09\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.0488434, Training accuracy: 0.6342857, Time: 08_05_2022__16:48:20\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.0479940, Training accuracy: 0.6346552, Time: 08_05_2022__16:48:31\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.0473470, Training accuracy: 0.6350000, Time: 08_05_2022__16:48:42\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.0447625, Training accuracy: 0.6350000, Time: 08_05_2022__16:48:53\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.0410943, Training accuracy: 0.6364844, Time: 08_05_2022__16:49:04\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.0420792, Training accuracy: 0.6365152, Time: 08_05_2022__16:49:15\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.0413036, Training accuracy: 0.6366176, Time: 08_05_2022__16:49:26\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.0412504, Training accuracy: 0.6364286, Time: 08_05_2022__16:49:37\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.0427046, Training accuracy: 0.6354861, Time: 08_05_2022__16:49:48\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.0411088, Training accuracy: 0.6356081, Time: 08_05_2022__16:50:00\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.0396840, Training accuracy: 0.6363816, Time: 08_05_2022__16:50:11\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.0372100, Training accuracy: 0.6369231, Time: 08_05_2022__16:50:22\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.0362350, Training accuracy: 0.6373750, Time: 08_05_2022__16:50:33\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.0384181, Training accuracy: 0.6369512, Time: 08_05_2022__16:50:44\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.0349917, Training accuracy: 0.6378571, Time: 08_05_2022__16:50:55\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.0340250, Training accuracy: 0.6384884, Time: 08_05_2022__16:51:06\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.0317503, Training accuracy: 0.6388636, Time: 08_05_2022__16:51:17\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.0311045, Training accuracy: 0.6392778, Time: 08_05_2022__16:51:28\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.0316485, Training accuracy: 0.6390217, Time: 08_05_2022__16:51:39\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.0292800, Training accuracy: 0.6406915, Time: 08_05_2022__16:51:50\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.0289823, Training accuracy: 0.6407292, Time: 08_05_2022__16:52:01\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.0275226, Training accuracy: 0.6410204, Time: 08_05_2022__16:52:12\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.0277274, Training accuracy: 0.6413000, Time: 08_05_2022__16:52:23\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.0274680, Training accuracy: 0.6418137, Time: 08_05_2022__16:52:34\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.0270558, Training accuracy: 0.6413462, Time: 08_05_2022__16:52:45\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.0267432, Training accuracy: 0.6415094, Time: 08_05_2022__16:52:56\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.0261700, Training accuracy: 0.6418981, Time: 08_05_2022__16:53:08\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.0256038, Training accuracy: 0.6423182, Time: 08_05_2022__16:53:19\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.0246176, Training accuracy: 0.6426786, Time: 08_05_2022__16:53:30\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.0232478, Training accuracy: 0.6428070, Time: 08_05_2022__16:53:41\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.0234153, Training accuracy: 0.6431034, Time: 08_05_2022__16:53:52\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.0237471, Training accuracy: 0.6429237, Time: 08_05_2022__16:54:03\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.0239105, Training accuracy: 0.6427917, Time: 08_05_2022__16:54:14\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.0233481, Training accuracy: 0.6431967, Time: 08_05_2022__16:54:25\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.0213054, Training accuracy: 0.6438306, Time: 08_05_2022__16:54:36\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.0211747, Training accuracy: 0.6434921, Time: 08_05_2022__16:54:47\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.0212043, Training accuracy: 0.6435937, Time: 08_05_2022__16:54:58\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.0201442, Training accuracy: 0.6437692, Time: 08_05_2022__16:55:09\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.0193272, Training accuracy: 0.6437121, Time: 08_05_2022__16:55:20\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.0185180, Training accuracy: 0.6438806, Time: 08_05_2022__16:55:31\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.0191325, Training accuracy: 0.6432721, Time: 08_05_2022__16:55:43\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.0182485, Training accuracy: 0.6438768, Time: 08_05_2022__16:55:54\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.0169850, Training accuracy: 0.6441071, Time: 08_05_2022__16:56:05\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.0163832, Training accuracy: 0.6440141, Time: 08_05_2022__16:56:16\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.0150428, Training accuracy: 0.6446528, Time: 08_05_2022__16:56:27\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.0142212, Training accuracy: 0.6448288, Time: 08_05_2022__16:56:38\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.0126666, Training accuracy: 0.6455405, Time: 08_05_2022__16:56:49\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.0107110, Training accuracy: 0.6463333, Time: 08_05_2022__16:57:00\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.0094733, Training accuracy: 0.6467105, Time: 08_05_2022__16:57:11\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.0095604, Training accuracy: 0.6467857, Time: 08_05_2022__16:57:22\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.0084411, Training accuracy: 0.6472115, Time: 08_05_2022__16:57:33\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.0072681, Training accuracy: 0.6477532, Time: 08_05_2022__16:57:44\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.0052665, Training accuracy: 0.6480312, Time: 08_05_2022__16:57:55\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.0057764, Training accuracy: 0.6479938, Time: 08_05_2022__16:58:06\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.0061156, Training accuracy: 0.6480793, Time: 08_05_2022__16:58:17\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.0053803, Training accuracy: 0.6484036, Time: 08_05_2022__16:58:29\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.0050270, Training accuracy: 0.6486310, Time: 08_05_2022__16:58:40\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.0042758, Training accuracy: 0.6487059, Time: 08_05_2022__16:58:51\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.0033195, Training accuracy: 0.6490698, Time: 08_05_2022__16:59:02\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.0026545, Training accuracy: 0.6489943, Time: 08_05_2022__16:59:13\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.0011264, Training accuracy: 0.6496875, Time: 08_05_2022__16:59:24\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 0.9994011, Training accuracy: 0.6503090, Time: 08_05_2022__16:59:35\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 0.9982587, Training accuracy: 0.6506389, Time: 08_05_2022__16:59:46\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 0.9976996, Training accuracy: 0.6509341, Time: 08_05_2022__16:59:57\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 0.9966224, Training accuracy: 0.6514674, Time: 08_05_2022__17:00:08\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 0.9965809, Training accuracy: 0.6514247, Time: 08_05_2022__17:00:19\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 0.9954733, Training accuracy: 0.6517553, Time: 08_05_2022__17:00:30\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 0.9952951, Training accuracy: 0.6520000, Time: 08_05_2022__17:00:41\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 0.9935065, Training accuracy: 0.6526823, Time: 08_05_2022__17:00:52\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 0.9916449, Training accuracy: 0.6532732, Time: 08_05_2022__17:01:03\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 0.9902428, Training accuracy: 0.6536990, Time: 08_05_2022__17:01:14\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 0.9901175, Training accuracy: 0.6535859, Time: 08_05_2022__17:01:25\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 0.9899788, Training accuracy: 0.6538000, Time: 08_05_2022__17:01:36\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 0.9905373, Training accuracy: 0.6535891, Time: 08_05_2022__17:01:47\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 0.9898458, Training accuracy: 0.6539461, Time: 08_05_2022__17:01:59\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 0.9884880, Training accuracy: 0.6545146, Time: 08_05_2022__17:02:10\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 0.9866534, Training accuracy: 0.6553365, Time: 08_05_2022__17:02:21\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 0.9858885, Training accuracy: 0.6556429, Time: 08_05_2022__17:02:32\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 0.9860759, Training accuracy: 0.6557547, Time: 08_05_2022__17:02:43\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 0.9846539, Training accuracy: 0.6563785, Time: 08_05_2022__17:02:54\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 0.9834348, Training accuracy: 0.6570139, Time: 08_05_2022__17:03:05\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 0.9831532, Training accuracy: 0.6572018, Time: 08_05_2022__17:03:16\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 0.9827651, Training accuracy: 0.6571818, Time: 08_05_2022__17:03:27\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 0.9812192, Training accuracy: 0.6575901, Time: 08_05_2022__17:03:38\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 0.9809204, Training accuracy: 0.6575670, Time: 08_05_2022__17:03:49\n","Epoch 3 of 5, Average training loss: 0.9809962, Average training accuracy: 0.6575556, Time: 08_05_2022__17:03:55\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fa40b034bb1472ba1ee4fd634760db8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.8633002, Validation accuracy: 0.7100000, Time: 08_05_2022__17:03:58 | Loss decreased from 1.0090519 to 0.8692046 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.8438868, Validation accuracy: 0.6975000, Time: 08_05_2022__17:04:04 | Loss decreased from 0.8692046 to 0.8448095 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.8578647, Validation accuracy: 0.6925000, Time: 08_05_2022__17:04:10\n","Step: 400 of 1250, Validation loss: 0.8417573, Validation accuracy: 0.7000000, Time: 08_05_2022__17:04:14 | Loss decreased from 0.8448095 to 0.8417378 .... Saving the model\n","Step: 500 of 1250, Validation loss: 0.8439303, Validation accuracy: 0.6965000, Time: 08_05_2022__17:04:20\n","Step: 600 of 1250, Validation loss: 0.8316620, Validation accuracy: 0.7016667, Time: 08_05_2022__17:04:23 | Loss decreased from 0.8417378 to 0.8321830 .... Saving the model\n","Step: 700 of 1250, Validation loss: 0.8274828, Validation accuracy: 0.7042857, Time: 08_05_2022__17:04:30 | Loss decreased from 0.8321830 to 0.8259631 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.8144961, Validation accuracy: 0.7068750, Time: 08_05_2022__17:04:36 | Loss decreased from 0.8259631 to 0.8146075 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.8215739, Validation accuracy: 0.7038889, Time: 08_05_2022__17:04:42\n","Step: 1000 of 1250, Validation loss: 0.8187011, Validation accuracy: 0.7052500, Time: 08_05_2022__17:04:46\n","Step: 1100 of 1250, Validation loss: 0.8164590, Validation accuracy: 0.7056818, Time: 08_05_2022__17:04:49\n","Step: 1200 of 1250, Validation loss: 0.8259575, Validation accuracy: 0.7008333, Time: 08_05_2022__17:04:53\n","Average validation loss: 0.8266584, Average validation accuracy: 0.7016000, Time: 08_05_2022__17:04:55\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90ddd3e20e0843f2b8af6087f9edbf6d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 0.7522481, Training accuracy: 0.7400000, Time: 08_05_2022__17:05:06\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 0.8087222, Training accuracy: 0.7150000, Time: 08_05_2022__17:05:17\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 0.8168877, Training accuracy: 0.7116667, Time: 08_05_2022__17:05:28\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 0.7956378, Training accuracy: 0.7137500, Time: 08_05_2022__17:05:39\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 0.8160712, Training accuracy: 0.7115000, Time: 08_05_2022__17:05:51\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 0.8295401, Training accuracy: 0.7062500, Time: 08_05_2022__17:06:02\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 0.8381303, Training accuracy: 0.7075000, Time: 08_05_2022__17:06:13\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 0.8435708, Training accuracy: 0.7046875, Time: 08_05_2022__17:06:24\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 0.8514053, Training accuracy: 0.7005556, Time: 08_05_2022__17:06:35\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 0.8459403, Training accuracy: 0.7030000, Time: 08_05_2022__17:06:46\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 0.8463517, Training accuracy: 0.7050000, Time: 08_05_2022__17:06:57\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 0.8535820, Training accuracy: 0.7020833, Time: 08_05_2022__17:07:08\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 0.8576527, Training accuracy: 0.7000000, Time: 08_05_2022__17:07:19\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 0.8576403, Training accuracy: 0.7016071, Time: 08_05_2022__17:07:30\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 0.8615609, Training accuracy: 0.7001667, Time: 08_05_2022__17:07:41\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 0.8616419, Training accuracy: 0.7004687, Time: 08_05_2022__17:07:52\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 0.8683985, Training accuracy: 0.6976471, Time: 08_05_2022__17:08:03\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 0.8699543, Training accuracy: 0.6962500, Time: 08_05_2022__17:08:14\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 0.8662640, Training accuracy: 0.6960526, Time: 08_05_2022__17:08:25\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 0.8657232, Training accuracy: 0.6955000, Time: 08_05_2022__17:08:36\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 0.8630984, Training accuracy: 0.6976190, Time: 08_05_2022__17:08:47\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 0.8624949, Training accuracy: 0.6977273, Time: 08_05_2022__17:08:58\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 0.8614624, Training accuracy: 0.6981522, Time: 08_05_2022__17:09:09\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 0.8596959, Training accuracy: 0.6993750, Time: 08_05_2022__17:09:20\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 0.8590105, Training accuracy: 0.6998000, Time: 08_05_2022__17:09:31\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 0.8582570, Training accuracy: 0.6992308, Time: 08_05_2022__17:09:42\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 0.8559930, Training accuracy: 0.7003704, Time: 08_05_2022__17:09:54\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 0.8570009, Training accuracy: 0.6994643, Time: 08_05_2022__17:10:05\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 0.8553241, Training accuracy: 0.7000862, Time: 08_05_2022__17:10:16\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 0.8552150, Training accuracy: 0.7000833, Time: 08_05_2022__17:10:27\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 0.8523137, Training accuracy: 0.7017742, Time: 08_05_2022__17:10:38\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 0.8494349, Training accuracy: 0.7018750, Time: 08_05_2022__17:10:49\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 0.8529149, Training accuracy: 0.7004545, Time: 08_05_2022__17:11:00\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 0.8508498, Training accuracy: 0.7014706, Time: 08_05_2022__17:11:11\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 0.8504942, Training accuracy: 0.7020000, Time: 08_05_2022__17:11:22\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 0.8503272, Training accuracy: 0.7024306, Time: 08_05_2022__17:11:33\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 0.8493996, Training accuracy: 0.7022297, Time: 08_05_2022__17:11:44\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 0.8479224, Training accuracy: 0.7027632, Time: 08_05_2022__17:11:55\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 0.8467730, Training accuracy: 0.7029487, Time: 08_05_2022__17:12:06\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 0.8450482, Training accuracy: 0.7035625, Time: 08_05_2022__17:12:17\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 0.8467080, Training accuracy: 0.7035976, Time: 08_05_2022__17:12:28\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 0.8437308, Training accuracy: 0.7042857, Time: 08_05_2022__17:12:39\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 0.8426207, Training accuracy: 0.7047093, Time: 08_05_2022__17:12:50\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 0.8405451, Training accuracy: 0.7054545, Time: 08_05_2022__17:13:01\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 0.8400191, Training accuracy: 0.7060556, Time: 08_05_2022__17:13:12\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 0.8402933, Training accuracy: 0.7062500, Time: 08_05_2022__17:13:23\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 0.8396560, Training accuracy: 0.7069149, Time: 08_05_2022__17:13:34\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 0.8392480, Training accuracy: 0.7069271, Time: 08_05_2022__17:13:46\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 0.8393135, Training accuracy: 0.7065816, Time: 08_05_2022__17:13:57\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 0.8405075, Training accuracy: 0.7066500, Time: 08_05_2022__17:14:08\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 0.8410551, Training accuracy: 0.7067157, Time: 08_05_2022__17:14:19\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 0.8409405, Training accuracy: 0.7064904, Time: 08_05_2022__17:14:30\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 0.8408717, Training accuracy: 0.7061792, Time: 08_05_2022__17:14:41\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 0.8416257, Training accuracy: 0.7062500, Time: 08_05_2022__17:14:52\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 0.8426014, Training accuracy: 0.7060000, Time: 08_05_2022__17:15:03\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 0.8425671, Training accuracy: 0.7059821, Time: 08_05_2022__17:15:14\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 0.8417443, Training accuracy: 0.7062719, Time: 08_05_2022__17:15:25\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 0.8419112, Training accuracy: 0.7061207, Time: 08_05_2022__17:15:36\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 0.8421504, Training accuracy: 0.7058898, Time: 08_05_2022__17:15:47\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 0.8433627, Training accuracy: 0.7057083, Time: 08_05_2022__17:15:58\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 0.8437293, Training accuracy: 0.7056967, Time: 08_05_2022__17:16:09\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 0.8429894, Training accuracy: 0.7058871, Time: 08_05_2022__17:16:20\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 0.8428694, Training accuracy: 0.7056349, Time: 08_05_2022__17:16:31\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 0.8420608, Training accuracy: 0.7060937, Time: 08_05_2022__17:16:42\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 0.8417949, Training accuracy: 0.7064231, Time: 08_05_2022__17:16:53\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 0.8406711, Training accuracy: 0.7069318, Time: 08_05_2022__17:17:04\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 0.8389414, Training accuracy: 0.7075373, Time: 08_05_2022__17:17:15\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 0.8383078, Training accuracy: 0.7076838, Time: 08_05_2022__17:17:26\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 0.8378607, Training accuracy: 0.7080072, Time: 08_05_2022__17:17:38\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 0.8366184, Training accuracy: 0.7086429, Time: 08_05_2022__17:17:49\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 0.8370584, Training accuracy: 0.7084859, Time: 08_05_2022__17:18:00\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 0.8358323, Training accuracy: 0.7087847, Time: 08_05_2022__17:18:11\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 0.8350042, Training accuracy: 0.7089384, Time: 08_05_2022__17:18:22\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 0.8338539, Training accuracy: 0.7094257, Time: 08_05_2022__17:18:33\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 0.8328762, Training accuracy: 0.7096667, Time: 08_05_2022__17:18:44\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 0.8318765, Training accuracy: 0.7099013, Time: 08_05_2022__17:18:55\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 0.8314057, Training accuracy: 0.7100649, Time: 08_05_2022__17:19:06\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 0.8313216, Training accuracy: 0.7102885, Time: 08_05_2022__17:19:17\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 0.8294080, Training accuracy: 0.7110759, Time: 08_05_2022__17:19:28\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 0.8281343, Training accuracy: 0.7113125, Time: 08_05_2022__17:19:39\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 0.8288590, Training accuracy: 0.7111420, Time: 08_05_2022__17:19:50\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 0.8284627, Training accuracy: 0.7114024, Time: 08_05_2022__17:20:01\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 0.8277301, Training accuracy: 0.7120482, Time: 08_05_2022__17:20:12\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 0.8282957, Training accuracy: 0.7121131, Time: 08_05_2022__17:20:23\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 0.8283612, Training accuracy: 0.7120588, Time: 08_05_2022__17:20:34\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 0.8273584, Training accuracy: 0.7126453, Time: 08_05_2022__17:20:45\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 0.8271570, Training accuracy: 0.7125575, Time: 08_05_2022__17:20:57\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 0.8264129, Training accuracy: 0.7129261, Time: 08_05_2022__17:21:08\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 0.8251507, Training accuracy: 0.7132584, Time: 08_05_2022__17:21:19\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 0.8249673, Training accuracy: 0.7131389, Time: 08_05_2022__17:21:30\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 0.8248370, Training accuracy: 0.7128846, Time: 08_05_2022__17:21:41\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 0.8243821, Training accuracy: 0.7127989, Time: 08_05_2022__17:21:52\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 0.8242380, Training accuracy: 0.7127151, Time: 08_05_2022__17:22:03\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 0.8242211, Training accuracy: 0.7127660, Time: 08_05_2022__17:22:14\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 0.8247332, Training accuracy: 0.7128158, Time: 08_05_2022__17:22:25\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 0.8237335, Training accuracy: 0.7132031, Time: 08_05_2022__17:22:36\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 0.8221767, Training accuracy: 0.7136598, Time: 08_05_2022__17:22:47\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 0.8207652, Training accuracy: 0.7141582, Time: 08_05_2022__17:22:58\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 0.8199774, Training accuracy: 0.7143939, Time: 08_05_2022__17:23:09\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 0.8196527, Training accuracy: 0.7146250, Time: 08_05_2022__17:23:20\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 0.8197260, Training accuracy: 0.7143317, Time: 08_05_2022__17:23:31\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 0.8188950, Training accuracy: 0.7145343, Time: 08_05_2022__17:23:42\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 0.8182653, Training accuracy: 0.7149272, Time: 08_05_2022__17:23:53\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 0.8165162, Training accuracy: 0.7153365, Time: 08_05_2022__17:24:04\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 0.8163298, Training accuracy: 0.7155000, Time: 08_05_2022__17:24:16\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 0.8167853, Training accuracy: 0.7153774, Time: 08_05_2022__17:24:27\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 0.8162485, Training accuracy: 0.7157944, Time: 08_05_2022__17:24:38\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 0.8160323, Training accuracy: 0.7159722, Time: 08_05_2022__17:24:49\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 0.8162851, Training accuracy: 0.7158028, Time: 08_05_2022__17:25:00\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 0.8164974, Training accuracy: 0.7157273, Time: 08_05_2022__17:25:11\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 0.8156651, Training accuracy: 0.7162387, Time: 08_05_2022__17:25:22\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 0.8151635, Training accuracy: 0.7164286, Time: 08_05_2022__17:25:33\n","Epoch 4 of 5, Average training loss: 0.8150501, Average training accuracy: 0.7165778, Time: 08_05_2022__17:25:38\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a584744a84541a4b153f5aa421a3c42"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.7457417, Validation accuracy: 0.7475000, Time: 08_05_2022__17:25:42 | Loss decreased from 0.8146075 to 0.7513246 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.7393226, Validation accuracy: 0.7475000, Time: 08_05_2022__17:25:48 | Loss decreased from 0.7513246 to 0.7386554 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.7695364, Validation accuracy: 0.7333333, Time: 08_05_2022__17:25:54\n","Step: 400 of 1250, Validation loss: 0.7475721, Validation accuracy: 0.7418750, Time: 08_05_2022__17:25:57\n","Step: 500 of 1250, Validation loss: 0.7501392, Validation accuracy: 0.7445000, Time: 08_05_2022__17:26:01\n","Step: 600 of 1250, Validation loss: 0.7393394, Validation accuracy: 0.7504167, Time: 08_05_2022__17:26:05\n","Step: 700 of 1250, Validation loss: 0.7305382, Validation accuracy: 0.7528571, Time: 08_05_2022__17:26:09 | Loss decreased from 0.7386554 to 0.7293209 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.7179751, Validation accuracy: 0.7537500, Time: 08_05_2022__17:26:15 | Loss decreased from 0.7293209 to 0.7178151 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.7220637, Validation accuracy: 0.7533333, Time: 08_05_2022__17:26:21\n","Step: 1000 of 1250, Validation loss: 0.7245316, Validation accuracy: 0.7507500, Time: 08_05_2022__17:26:24\n","Step: 1100 of 1250, Validation loss: 0.7294298, Validation accuracy: 0.7500000, Time: 08_05_2022__17:26:28\n","Step: 1200 of 1250, Validation loss: 0.7374122, Validation accuracy: 0.7464583, Time: 08_05_2022__17:26:32\n","Average validation loss: 0.7380581, Average validation accuracy: 0.7458000, Time: 08_05_2022__17:26:34\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5efde3f24754c249486b25e0a90cf43"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 0.6136989, Training accuracy: 0.7800000, Time: 08_05_2022__17:26:45\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 0.6549760, Training accuracy: 0.7762500, Time: 08_05_2022__17:26:56\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 0.6756159, Training accuracy: 0.7683333, Time: 08_05_2022__17:27:07\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 0.6516126, Training accuracy: 0.7806250, Time: 08_05_2022__17:27:18\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 0.6698139, Training accuracy: 0.7695000, Time: 08_05_2022__17:27:29\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 0.6925475, Training accuracy: 0.7612500, Time: 08_05_2022__17:27:40\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 0.7053985, Training accuracy: 0.7564286, Time: 08_05_2022__17:27:51\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 0.7063474, Training accuracy: 0.7540625, Time: 08_05_2022__17:28:02\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 0.7160738, Training accuracy: 0.7500000, Time: 08_05_2022__17:28:13\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 0.7105926, Training accuracy: 0.7525000, Time: 08_05_2022__17:28:24\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 0.7162443, Training accuracy: 0.7506818, Time: 08_05_2022__17:28:36\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 0.7198351, Training accuracy: 0.7481250, Time: 08_05_2022__17:28:47\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 0.7243721, Training accuracy: 0.7473077, Time: 08_05_2022__17:28:58\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 0.7281742, Training accuracy: 0.7480357, Time: 08_05_2022__17:29:09\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 0.7343062, Training accuracy: 0.7451667, Time: 08_05_2022__17:29:20\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 0.7332993, Training accuracy: 0.7450000, Time: 08_05_2022__17:29:31\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 0.7375460, Training accuracy: 0.7439706, Time: 08_05_2022__17:29:42\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 0.7373601, Training accuracy: 0.7434722, Time: 08_05_2022__17:29:53\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 0.7358780, Training accuracy: 0.7439474, Time: 08_05_2022__17:30:04\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 0.7388856, Training accuracy: 0.7425000, Time: 08_05_2022__17:30:15\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 0.7367878, Training accuracy: 0.7438095, Time: 08_05_2022__17:30:26\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 0.7368656, Training accuracy: 0.7442045, Time: 08_05_2022__17:30:37\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 0.7340787, Training accuracy: 0.7460870, Time: 08_05_2022__17:30:48\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 0.7296788, Training accuracy: 0.7472917, Time: 08_05_2022__17:30:59\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 0.7278799, Training accuracy: 0.7485000, Time: 08_05_2022__17:31:10\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 0.7276073, Training accuracy: 0.7480769, Time: 08_05_2022__17:31:22\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 0.7276315, Training accuracy: 0.7475926, Time: 08_05_2022__17:31:33\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 0.7284298, Training accuracy: 0.7476786, Time: 08_05_2022__17:31:44\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 0.7271839, Training accuracy: 0.7482759, Time: 08_05_2022__17:31:55\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 0.7265329, Training accuracy: 0.7479167, Time: 08_05_2022__17:32:06\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 0.7241337, Training accuracy: 0.7495968, Time: 08_05_2022__17:32:17\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 0.7231127, Training accuracy: 0.7498438, Time: 08_05_2022__17:32:28\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 0.7245846, Training accuracy: 0.7495455, Time: 08_05_2022__17:32:39\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 0.7242842, Training accuracy: 0.7496324, Time: 08_05_2022__17:32:50\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 0.7239666, Training accuracy: 0.7495714, Time: 08_05_2022__17:33:01\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 0.7241571, Training accuracy: 0.7494444, Time: 08_05_2022__17:33:12\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 0.7239774, Training accuracy: 0.7499324, Time: 08_05_2022__17:33:23\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 0.7219604, Training accuracy: 0.7500658, Time: 08_05_2022__17:33:34\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 0.7221063, Training accuracy: 0.7496795, Time: 08_05_2022__17:33:45\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 0.7191608, Training accuracy: 0.7505625, Time: 08_05_2022__17:33:56\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 0.7201200, Training accuracy: 0.7506098, Time: 08_05_2022__17:34:07\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 0.7189648, Training accuracy: 0.7509524, Time: 08_05_2022__17:34:19\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 0.7176273, Training accuracy: 0.7514535, Time: 08_05_2022__17:34:30\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 0.7162103, Training accuracy: 0.7520455, Time: 08_05_2022__17:34:41\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 0.7156398, Training accuracy: 0.7523333, Time: 08_05_2022__17:34:52\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 0.7166900, Training accuracy: 0.7521739, Time: 08_05_2022__17:35:03\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 0.7155780, Training accuracy: 0.7527128, Time: 08_05_2022__17:35:14\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 0.7164933, Training accuracy: 0.7523958, Time: 08_05_2022__17:35:25\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 0.7154868, Training accuracy: 0.7528571, Time: 08_05_2022__17:35:36\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 0.7158850, Training accuracy: 0.7531000, Time: 08_05_2022__17:35:47\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 0.7160172, Training accuracy: 0.7532353, Time: 08_05_2022__17:35:58\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 0.7168799, Training accuracy: 0.7529327, Time: 08_05_2022__17:36:09\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 0.7176537, Training accuracy: 0.7525472, Time: 08_05_2022__17:36:20\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 0.7166345, Training accuracy: 0.7525926, Time: 08_05_2022__17:36:31\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 0.7173759, Training accuracy: 0.7524091, Time: 08_05_2022__17:36:42\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 0.7165387, Training accuracy: 0.7522768, Time: 08_05_2022__17:36:53\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 0.7152491, Training accuracy: 0.7525439, Time: 08_05_2022__17:37:04\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 0.7155531, Training accuracy: 0.7524138, Time: 08_05_2022__17:37:16\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 0.7164231, Training accuracy: 0.7524153, Time: 08_05_2022__17:37:27\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 0.7178155, Training accuracy: 0.7519167, Time: 08_05_2022__17:37:38\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 0.7182715, Training accuracy: 0.7518852, Time: 08_05_2022__17:37:49\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 0.7172716, Training accuracy: 0.7522177, Time: 08_05_2022__17:38:00\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 0.7175281, Training accuracy: 0.7519048, Time: 08_05_2022__17:38:11\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 0.7173175, Training accuracy: 0.7519922, Time: 08_05_2022__17:38:22\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 0.7163059, Training accuracy: 0.7526538, Time: 08_05_2022__17:38:33\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 0.7151876, Training accuracy: 0.7527273, Time: 08_05_2022__17:38:44\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 0.7145791, Training accuracy: 0.7529851, Time: 08_05_2022__17:38:55\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 0.7140419, Training accuracy: 0.7533088, Time: 08_05_2022__17:39:06\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 0.7125943, Training accuracy: 0.7536957, Time: 08_05_2022__17:39:17\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 0.7114012, Training accuracy: 0.7537857, Time: 08_05_2022__17:39:28\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 0.7121410, Training accuracy: 0.7533099, Time: 08_05_2022__17:39:39\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 0.7113763, Training accuracy: 0.7537153, Time: 08_05_2022__17:39:50\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 0.7100898, Training accuracy: 0.7538014, Time: 08_05_2022__17:40:01\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 0.7097083, Training accuracy: 0.7540203, Time: 08_05_2022__17:40:12\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 0.7091270, Training accuracy: 0.7539667, Time: 08_05_2022__17:40:23\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 0.7079993, Training accuracy: 0.7542763, Time: 08_05_2022__17:40:34\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 0.7079373, Training accuracy: 0.7542532, Time: 08_05_2022__17:40:46\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 0.7073646, Training accuracy: 0.7544231, Time: 08_05_2022__17:40:57\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 0.7058565, Training accuracy: 0.7552532, Time: 08_05_2022__17:41:08\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 0.7051947, Training accuracy: 0.7552500, Time: 08_05_2022__17:41:19\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 0.7060564, Training accuracy: 0.7548765, Time: 08_05_2022__17:41:30\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 0.7058950, Training accuracy: 0.7550000, Time: 08_05_2022__17:41:41\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 0.7052376, Training accuracy: 0.7550904, Time: 08_05_2022__17:41:52\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 0.7062255, Training accuracy: 0.7548810, Time: 08_05_2022__17:42:03\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 0.7061963, Training accuracy: 0.7549412, Time: 08_05_2022__17:42:14\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 0.7060080, Training accuracy: 0.7552616, Time: 08_05_2022__17:42:25\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 0.7062700, Training accuracy: 0.7552011, Time: 08_05_2022__17:42:36\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 0.7049614, Training accuracy: 0.7556818, Time: 08_05_2022__17:42:47\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 0.7044650, Training accuracy: 0.7558708, Time: 08_05_2022__17:42:58\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 0.7037971, Training accuracy: 0.7562778, Time: 08_05_2022__17:43:09\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 0.7038548, Training accuracy: 0.7563187, Time: 08_05_2022__17:43:20\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 0.7031461, Training accuracy: 0.7563315, Time: 08_05_2022__17:43:31\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 0.7032949, Training accuracy: 0.7562634, Time: 08_05_2022__17:43:42\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 0.7029684, Training accuracy: 0.7561968, Time: 08_05_2022__17:43:54\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 0.7035843, Training accuracy: 0.7557895, Time: 08_05_2022__17:44:05\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 0.7027480, Training accuracy: 0.7561198, Time: 08_05_2022__17:44:16\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 0.7012070, Training accuracy: 0.7565722, Time: 08_05_2022__17:44:27\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 0.7004424, Training accuracy: 0.7569388, Time: 08_05_2022__17:44:38\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 0.7008387, Training accuracy: 0.7569192, Time: 08_05_2022__17:44:49\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 0.7007392, Training accuracy: 0.7571250, Time: 08_05_2022__17:45:00\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 0.7007201, Training accuracy: 0.7569059, Time: 08_05_2022__17:45:11\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 0.7000371, Training accuracy: 0.7569853, Time: 08_05_2022__17:45:22\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 0.6990724, Training accuracy: 0.7574515, Time: 08_05_2022__17:45:33\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 0.6977501, Training accuracy: 0.7578606, Time: 08_05_2022__17:45:44\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 0.6967444, Training accuracy: 0.7582857, Time: 08_05_2022__17:45:55\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 0.6974522, Training accuracy: 0.7581368, Time: 08_05_2022__17:46:06\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 0.6969163, Training accuracy: 0.7582710, Time: 08_05_2022__17:46:17\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 0.6965151, Training accuracy: 0.7585417, Time: 08_05_2022__17:46:28\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 0.6973441, Training accuracy: 0.7583028, Time: 08_05_2022__17:46:39\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 0.6978474, Training accuracy: 0.7581818, Time: 08_05_2022__17:46:50\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 0.6968690, Training accuracy: 0.7584685, Time: 08_05_2022__17:47:01\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 0.6963931, Training accuracy: 0.7585268, Time: 08_05_2022__17:47:13\n","Epoch 5 of 5, Average training loss: 0.6964087, Average training accuracy: 0.7584667, Time: 08_05_2022__17:47:18\n","###################### Validating vgg19_batch_norm SGD, lr_0.001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36e9b8debc144e80abba333d094ed5d4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.7309337, Validation accuracy: 0.7450000, Time: 08_05_2022__17:47:22\n","Step: 200 of 1250, Validation loss: 0.7039069, Validation accuracy: 0.7512500, Time: 08_05_2022__17:47:25 | Loss decreased from 0.7178151 to 0.7039128 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.7241604, Validation accuracy: 0.7508333, Time: 08_05_2022__17:47:31\n","Step: 400 of 1250, Validation loss: 0.7005365, Validation accuracy: 0.7593750, Time: 08_05_2022__17:47:35 | Loss decreased from 0.7039128 to 0.7008334 .... Saving the model\n","Step: 500 of 1250, Validation loss: 0.6982520, Validation accuracy: 0.7585000, Time: 08_05_2022__17:47:41 | Loss decreased from 0.7008334 to 0.6968820 .... Saving the model\n","Step: 600 of 1250, Validation loss: 0.6854970, Validation accuracy: 0.7629167, Time: 08_05_2022__17:47:46 | Loss decreased from 0.6968820 to 0.6863536 .... Saving the model\n","Step: 700 of 1250, Validation loss: 0.6766227, Validation accuracy: 0.7657143, Time: 08_05_2022__17:47:52 | Loss decreased from 0.6863536 to 0.6762735 .... Saving the model\n","Step: 800 of 1250, Validation loss: 0.6615756, Validation accuracy: 0.7700000, Time: 08_05_2022__17:47:58 | Loss decreased from 0.6762735 to 0.6616930 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.6599705, Validation accuracy: 0.7716667, Time: 08_05_2022__17:48:04 | Loss decreased from 0.6616930 to 0.6600729 .... Saving the model\n","Step: 1000 of 1250, Validation loss: 0.6569169, Validation accuracy: 0.7722500, Time: 08_05_2022__17:48:10 | Loss decreased from 0.6600729 to 0.6571033 .... Saving the model\n","Step: 1100 of 1250, Validation loss: 0.6573371, Validation accuracy: 0.7704545, Time: 08_05_2022__17:48:16\n","Step: 1200 of 1250, Validation loss: 0.6644214, Validation accuracy: 0.7677083, Time: 08_05_2022__17:48:20\n","Average validation loss: 0.6632106, Average validation accuracy: 0.7684000, Time: 08_05_2022__17:48:22\n","###################### Testing vgg19_batch_norm SGD, lr_0.001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a13cfc4d134c4bd780b3b4a7f1b33631"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.8075000, Time: 08_05_2022__17:48:34\n","Step: 200 of 2500, Test accuracy: 0.7925000, Time: 08_05_2022__17:48:38\n","Step: 300 of 2500, Test accuracy: 0.7916667, Time: 08_05_2022__17:48:41\n","Step: 400 of 2500, Test accuracy: 0.7837500, Time: 08_05_2022__17:48:45\n","Step: 500 of 2500, Test accuracy: 0.7770000, Time: 08_05_2022__17:48:49\n","Step: 600 of 2500, Test accuracy: 0.7716667, Time: 08_05_2022__17:48:52\n","Step: 700 of 2500, Test accuracy: 0.7660714, Time: 08_05_2022__17:48:56\n","Step: 800 of 2500, Test accuracy: 0.7681250, Time: 08_05_2022__17:49:00\n","Step: 900 of 2500, Test accuracy: 0.7644444, Time: 08_05_2022__17:49:03\n","Step: 1000 of 2500, Test accuracy: 0.7630000, Time: 08_05_2022__17:49:07\n","Step: 1100 of 2500, Test accuracy: 0.7665909, Time: 08_05_2022__17:49:11\n","Step: 1200 of 2500, Test accuracy: 0.7683333, Time: 08_05_2022__17:49:14\n","Step: 1300 of 2500, Test accuracy: 0.7709615, Time: 08_05_2022__17:49:18\n","Step: 1400 of 2500, Test accuracy: 0.7707143, Time: 08_05_2022__17:49:21\n","Step: 1500 of 2500, Test accuracy: 0.7695000, Time: 08_05_2022__17:49:25\n","Step: 1600 of 2500, Test accuracy: 0.7690625, Time: 08_05_2022__17:49:29\n","Step: 1700 of 2500, Test accuracy: 0.7685294, Time: 08_05_2022__17:49:32\n","Step: 1800 of 2500, Test accuracy: 0.7680556, Time: 08_05_2022__17:49:36\n","Step: 1900 of 2500, Test accuracy: 0.7681579, Time: 08_05_2022__17:49:40\n","Step: 2000 of 2500, Test accuracy: 0.7678750, Time: 08_05_2022__17:49:43\n","Step: 2100 of 2500, Test accuracy: 0.7672619, Time: 08_05_2022__17:49:47\n","Step: 2200 of 2500, Test accuracy: 0.7654545, Time: 08_05_2022__17:49:51\n","Step: 2300 of 2500, Test accuracy: 0.7677174, Time: 08_05_2022__17:49:54\n","Step: 2400 of 2500, Test accuracy: 0.7684375, Time: 08_05_2022__17:49:58\n","Step: 2500 of 2500, Test accuracy: 0.7686000, Time: 08_05_2022__17:50:01\n","Average testing accuracy: 0.7686000, Time: 08_05_2022__17:50:01\n","###################### Training vgg19_batch_norm SGD, lr_0.0001, momentum_0 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b214598214e49ac90e52ecfc824a528"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 2.5086761, Training accuracy: 0.0900000, Time: 08_05_2022__17:50:14\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 2.4745761, Training accuracy: 0.1062500, Time: 08_05_2022__17:50:25\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 2.4567622, Training accuracy: 0.1050000, Time: 08_05_2022__17:50:35\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 2.4529472, Training accuracy: 0.1050000, Time: 08_05_2022__17:50:46\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 2.4516159, Training accuracy: 0.1050000, Time: 08_05_2022__17:50:56\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 2.4511682, Training accuracy: 0.1016667, Time: 08_05_2022__17:51:07\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.4434831, Training accuracy: 0.1014286, Time: 08_05_2022__17:51:17\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.4415696, Training accuracy: 0.1021875, Time: 08_05_2022__17:51:28\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.4419399, Training accuracy: 0.0997222, Time: 08_05_2022__17:51:39\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.4398949, Training accuracy: 0.0982500, Time: 08_05_2022__17:51:49\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.4338084, Training accuracy: 0.1013636, Time: 08_05_2022__17:52:00\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.4254946, Training accuracy: 0.1050000, Time: 08_05_2022__17:52:10\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.4212268, Training accuracy: 0.1075000, Time: 08_05_2022__17:52:21\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.4127522, Training accuracy: 0.1094643, Time: 08_05_2022__17:52:31\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.4111609, Training accuracy: 0.1103333, Time: 08_05_2022__17:52:42\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.4066122, Training accuracy: 0.1123438, Time: 08_05_2022__17:52:52\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.4039890, Training accuracy: 0.1126471, Time: 08_05_2022__17:53:03\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.4015473, Training accuracy: 0.1131944, Time: 08_05_2022__17:53:13\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.3963126, Training accuracy: 0.1160526, Time: 08_05_2022__17:53:24\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.3912243, Training accuracy: 0.1177500, Time: 08_05_2022__17:53:35\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.3867715, Training accuracy: 0.1184524, Time: 08_05_2022__17:53:45\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.3838324, Training accuracy: 0.1193182, Time: 08_05_2022__17:53:56\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.3813903, Training accuracy: 0.1202174, Time: 08_05_2022__17:54:06\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.3783031, Training accuracy: 0.1214583, Time: 08_05_2022__17:54:17\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.3750340, Training accuracy: 0.1221000, Time: 08_05_2022__17:54:27\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.3702122, Training accuracy: 0.1233654, Time: 08_05_2022__17:54:38\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.3679968, Training accuracy: 0.1238889, Time: 08_05_2022__17:54:48\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.3657216, Training accuracy: 0.1241964, Time: 08_05_2022__17:54:59\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.3614155, Training accuracy: 0.1251724, Time: 08_05_2022__17:55:09\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.3583468, Training accuracy: 0.1262500, Time: 08_05_2022__17:55:20\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.3555226, Training accuracy: 0.1282258, Time: 08_05_2022__17:55:31\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.3525102, Training accuracy: 0.1282813, Time: 08_05_2022__17:55:41\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.3518267, Training accuracy: 0.1278788, Time: 08_05_2022__17:55:52\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.3495304, Training accuracy: 0.1280882, Time: 08_05_2022__17:56:02\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.3470775, Training accuracy: 0.1292143, Time: 08_05_2022__17:56:13\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.3453903, Training accuracy: 0.1302778, Time: 08_05_2022__17:56:23\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.3437078, Training accuracy: 0.1307432, Time: 08_05_2022__17:56:34\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.3406150, Training accuracy: 0.1316447, Time: 08_05_2022__17:56:44\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.3384187, Training accuracy: 0.1330128, Time: 08_05_2022__17:56:55\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.3362444, Training accuracy: 0.1331875, Time: 08_05_2022__17:57:05\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.3330372, Training accuracy: 0.1345122, Time: 08_05_2022__17:57:16\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.3308356, Training accuracy: 0.1352976, Time: 08_05_2022__17:57:27\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.3280474, Training accuracy: 0.1368023, Time: 08_05_2022__17:57:37\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.3253956, Training accuracy: 0.1369886, Time: 08_05_2022__17:57:48\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.3219422, Training accuracy: 0.1381111, Time: 08_05_2022__17:57:58\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.3195263, Training accuracy: 0.1389674, Time: 08_05_2022__17:58:09\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.3168560, Training accuracy: 0.1401064, Time: 08_05_2022__17:58:19\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 2.3155383, Training accuracy: 0.1409375, Time: 08_05_2022__17:58:30\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 2.3132500, Training accuracy: 0.1423469, Time: 08_05_2022__17:58:40\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 2.3105844, Training accuracy: 0.1431000, Time: 08_05_2022__17:58:51\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 2.3079863, Training accuracy: 0.1442647, Time: 08_05_2022__17:59:01\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 2.3054959, Training accuracy: 0.1450962, Time: 08_05_2022__17:59:12\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 2.3036168, Training accuracy: 0.1460849, Time: 08_05_2022__17:59:22\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 2.3016510, Training accuracy: 0.1466204, Time: 08_05_2022__17:59:33\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 2.2992149, Training accuracy: 0.1472273, Time: 08_05_2022__17:59:44\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 2.2973566, Training accuracy: 0.1481696, Time: 08_05_2022__17:59:54\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 2.2950944, Training accuracy: 0.1491228, Time: 08_05_2022__18:00:05\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 2.2927385, Training accuracy: 0.1500862, Time: 08_05_2022__18:00:15\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 2.2900972, Training accuracy: 0.1513136, Time: 08_05_2022__18:00:26\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 2.2879194, Training accuracy: 0.1520417, Time: 08_05_2022__18:00:36\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 2.2865925, Training accuracy: 0.1524180, Time: 08_05_2022__18:00:47\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 2.2843113, Training accuracy: 0.1528629, Time: 08_05_2022__18:00:57\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 2.2821933, Training accuracy: 0.1541667, Time: 08_05_2022__18:01:08\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 2.2809259, Training accuracy: 0.1542969, Time: 08_05_2022__18:01:18\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 2.2770697, Training accuracy: 0.1558846, Time: 08_05_2022__18:01:29\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 2.2749311, Training accuracy: 0.1567045, Time: 08_05_2022__18:01:40\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 2.2728306, Training accuracy: 0.1579478, Time: 08_05_2022__18:01:50\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 2.2707850, Training accuracy: 0.1586765, Time: 08_05_2022__18:02:01\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 2.2691808, Training accuracy: 0.1590580, Time: 08_05_2022__18:02:11\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 2.2667945, Training accuracy: 0.1598929, Time: 08_05_2022__18:02:22\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 2.2649978, Training accuracy: 0.1604225, Time: 08_05_2022__18:02:32\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 2.2627310, Training accuracy: 0.1614236, Time: 08_05_2022__18:02:43\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 2.2603952, Training accuracy: 0.1623288, Time: 08_05_2022__18:02:53\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 2.2589715, Training accuracy: 0.1631081, Time: 08_05_2022__18:03:04\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 2.2574897, Training accuracy: 0.1638000, Time: 08_05_2022__18:03:14\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 2.2559369, Training accuracy: 0.1644079, Time: 08_05_2022__18:03:25\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 2.2541785, Training accuracy: 0.1650649, Time: 08_05_2022__18:03:36\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 2.2522964, Training accuracy: 0.1655449, Time: 08_05_2022__18:03:46\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 2.2506090, Training accuracy: 0.1667405, Time: 08_05_2022__18:03:57\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 2.2492063, Training accuracy: 0.1671875, Time: 08_05_2022__18:04:07\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 2.2467542, Training accuracy: 0.1684259, Time: 08_05_2022__18:04:18\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 2.2445405, Training accuracy: 0.1691463, Time: 08_05_2022__18:04:28\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 2.2423122, Training accuracy: 0.1701807, Time: 08_05_2022__18:04:39\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 2.2403935, Training accuracy: 0.1707738, Time: 08_05_2022__18:04:49\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 2.2385399, Training accuracy: 0.1716176, Time: 08_05_2022__18:05:00\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 2.2370704, Training accuracy: 0.1720930, Time: 08_05_2022__18:05:10\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 2.2353812, Training accuracy: 0.1725862, Time: 08_05_2022__18:05:21\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 2.2332619, Training accuracy: 0.1734091, Time: 08_05_2022__18:05:32\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 2.2314123, Training accuracy: 0.1740449, Time: 08_05_2022__18:05:42\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 2.2297857, Training accuracy: 0.1742500, Time: 08_05_2022__18:05:53\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 2.2280961, Training accuracy: 0.1748077, Time: 08_05_2022__18:06:03\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 2.2257654, Training accuracy: 0.1755978, Time: 08_05_2022__18:06:14\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 2.2240236, Training accuracy: 0.1769086, Time: 08_05_2022__18:06:24\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 2.2227421, Training accuracy: 0.1775000, Time: 08_05_2022__18:06:35\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 2.2217265, Training accuracy: 0.1783684, Time: 08_05_2022__18:06:45\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 2.2201408, Training accuracy: 0.1791667, Time: 08_05_2022__18:06:56\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 2.2177365, Training accuracy: 0.1801546, Time: 08_05_2022__18:07:06\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 2.2161002, Training accuracy: 0.1804847, Time: 08_05_2022__18:07:17\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 2.2144288, Training accuracy: 0.1811364, Time: 08_05_2022__18:07:28\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 2.2134834, Training accuracy: 0.1815250, Time: 08_05_2022__18:07:38\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 2.2123434, Training accuracy: 0.1819554, Time: 08_05_2022__18:07:49\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 2.2100806, Training accuracy: 0.1827206, Time: 08_05_2022__18:07:59\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 2.2083164, Training accuracy: 0.1835922, Time: 08_05_2022__18:08:10\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 2.2060705, Training accuracy: 0.1847596, Time: 08_05_2022__18:08:20\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 2.2049742, Training accuracy: 0.1852381, Time: 08_05_2022__18:08:31\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 2.2032357, Training accuracy: 0.1860377, Time: 08_05_2022__18:08:41\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 2.2018135, Training accuracy: 0.1864486, Time: 08_05_2022__18:08:52\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 2.2003855, Training accuracy: 0.1869444, Time: 08_05_2022__18:09:02\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 2.1986246, Training accuracy: 0.1875459, Time: 08_05_2022__18:09:13\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 2.1974847, Training accuracy: 0.1880227, Time: 08_05_2022__18:09:23\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 2.1955562, Training accuracy: 0.1888514, Time: 08_05_2022__18:09:34\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 2.1938421, Training accuracy: 0.1892857, Time: 08_05_2022__18:09:45\n","Epoch 1 of 5, Average training loss: 2.1932958, Average training accuracy: 0.1893333, Time: 08_05_2022__18:09:50\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c105bda548349148637fd6ba4670e66"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.9519768, Validation accuracy: 0.3075000, Time: 08_05_2022__18:09:54 | Loss decreased from inf to 1.9536504 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.9333054, Validation accuracy: 0.3162500, Time: 08_05_2022__18:09:59 | Loss decreased from 1.9536504 to 1.9339117 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.9331244, Validation accuracy: 0.3050000, Time: 08_05_2022__18:10:05 | Loss decreased from 1.9339117 to 1.9323384 .... Saving the model\n","Step: 400 of 1250, Validation loss: 1.9414602, Validation accuracy: 0.3043750, Time: 08_05_2022__18:10:11\n","Step: 500 of 1250, Validation loss: 1.9500185, Validation accuracy: 0.3085000, Time: 08_05_2022__18:10:15\n","Step: 600 of 1250, Validation loss: 1.9420176, Validation accuracy: 0.3125000, Time: 08_05_2022__18:10:19\n","Step: 700 of 1250, Validation loss: 1.9354311, Validation accuracy: 0.3178571, Time: 08_05_2022__18:10:23\n","Step: 800 of 1250, Validation loss: 1.9278892, Validation accuracy: 0.3190625, Time: 08_05_2022__18:10:26 | Loss decreased from 1.9323384 to 1.9283724 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.9284349, Validation accuracy: 0.3163889, Time: 08_05_2022__18:10:32\n","Step: 1000 of 1250, Validation loss: 1.9281714, Validation accuracy: 0.3170000, Time: 08_05_2022__18:10:36 | Loss decreased from 1.9283724 to 1.9280875 .... Saving the model\n","Step: 1100 of 1250, Validation loss: 1.9361188, Validation accuracy: 0.3152273, Time: 08_05_2022__18:10:42\n","Step: 1200 of 1250, Validation loss: 1.9385972, Validation accuracy: 0.3177083, Time: 08_05_2022__18:10:45\n","Average validation loss: 1.9382154, Average validation accuracy: 0.3168000, Time: 08_05_2022__18:10:47\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afc67279b76a4db1bbe60e11931382bc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.9529125, Training accuracy: 0.2975000, Time: 08_05_2022__18:10:58\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.9966798, Training accuracy: 0.2650000, Time: 08_05_2022__18:11:09\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 2.0073732, Training accuracy: 0.2533333, Time: 08_05_2022__18:11:19\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 2.0047552, Training accuracy: 0.2575000, Time: 08_05_2022__18:11:30\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 2.0017974, Training accuracy: 0.2590000, Time: 08_05_2022__18:11:41\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 2.0026003, Training accuracy: 0.2520833, Time: 08_05_2022__18:11:51\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 2.0063656, Training accuracy: 0.2503571, Time: 08_05_2022__18:12:02\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 2.0048453, Training accuracy: 0.2509375, Time: 08_05_2022__18:12:13\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 2.0093928, Training accuracy: 0.2513889, Time: 08_05_2022__18:12:23\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 2.0126858, Training accuracy: 0.2525000, Time: 08_05_2022__18:12:34\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 2.0119979, Training accuracy: 0.2547727, Time: 08_05_2022__18:12:45\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 2.0087500, Training accuracy: 0.2558333, Time: 08_05_2022__18:12:55\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 2.0054848, Training accuracy: 0.2573077, Time: 08_05_2022__18:13:06\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 2.0008674, Training accuracy: 0.2580357, Time: 08_05_2022__18:13:17\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 2.0003164, Training accuracy: 0.2580000, Time: 08_05_2022__18:13:27\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.9979768, Training accuracy: 0.2626562, Time: 08_05_2022__18:13:38\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.9950892, Training accuracy: 0.2651471, Time: 08_05_2022__18:13:49\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.9940579, Training accuracy: 0.2669444, Time: 08_05_2022__18:13:59\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.9905485, Training accuracy: 0.2684211, Time: 08_05_2022__18:14:10\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.9908853, Training accuracy: 0.2678750, Time: 08_05_2022__18:14:21\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.9865853, Training accuracy: 0.2698810, Time: 08_05_2022__18:14:31\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.9864703, Training accuracy: 0.2703409, Time: 08_05_2022__18:14:42\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.9848961, Training accuracy: 0.2709783, Time: 08_05_2022__18:14:53\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.9846494, Training accuracy: 0.2720833, Time: 08_05_2022__18:15:03\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.9806113, Training accuracy: 0.2737000, Time: 08_05_2022__18:15:14\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.9789545, Training accuracy: 0.2752885, Time: 08_05_2022__18:15:25\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.9783192, Training accuracy: 0.2757407, Time: 08_05_2022__18:15:35\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.9777475, Training accuracy: 0.2764286, Time: 08_05_2022__18:15:46\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.9760901, Training accuracy: 0.2759483, Time: 08_05_2022__18:15:57\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.9739368, Training accuracy: 0.2772500, Time: 08_05_2022__18:16:07\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.9706858, Training accuracy: 0.2787903, Time: 08_05_2022__18:16:18\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.9679810, Training accuracy: 0.2796875, Time: 08_05_2022__18:16:29\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.9693249, Training accuracy: 0.2793182, Time: 08_05_2022__18:16:39\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.9688777, Training accuracy: 0.2800000, Time: 08_05_2022__18:16:50\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.9677219, Training accuracy: 0.2806429, Time: 08_05_2022__18:17:00\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.9667849, Training accuracy: 0.2813194, Time: 08_05_2022__18:17:11\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.9658590, Training accuracy: 0.2819595, Time: 08_05_2022__18:17:22\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.9644828, Training accuracy: 0.2823026, Time: 08_05_2022__18:17:32\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.9645208, Training accuracy: 0.2823718, Time: 08_05_2022__18:17:43\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.9626634, Training accuracy: 0.2833125, Time: 08_05_2022__18:17:54\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.9624445, Training accuracy: 0.2829878, Time: 08_05_2022__18:18:04\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.9608444, Training accuracy: 0.2837500, Time: 08_05_2022__18:18:15\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.9602852, Training accuracy: 0.2848837, Time: 08_05_2022__18:18:26\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.9576635, Training accuracy: 0.2856250, Time: 08_05_2022__18:18:36\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.9553150, Training accuracy: 0.2862222, Time: 08_05_2022__18:18:47\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.9543345, Training accuracy: 0.2867935, Time: 08_05_2022__18:18:58\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.9533215, Training accuracy: 0.2870745, Time: 08_05_2022__18:19:08\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.9530256, Training accuracy: 0.2869271, Time: 08_05_2022__18:19:19\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.9531641, Training accuracy: 0.2871429, Time: 08_05_2022__18:19:30\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.9542245, Training accuracy: 0.2868000, Time: 08_05_2022__18:19:40\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.9516782, Training accuracy: 0.2877451, Time: 08_05_2022__18:19:51\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.9521920, Training accuracy: 0.2880288, Time: 08_05_2022__18:20:02\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.9515056, Training accuracy: 0.2884906, Time: 08_05_2022__18:20:12\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.9499253, Training accuracy: 0.2891667, Time: 08_05_2022__18:20:23\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.9477443, Training accuracy: 0.2902273, Time: 08_05_2022__18:20:34\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.9468306, Training accuracy: 0.2903571, Time: 08_05_2022__18:20:44\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.9462706, Training accuracy: 0.2904825, Time: 08_05_2022__18:20:55\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.9457482, Training accuracy: 0.2902155, Time: 08_05_2022__18:21:06\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.9451929, Training accuracy: 0.2908898, Time: 08_05_2022__18:21:16\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.9440545, Training accuracy: 0.2915833, Time: 08_05_2022__18:21:27\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.9439669, Training accuracy: 0.2914344, Time: 08_05_2022__18:21:38\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.9420342, Training accuracy: 0.2922984, Time: 08_05_2022__18:21:48\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.9411232, Training accuracy: 0.2918651, Time: 08_05_2022__18:21:59\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.9406849, Training accuracy: 0.2916016, Time: 08_05_2022__18:22:10\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.9383510, Training accuracy: 0.2926154, Time: 08_05_2022__18:22:20\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.9383397, Training accuracy: 0.2929924, Time: 08_05_2022__18:22:31\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.9381536, Training accuracy: 0.2928358, Time: 08_05_2022__18:22:41\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.9368491, Training accuracy: 0.2933456, Time: 08_05_2022__18:22:52\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.9354614, Training accuracy: 0.2935870, Time: 08_05_2022__18:23:03\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.9346377, Training accuracy: 0.2938214, Time: 08_05_2022__18:23:13\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.9338882, Training accuracy: 0.2939437, Time: 08_05_2022__18:23:24\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.9326611, Training accuracy: 0.2948611, Time: 08_05_2022__18:23:35\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.9318067, Training accuracy: 0.2945548, Time: 08_05_2022__18:23:45\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.9321345, Training accuracy: 0.2947297, Time: 08_05_2022__18:23:56\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.9320330, Training accuracy: 0.2948667, Time: 08_05_2022__18:24:07\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.9318900, Training accuracy: 0.2951645, Time: 08_05_2022__18:24:17\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.9311682, Training accuracy: 0.2959416, Time: 08_05_2022__18:24:28\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.9294840, Training accuracy: 0.2965385, Time: 08_05_2022__18:24:39\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.9281621, Training accuracy: 0.2967089, Time: 08_05_2022__18:24:49\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.9274723, Training accuracy: 0.2970313, Time: 08_05_2022__18:25:00\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.9263715, Training accuracy: 0.2970988, Time: 08_05_2022__18:25:11\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.9259220, Training accuracy: 0.2972866, Time: 08_05_2022__18:25:21\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.9251373, Training accuracy: 0.2975000, Time: 08_05_2022__18:25:32\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.9245139, Training accuracy: 0.2972917, Time: 08_05_2022__18:25:42\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.9234000, Training accuracy: 0.2976765, Time: 08_05_2022__18:25:53\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.9218743, Training accuracy: 0.2981105, Time: 08_05_2022__18:26:04\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.9205140, Training accuracy: 0.2983621, Time: 08_05_2022__18:26:14\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.9188389, Training accuracy: 0.2989489, Time: 08_05_2022__18:26:25\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.9175176, Training accuracy: 0.2991854, Time: 08_05_2022__18:26:35\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.9165460, Training accuracy: 0.2992500, Time: 08_05_2022__18:26:46\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.9154660, Training accuracy: 0.2996154, Time: 08_05_2022__18:26:56\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.9140999, Training accuracy: 0.3002717, Time: 08_05_2022__18:27:07\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.9126785, Training accuracy: 0.3005645, Time: 08_05_2022__18:27:18\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.9116132, Training accuracy: 0.3013830, Time: 08_05_2022__18:27:28\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.9115338, Training accuracy: 0.3016842, Time: 08_05_2022__18:27:39\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.9099967, Training accuracy: 0.3023438, Time: 08_05_2022__18:27:49\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.9084303, Training accuracy: 0.3029639, Time: 08_05_2022__18:28:00\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.9067472, Training accuracy: 0.3033929, Time: 08_05_2022__18:28:11\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.9058763, Training accuracy: 0.3037374, Time: 08_05_2022__18:28:21\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.9056433, Training accuracy: 0.3038500, Time: 08_05_2022__18:28:32\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.9054509, Training accuracy: 0.3039851, Time: 08_05_2022__18:28:42\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.9042204, Training accuracy: 0.3043137, Time: 08_05_2022__18:28:53\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.9036388, Training accuracy: 0.3046602, Time: 08_05_2022__18:29:03\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.9025498, Training accuracy: 0.3053365, Time: 08_05_2022__18:29:14\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.9021173, Training accuracy: 0.3055238, Time: 08_05_2022__18:29:25\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.9012464, Training accuracy: 0.3061085, Time: 08_05_2022__18:29:35\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.9010785, Training accuracy: 0.3058879, Time: 08_05_2022__18:29:46\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.8999584, Training accuracy: 0.3062269, Time: 08_05_2022__18:29:57\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.8992706, Training accuracy: 0.3061697, Time: 08_05_2022__18:30:07\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.8992454, Training accuracy: 0.3059773, Time: 08_05_2022__18:30:18\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.8982238, Training accuracy: 0.3062838, Time: 08_05_2022__18:30:28\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.8972806, Training accuracy: 0.3063839, Time: 08_05_2022__18:30:39\n","Epoch 2 of 5, Average training loss: 1.8969939, Average training accuracy: 0.3063333, Time: 08_05_2022__18:30:44\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bf6598f9879411f9fa72e339b88ee5f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.6518296, Validation accuracy: 0.4550000, Time: 08_05_2022__18:30:48 | Loss decreased from 1.9280875 to 1.6532951 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.6599685, Validation accuracy: 0.4400000, Time: 08_05_2022__18:30:54\n","Step: 300 of 1250, Validation loss: 1.6766895, Validation accuracy: 0.4183333, Time: 08_05_2022__18:30:58\n","Step: 400 of 1250, Validation loss: 1.6883147, Validation accuracy: 0.4131250, Time: 08_05_2022__18:31:01\n","Step: 500 of 1250, Validation loss: 1.6989068, Validation accuracy: 0.4065000, Time: 08_05_2022__18:31:05\n","Step: 600 of 1250, Validation loss: 1.6911986, Validation accuracy: 0.4062500, Time: 08_05_2022__18:31:09\n","Step: 700 of 1250, Validation loss: 1.6833846, Validation accuracy: 0.4092857, Time: 08_05_2022__18:31:13\n","Step: 800 of 1250, Validation loss: 1.6789245, Validation accuracy: 0.4087500, Time: 08_05_2022__18:31:16\n","Step: 900 of 1250, Validation loss: 1.6776739, Validation accuracy: 0.4069444, Time: 08_05_2022__18:31:20\n","Step: 1000 of 1250, Validation loss: 1.6803110, Validation accuracy: 0.4035000, Time: 08_05_2022__18:31:24\n","Step: 1100 of 1250, Validation loss: 1.6861636, Validation accuracy: 0.3997727, Time: 08_05_2022__18:31:27\n","Step: 1200 of 1250, Validation loss: 1.6866272, Validation accuracy: 0.3991667, Time: 08_05_2022__18:31:31\n","Average validation loss: 1.6859857, Average validation accuracy: 0.3992000, Time: 08_05_2022__18:31:33\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53ea92ba074c4af8aea1b4fbf779c99b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.6922980, Training accuracy: 0.4025000, Time: 08_05_2022__18:31:44\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.7366864, Training accuracy: 0.3687500, Time: 08_05_2022__18:31:54\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.7718615, Training accuracy: 0.3558333, Time: 08_05_2022__18:32:05\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.7814909, Training accuracy: 0.3525000, Time: 08_05_2022__18:32:15\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.7777168, Training accuracy: 0.3480000, Time: 08_05_2022__18:32:26\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.7750421, Training accuracy: 0.3504167, Time: 08_05_2022__18:32:36\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.7797606, Training accuracy: 0.3489286, Time: 08_05_2022__18:32:47\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.7851312, Training accuracy: 0.3456250, Time: 08_05_2022__18:32:58\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.7846041, Training accuracy: 0.3475000, Time: 08_05_2022__18:33:08\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.7896346, Training accuracy: 0.3440000, Time: 08_05_2022__18:33:19\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.7873499, Training accuracy: 0.3470455, Time: 08_05_2022__18:33:29\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.7880813, Training accuracy: 0.3470833, Time: 08_05_2022__18:33:40\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.7831641, Training accuracy: 0.3473077, Time: 08_05_2022__18:33:51\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.7816422, Training accuracy: 0.3482143, Time: 08_05_2022__18:34:01\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.7849147, Training accuracy: 0.3455000, Time: 08_05_2022__18:34:12\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.7901606, Training accuracy: 0.3459375, Time: 08_05_2022__18:34:22\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.7893380, Training accuracy: 0.3454412, Time: 08_05_2022__18:34:33\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.7879618, Training accuracy: 0.3462500, Time: 08_05_2022__18:34:44\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.7875464, Training accuracy: 0.3450000, Time: 08_05_2022__18:34:54\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.7882253, Training accuracy: 0.3446250, Time: 08_05_2022__18:35:05\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.7860798, Training accuracy: 0.3455952, Time: 08_05_2022__18:35:15\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.7860600, Training accuracy: 0.3451136, Time: 08_05_2022__18:35:26\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.7840493, Training accuracy: 0.3455435, Time: 08_05_2022__18:35:37\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.7819073, Training accuracy: 0.3470833, Time: 08_05_2022__18:35:47\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.7776509, Training accuracy: 0.3484000, Time: 08_05_2022__18:35:58\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.7752093, Training accuracy: 0.3490385, Time: 08_05_2022__18:36:08\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.7735831, Training accuracy: 0.3496296, Time: 08_05_2022__18:36:19\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.7738072, Training accuracy: 0.3498214, Time: 08_05_2022__18:36:30\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.7748410, Training accuracy: 0.3495690, Time: 08_05_2022__18:36:40\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.7744391, Training accuracy: 0.3499167, Time: 08_05_2022__18:36:51\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.7718410, Training accuracy: 0.3507258, Time: 08_05_2022__18:37:01\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.7695575, Training accuracy: 0.3515625, Time: 08_05_2022__18:37:12\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.7712420, Training accuracy: 0.3515152, Time: 08_05_2022__18:37:22\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.7711567, Training accuracy: 0.3515441, Time: 08_05_2022__18:37:33\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.7702211, Training accuracy: 0.3515714, Time: 08_05_2022__18:37:44\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.7717378, Training accuracy: 0.3507639, Time: 08_05_2022__18:37:54\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.7729057, Training accuracy: 0.3497297, Time: 08_05_2022__18:38:05\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.7721160, Training accuracy: 0.3501974, Time: 08_05_2022__18:38:15\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.7720897, Training accuracy: 0.3505769, Time: 08_05_2022__18:38:26\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.7713411, Training accuracy: 0.3513125, Time: 08_05_2022__18:38:36\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.7721952, Training accuracy: 0.3508537, Time: 08_05_2022__18:38:47\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.7704794, Training accuracy: 0.3520238, Time: 08_05_2022__18:38:58\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.7698231, Training accuracy: 0.3515698, Time: 08_05_2022__18:39:08\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.7680514, Training accuracy: 0.3513068, Time: 08_05_2022__18:39:19\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.7659741, Training accuracy: 0.3522778, Time: 08_05_2022__18:39:29\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.7655151, Training accuracy: 0.3525543, Time: 08_05_2022__18:39:40\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.7655668, Training accuracy: 0.3526064, Time: 08_05_2022__18:39:51\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.7656259, Training accuracy: 0.3526042, Time: 08_05_2022__18:40:01\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.7660636, Training accuracy: 0.3527551, Time: 08_05_2022__18:40:12\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.7668052, Training accuracy: 0.3524500, Time: 08_05_2022__18:40:22\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.7651780, Training accuracy: 0.3530392, Time: 08_05_2022__18:40:33\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.7658468, Training accuracy: 0.3535577, Time: 08_05_2022__18:40:43\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.7653119, Training accuracy: 0.3540094, Time: 08_05_2022__18:40:54\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.7645987, Training accuracy: 0.3541667, Time: 08_05_2022__18:41:05\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.7631979, Training accuracy: 0.3545909, Time: 08_05_2022__18:41:15\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.7622034, Training accuracy: 0.3546429, Time: 08_05_2022__18:41:26\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.7619279, Training accuracy: 0.3548684, Time: 08_05_2022__18:41:36\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.7614481, Training accuracy: 0.3553448, Time: 08_05_2022__18:41:47\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.7614922, Training accuracy: 0.3561017, Time: 08_05_2022__18:41:58\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.7605943, Training accuracy: 0.3564167, Time: 08_05_2022__18:42:08\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.7604084, Training accuracy: 0.3563934, Time: 08_05_2022__18:42:19\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.7591861, Training accuracy: 0.3571371, Time: 08_05_2022__18:42:29\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.7588960, Training accuracy: 0.3566667, Time: 08_05_2022__18:42:40\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.7594299, Training accuracy: 0.3563672, Time: 08_05_2022__18:42:51\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.7582384, Training accuracy: 0.3571923, Time: 08_05_2022__18:43:01\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.7585974, Training accuracy: 0.3573485, Time: 08_05_2022__18:43:12\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.7585908, Training accuracy: 0.3571642, Time: 08_05_2022__18:43:22\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.7587632, Training accuracy: 0.3570956, Time: 08_05_2022__18:43:33\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.7577714, Training accuracy: 0.3575725, Time: 08_05_2022__18:43:43\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.7571990, Training accuracy: 0.3580000, Time: 08_05_2022__18:43:54\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.7567902, Training accuracy: 0.3579225, Time: 08_05_2022__18:44:05\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.7562386, Training accuracy: 0.3580903, Time: 08_05_2022__18:44:15\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.7556489, Training accuracy: 0.3580137, Time: 08_05_2022__18:44:26\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.7569035, Training accuracy: 0.3577027, Time: 08_05_2022__18:44:37\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.7569142, Training accuracy: 0.3579667, Time: 08_05_2022__18:44:47\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.7564818, Training accuracy: 0.3580263, Time: 08_05_2022__18:44:58\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.7555844, Training accuracy: 0.3586688, Time: 08_05_2022__18:45:08\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.7543973, Training accuracy: 0.3592308, Time: 08_05_2022__18:45:19\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.7542325, Training accuracy: 0.3593671, Time: 08_05_2022__18:45:29\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.7543178, Training accuracy: 0.3594688, Time: 08_05_2022__18:45:40\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.7538698, Training accuracy: 0.3595062, Time: 08_05_2022__18:45:51\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.7539025, Training accuracy: 0.3593902, Time: 08_05_2022__18:46:01\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.7528854, Training accuracy: 0.3600301, Time: 08_05_2022__18:46:12\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.7526970, Training accuracy: 0.3601190, Time: 08_05_2022__18:46:22\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.7523550, Training accuracy: 0.3603235, Time: 08_05_2022__18:46:33\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.7512366, Training accuracy: 0.3607849, Time: 08_05_2022__18:46:44\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.7509345, Training accuracy: 0.3610345, Time: 08_05_2022__18:46:54\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.7496373, Training accuracy: 0.3615057, Time: 08_05_2022__18:47:05\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 1.7484057, Training accuracy: 0.3617135, Time: 08_05_2022__18:47:15\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 1.7480710, Training accuracy: 0.3619722, Time: 08_05_2022__18:47:26\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 1.7473202, Training accuracy: 0.3623077, Time: 08_05_2022__18:47:37\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 1.7464714, Training accuracy: 0.3629891, Time: 08_05_2022__18:47:47\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 1.7460510, Training accuracy: 0.3631720, Time: 08_05_2022__18:47:58\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 1.7457794, Training accuracy: 0.3634840, Time: 08_05_2022__18:48:08\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 1.7466163, Training accuracy: 0.3631579, Time: 08_05_2022__18:48:19\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 1.7453048, Training accuracy: 0.3639062, Time: 08_05_2022__18:48:30\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 1.7437260, Training accuracy: 0.3648454, Time: 08_05_2022__18:48:40\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 1.7425054, Training accuracy: 0.3651786, Time: 08_05_2022__18:48:51\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 1.7418268, Training accuracy: 0.3653788, Time: 08_05_2022__18:49:01\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 1.7415614, Training accuracy: 0.3654500, Time: 08_05_2022__18:49:12\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 1.7420154, Training accuracy: 0.3655693, Time: 08_05_2022__18:49:23\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 1.7419686, Training accuracy: 0.3654657, Time: 08_05_2022__18:49:33\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 1.7418147, Training accuracy: 0.3657767, Time: 08_05_2022__18:49:44\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 1.7412435, Training accuracy: 0.3659615, Time: 08_05_2022__18:49:54\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 1.7415235, Training accuracy: 0.3659286, Time: 08_05_2022__18:50:05\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 1.7410740, Training accuracy: 0.3661321, Time: 08_05_2022__18:50:15\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 1.7406231, Training accuracy: 0.3660748, Time: 08_05_2022__18:50:26\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 1.7397092, Training accuracy: 0.3667593, Time: 08_05_2022__18:50:37\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 1.7395525, Training accuracy: 0.3667202, Time: 08_05_2022__18:50:47\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 1.7394501, Training accuracy: 0.3669773, Time: 08_05_2022__18:50:58\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 1.7385630, Training accuracy: 0.3672973, Time: 08_05_2022__18:51:08\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 1.7381868, Training accuracy: 0.3672545, Time: 08_05_2022__18:51:19\n","Epoch 3 of 5, Average training loss: 1.7381421, Average training accuracy: 0.3671111, Time: 08_05_2022__18:51:24\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c9e7182f90f44d984fbcf9ecf2ac40e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.5398089, Validation accuracy: 0.4700000, Time: 08_05_2022__18:51:28 | Loss decreased from 1.6532951 to 1.5406820 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.5315529, Validation accuracy: 0.4737500, Time: 08_05_2022__18:51:34 | Loss decreased from 1.5406820 to 1.5339620 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.5473359, Validation accuracy: 0.4475000, Time: 08_05_2022__18:51:40\n","Step: 400 of 1250, Validation loss: 1.5606483, Validation accuracy: 0.4425000, Time: 08_05_2022__18:51:44\n","Step: 500 of 1250, Validation loss: 1.5678168, Validation accuracy: 0.4405000, Time: 08_05_2022__18:51:48\n","Step: 600 of 1250, Validation loss: 1.5591309, Validation accuracy: 0.4441667, Time: 08_05_2022__18:51:51\n","Step: 700 of 1250, Validation loss: 1.5527509, Validation accuracy: 0.4467857, Time: 08_05_2022__18:51:55\n","Step: 800 of 1250, Validation loss: 1.5492897, Validation accuracy: 0.4453125, Time: 08_05_2022__18:51:59\n","Step: 900 of 1250, Validation loss: 1.5481573, Validation accuracy: 0.4444444, Time: 08_05_2022__18:52:03\n","Step: 1000 of 1250, Validation loss: 1.5519552, Validation accuracy: 0.4400000, Time: 08_05_2022__18:52:06\n","Step: 1100 of 1250, Validation loss: 1.5546205, Validation accuracy: 0.4425000, Time: 08_05_2022__18:52:10\n","Step: 1200 of 1250, Validation loss: 1.5544828, Validation accuracy: 0.4414583, Time: 08_05_2022__18:52:14\n","Average validation loss: 1.5523509, Average validation accuracy: 0.4422000, Time: 08_05_2022__18:52:15\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25346fcd747b456f8a82eb3fd9f91f8e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 1.5692591, Training accuracy: 0.4475000, Time: 08_05_2022__18:52:26\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 1.6350843, Training accuracy: 0.4200000, Time: 08_05_2022__18:52:37\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 1.6788946, Training accuracy: 0.3941667, Time: 08_05_2022__18:52:47\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 1.6792689, Training accuracy: 0.3925000, Time: 08_05_2022__18:52:58\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 1.6786332, Training accuracy: 0.3855000, Time: 08_05_2022__18:53:08\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 1.6750749, Training accuracy: 0.3879167, Time: 08_05_2022__18:53:19\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 1.6815990, Training accuracy: 0.3867857, Time: 08_05_2022__18:53:30\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 1.6824816, Training accuracy: 0.3884375, Time: 08_05_2022__18:53:40\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 1.6786591, Training accuracy: 0.3913889, Time: 08_05_2022__18:53:51\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 1.6773701, Training accuracy: 0.3920000, Time: 08_05_2022__18:54:01\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 1.6747513, Training accuracy: 0.3938636, Time: 08_05_2022__18:54:12\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 1.6756236, Training accuracy: 0.3931250, Time: 08_05_2022__18:54:23\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 1.6737075, Training accuracy: 0.3934615, Time: 08_05_2022__18:54:33\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 1.6707598, Training accuracy: 0.3950000, Time: 08_05_2022__18:54:44\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 1.6716834, Training accuracy: 0.3928333, Time: 08_05_2022__18:54:54\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 1.6713645, Training accuracy: 0.3940625, Time: 08_05_2022__18:55:05\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 1.6707611, Training accuracy: 0.3929412, Time: 08_05_2022__18:55:16\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 1.6711548, Training accuracy: 0.3923611, Time: 08_05_2022__18:55:26\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 1.6724613, Training accuracy: 0.3919737, Time: 08_05_2022__18:55:37\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 1.6730330, Training accuracy: 0.3907500, Time: 08_05_2022__18:55:47\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 1.6730910, Training accuracy: 0.3903571, Time: 08_05_2022__18:55:58\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 1.6736674, Training accuracy: 0.3896591, Time: 08_05_2022__18:56:08\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 1.6722918, Training accuracy: 0.3883696, Time: 08_05_2022__18:56:19\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 1.6703051, Training accuracy: 0.3896875, Time: 08_05_2022__18:56:30\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 1.6677412, Training accuracy: 0.3929000, Time: 08_05_2022__18:56:40\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 1.6671703, Training accuracy: 0.3925962, Time: 08_05_2022__18:56:51\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 1.6645895, Training accuracy: 0.3941667, Time: 08_05_2022__18:57:01\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 1.6660499, Training accuracy: 0.3929464, Time: 08_05_2022__18:57:12\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 1.6656827, Training accuracy: 0.3926724, Time: 08_05_2022__18:57:23\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 1.6655057, Training accuracy: 0.3928333, Time: 08_05_2022__18:57:33\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 1.6635345, Training accuracy: 0.3932258, Time: 08_05_2022__18:57:44\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 1.6618636, Training accuracy: 0.3940625, Time: 08_05_2022__18:57:54\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 1.6639974, Training accuracy: 0.3943939, Time: 08_05_2022__18:58:05\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 1.6638554, Training accuracy: 0.3939706, Time: 08_05_2022__18:58:16\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 1.6633411, Training accuracy: 0.3940714, Time: 08_05_2022__18:58:26\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 1.6645535, Training accuracy: 0.3927778, Time: 08_05_2022__18:58:37\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 1.6661214, Training accuracy: 0.3920270, Time: 08_05_2022__18:58:47\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 1.6669330, Training accuracy: 0.3921053, Time: 08_05_2022__18:58:58\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 1.6670311, Training accuracy: 0.3920513, Time: 08_05_2022__18:59:09\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 1.6668727, Training accuracy: 0.3922500, Time: 08_05_2022__18:59:19\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 1.6675330, Training accuracy: 0.3920122, Time: 08_05_2022__18:59:30\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 1.6655574, Training accuracy: 0.3925595, Time: 08_05_2022__18:59:40\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 1.6660084, Training accuracy: 0.3927907, Time: 08_05_2022__18:59:51\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 1.6635410, Training accuracy: 0.3942614, Time: 08_05_2022__19:00:02\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 1.6611204, Training accuracy: 0.3950556, Time: 08_05_2022__19:00:12\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 1.6603780, Training accuracy: 0.3955435, Time: 08_05_2022__19:00:23\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 1.6599669, Training accuracy: 0.3960106, Time: 08_05_2022__19:00:33\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 1.6594546, Training accuracy: 0.3960938, Time: 08_05_2022__19:00:44\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 1.6599963, Training accuracy: 0.3955612, Time: 08_05_2022__19:00:55\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 1.6612600, Training accuracy: 0.3948000, Time: 08_05_2022__19:01:05\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 1.6599770, Training accuracy: 0.3956373, Time: 08_05_2022__19:01:16\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 1.6607145, Training accuracy: 0.3959135, Time: 08_05_2022__19:01:26\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 1.6598498, Training accuracy: 0.3966509, Time: 08_05_2022__19:01:37\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 1.6596062, Training accuracy: 0.3971759, Time: 08_05_2022__19:01:47\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 1.6587543, Training accuracy: 0.3976818, Time: 08_05_2022__19:01:58\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 1.6583593, Training accuracy: 0.3977679, Time: 08_05_2022__19:02:09\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 1.6592344, Training accuracy: 0.3973246, Time: 08_05_2022__19:02:19\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 1.6588585, Training accuracy: 0.3976293, Time: 08_05_2022__19:02:30\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 1.6593947, Training accuracy: 0.3978814, Time: 08_05_2022__19:02:40\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 1.6586961, Training accuracy: 0.3981250, Time: 08_05_2022__19:02:51\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 1.6586316, Training accuracy: 0.3983607, Time: 08_05_2022__19:03:02\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 1.6574930, Training accuracy: 0.3991129, Time: 08_05_2022__19:03:12\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 1.6568718, Training accuracy: 0.3994048, Time: 08_05_2022__19:03:23\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 1.6563763, Training accuracy: 0.3996875, Time: 08_05_2022__19:03:34\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 1.6546898, Training accuracy: 0.4001538, Time: 08_05_2022__19:03:44\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 1.6548037, Training accuracy: 0.4003030, Time: 08_05_2022__19:03:55\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 1.6545119, Training accuracy: 0.4002239, Time: 08_05_2022__19:04:05\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 1.6549888, Training accuracy: 0.3999632, Time: 08_05_2022__19:04:16\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 1.6539113, Training accuracy: 0.4000725, Time: 08_05_2022__19:04:26\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 1.6527103, Training accuracy: 0.4004286, Time: 08_05_2022__19:04:37\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 1.6523561, Training accuracy: 0.4000352, Time: 08_05_2022__19:04:48\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 1.6513085, Training accuracy: 0.4002083, Time: 08_05_2022__19:04:58\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 1.6509534, Training accuracy: 0.4001027, Time: 08_05_2022__19:05:09\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 1.6521774, Training accuracy: 0.3994932, Time: 08_05_2022__19:05:19\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 1.6527556, Training accuracy: 0.3991333, Time: 08_05_2022__19:05:30\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 1.6529146, Training accuracy: 0.3985197, Time: 08_05_2022__19:05:41\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 1.6524456, Training accuracy: 0.3990909, Time: 08_05_2022__19:05:51\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 1.6506743, Training accuracy: 0.4001603, Time: 08_05_2022__19:06:02\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 1.6507622, Training accuracy: 0.3997785, Time: 08_05_2022__19:06:12\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 1.6500373, Training accuracy: 0.3999063, Time: 08_05_2022__19:06:23\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 1.6497219, Training accuracy: 0.4000926, Time: 08_05_2022__19:06:34\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 1.6499363, Training accuracy: 0.3995732, Time: 08_05_2022__19:06:44\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 1.6495720, Training accuracy: 0.3999398, Time: 08_05_2022__19:06:55\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 1.6495904, Training accuracy: 0.3999405, Time: 08_05_2022__19:07:05\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 1.6487525, Training accuracy: 0.4002647, Time: 08_05_2022__19:07:16\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 1.6476467, Training accuracy: 0.4008430, Time: 08_05_2022__19:07:26\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 1.6469467, Training accuracy: 0.4011207, Time: 08_05_2022__19:07:37\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 1.6462083, Training accuracy: 0.4013636, Time: 08_05_2022__19:07:48\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 1.6452796, Training accuracy: 0.4015730, Time: 08_05_2022__19:07:58\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 1.6448361, Training accuracy: 0.4016944, Time: 08_05_2022__19:08:09\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 1.6435701, Training accuracy: 0.4020330, Time: 08_05_2022__19:08:19\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 1.6428924, Training accuracy: 0.4025272, Time: 08_05_2022__19:08:30\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 1.6423922, Training accuracy: 0.4027419, Time: 08_05_2022__19:08:40\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 1.6421636, Training accuracy: 0.4028191, Time: 08_05_2022__19:08:51\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 1.6435706, Training accuracy: 0.4026316, Time: 08_05_2022__19:09:02\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 1.6426728, Training accuracy: 0.4028385, Time: 08_05_2022__19:09:12\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 1.6413534, Training accuracy: 0.4035567, Time: 08_05_2022__19:09:23\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 1.6401799, Training accuracy: 0.4037755, Time: 08_05_2022__19:09:33\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 1.6400475, Training accuracy: 0.4038384, Time: 08_05_2022__19:09:44\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 1.6401721, Training accuracy: 0.4039000, Time: 08_05_2022__19:09:54\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 1.6409404, Training accuracy: 0.4034406, Time: 08_05_2022__19:10:05\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 1.6404468, Training accuracy: 0.4034314, Time: 08_05_2022__19:10:16\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 1.6406797, Training accuracy: 0.4034709, Time: 08_05_2022__19:10:26\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 1.6403131, Training accuracy: 0.4034856, Time: 08_05_2022__19:10:37\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 1.6407094, Training accuracy: 0.4032381, Time: 08_05_2022__19:10:47\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 1.6404612, Training accuracy: 0.4031132, Time: 08_05_2022__19:10:58\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 1.6403329, Training accuracy: 0.4030140, Time: 08_05_2022__19:11:08\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 1.6398133, Training accuracy: 0.4034028, Time: 08_05_2022__19:11:19\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 1.6399204, Training accuracy: 0.4034862, Time: 08_05_2022__19:11:29\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 1.6403974, Training accuracy: 0.4030000, Time: 08_05_2022__19:11:40\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 1.6394496, Training accuracy: 0.4032883, Time: 08_05_2022__19:11:51\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 1.6393860, Training accuracy: 0.4032366, Time: 08_05_2022__19:12:01\n","Epoch 4 of 5, Average training loss: 1.6393843, Average training accuracy: 0.4032222, Time: 08_05_2022__19:12:06\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1339154ab8934984acf669e0d981921e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.4408872, Validation accuracy: 0.4950000, Time: 08_05_2022__19:12:10 | Loss decreased from 1.5339620 to 1.4393289 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.4395747, Validation accuracy: 0.4887500, Time: 08_05_2022__19:12:16\n","Step: 300 of 1250, Validation loss: 1.4546029, Validation accuracy: 0.4683333, Time: 08_05_2022__19:12:20\n","Step: 400 of 1250, Validation loss: 1.4634028, Validation accuracy: 0.4650000, Time: 08_05_2022__19:12:23\n","Step: 500 of 1250, Validation loss: 1.4686699, Validation accuracy: 0.4685000, Time: 08_05_2022__19:12:27\n","Step: 600 of 1250, Validation loss: 1.4714359, Validation accuracy: 0.4700000, Time: 08_05_2022__19:12:31\n","Step: 700 of 1250, Validation loss: 1.4621786, Validation accuracy: 0.4725000, Time: 08_05_2022__19:12:35\n","Step: 800 of 1250, Validation loss: 1.4570318, Validation accuracy: 0.4737500, Time: 08_05_2022__19:12:38\n","Step: 900 of 1250, Validation loss: 1.4589800, Validation accuracy: 0.4705556, Time: 08_05_2022__19:12:42\n","Step: 1000 of 1250, Validation loss: 1.4625122, Validation accuracy: 0.4685000, Time: 08_05_2022__19:12:45\n","Step: 1100 of 1250, Validation loss: 1.4644979, Validation accuracy: 0.4686364, Time: 08_05_2022__19:12:49\n","Step: 1200 of 1250, Validation loss: 1.4653685, Validation accuracy: 0.4685417, Time: 08_05_2022__19:12:53\n","Average validation loss: 1.4642459, Average validation accuracy: 0.4692000, Time: 08_05_2022__19:12:55\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4975a0614104d638f7fc0b3c0897720"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 1.5007875, Training accuracy: 0.4525000, Time: 08_05_2022__19:13:05\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 1.5239040, Training accuracy: 0.4587500, Time: 08_05_2022__19:13:16\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 1.5651583, Training accuracy: 0.4433333, Time: 08_05_2022__19:13:26\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 1.5730178, Training accuracy: 0.4381250, Time: 08_05_2022__19:13:37\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 1.5767824, Training accuracy: 0.4300000, Time: 08_05_2022__19:13:47\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 1.5696624, Training accuracy: 0.4333333, Time: 08_05_2022__19:13:58\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 1.5770316, Training accuracy: 0.4289286, Time: 08_05_2022__19:14:09\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 1.5721591, Training accuracy: 0.4309375, Time: 08_05_2022__19:14:19\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 1.5739544, Training accuracy: 0.4313889, Time: 08_05_2022__19:14:30\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 1.5759936, Training accuracy: 0.4307500, Time: 08_05_2022__19:14:40\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 1.5760153, Training accuracy: 0.4295455, Time: 08_05_2022__19:14:51\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 1.5783606, Training accuracy: 0.4268750, Time: 08_05_2022__19:15:01\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 1.5775521, Training accuracy: 0.4261538, Time: 08_05_2022__19:15:12\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 1.5744734, Training accuracy: 0.4264286, Time: 08_05_2022__19:15:22\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 1.5772468, Training accuracy: 0.4256667, Time: 08_05_2022__19:15:33\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 1.5783071, Training accuracy: 0.4260937, Time: 08_05_2022__19:15:44\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 1.5809202, Training accuracy: 0.4247059, Time: 08_05_2022__19:15:54\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 1.5813974, Training accuracy: 0.4237500, Time: 08_05_2022__19:16:05\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 1.5832910, Training accuracy: 0.4222368, Time: 08_05_2022__19:16:15\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 1.5849135, Training accuracy: 0.4213750, Time: 08_05_2022__19:16:26\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 1.5837894, Training accuracy: 0.4222619, Time: 08_05_2022__19:16:36\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 1.5840675, Training accuracy: 0.4206818, Time: 08_05_2022__19:16:47\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 1.5846085, Training accuracy: 0.4205435, Time: 08_05_2022__19:16:58\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 1.5830996, Training accuracy: 0.4209375, Time: 08_05_2022__19:17:08\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 1.5815989, Training accuracy: 0.4215000, Time: 08_05_2022__19:17:19\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 1.5794356, Training accuracy: 0.4226923, Time: 08_05_2022__19:17:29\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 1.5777277, Training accuracy: 0.4230556, Time: 08_05_2022__19:17:40\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 1.5799688, Training accuracy: 0.4217857, Time: 08_05_2022__19:17:50\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 1.5808622, Training accuracy: 0.4221552, Time: 08_05_2022__19:18:01\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 1.5802857, Training accuracy: 0.4224167, Time: 08_05_2022__19:18:11\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 1.5773812, Training accuracy: 0.4231452, Time: 08_05_2022__19:18:22\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 1.5738203, Training accuracy: 0.4252344, Time: 08_05_2022__19:18:33\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 1.5760913, Training accuracy: 0.4244697, Time: 08_05_2022__19:18:43\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 1.5767166, Training accuracy: 0.4241176, Time: 08_05_2022__19:18:54\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 1.5755787, Training accuracy: 0.4242143, Time: 08_05_2022__19:19:04\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 1.5771385, Training accuracy: 0.4237500, Time: 08_05_2022__19:19:15\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 1.5783516, Training accuracy: 0.4233108, Time: 08_05_2022__19:19:25\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 1.5792972, Training accuracy: 0.4234211, Time: 08_05_2022__19:19:36\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 1.5791633, Training accuracy: 0.4235897, Time: 08_05_2022__19:19:47\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 1.5785464, Training accuracy: 0.4240000, Time: 08_05_2022__19:19:57\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 1.5802451, Training accuracy: 0.4238415, Time: 08_05_2022__19:20:08\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 1.5786033, Training accuracy: 0.4251190, Time: 08_05_2022__19:20:18\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 1.5783992, Training accuracy: 0.4245930, Time: 08_05_2022__19:20:29\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 1.5768107, Training accuracy: 0.4245455, Time: 08_05_2022__19:20:39\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 1.5751443, Training accuracy: 0.4250556, Time: 08_05_2022__19:20:50\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 1.5752074, Training accuracy: 0.4249457, Time: 08_05_2022__19:21:01\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 1.5749907, Training accuracy: 0.4250532, Time: 08_05_2022__19:21:11\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 1.5748872, Training accuracy: 0.4256771, Time: 08_05_2022__19:21:22\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 1.5743847, Training accuracy: 0.4261224, Time: 08_05_2022__19:21:32\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 1.5751023, Training accuracy: 0.4264000, Time: 08_05_2022__19:21:43\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 1.5734054, Training accuracy: 0.4276471, Time: 08_05_2022__19:21:53\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 1.5748421, Training accuracy: 0.4275962, Time: 08_05_2022__19:22:04\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 1.5741821, Training accuracy: 0.4281604, Time: 08_05_2022__19:22:15\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 1.5746607, Training accuracy: 0.4282870, Time: 08_05_2022__19:22:25\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 1.5747671, Training accuracy: 0.4279545, Time: 08_05_2022__19:22:36\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 1.5745439, Training accuracy: 0.4279464, Time: 08_05_2022__19:22:46\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 1.5750776, Training accuracy: 0.4277193, Time: 08_05_2022__19:22:57\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 1.5746249, Training accuracy: 0.4274569, Time: 08_05_2022__19:23:07\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 1.5748038, Training accuracy: 0.4274576, Time: 08_05_2022__19:23:18\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 1.5742117, Training accuracy: 0.4278333, Time: 08_05_2022__19:23:29\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 1.5741593, Training accuracy: 0.4280328, Time: 08_05_2022__19:23:39\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 1.5729063, Training accuracy: 0.4285887, Time: 08_05_2022__19:23:50\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 1.5724895, Training accuracy: 0.4289286, Time: 08_05_2022__19:24:00\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 1.5732558, Training accuracy: 0.4287109, Time: 08_05_2022__19:24:11\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 1.5726093, Training accuracy: 0.4295385, Time: 08_05_2022__19:24:21\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 1.5721088, Training accuracy: 0.4294697, Time: 08_05_2022__19:24:32\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 1.5718015, Training accuracy: 0.4298881, Time: 08_05_2022__19:24:42\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 1.5716692, Training accuracy: 0.4299265, Time: 08_05_2022__19:24:53\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 1.5706742, Training accuracy: 0.4303261, Time: 08_05_2022__19:25:04\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 1.5701825, Training accuracy: 0.4306429, Time: 08_05_2022__19:25:14\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 1.5701891, Training accuracy: 0.4302113, Time: 08_05_2022__19:25:25\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 1.5698681, Training accuracy: 0.4301389, Time: 08_05_2022__19:25:35\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 1.5692164, Training accuracy: 0.4300685, Time: 08_05_2022__19:25:46\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 1.5706920, Training accuracy: 0.4296622, Time: 08_05_2022__19:25:56\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 1.5709080, Training accuracy: 0.4288667, Time: 08_05_2022__19:26:07\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 1.5706780, Training accuracy: 0.4291118, Time: 08_05_2022__19:26:18\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 1.5709170, Training accuracy: 0.4296104, Time: 08_05_2022__19:26:28\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 1.5697268, Training accuracy: 0.4303526, Time: 08_05_2022__19:26:39\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 1.5697953, Training accuracy: 0.4300000, Time: 08_05_2022__19:26:49\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 1.5696264, Training accuracy: 0.4299062, Time: 08_05_2022__19:27:00\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 1.5698901, Training accuracy: 0.4298765, Time: 08_05_2022__19:27:10\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 1.5699941, Training accuracy: 0.4296951, Time: 08_05_2022__19:27:21\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 1.5694659, Training accuracy: 0.4303012, Time: 08_05_2022__19:27:31\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 1.5693701, Training accuracy: 0.4302679, Time: 08_05_2022__19:27:42\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 1.5689891, Training accuracy: 0.4306471, Time: 08_05_2022__19:27:53\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 1.5676614, Training accuracy: 0.4315407, Time: 08_05_2022__19:28:03\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 1.5674584, Training accuracy: 0.4315517, Time: 08_05_2022__19:28:14\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 1.5664924, Training accuracy: 0.4314773, Time: 08_05_2022__19:28:24\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 1.5657318, Training accuracy: 0.4315169, Time: 08_05_2022__19:28:35\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 1.5652473, Training accuracy: 0.4317500, Time: 08_05_2022__19:28:45\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 1.5648219, Training accuracy: 0.4318407, Time: 08_05_2022__19:28:56\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 1.5644472, Training accuracy: 0.4322011, Time: 08_05_2022__19:29:07\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 1.5644013, Training accuracy: 0.4323387, Time: 08_05_2022__19:29:17\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 1.5644394, Training accuracy: 0.4324202, Time: 08_05_2022__19:29:28\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 1.5657739, Training accuracy: 0.4318947, Time: 08_05_2022__19:29:38\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 1.5643969, Training accuracy: 0.4324740, Time: 08_05_2022__19:29:49\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 1.5634381, Training accuracy: 0.4329124, Time: 08_05_2022__19:29:59\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 1.5626396, Training accuracy: 0.4330357, Time: 08_05_2022__19:30:10\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 1.5627752, Training accuracy: 0.4327525, Time: 08_05_2022__19:30:21\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 1.5630077, Training accuracy: 0.4326500, Time: 08_05_2022__19:30:31\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 1.5636117, Training accuracy: 0.4323020, Time: 08_05_2022__19:30:42\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 1.5631214, Training accuracy: 0.4321078, Time: 08_05_2022__19:30:52\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 1.5627814, Training accuracy: 0.4321359, Time: 08_05_2022__19:31:03\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 1.5624431, Training accuracy: 0.4322596, Time: 08_05_2022__19:31:13\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 1.5625396, Training accuracy: 0.4322381, Time: 08_05_2022__19:31:24\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 1.5626500, Training accuracy: 0.4319104, Time: 08_05_2022__19:31:34\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 1.5624714, Training accuracy: 0.4316822, Time: 08_05_2022__19:31:45\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 1.5619306, Training accuracy: 0.4321991, Time: 08_05_2022__19:31:56\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 1.5620660, Training accuracy: 0.4323853, Time: 08_05_2022__19:32:06\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 1.5627574, Training accuracy: 0.4318636, Time: 08_05_2022__19:32:17\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 1.5616019, Training accuracy: 0.4323649, Time: 08_05_2022__19:32:27\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 1.5610574, Training accuracy: 0.4325670, Time: 08_05_2022__19:32:38\n","Epoch 5 of 5, Average training loss: 1.5610129, Average training accuracy: 0.4325778, Time: 08_05_2022__19:32:43\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bb2a8346fed4466b0583cfe5c6dcb35"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.3930789, Validation accuracy: 0.5050000, Time: 08_05_2022__19:32:47 | Loss decreased from 1.4393289 to 1.3938538 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.4034752, Validation accuracy: 0.5112500, Time: 08_05_2022__19:32:53\n","Step: 300 of 1250, Validation loss: 1.4224945, Validation accuracy: 0.4916667, Time: 08_05_2022__19:32:56\n","Step: 400 of 1250, Validation loss: 1.4219800, Validation accuracy: 0.4937500, Time: 08_05_2022__19:33:00\n","Step: 500 of 1250, Validation loss: 1.4251743, Validation accuracy: 0.4950000, Time: 08_05_2022__19:33:04\n","Step: 600 of 1250, Validation loss: 1.4160699, Validation accuracy: 0.4929167, Time: 08_05_2022__19:33:08\n","Step: 700 of 1250, Validation loss: 1.4035639, Validation accuracy: 0.4985714, Time: 08_05_2022__19:33:11\n","Step: 800 of 1250, Validation loss: 1.3995055, Validation accuracy: 0.4956250, Time: 08_05_2022__19:33:15\n","Step: 900 of 1250, Validation loss: 1.4003736, Validation accuracy: 0.4950000, Time: 08_05_2022__19:33:19\n","Step: 1000 of 1250, Validation loss: 1.4068507, Validation accuracy: 0.4912500, Time: 08_05_2022__19:33:22\n","Step: 1100 of 1250, Validation loss: 1.4076147, Validation accuracy: 0.4913636, Time: 08_05_2022__19:33:26\n","Step: 1200 of 1250, Validation loss: 1.4097273, Validation accuracy: 0.4895833, Time: 08_05_2022__19:33:30\n","Average validation loss: 1.4079560, Average validation accuracy: 0.4908000, Time: 08_05_2022__19:33:32\n","###################### Testing vgg19_batch_norm SGD, lr_0.0001, momentum_0 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a082951c66f649fd993527057e09db2e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.4625000, Time: 08_05_2022__19:33:44\n","Step: 200 of 2500, Test accuracy: 0.4762500, Time: 08_05_2022__19:33:47\n","Step: 300 of 2500, Test accuracy: 0.4850000, Time: 08_05_2022__19:33:51\n","Step: 400 of 2500, Test accuracy: 0.4831250, Time: 08_05_2022__19:33:54\n","Step: 500 of 2500, Test accuracy: 0.4840000, Time: 08_05_2022__19:33:58\n","Step: 600 of 2500, Test accuracy: 0.4858333, Time: 08_05_2022__19:34:02\n","Step: 700 of 2500, Test accuracy: 0.4835714, Time: 08_05_2022__19:34:05\n","Step: 800 of 2500, Test accuracy: 0.4859375, Time: 08_05_2022__19:34:09\n","Step: 900 of 2500, Test accuracy: 0.4852778, Time: 08_05_2022__19:34:13\n","Step: 1000 of 2500, Test accuracy: 0.4855000, Time: 08_05_2022__19:34:16\n","Step: 1100 of 2500, Test accuracy: 0.4893182, Time: 08_05_2022__19:34:20\n","Step: 1200 of 2500, Test accuracy: 0.4912500, Time: 08_05_2022__19:34:23\n","Step: 1300 of 2500, Test accuracy: 0.4907692, Time: 08_05_2022__19:34:27\n","Step: 1400 of 2500, Test accuracy: 0.4871429, Time: 08_05_2022__19:34:31\n","Step: 1500 of 2500, Test accuracy: 0.4885000, Time: 08_05_2022__19:34:34\n","Step: 1600 of 2500, Test accuracy: 0.4876563, Time: 08_05_2022__19:34:38\n","Step: 1700 of 2500, Test accuracy: 0.4885294, Time: 08_05_2022__19:34:41\n","Step: 1800 of 2500, Test accuracy: 0.4858333, Time: 08_05_2022__19:34:45\n","Step: 1900 of 2500, Test accuracy: 0.4871053, Time: 08_05_2022__19:34:49\n","Step: 2000 of 2500, Test accuracy: 0.4870000, Time: 08_05_2022__19:34:52\n","Step: 2100 of 2500, Test accuracy: 0.4858333, Time: 08_05_2022__19:34:56\n","Step: 2200 of 2500, Test accuracy: 0.4861364, Time: 08_05_2022__19:35:00\n","Step: 2300 of 2500, Test accuracy: 0.4870652, Time: 08_05_2022__19:35:03\n","Step: 2400 of 2500, Test accuracy: 0.4876042, Time: 08_05_2022__19:35:07\n","Step: 2500 of 2500, Test accuracy: 0.4852000, Time: 08_05_2022__19:35:10\n","Average testing accuracy: 0.4852000, Time: 08_05_2022__19:35:10\n","###################### Training vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d0f7bd0395d448cb0f9cb46d3e02b35"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 2.4758767, Training accuracy: 0.1075000, Time: 08_05_2022__19:35:24\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 2.4655192, Training accuracy: 0.1050000, Time: 08_05_2022__19:35:35\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 2.4580562, Training accuracy: 0.1066667, Time: 08_05_2022__19:35:46\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 2.4498183, Training accuracy: 0.1100000, Time: 08_05_2022__19:35:57\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 2.4453662, Training accuracy: 0.1095000, Time: 08_05_2022__19:36:08\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 2.4452819, Training accuracy: 0.1091667, Time: 08_05_2022__19:36:19\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.4326410, Training accuracy: 0.1089286, Time: 08_05_2022__19:36:30\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.4302717, Training accuracy: 0.1068750, Time: 08_05_2022__19:36:41\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.4260684, Training accuracy: 0.1069444, Time: 08_05_2022__19:36:52\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.4227573, Training accuracy: 0.1070000, Time: 08_05_2022__19:37:03\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.4163586, Training accuracy: 0.1100000, Time: 08_05_2022__19:37:14\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.4074044, Training accuracy: 0.1131250, Time: 08_05_2022__19:37:25\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.4023679, Training accuracy: 0.1148077, Time: 08_05_2022__19:37:37\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.3935791, Training accuracy: 0.1176786, Time: 08_05_2022__19:37:48\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.3919268, Training accuracy: 0.1176667, Time: 08_05_2022__19:37:59\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.3886558, Training accuracy: 0.1189063, Time: 08_05_2022__19:38:10\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.3865551, Training accuracy: 0.1182353, Time: 08_05_2022__19:38:21\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.3820339, Training accuracy: 0.1198611, Time: 08_05_2022__19:38:32\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.3760969, Training accuracy: 0.1225000, Time: 08_05_2022__19:38:43\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.3714573, Training accuracy: 0.1238750, Time: 08_05_2022__19:38:54\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.3658185, Training accuracy: 0.1258333, Time: 08_05_2022__19:39:05\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.3621461, Training accuracy: 0.1268182, Time: 08_05_2022__19:39:16\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.3594752, Training accuracy: 0.1269565, Time: 08_05_2022__19:39:27\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.3562238, Training accuracy: 0.1286458, Time: 08_05_2022__19:39:38\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.3519251, Training accuracy: 0.1297000, Time: 08_05_2022__19:39:49\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.3461735, Training accuracy: 0.1316346, Time: 08_05_2022__19:40:00\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.3446914, Training accuracy: 0.1319444, Time: 08_05_2022__19:40:12\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.3417273, Training accuracy: 0.1316964, Time: 08_05_2022__19:40:23\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.3374740, Training accuracy: 0.1327586, Time: 08_05_2022__19:40:34\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.3341192, Training accuracy: 0.1338333, Time: 08_05_2022__19:40:45\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.3299607, Training accuracy: 0.1355645, Time: 08_05_2022__19:40:56\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.3259879, Training accuracy: 0.1366406, Time: 08_05_2022__19:41:07\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.3242610, Training accuracy: 0.1375000, Time: 08_05_2022__19:41:18\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.3212499, Training accuracy: 0.1386765, Time: 08_05_2022__19:41:29\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.3183466, Training accuracy: 0.1396429, Time: 08_05_2022__19:41:40\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.3162545, Training accuracy: 0.1399306, Time: 08_05_2022__19:41:51\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.3130759, Training accuracy: 0.1412838, Time: 08_05_2022__19:42:02\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.3096691, Training accuracy: 0.1427632, Time: 08_05_2022__19:42:13\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.3064304, Training accuracy: 0.1436538, Time: 08_05_2022__19:42:24\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.3033574, Training accuracy: 0.1448125, Time: 08_05_2022__19:42:36\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.2999981, Training accuracy: 0.1462195, Time: 08_05_2022__19:42:47\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.2970988, Training accuracy: 0.1472024, Time: 08_05_2022__19:42:58\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.2935944, Training accuracy: 0.1494767, Time: 08_05_2022__19:43:09\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.2901405, Training accuracy: 0.1502841, Time: 08_05_2022__19:43:20\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.2862437, Training accuracy: 0.1513889, Time: 08_05_2022__19:43:31\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.2827349, Training accuracy: 0.1529348, Time: 08_05_2022__19:43:42\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.2789857, Training accuracy: 0.1545213, Time: 08_05_2022__19:43:53\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 2.2763252, Training accuracy: 0.1560417, Time: 08_05_2022__19:44:04\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 2.2728987, Training accuracy: 0.1570918, Time: 08_05_2022__19:44:15\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 2.2697134, Training accuracy: 0.1585000, Time: 08_05_2022__19:44:26\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 2.2666428, Training accuracy: 0.1596569, Time: 08_05_2022__19:44:37\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 2.2640762, Training accuracy: 0.1609615, Time: 08_05_2022__19:44:48\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 2.2614493, Training accuracy: 0.1618868, Time: 08_05_2022__19:44:59\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 2.2585055, Training accuracy: 0.1629630, Time: 08_05_2022__19:45:11\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 2.2549557, Training accuracy: 0.1643636, Time: 08_05_2022__19:45:22\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 2.2528954, Training accuracy: 0.1649107, Time: 08_05_2022__19:45:33\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 2.2503757, Training accuracy: 0.1660088, Time: 08_05_2022__19:45:44\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 2.2474462, Training accuracy: 0.1673276, Time: 08_05_2022__19:45:55\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 2.2438357, Training accuracy: 0.1691949, Time: 08_05_2022__19:46:06\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 2.2405930, Training accuracy: 0.1706667, Time: 08_05_2022__19:46:17\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 2.2382772, Training accuracy: 0.1711885, Time: 08_05_2022__19:46:28\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 2.2352839, Training accuracy: 0.1721371, Time: 08_05_2022__19:46:39\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 2.2318793, Training accuracy: 0.1738889, Time: 08_05_2022__19:46:50\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 2.2295325, Training accuracy: 0.1748437, Time: 08_05_2022__19:47:01\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 2.2255134, Training accuracy: 0.1760385, Time: 08_05_2022__19:47:12\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 2.2227764, Training accuracy: 0.1769318, Time: 08_05_2022__19:47:23\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 2.2202643, Training accuracy: 0.1779104, Time: 08_05_2022__19:47:35\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 2.2175318, Training accuracy: 0.1782353, Time: 08_05_2022__19:47:46\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 2.2148510, Training accuracy: 0.1790580, Time: 08_05_2022__19:47:57\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 2.2120203, Training accuracy: 0.1801429, Time: 08_05_2022__19:48:08\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 2.2094764, Training accuracy: 0.1810563, Time: 08_05_2022__19:48:19\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 2.2064300, Training accuracy: 0.1822222, Time: 08_05_2022__19:48:30\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 2.2028766, Training accuracy: 0.1836301, Time: 08_05_2022__19:48:41\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 2.2008217, Training accuracy: 0.1843581, Time: 08_05_2022__19:48:52\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 2.1987054, Training accuracy: 0.1853667, Time: 08_05_2022__19:49:03\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 2.1968384, Training accuracy: 0.1860197, Time: 08_05_2022__19:49:14\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 2.1942660, Training accuracy: 0.1870130, Time: 08_05_2022__19:49:25\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 2.1915222, Training accuracy: 0.1883333, Time: 08_05_2022__19:49:36\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 2.1891361, Training accuracy: 0.1894304, Time: 08_05_2022__19:49:48\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 2.1870287, Training accuracy: 0.1903438, Time: 08_05_2022__19:49:59\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 2.1838218, Training accuracy: 0.1914815, Time: 08_05_2022__19:50:10\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 2.1811006, Training accuracy: 0.1925000, Time: 08_05_2022__19:50:21\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 2.1782812, Training accuracy: 0.1937349, Time: 08_05_2022__19:50:32\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 2.1757065, Training accuracy: 0.1946429, Time: 08_05_2022__19:50:43\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 2.1728626, Training accuracy: 0.1960588, Time: 08_05_2022__19:50:54\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 2.1701656, Training accuracy: 0.1972384, Time: 08_05_2022__19:51:05\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 2.1676782, Training accuracy: 0.1981897, Time: 08_05_2022__19:51:16\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 2.1645312, Training accuracy: 0.1994034, Time: 08_05_2022__19:51:27\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 2.1618836, Training accuracy: 0.2002247, Time: 08_05_2022__19:51:38\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 2.1594652, Training accuracy: 0.2009444, Time: 08_05_2022__19:51:49\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 2.1570812, Training accuracy: 0.2019231, Time: 08_05_2022__19:52:00\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 2.1546943, Training accuracy: 0.2029076, Time: 08_05_2022__19:52:11\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 2.1523319, Training accuracy: 0.2038441, Time: 08_05_2022__19:52:23\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 2.1501230, Training accuracy: 0.2046277, Time: 08_05_2022__19:52:34\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 2.1485290, Training accuracy: 0.2053158, Time: 08_05_2022__19:52:45\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 2.1458151, Training accuracy: 0.2064844, Time: 08_05_2022__19:52:56\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 2.1425452, Training accuracy: 0.2079381, Time: 08_05_2022__19:53:07\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 2.1401018, Training accuracy: 0.2086480, Time: 08_05_2022__19:53:18\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 2.1379467, Training accuracy: 0.2098232, Time: 08_05_2022__19:53:29\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 2.1363341, Training accuracy: 0.2104000, Time: 08_05_2022__19:53:40\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 2.1347012, Training accuracy: 0.2111139, Time: 08_05_2022__19:53:51\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 2.1326298, Training accuracy: 0.2120343, Time: 08_05_2022__19:54:02\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 2.1305198, Training accuracy: 0.2130097, Time: 08_05_2022__19:54:13\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 2.1279414, Training accuracy: 0.2141106, Time: 08_05_2022__19:54:24\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 2.1265859, Training accuracy: 0.2145476, Time: 08_05_2022__19:54:35\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 2.1241895, Training accuracy: 0.2154245, Time: 08_05_2022__19:54:46\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 2.1221031, Training accuracy: 0.2158178, Time: 08_05_2022__19:54:58\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 2.1197130, Training accuracy: 0.2169213, Time: 08_05_2022__19:55:09\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 2.1174931, Training accuracy: 0.2175917, Time: 08_05_2022__19:55:20\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 2.1157484, Training accuracy: 0.2183636, Time: 08_05_2022__19:55:31\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 2.1132789, Training accuracy: 0.2193694, Time: 08_05_2022__19:55:42\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 2.1110575, Training accuracy: 0.2200223, Time: 08_05_2022__19:55:53\n","Epoch 1 of 5, Average training loss: 2.1102555, Average training accuracy: 0.2202222, Time: 08_05_2022__19:55:58\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4a9b66b26b2472ea00a565f53ce6bd5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.7323369, Validation accuracy: 0.3950000, Time: 08_05_2022__19:56:02 | Loss decreased from inf to 1.7346839 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.7389296, Validation accuracy: 0.3875000, Time: 08_05_2022__19:56:08\n","Step: 300 of 1250, Validation loss: 1.7465069, Validation accuracy: 0.3725000, Time: 08_05_2022__19:56:12\n","Step: 400 of 1250, Validation loss: 1.7564510, Validation accuracy: 0.3687500, Time: 08_05_2022__19:56:15\n","Step: 500 of 1250, Validation loss: 1.7617322, Validation accuracy: 0.3685000, Time: 08_05_2022__19:56:19\n","Step: 600 of 1250, Validation loss: 1.7534092, Validation accuracy: 0.3708333, Time: 08_05_2022__19:56:23\n","Step: 700 of 1250, Validation loss: 1.7435595, Validation accuracy: 0.3778571, Time: 08_05_2022__19:56:26\n","Step: 800 of 1250, Validation loss: 1.7364488, Validation accuracy: 0.3796875, Time: 08_05_2022__19:56:30\n","Step: 900 of 1250, Validation loss: 1.7365628, Validation accuracy: 0.3763889, Time: 08_05_2022__19:56:34\n","Step: 1000 of 1250, Validation loss: 1.7371315, Validation accuracy: 0.3762500, Time: 08_05_2022__19:56:37\n","Step: 1100 of 1250, Validation loss: 1.7427372, Validation accuracy: 0.3740909, Time: 08_05_2022__19:56:41\n","Step: 1200 of 1250, Validation loss: 1.7421458, Validation accuracy: 0.3739583, Time: 08_05_2022__19:56:44\n","Average validation loss: 1.7414850, Average validation accuracy: 0.3734000, Time: 08_05_2022__19:56:46\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4c3ad914afd4da28d4e9045403788c6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.7865357, Training accuracy: 0.3800000, Time: 08_05_2022__19:56:58\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.8381396, Training accuracy: 0.3287500, Time: 08_05_2022__19:57:09\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.8597845, Training accuracy: 0.3191667, Time: 08_05_2022__19:57:20\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.8720961, Training accuracy: 0.3150000, Time: 08_05_2022__19:57:31\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.8684487, Training accuracy: 0.3155000, Time: 08_05_2022__19:57:42\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.8663905, Training accuracy: 0.3183333, Time: 08_05_2022__19:57:53\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.8704402, Training accuracy: 0.3121429, Time: 08_05_2022__19:58:04\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.8673549, Training accuracy: 0.3125000, Time: 08_05_2022__19:58:15\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.8710769, Training accuracy: 0.3125000, Time: 08_05_2022__19:58:26\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.8710509, Training accuracy: 0.3122500, Time: 08_05_2022__19:58:37\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.8713286, Training accuracy: 0.3113636, Time: 08_05_2022__19:58:48\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.8712578, Training accuracy: 0.3125000, Time: 08_05_2022__19:58:59\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.8669807, Training accuracy: 0.3144231, Time: 08_05_2022__19:59:11\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.8620464, Training accuracy: 0.3164286, Time: 08_05_2022__19:59:22\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.8614278, Training accuracy: 0.3180000, Time: 08_05_2022__19:59:33\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.8613844, Training accuracy: 0.3173437, Time: 08_05_2022__19:59:44\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.8586828, Training accuracy: 0.3204412, Time: 08_05_2022__19:59:55\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.8562903, Training accuracy: 0.3223611, Time: 08_05_2022__20:00:06\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.8544609, Training accuracy: 0.3234211, Time: 08_05_2022__20:00:17\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.8524607, Training accuracy: 0.3230000, Time: 08_05_2022__20:00:28\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.8474671, Training accuracy: 0.3245238, Time: 08_05_2022__20:00:39\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.8486511, Training accuracy: 0.3248864, Time: 08_05_2022__20:00:50\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.8475129, Training accuracy: 0.3251087, Time: 08_05_2022__20:01:01\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.8468487, Training accuracy: 0.3255208, Time: 08_05_2022__20:01:12\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.8427509, Training accuracy: 0.3265000, Time: 08_05_2022__20:01:24\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.8407833, Training accuracy: 0.3272115, Time: 08_05_2022__20:01:35\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.8388566, Training accuracy: 0.3274074, Time: 08_05_2022__20:01:46\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.8385151, Training accuracy: 0.3269643, Time: 08_05_2022__20:01:57\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.8382587, Training accuracy: 0.3260345, Time: 08_05_2022__20:02:08\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.8378629, Training accuracy: 0.3253333, Time: 08_05_2022__20:02:19\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.8350110, Training accuracy: 0.3258065, Time: 08_05_2022__20:02:30\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.8332418, Training accuracy: 0.3259375, Time: 08_05_2022__20:02:41\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.8346657, Training accuracy: 0.3255303, Time: 08_05_2022__20:02:52\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.8345853, Training accuracy: 0.3252206, Time: 08_05_2022__20:03:03\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.8335927, Training accuracy: 0.3255714, Time: 08_05_2022__20:03:14\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.8330191, Training accuracy: 0.3256250, Time: 08_05_2022__20:03:25\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.8339738, Training accuracy: 0.3261486, Time: 08_05_2022__20:03:36\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.8333215, Training accuracy: 0.3271711, Time: 08_05_2022__20:03:48\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.8321340, Training accuracy: 0.3278846, Time: 08_05_2022__20:03:59\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.8312981, Training accuracy: 0.3284375, Time: 08_05_2022__20:04:10\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.8313485, Training accuracy: 0.3291463, Time: 08_05_2022__20:04:21\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.8300072, Training accuracy: 0.3296429, Time: 08_05_2022__20:04:32\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.8300647, Training accuracy: 0.3297674, Time: 08_05_2022__20:04:43\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.8275179, Training accuracy: 0.3301705, Time: 08_05_2022__20:04:54\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.8251352, Training accuracy: 0.3308889, Time: 08_05_2022__20:05:05\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.8239564, Training accuracy: 0.3314130, Time: 08_05_2022__20:05:16\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.8235796, Training accuracy: 0.3311702, Time: 08_05_2022__20:05:27\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.8235051, Training accuracy: 0.3307813, Time: 08_05_2022__20:05:38\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.8230531, Training accuracy: 0.3313265, Time: 08_05_2022__20:05:49\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.8239311, Training accuracy: 0.3310000, Time: 08_05_2022__20:06:01\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.8218067, Training accuracy: 0.3318137, Time: 08_05_2022__20:06:12\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.8230771, Training accuracy: 0.3315865, Time: 08_05_2022__20:06:23\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.8221241, Training accuracy: 0.3321226, Time: 08_05_2022__20:06:34\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.8213190, Training accuracy: 0.3328704, Time: 08_05_2022__20:06:45\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.8199794, Training accuracy: 0.3334545, Time: 08_05_2022__20:06:56\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.8190068, Training accuracy: 0.3334821, Time: 08_05_2022__20:07:07\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.8183668, Training accuracy: 0.3339035, Time: 08_05_2022__20:07:18\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.8177667, Training accuracy: 0.3344828, Time: 08_05_2022__20:07:29\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.8173821, Training accuracy: 0.3349576, Time: 08_05_2022__20:07:40\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.8161740, Training accuracy: 0.3355000, Time: 08_05_2022__20:07:51\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.8155986, Training accuracy: 0.3352459, Time: 08_05_2022__20:08:03\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.8142012, Training accuracy: 0.3356048, Time: 08_05_2022__20:08:14\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.8138203, Training accuracy: 0.3357540, Time: 08_05_2022__20:08:25\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.8133875, Training accuracy: 0.3357031, Time: 08_05_2022__20:08:36\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.8113067, Training accuracy: 0.3358846, Time: 08_05_2022__20:08:47\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.8111666, Training accuracy: 0.3360227, Time: 08_05_2022__20:08:58\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.8111021, Training accuracy: 0.3357836, Time: 08_05_2022__20:09:09\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.8109188, Training accuracy: 0.3361397, Time: 08_05_2022__20:09:20\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.8097568, Training accuracy: 0.3367754, Time: 08_05_2022__20:09:31\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.8086597, Training accuracy: 0.3372857, Time: 08_05_2022__20:09:43\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.8079873, Training accuracy: 0.3370070, Time: 08_05_2022__20:09:54\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.8065582, Training accuracy: 0.3378125, Time: 08_05_2022__20:10:05\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.8059587, Training accuracy: 0.3376712, Time: 08_05_2022__20:10:16\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.8066779, Training accuracy: 0.3376689, Time: 08_05_2022__20:10:27\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.8069873, Training accuracy: 0.3379667, Time: 08_05_2022__20:10:38\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.8066594, Training accuracy: 0.3381579, Time: 08_05_2022__20:10:49\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.8059894, Training accuracy: 0.3385714, Time: 08_05_2022__20:11:00\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.8041279, Training accuracy: 0.3393590, Time: 08_05_2022__20:11:11\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.8029627, Training accuracy: 0.3397785, Time: 08_05_2022__20:11:22\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.8024143, Training accuracy: 0.3399687, Time: 08_05_2022__20:11:33\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.8019114, Training accuracy: 0.3398457, Time: 08_05_2022__20:11:44\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.8016265, Training accuracy: 0.3396951, Time: 08_05_2022__20:11:56\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.8007572, Training accuracy: 0.3401205, Time: 08_05_2022__20:12:07\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.8007532, Training accuracy: 0.3402381, Time: 08_05_2022__20:12:18\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.7996773, Training accuracy: 0.3407353, Time: 08_05_2022__20:12:29\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.7981333, Training accuracy: 0.3410756, Time: 08_05_2022__20:12:40\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.7972234, Training accuracy: 0.3414943, Time: 08_05_2022__20:12:51\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.7957346, Training accuracy: 0.3421023, Time: 08_05_2022__20:13:02\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.7945809, Training accuracy: 0.3425562, Time: 08_05_2022__20:13:13\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.7944685, Training accuracy: 0.3424722, Time: 08_05_2022__20:13:24\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.7937649, Training accuracy: 0.3428571, Time: 08_05_2022__20:13:35\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.7925659, Training accuracy: 0.3433696, Time: 08_05_2022__20:13:46\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.7916726, Training accuracy: 0.3437097, Time: 08_05_2022__20:13:58\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.7909249, Training accuracy: 0.3439894, Time: 08_05_2022__20:14:09\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.7913062, Training accuracy: 0.3442632, Time: 08_05_2022__20:14:20\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.7898949, Training accuracy: 0.3451042, Time: 08_05_2022__20:14:31\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.7885292, Training accuracy: 0.3456186, Time: 08_05_2022__20:14:42\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.7868965, Training accuracy: 0.3464286, Time: 08_05_2022__20:14:53\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.7864927, Training accuracy: 0.3467424, Time: 08_05_2022__20:15:04\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.7861871, Training accuracy: 0.3467250, Time: 08_05_2022__20:15:15\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.7863492, Training accuracy: 0.3469059, Time: 08_05_2022__20:15:26\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.7855763, Training accuracy: 0.3470833, Time: 08_05_2022__20:15:37\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.7854225, Training accuracy: 0.3471117, Time: 08_05_2022__20:15:48\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.7843260, Training accuracy: 0.3473798, Time: 08_05_2022__20:15:59\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.7840677, Training accuracy: 0.3477619, Time: 08_05_2022__20:16:11\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.7833326, Training accuracy: 0.3478774, Time: 08_05_2022__20:16:22\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.7831456, Training accuracy: 0.3475935, Time: 08_05_2022__20:16:33\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.7822287, Training accuracy: 0.3483102, Time: 08_05_2022__20:16:44\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.7817538, Training accuracy: 0.3483716, Time: 08_05_2022__20:16:55\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.7819473, Training accuracy: 0.3480455, Time: 08_05_2022__20:17:06\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.7808030, Training accuracy: 0.3486486, Time: 08_05_2022__20:17:17\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.7800793, Training accuracy: 0.3488393, Time: 08_05_2022__20:17:28\n","Epoch 2 of 5, Average training loss: 1.7799723, Average training accuracy: 0.3488889, Time: 08_05_2022__20:17:34\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38104948a0e44921b9c09517829018b7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.5397088, Validation accuracy: 0.4625000, Time: 08_05_2022__20:17:37 | Loss decreased from 1.7346839 to 1.5385006 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.5445595, Validation accuracy: 0.4637500, Time: 08_05_2022__20:17:44\n","Step: 300 of 1250, Validation loss: 1.5701793, Validation accuracy: 0.4408333, Time: 08_05_2022__20:17:47\n","Step: 400 of 1250, Validation loss: 1.5795215, Validation accuracy: 0.4350000, Time: 08_05_2022__20:17:51\n","Step: 500 of 1250, Validation loss: 1.5886831, Validation accuracy: 0.4310000, Time: 08_05_2022__20:17:55\n","Step: 600 of 1250, Validation loss: 1.5823841, Validation accuracy: 0.4341667, Time: 08_05_2022__20:17:58\n","Step: 700 of 1250, Validation loss: 1.5741563, Validation accuracy: 0.4396429, Time: 08_05_2022__20:18:02\n","Step: 800 of 1250, Validation loss: 1.5691757, Validation accuracy: 0.4396875, Time: 08_05_2022__20:18:06\n","Step: 900 of 1250, Validation loss: 1.5673051, Validation accuracy: 0.4411111, Time: 08_05_2022__20:18:09\n","Step: 1000 of 1250, Validation loss: 1.5702705, Validation accuracy: 0.4400000, Time: 08_05_2022__20:18:13\n","Step: 1100 of 1250, Validation loss: 1.5755381, Validation accuracy: 0.4375000, Time: 08_05_2022__20:18:17\n","Step: 1200 of 1250, Validation loss: 1.5739425, Validation accuracy: 0.4368750, Time: 08_05_2022__20:18:20\n","Average validation loss: 1.5726816, Average validation accuracy: 0.4376000, Time: 08_05_2022__20:18:22\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b2531d57899420d830cc702959356dd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.5885739, Training accuracy: 0.4350000, Time: 08_05_2022__20:18:33\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.6462660, Training accuracy: 0.4087500, Time: 08_05_2022__20:18:44\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.6784037, Training accuracy: 0.3983333, Time: 08_05_2022__20:18:55\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.6889150, Training accuracy: 0.3893750, Time: 08_05_2022__20:19:07\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.6867947, Training accuracy: 0.3875000, Time: 08_05_2022__20:19:18\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.6776610, Training accuracy: 0.3950000, Time: 08_05_2022__20:19:29\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.6811566, Training accuracy: 0.3932143, Time: 08_05_2022__20:19:40\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.6841267, Training accuracy: 0.3856250, Time: 08_05_2022__20:19:51\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.6835125, Training accuracy: 0.3869444, Time: 08_05_2022__20:20:02\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.6873056, Training accuracy: 0.3837500, Time: 08_05_2022__20:20:13\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.6899114, Training accuracy: 0.3822727, Time: 08_05_2022__20:20:24\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.6894335, Training accuracy: 0.3800000, Time: 08_05_2022__20:20:35\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.6851451, Training accuracy: 0.3817308, Time: 08_05_2022__20:20:46\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.6811734, Training accuracy: 0.3835714, Time: 08_05_2022__20:20:57\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.6853045, Training accuracy: 0.3815000, Time: 08_05_2022__20:21:09\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.6873988, Training accuracy: 0.3820312, Time: 08_05_2022__20:21:20\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.6879846, Training accuracy: 0.3814706, Time: 08_05_2022__20:21:31\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.6853960, Training accuracy: 0.3825000, Time: 08_05_2022__20:21:42\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.6851770, Training accuracy: 0.3810526, Time: 08_05_2022__20:21:53\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.6860876, Training accuracy: 0.3825000, Time: 08_05_2022__20:22:04\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.6846430, Training accuracy: 0.3827381, Time: 08_05_2022__20:22:15\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.6854897, Training accuracy: 0.3829545, Time: 08_05_2022__20:22:26\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.6842586, Training accuracy: 0.3831522, Time: 08_05_2022__20:22:37\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.6815046, Training accuracy: 0.3854167, Time: 08_05_2022__20:22:48\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.6766249, Training accuracy: 0.3874000, Time: 08_05_2022__20:22:59\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.6749787, Training accuracy: 0.3879808, Time: 08_05_2022__20:23:11\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.6735213, Training accuracy: 0.3884259, Time: 08_05_2022__20:23:22\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.6744314, Training accuracy: 0.3870536, Time: 08_05_2022__20:23:33\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.6766950, Training accuracy: 0.3864655, Time: 08_05_2022__20:23:44\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.6762383, Training accuracy: 0.3864167, Time: 08_05_2022__20:23:55\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.6739838, Training accuracy: 0.3861290, Time: 08_05_2022__20:24:06\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.6725649, Training accuracy: 0.3871875, Time: 08_05_2022__20:24:17\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.6741464, Training accuracy: 0.3872727, Time: 08_05_2022__20:24:28\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.6739093, Training accuracy: 0.3875000, Time: 08_05_2022__20:24:39\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.6729954, Training accuracy: 0.3880714, Time: 08_05_2022__20:24:50\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.6754049, Training accuracy: 0.3875000, Time: 08_05_2022__20:25:01\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.6771224, Training accuracy: 0.3866892, Time: 08_05_2022__20:25:13\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.6763769, Training accuracy: 0.3875658, Time: 08_05_2022__20:25:24\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.6755267, Training accuracy: 0.3886538, Time: 08_05_2022__20:25:35\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.6757172, Training accuracy: 0.3890625, Time: 08_05_2022__20:25:46\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.6780412, Training accuracy: 0.3874390, Time: 08_05_2022__20:25:57\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.6762487, Training accuracy: 0.3887500, Time: 08_05_2022__20:26:08\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.6766170, Training accuracy: 0.3887209, Time: 08_05_2022__20:26:19\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.6746820, Training accuracy: 0.3886364, Time: 08_05_2022__20:26:30\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.6726122, Training accuracy: 0.3897778, Time: 08_05_2022__20:26:41\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.6718078, Training accuracy: 0.3901630, Time: 08_05_2022__20:26:52\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.6711812, Training accuracy: 0.3906383, Time: 08_05_2022__20:27:04\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.6707391, Training accuracy: 0.3911458, Time: 08_05_2022__20:27:15\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.6718727, Training accuracy: 0.3911224, Time: 08_05_2022__20:27:26\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.6727557, Training accuracy: 0.3907500, Time: 08_05_2022__20:27:37\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.6709584, Training accuracy: 0.3913235, Time: 08_05_2022__20:27:48\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.6718150, Training accuracy: 0.3914904, Time: 08_05_2022__20:27:59\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.6712095, Training accuracy: 0.3910849, Time: 08_05_2022__20:28:10\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.6706367, Training accuracy: 0.3916667, Time: 08_05_2022__20:28:21\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.6696355, Training accuracy: 0.3920000, Time: 08_05_2022__20:28:32\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.6690853, Training accuracy: 0.3922768, Time: 08_05_2022__20:28:43\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.6685503, Training accuracy: 0.3925877, Time: 08_05_2022__20:28:54\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.6683411, Training accuracy: 0.3928879, Time: 08_05_2022__20:29:06\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.6683424, Training accuracy: 0.3926695, Time: 08_05_2022__20:29:17\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.6675182, Training accuracy: 0.3929583, Time: 08_05_2022__20:29:28\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.6665888, Training accuracy: 0.3931557, Time: 08_05_2022__20:29:39\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.6654103, Training accuracy: 0.3932661, Time: 08_05_2022__20:29:50\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.6659815, Training accuracy: 0.3928968, Time: 08_05_2022__20:30:01\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.6660593, Training accuracy: 0.3929687, Time: 08_05_2022__20:30:12\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.6648730, Training accuracy: 0.3933077, Time: 08_05_2022__20:30:23\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.6650209, Training accuracy: 0.3937500, Time: 08_05_2022__20:30:34\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.6652201, Training accuracy: 0.3934328, Time: 08_05_2022__20:30:45\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.6655110, Training accuracy: 0.3934926, Time: 08_05_2022__20:30:56\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.6649779, Training accuracy: 0.3937319, Time: 08_05_2022__20:31:08\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.6641016, Training accuracy: 0.3942857, Time: 08_05_2022__20:31:19\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.6639033, Training accuracy: 0.3939437, Time: 08_05_2022__20:31:30\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.6636133, Training accuracy: 0.3941667, Time: 08_05_2022__20:31:41\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.6631610, Training accuracy: 0.3942123, Time: 08_05_2022__20:31:52\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.6645407, Training accuracy: 0.3935811, Time: 08_05_2022__20:32:03\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.6647264, Training accuracy: 0.3936000, Time: 08_05_2022__20:32:14\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.6640264, Training accuracy: 0.3939803, Time: 08_05_2022__20:32:25\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.6630294, Training accuracy: 0.3946104, Time: 08_05_2022__20:32:36\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.6623000, Training accuracy: 0.3947436, Time: 08_05_2022__20:32:47\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.6623502, Training accuracy: 0.3948418, Time: 08_05_2022__20:32:58\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.6624529, Training accuracy: 0.3946875, Time: 08_05_2022__20:33:10\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.6626882, Training accuracy: 0.3946605, Time: 08_05_2022__20:33:21\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.6628159, Training accuracy: 0.3946646, Time: 08_05_2022__20:33:32\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.6621277, Training accuracy: 0.3951807, Time: 08_05_2022__20:33:43\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.6622360, Training accuracy: 0.3950595, Time: 08_05_2022__20:33:54\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.6620324, Training accuracy: 0.3949118, Time: 08_05_2022__20:34:05\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.6608644, Training accuracy: 0.3953779, Time: 08_05_2022__20:34:16\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.6604653, Training accuracy: 0.3959770, Time: 08_05_2022__20:34:27\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.6594145, Training accuracy: 0.3964205, Time: 08_05_2022__20:34:38\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 1.6582497, Training accuracy: 0.3969382, Time: 08_05_2022__20:34:49\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 1.6585049, Training accuracy: 0.3966389, Time: 08_05_2022__20:35:00\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 1.6580548, Training accuracy: 0.3969780, Time: 08_05_2022__20:35:12\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 1.6573900, Training accuracy: 0.3973641, Time: 08_05_2022__20:35:23\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 1.6570170, Training accuracy: 0.3978495, Time: 08_05_2022__20:35:34\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 1.6566651, Training accuracy: 0.3980585, Time: 08_05_2022__20:35:45\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 1.6573080, Training accuracy: 0.3978158, Time: 08_05_2022__20:35:56\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 1.6561442, Training accuracy: 0.3981510, Time: 08_05_2022__20:36:07\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 1.6545449, Training accuracy: 0.3989433, Time: 08_05_2022__20:36:18\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 1.6533678, Training accuracy: 0.3992347, Time: 08_05_2022__20:36:29\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 1.6530150, Training accuracy: 0.3992929, Time: 08_05_2022__20:36:40\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 1.6528478, Training accuracy: 0.3990750, Time: 08_05_2022__20:36:51\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 1.6534641, Training accuracy: 0.3989356, Time: 08_05_2022__20:37:02\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 1.6530368, Training accuracy: 0.3990441, Time: 08_05_2022__20:37:14\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 1.6530574, Training accuracy: 0.3990777, Time: 08_05_2022__20:37:25\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 1.6522995, Training accuracy: 0.3994952, Time: 08_05_2022__20:37:36\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 1.6526174, Training accuracy: 0.3993333, Time: 08_05_2022__20:37:47\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 1.6526652, Training accuracy: 0.3991745, Time: 08_05_2022__20:37:58\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 1.6521173, Training accuracy: 0.3990888, Time: 08_05_2022__20:38:09\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 1.6514986, Training accuracy: 0.3998380, Time: 08_05_2022__20:38:20\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 1.6516311, Training accuracy: 0.3997477, Time: 08_05_2022__20:38:31\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 1.6516547, Training accuracy: 0.3997955, Time: 08_05_2022__20:38:42\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 1.6509939, Training accuracy: 0.4003378, Time: 08_05_2022__20:38:53\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 1.6509064, Training accuracy: 0.4002009, Time: 08_05_2022__20:39:04\n","Epoch 3 of 5, Average training loss: 1.6508666, Average training accuracy: 0.4002889, Time: 08_05_2022__20:39:10\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04e71f616b8f4a849987fa37213cc16e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.4310770, Validation accuracy: 0.5150000, Time: 08_05_2022__20:39:14 | Loss decreased from 1.5385006 to 1.4291409 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.4375404, Validation accuracy: 0.4937500, Time: 08_05_2022__20:39:19\n","Step: 300 of 1250, Validation loss: 1.4557018, Validation accuracy: 0.4716667, Time: 08_05_2022__20:39:23\n","Step: 400 of 1250, Validation loss: 1.4636992, Validation accuracy: 0.4725000, Time: 08_05_2022__20:39:27\n","Step: 500 of 1250, Validation loss: 1.4736444, Validation accuracy: 0.4675000, Time: 08_05_2022__20:39:31\n","Step: 600 of 1250, Validation loss: 1.4695405, Validation accuracy: 0.4720833, Time: 08_05_2022__20:39:34\n","Step: 700 of 1250, Validation loss: 1.4627310, Validation accuracy: 0.4785714, Time: 08_05_2022__20:39:38\n","Step: 800 of 1250, Validation loss: 1.4606950, Validation accuracy: 0.4784375, Time: 08_05_2022__20:39:42\n","Step: 900 of 1250, Validation loss: 1.4637586, Validation accuracy: 0.4747222, Time: 08_05_2022__20:39:45\n","Step: 1000 of 1250, Validation loss: 1.4661026, Validation accuracy: 0.4722500, Time: 08_05_2022__20:39:49\n","Step: 1100 of 1250, Validation loss: 1.4685273, Validation accuracy: 0.4747727, Time: 08_05_2022__20:39:52\n","Step: 1200 of 1250, Validation loss: 1.4677957, Validation accuracy: 0.4752083, Time: 08_05_2022__20:39:56\n","Average validation loss: 1.4662699, Average validation accuracy: 0.4764000, Time: 08_05_2022__20:39:58\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6dc8647f6ec45528ba81ca446a925e4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 1.4974576, Training accuracy: 0.4675000, Time: 08_05_2022__20:40:09\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 1.5401907, Training accuracy: 0.4475000, Time: 08_05_2022__20:40:20\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 1.5826395, Training accuracy: 0.4308333, Time: 08_05_2022__20:40:31\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 1.5825114, Training accuracy: 0.4300000, Time: 08_05_2022__20:40:42\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 1.5857375, Training accuracy: 0.4230000, Time: 08_05_2022__20:40:53\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 1.5828368, Training accuracy: 0.4258333, Time: 08_05_2022__20:41:04\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 1.5890676, Training accuracy: 0.4214286, Time: 08_05_2022__20:41:16\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 1.5907285, Training accuracy: 0.4228125, Time: 08_05_2022__20:41:27\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 1.5880383, Training accuracy: 0.4236111, Time: 08_05_2022__20:41:38\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 1.5888714, Training accuracy: 0.4222500, Time: 08_05_2022__20:41:49\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 1.5875382, Training accuracy: 0.4225000, Time: 08_05_2022__20:42:00\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 1.5872424, Training accuracy: 0.4231250, Time: 08_05_2022__20:42:11\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 1.5860292, Training accuracy: 0.4248077, Time: 08_05_2022__20:42:22\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 1.5840855, Training accuracy: 0.4264286, Time: 08_05_2022__20:42:33\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 1.5867402, Training accuracy: 0.4258333, Time: 08_05_2022__20:42:44\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 1.5869856, Training accuracy: 0.4256250, Time: 08_05_2022__20:42:55\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 1.5887879, Training accuracy: 0.4233824, Time: 08_05_2022__20:43:07\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 1.5872973, Training accuracy: 0.4230556, Time: 08_05_2022__20:43:18\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 1.5885024, Training accuracy: 0.4219737, Time: 08_05_2022__20:43:29\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 1.5903167, Training accuracy: 0.4230000, Time: 08_05_2022__20:43:40\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 1.5896992, Training accuracy: 0.4232143, Time: 08_05_2022__20:43:51\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 1.5894784, Training accuracy: 0.4232955, Time: 08_05_2022__20:44:02\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 1.5889537, Training accuracy: 0.4222826, Time: 08_05_2022__20:44:13\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 1.5869012, Training accuracy: 0.4226042, Time: 08_05_2022__20:44:24\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 1.5838469, Training accuracy: 0.4244000, Time: 08_05_2022__20:44:35\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 1.5844844, Training accuracy: 0.4237500, Time: 08_05_2022__20:44:46\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 1.5818608, Training accuracy: 0.4246296, Time: 08_05_2022__20:44:57\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 1.5821896, Training accuracy: 0.4236607, Time: 08_05_2022__20:45:09\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 1.5819812, Training accuracy: 0.4247414, Time: 08_05_2022__20:45:20\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 1.5825930, Training accuracy: 0.4243333, Time: 08_05_2022__20:45:31\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 1.5807351, Training accuracy: 0.4245968, Time: 08_05_2022__20:45:42\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 1.5789597, Training accuracy: 0.4247656, Time: 08_05_2022__20:45:53\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 1.5806748, Training accuracy: 0.4237879, Time: 08_05_2022__20:46:04\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 1.5800520, Training accuracy: 0.4234559, Time: 08_05_2022__20:46:15\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 1.5789647, Training accuracy: 0.4247857, Time: 08_05_2022__20:46:26\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 1.5794759, Training accuracy: 0.4240278, Time: 08_05_2022__20:46:37\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 1.5815851, Training accuracy: 0.4230405, Time: 08_05_2022__20:46:48\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 1.5816210, Training accuracy: 0.4236842, Time: 08_05_2022__20:46:59\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 1.5810409, Training accuracy: 0.4240385, Time: 08_05_2022__20:47:11\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 1.5810114, Training accuracy: 0.4243125, Time: 08_05_2022__20:47:22\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 1.5824683, Training accuracy: 0.4239634, Time: 08_05_2022__20:47:33\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 1.5801678, Training accuracy: 0.4253571, Time: 08_05_2022__20:47:44\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 1.5805111, Training accuracy: 0.4251163, Time: 08_05_2022__20:47:55\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 1.5788902, Training accuracy: 0.4259091, Time: 08_05_2022__20:48:06\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 1.5770183, Training accuracy: 0.4265000, Time: 08_05_2022__20:48:17\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 1.5762956, Training accuracy: 0.4270652, Time: 08_05_2022__20:48:28\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 1.5759504, Training accuracy: 0.4269681, Time: 08_05_2022__20:48:39\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 1.5755051, Training accuracy: 0.4272917, Time: 08_05_2022__20:48:50\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 1.5757943, Training accuracy: 0.4271429, Time: 08_05_2022__20:49:01\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 1.5773732, Training accuracy: 0.4275000, Time: 08_05_2022__20:49:13\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 1.5761367, Training accuracy: 0.4281373, Time: 08_05_2022__20:49:24\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 1.5768464, Training accuracy: 0.4280288, Time: 08_05_2022__20:49:35\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 1.5765633, Training accuracy: 0.4284434, Time: 08_05_2022__20:49:46\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 1.5760956, Training accuracy: 0.4296296, Time: 08_05_2022__20:49:57\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 1.5760365, Training accuracy: 0.4299545, Time: 08_05_2022__20:50:08\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 1.5759277, Training accuracy: 0.4295536, Time: 08_05_2022__20:50:19\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 1.5765201, Training accuracy: 0.4294298, Time: 08_05_2022__20:50:30\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 1.5762162, Training accuracy: 0.4289224, Time: 08_05_2022__20:50:41\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 1.5767283, Training accuracy: 0.4289831, Time: 08_05_2022__20:50:52\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 1.5758471, Training accuracy: 0.4295417, Time: 08_05_2022__20:51:03\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 1.5760780, Training accuracy: 0.4296311, Time: 08_05_2022__20:51:14\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 1.5748685, Training accuracy: 0.4298387, Time: 08_05_2022__20:51:26\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 1.5750708, Training accuracy: 0.4298016, Time: 08_05_2022__20:51:37\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 1.5742453, Training accuracy: 0.4298438, Time: 08_05_2022__20:51:48\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 1.5727518, Training accuracy: 0.4303846, Time: 08_05_2022__20:51:59\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 1.5729380, Training accuracy: 0.4302273, Time: 08_05_2022__20:52:10\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 1.5730853, Training accuracy: 0.4302239, Time: 08_05_2022__20:52:21\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 1.5732710, Training accuracy: 0.4302206, Time: 08_05_2022__20:52:32\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 1.5725164, Training accuracy: 0.4302174, Time: 08_05_2022__20:52:43\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 1.5710142, Training accuracy: 0.4306429, Time: 08_05_2022__20:52:54\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 1.5707362, Training accuracy: 0.4304225, Time: 08_05_2022__20:53:05\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 1.5704283, Training accuracy: 0.4304861, Time: 08_05_2022__20:53:16\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 1.5697912, Training accuracy: 0.4302397, Time: 08_05_2022__20:53:28\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 1.5709847, Training accuracy: 0.4295270, Time: 08_05_2022__20:53:39\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 1.5711116, Training accuracy: 0.4293000, Time: 08_05_2022__20:53:50\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 1.5709439, Training accuracy: 0.4290132, Time: 08_05_2022__20:54:01\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 1.5703948, Training accuracy: 0.4294156, Time: 08_05_2022__20:54:12\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 1.5690390, Training accuracy: 0.4299359, Time: 08_05_2022__20:54:23\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 1.5684131, Training accuracy: 0.4300316, Time: 08_05_2022__20:54:34\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 1.5680319, Training accuracy: 0.4302500, Time: 08_05_2022__20:54:45\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 1.5676536, Training accuracy: 0.4302778, Time: 08_05_2022__20:54:56\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 1.5673419, Training accuracy: 0.4302439, Time: 08_05_2022__20:55:08\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 1.5665434, Training accuracy: 0.4307229, Time: 08_05_2022__20:55:19\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 1.5666602, Training accuracy: 0.4306845, Time: 08_05_2022__20:55:30\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 1.5657237, Training accuracy: 0.4310294, Time: 08_05_2022__20:55:41\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 1.5646741, Training accuracy: 0.4318895, Time: 08_05_2022__20:55:52\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 1.5643913, Training accuracy: 0.4322414, Time: 08_05_2022__20:56:03\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 1.5636669, Training accuracy: 0.4324432, Time: 08_05_2022__20:56:14\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 1.5628506, Training accuracy: 0.4326404, Time: 08_05_2022__20:56:25\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 1.5630267, Training accuracy: 0.4325556, Time: 08_05_2022__20:56:36\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 1.5622389, Training accuracy: 0.4330769, Time: 08_05_2022__20:56:47\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 1.5609613, Training accuracy: 0.4336957, Time: 08_05_2022__20:56:59\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 1.5609147, Training accuracy: 0.4338172, Time: 08_05_2022__20:57:10\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 1.5608425, Training accuracy: 0.4339096, Time: 08_05_2022__20:57:21\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 1.5617248, Training accuracy: 0.4337632, Time: 08_05_2022__20:57:32\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 1.5606044, Training accuracy: 0.4344271, Time: 08_05_2022__20:57:43\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 1.5591888, Training accuracy: 0.4350773, Time: 08_05_2022__20:57:54\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 1.5578955, Training accuracy: 0.4354592, Time: 08_05_2022__20:58:05\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 1.5579565, Training accuracy: 0.4358333, Time: 08_05_2022__20:58:16\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 1.5578807, Training accuracy: 0.4359750, Time: 08_05_2022__20:58:27\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 1.5585911, Training accuracy: 0.4360396, Time: 08_05_2022__20:58:38\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 1.5580938, Training accuracy: 0.4360049, Time: 08_05_2022__20:58:50\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 1.5581410, Training accuracy: 0.4360922, Time: 08_05_2022__20:59:01\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 1.5577871, Training accuracy: 0.4363462, Time: 08_05_2022__20:59:12\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 1.5579258, Training accuracy: 0.4365000, Time: 08_05_2022__20:59:23\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 1.5578065, Training accuracy: 0.4363443, Time: 08_05_2022__20:59:34\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 1.5577888, Training accuracy: 0.4359346, Time: 08_05_2022__20:59:45\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 1.5571948, Training accuracy: 0.4362963, Time: 08_05_2022__20:59:56\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 1.5577207, Training accuracy: 0.4363073, Time: 08_05_2022__21:00:07\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 1.5581060, Training accuracy: 0.4359091, Time: 08_05_2022__21:00:18\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 1.5571413, Training accuracy: 0.4362613, Time: 08_05_2022__21:00:30\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 1.5568122, Training accuracy: 0.4363616, Time: 08_05_2022__21:00:41\n","Epoch 4 of 5, Average training loss: 1.5569002, Average training accuracy: 0.4364444, Time: 08_05_2022__21:00:46\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf422f85e6054c3aa9c7a2f2304ebb78"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.3539062, Validation accuracy: 0.5300000, Time: 08_05_2022__21:00:50 | Loss decreased from 1.4291409 to 1.3539928 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.3643253, Validation accuracy: 0.5200000, Time: 08_05_2022__21:00:56\n","Step: 300 of 1250, Validation loss: 1.3900350, Validation accuracy: 0.4950000, Time: 08_05_2022__21:00:59\n","Step: 400 of 1250, Validation loss: 1.3939011, Validation accuracy: 0.4950000, Time: 08_05_2022__21:01:03\n","Step: 500 of 1250, Validation loss: 1.3983438, Validation accuracy: 0.4985000, Time: 08_05_2022__21:01:07\n","Step: 600 of 1250, Validation loss: 1.3941105, Validation accuracy: 0.4995833, Time: 08_05_2022__21:01:11\n","Step: 700 of 1250, Validation loss: 1.3832067, Validation accuracy: 0.5050000, Time: 08_05_2022__21:01:14\n","Step: 800 of 1250, Validation loss: 1.3783064, Validation accuracy: 0.5065625, Time: 08_05_2022__21:01:18\n","Step: 900 of 1250, Validation loss: 1.3775891, Validation accuracy: 0.5050000, Time: 08_05_2022__21:01:22\n","Step: 1000 of 1250, Validation loss: 1.3804042, Validation accuracy: 0.5015000, Time: 08_05_2022__21:01:25\n","Step: 1100 of 1250, Validation loss: 1.3827734, Validation accuracy: 0.5015909, Time: 08_05_2022__21:01:29\n","Step: 1200 of 1250, Validation loss: 1.3830736, Validation accuracy: 0.5000000, Time: 08_05_2022__21:01:32\n","Average validation loss: 1.3834762, Average validation accuracy: 0.5000000, Time: 08_05_2022__21:01:34\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa10f6cb10fe4279b5d7e788d369772f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 1.4202168, Training accuracy: 0.5000000, Time: 08_05_2022__21:01:45\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 1.4562405, Training accuracy: 0.4875000, Time: 08_05_2022__21:01:57\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 1.4916549, Training accuracy: 0.4575000, Time: 08_05_2022__21:02:08\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 1.4885032, Training accuracy: 0.4600000, Time: 08_05_2022__21:02:19\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 1.4903725, Training accuracy: 0.4530000, Time: 08_05_2022__21:02:30\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 1.4827573, Training accuracy: 0.4604167, Time: 08_05_2022__21:02:41\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 1.4949088, Training accuracy: 0.4550000, Time: 08_05_2022__21:02:52\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 1.4942336, Training accuracy: 0.4562500, Time: 08_05_2022__21:03:03\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 1.4975391, Training accuracy: 0.4541667, Time: 08_05_2022__21:03:14\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 1.5018724, Training accuracy: 0.4535000, Time: 08_05_2022__21:03:26\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 1.5026874, Training accuracy: 0.4511364, Time: 08_05_2022__21:03:37\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 1.5050392, Training accuracy: 0.4522917, Time: 08_05_2022__21:03:48\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 1.5023032, Training accuracy: 0.4523077, Time: 08_05_2022__21:03:59\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 1.4992308, Training accuracy: 0.4530357, Time: 08_05_2022__21:04:10\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 1.5048646, Training accuracy: 0.4511667, Time: 08_05_2022__21:04:21\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 1.5047313, Training accuracy: 0.4526562, Time: 08_05_2022__21:04:32\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 1.5045336, Training accuracy: 0.4529412, Time: 08_05_2022__21:04:43\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 1.5032904, Training accuracy: 0.4526389, Time: 08_05_2022__21:04:55\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 1.5037372, Training accuracy: 0.4521053, Time: 08_05_2022__21:05:06\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 1.5056870, Training accuracy: 0.4518750, Time: 08_05_2022__21:05:17\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 1.5054765, Training accuracy: 0.4523810, Time: 08_05_2022__21:05:28\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 1.5061803, Training accuracy: 0.4525000, Time: 08_05_2022__21:05:39\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 1.5034515, Training accuracy: 0.4535870, Time: 08_05_2022__21:05:50\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 1.5001943, Training accuracy: 0.4544792, Time: 08_05_2022__21:06:01\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 1.4997056, Training accuracy: 0.4554000, Time: 08_05_2022__21:06:12\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 1.4989391, Training accuracy: 0.4562500, Time: 08_05_2022__21:06:23\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 1.4962588, Training accuracy: 0.4572222, Time: 08_05_2022__21:06:34\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 1.4981932, Training accuracy: 0.4559821, Time: 08_05_2022__21:06:46\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 1.4978794, Training accuracy: 0.4553448, Time: 08_05_2022__21:06:57\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 1.4976313, Training accuracy: 0.4552500, Time: 08_05_2022__21:07:08\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 1.4950446, Training accuracy: 0.4558065, Time: 08_05_2022__21:07:19\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 1.4931448, Training accuracy: 0.4569531, Time: 08_05_2022__21:07:30\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 1.4941968, Training accuracy: 0.4562879, Time: 08_05_2022__21:07:41\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 1.4945284, Training accuracy: 0.4561029, Time: 08_05_2022__21:07:52\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 1.4942515, Training accuracy: 0.4561429, Time: 08_05_2022__21:08:03\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 1.4963082, Training accuracy: 0.4555556, Time: 08_05_2022__21:08:14\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 1.4969702, Training accuracy: 0.4547973, Time: 08_05_2022__21:08:26\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 1.4976381, Training accuracy: 0.4546711, Time: 08_05_2022__21:08:37\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 1.4969103, Training accuracy: 0.4551282, Time: 08_05_2022__21:08:48\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 1.4963450, Training accuracy: 0.4558750, Time: 08_05_2022__21:08:59\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 1.4977823, Training accuracy: 0.4556098, Time: 08_05_2022__21:09:10\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 1.4955665, Training accuracy: 0.4564286, Time: 08_05_2022__21:09:21\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 1.4948309, Training accuracy: 0.4573256, Time: 08_05_2022__21:09:32\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 1.4925589, Training accuracy: 0.4581250, Time: 08_05_2022__21:09:43\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 1.4907904, Training accuracy: 0.4592778, Time: 08_05_2022__21:09:54\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 1.4906191, Training accuracy: 0.4597283, Time: 08_05_2022__21:10:05\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 1.4906316, Training accuracy: 0.4598936, Time: 08_05_2022__21:10:17\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 1.4912480, Training accuracy: 0.4591667, Time: 08_05_2022__21:10:28\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 1.4904123, Training accuracy: 0.4596429, Time: 08_05_2022__21:10:39\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 1.4910142, Training accuracy: 0.4599000, Time: 08_05_2022__21:10:50\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 1.4897301, Training accuracy: 0.4607353, Time: 08_05_2022__21:11:01\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 1.4906771, Training accuracy: 0.4606731, Time: 08_05_2022__21:11:12\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 1.4903855, Training accuracy: 0.4608962, Time: 08_05_2022__21:11:23\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 1.4906989, Training accuracy: 0.4611111, Time: 08_05_2022__21:11:34\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 1.4907486, Training accuracy: 0.4611818, Time: 08_05_2022__21:11:45\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 1.4902329, Training accuracy: 0.4617411, Time: 08_05_2022__21:11:56\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 1.4903850, Training accuracy: 0.4618421, Time: 08_05_2022__21:12:07\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 1.4902687, Training accuracy: 0.4617672, Time: 08_05_2022__21:12:19\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 1.4904858, Training accuracy: 0.4617797, Time: 08_05_2022__21:12:30\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 1.4901032, Training accuracy: 0.4620833, Time: 08_05_2022__21:12:41\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 1.4896900, Training accuracy: 0.4621721, Time: 08_05_2022__21:12:52\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 1.4884970, Training accuracy: 0.4625403, Time: 08_05_2022__21:13:03\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 1.4888479, Training accuracy: 0.4622619, Time: 08_05_2022__21:13:14\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 1.4891757, Training accuracy: 0.4620313, Time: 08_05_2022__21:13:25\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 1.4884498, Training accuracy: 0.4624615, Time: 08_05_2022__21:13:36\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 1.4879824, Training accuracy: 0.4625758, Time: 08_05_2022__21:13:47\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 1.4870316, Training accuracy: 0.4629851, Time: 08_05_2022__21:13:59\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 1.4876751, Training accuracy: 0.4627574, Time: 08_05_2022__21:14:10\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 1.4872665, Training accuracy: 0.4626812, Time: 08_05_2022__21:14:21\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 1.4862162, Training accuracy: 0.4632143, Time: 08_05_2022__21:14:32\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 1.4862408, Training accuracy: 0.4630986, Time: 08_05_2022__21:14:43\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 1.4859665, Training accuracy: 0.4631597, Time: 08_05_2022__21:14:54\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 1.4853467, Training accuracy: 0.4632192, Time: 08_05_2022__21:15:05\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 1.4862673, Training accuracy: 0.4631081, Time: 08_05_2022__21:15:16\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 1.4861732, Training accuracy: 0.4631000, Time: 08_05_2022__21:15:27\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 1.4857895, Training accuracy: 0.4633882, Time: 08_05_2022__21:15:39\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 1.4859479, Training accuracy: 0.4635714, Time: 08_05_2022__21:15:50\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 1.4844551, Training accuracy: 0.4643910, Time: 08_05_2022__21:16:01\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 1.4842044, Training accuracy: 0.4639241, Time: 08_05_2022__21:16:12\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 1.4841722, Training accuracy: 0.4638437, Time: 08_05_2022__21:16:23\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 1.4841589, Training accuracy: 0.4633951, Time: 08_05_2022__21:16:34\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 1.4844039, Training accuracy: 0.4631098, Time: 08_05_2022__21:16:45\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 1.4838231, Training accuracy: 0.4634337, Time: 08_05_2022__21:16:56\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 1.4837859, Training accuracy: 0.4633631, Time: 08_05_2022__21:17:07\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 1.4835987, Training accuracy: 0.4632941, Time: 08_05_2022__21:17:18\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 1.4825822, Training accuracy: 0.4641279, Time: 08_05_2022__21:17:30\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 1.4825067, Training accuracy: 0.4641092, Time: 08_05_2022__21:17:41\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 1.4815431, Training accuracy: 0.4642330, Time: 08_05_2022__21:17:52\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 1.4807428, Training accuracy: 0.4643539, Time: 08_05_2022__21:18:03\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 1.4806555, Training accuracy: 0.4644167, Time: 08_05_2022__21:18:14\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 1.4805918, Training accuracy: 0.4645879, Time: 08_05_2022__21:18:25\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 1.4797804, Training accuracy: 0.4651902, Time: 08_05_2022__21:18:36\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 1.4796954, Training accuracy: 0.4653495, Time: 08_05_2022__21:18:47\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 1.4794221, Training accuracy: 0.4655053, Time: 08_05_2022__21:18:58\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 1.4804304, Training accuracy: 0.4650000, Time: 08_05_2022__21:19:10\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 1.4790856, Training accuracy: 0.4655729, Time: 08_05_2022__21:19:21\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 1.4781132, Training accuracy: 0.4659536, Time: 08_05_2022__21:19:32\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 1.4771398, Training accuracy: 0.4662755, Time: 08_05_2022__21:19:43\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 1.4769995, Training accuracy: 0.4663636, Time: 08_05_2022__21:19:54\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 1.4770286, Training accuracy: 0.4666500, Time: 08_05_2022__21:20:05\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 1.4775654, Training accuracy: 0.4664851, Time: 08_05_2022__21:20:16\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 1.4773272, Training accuracy: 0.4661520, Time: 08_05_2022__21:20:27\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 1.4770182, Training accuracy: 0.4659466, Time: 08_05_2022__21:20:38\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 1.4768320, Training accuracy: 0.4660817, Time: 08_05_2022__21:20:50\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 1.4769113, Training accuracy: 0.4660714, Time: 08_05_2022__21:21:01\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 1.4767427, Training accuracy: 0.4657547, Time: 08_05_2022__21:21:12\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 1.4764997, Training accuracy: 0.4658178, Time: 08_05_2022__21:21:23\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 1.4758535, Training accuracy: 0.4661111, Time: 08_05_2022__21:21:34\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 1.4764280, Training accuracy: 0.4661697, Time: 08_05_2022__21:21:45\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 1.4767955, Training accuracy: 0.4659091, Time: 08_05_2022__21:21:57\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 1.4757035, Training accuracy: 0.4662838, Time: 08_05_2022__21:22:08\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 1.4752787, Training accuracy: 0.4664732, Time: 08_05_2022__21:22:19\n","Epoch 5 of 5, Average training loss: 1.4754033, Average training accuracy: 0.4664222, Time: 08_05_2022__21:22:25\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75fd52d7d8964e28bf3fee7a38c25591"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.3047860, Validation accuracy: 0.5525000, Time: 08_05_2022__21:22:28 | Loss decreased from 1.3539928 to 1.3062369 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.3271267, Validation accuracy: 0.5300000, Time: 08_05_2022__21:22:34\n","Step: 300 of 1250, Validation loss: 1.3544011, Validation accuracy: 0.5100000, Time: 08_05_2022__21:22:38\n","Step: 400 of 1250, Validation loss: 1.3539971, Validation accuracy: 0.5062500, Time: 08_05_2022__21:22:42\n","Step: 500 of 1250, Validation loss: 1.3596393, Validation accuracy: 0.5045000, Time: 08_05_2022__21:22:45\n","Step: 600 of 1250, Validation loss: 1.3524444, Validation accuracy: 0.5045833, Time: 08_05_2022__21:22:49\n","Step: 700 of 1250, Validation loss: 1.3438683, Validation accuracy: 0.5128571, Time: 08_05_2022__21:22:53\n","Step: 800 of 1250, Validation loss: 1.3391003, Validation accuracy: 0.5153125, Time: 08_05_2022__21:22:56\n","Step: 900 of 1250, Validation loss: 1.3395856, Validation accuracy: 0.5166667, Time: 08_05_2022__21:23:00\n","Step: 1000 of 1250, Validation loss: 1.3454625, Validation accuracy: 0.5117500, Time: 08_05_2022__21:23:04\n","Step: 1100 of 1250, Validation loss: 1.3482655, Validation accuracy: 0.5111364, Time: 08_05_2022__21:23:07\n","Step: 1200 of 1250, Validation loss: 1.3514516, Validation accuracy: 0.5097917, Time: 08_05_2022__21:23:11\n","Average validation loss: 1.3510958, Average validation accuracy: 0.5098000, Time: 08_05_2022__21:23:13\n","###################### Testing vgg19_batch_norm SGD, lr_0.0001, momentum_0.3 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bb194932b0741c1a839ff7c60e2bf9a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.4550000, Time: 08_05_2022__21:23:24\n","Step: 200 of 2500, Test accuracy: 0.4575000, Time: 08_05_2022__21:23:28\n","Step: 300 of 2500, Test accuracy: 0.4783333, Time: 08_05_2022__21:23:32\n","Step: 400 of 2500, Test accuracy: 0.4856250, Time: 08_05_2022__21:23:35\n","Step: 500 of 2500, Test accuracy: 0.4885000, Time: 08_05_2022__21:23:39\n","Step: 600 of 2500, Test accuracy: 0.4929167, Time: 08_05_2022__21:23:43\n","Step: 700 of 2500, Test accuracy: 0.4960714, Time: 08_05_2022__21:23:46\n","Step: 800 of 2500, Test accuracy: 0.5028125, Time: 08_05_2022__21:23:50\n","Step: 900 of 2500, Test accuracy: 0.5019444, Time: 08_05_2022__21:23:54\n","Step: 1000 of 2500, Test accuracy: 0.5017500, Time: 08_05_2022__21:23:57\n","Step: 1100 of 2500, Test accuracy: 0.5050000, Time: 08_05_2022__21:24:01\n","Step: 1200 of 2500, Test accuracy: 0.5085417, Time: 08_05_2022__21:24:05\n","Step: 1300 of 2500, Test accuracy: 0.5094231, Time: 08_05_2022__21:24:08\n","Step: 1400 of 2500, Test accuracy: 0.5058929, Time: 08_05_2022__21:24:12\n","Step: 1500 of 2500, Test accuracy: 0.5055000, Time: 08_05_2022__21:24:16\n","Step: 1600 of 2500, Test accuracy: 0.5064062, Time: 08_05_2022__21:24:19\n","Step: 1700 of 2500, Test accuracy: 0.5072059, Time: 08_05_2022__21:24:23\n","Step: 1800 of 2500, Test accuracy: 0.5058333, Time: 08_05_2022__21:24:27\n","Step: 1900 of 2500, Test accuracy: 0.5060526, Time: 08_05_2022__21:24:31\n","Step: 2000 of 2500, Test accuracy: 0.5060000, Time: 08_05_2022__21:24:34\n","Step: 2100 of 2500, Test accuracy: 0.5052381, Time: 08_05_2022__21:24:38\n","Step: 2200 of 2500, Test accuracy: 0.5054545, Time: 08_05_2022__21:24:42\n","Step: 2300 of 2500, Test accuracy: 0.5057609, Time: 08_05_2022__21:24:45\n","Step: 2400 of 2500, Test accuracy: 0.5068750, Time: 08_05_2022__21:24:49\n","Step: 2500 of 2500, Test accuracy: 0.5045000, Time: 08_05_2022__21:24:53\n","Average testing accuracy: 0.5045000, Time: 08_05_2022__21:24:53\n","###################### Training vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec67a36b5b78402d932b8ef1fa159857"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 2.4928353, Training accuracy: 0.1050000, Time: 08_05_2022__21:25:06\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 2.4745509, Training accuracy: 0.1100000, Time: 08_05_2022__21:25:17\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 2.4600401, Training accuracy: 0.1083333, Time: 08_05_2022__21:25:28\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 2.4418012, Training accuracy: 0.1112500, Time: 08_05_2022__21:25:40\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 2.4366823, Training accuracy: 0.1095000, Time: 08_05_2022__21:25:51\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 2.4336785, Training accuracy: 0.1087500, Time: 08_05_2022__21:26:02\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.4209815, Training accuracy: 0.1110714, Time: 08_05_2022__21:26:13\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.4140548, Training accuracy: 0.1115625, Time: 08_05_2022__21:26:24\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.4088312, Training accuracy: 0.1086111, Time: 08_05_2022__21:26:36\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.4030077, Training accuracy: 0.1085000, Time: 08_05_2022__21:26:47\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.3941972, Training accuracy: 0.1118182, Time: 08_05_2022__21:26:58\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.3839556, Training accuracy: 0.1175000, Time: 08_05_2022__21:27:09\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.3728050, Training accuracy: 0.1209615, Time: 08_05_2022__21:27:20\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.3638825, Training accuracy: 0.1237500, Time: 08_05_2022__21:27:32\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.3595821, Training accuracy: 0.1256667, Time: 08_05_2022__21:27:43\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.3539222, Training accuracy: 0.1256250, Time: 08_05_2022__21:27:54\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.3493760, Training accuracy: 0.1257353, Time: 08_05_2022__21:28:05\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.3416977, Training accuracy: 0.1288889, Time: 08_05_2022__21:28:16\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.3342274, Training accuracy: 0.1322368, Time: 08_05_2022__21:28:27\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.3281740, Training accuracy: 0.1331250, Time: 08_05_2022__21:28:39\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.3214311, Training accuracy: 0.1364286, Time: 08_05_2022__21:28:50\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.3157666, Training accuracy: 0.1376136, Time: 08_05_2022__21:29:01\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.3103581, Training accuracy: 0.1398913, Time: 08_05_2022__21:29:12\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.3059253, Training accuracy: 0.1429167, Time: 08_05_2022__21:29:23\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.2988273, Training accuracy: 0.1451000, Time: 08_05_2022__21:29:35\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.2914558, Training accuracy: 0.1481731, Time: 08_05_2022__21:29:46\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.2870851, Training accuracy: 0.1502778, Time: 08_05_2022__21:29:57\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.2816169, Training accuracy: 0.1514286, Time: 08_05_2022__21:30:08\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.2762884, Training accuracy: 0.1523276, Time: 08_05_2022__21:30:19\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.2724157, Training accuracy: 0.1542500, Time: 08_05_2022__21:30:31\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.2653256, Training accuracy: 0.1564516, Time: 08_05_2022__21:30:42\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.2602485, Training accuracy: 0.1585156, Time: 08_05_2022__21:30:53\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.2571615, Training accuracy: 0.1604545, Time: 08_05_2022__21:31:04\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.2521793, Training accuracy: 0.1619118, Time: 08_05_2022__21:31:15\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.2482571, Training accuracy: 0.1632143, Time: 08_05_2022__21:31:27\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.2456987, Training accuracy: 0.1634722, Time: 08_05_2022__21:31:38\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.2423623, Training accuracy: 0.1651351, Time: 08_05_2022__21:31:49\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.2382654, Training accuracy: 0.1666447, Time: 08_05_2022__21:32:00\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.2345974, Training accuracy: 0.1679487, Time: 08_05_2022__21:32:11\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.2304699, Training accuracy: 0.1696875, Time: 08_05_2022__21:32:22\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.2262600, Training accuracy: 0.1721341, Time: 08_05_2022__21:32:33\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.2212269, Training accuracy: 0.1742262, Time: 08_05_2022__21:32:45\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.2169212, Training accuracy: 0.1763953, Time: 08_05_2022__21:32:56\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 2.2118825, Training accuracy: 0.1786932, Time: 08_05_2022__21:33:07\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 2.2064825, Training accuracy: 0.1808889, Time: 08_05_2022__21:33:18\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 2.2022754, Training accuracy: 0.1828804, Time: 08_05_2022__21:33:29\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 2.1973051, Training accuracy: 0.1847872, Time: 08_05_2022__21:33:40\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 2.1944752, Training accuracy: 0.1860417, Time: 08_05_2022__21:33:51\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 2.1907603, Training accuracy: 0.1874490, Time: 08_05_2022__21:34:02\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 2.1876806, Training accuracy: 0.1884500, Time: 08_05_2022__21:34:13\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 2.1838117, Training accuracy: 0.1900490, Time: 08_05_2022__21:34:25\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 2.1811328, Training accuracy: 0.1911058, Time: 08_05_2022__21:34:36\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 2.1775087, Training accuracy: 0.1927358, Time: 08_05_2022__21:34:47\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 2.1735568, Training accuracy: 0.1941204, Time: 08_05_2022__21:34:58\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 2.1687990, Training accuracy: 0.1955909, Time: 08_05_2022__21:35:09\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 2.1650008, Training accuracy: 0.1972768, Time: 08_05_2022__21:35:20\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 2.1614692, Training accuracy: 0.1992544, Time: 08_05_2022__21:35:31\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 2.1579784, Training accuracy: 0.2009483, Time: 08_05_2022__21:35:42\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 2.1539763, Training accuracy: 0.2027542, Time: 08_05_2022__21:35:53\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 2.1499030, Training accuracy: 0.2046667, Time: 08_05_2022__21:36:05\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 2.1472823, Training accuracy: 0.2061475, Time: 08_05_2022__21:36:16\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 2.1432060, Training accuracy: 0.2075403, Time: 08_05_2022__21:36:27\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 2.1392606, Training accuracy: 0.2089683, Time: 08_05_2022__21:36:38\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 2.1367322, Training accuracy: 0.2100391, Time: 08_05_2022__21:36:49\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 2.1315730, Training accuracy: 0.2123077, Time: 08_05_2022__21:37:00\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 2.1286269, Training accuracy: 0.2129167, Time: 08_05_2022__21:37:11\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 2.1250015, Training accuracy: 0.2143284, Time: 08_05_2022__21:37:22\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 2.1221518, Training accuracy: 0.2156985, Time: 08_05_2022__21:37:34\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 2.1189504, Training accuracy: 0.2168478, Time: 08_05_2022__21:37:45\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 2.1157858, Training accuracy: 0.2180000, Time: 08_05_2022__21:37:56\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 2.1135326, Training accuracy: 0.2187676, Time: 08_05_2022__21:38:07\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 2.1098921, Training accuracy: 0.2200347, Time: 08_05_2022__21:38:18\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 2.1059954, Training accuracy: 0.2215411, Time: 08_05_2022__21:38:29\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 2.1035550, Training accuracy: 0.2223649, Time: 08_05_2022__21:38:40\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 2.1009854, Training accuracy: 0.2234667, Time: 08_05_2022__21:38:51\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 2.0990680, Training accuracy: 0.2240461, Time: 08_05_2022__21:39:03\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 2.0961924, Training accuracy: 0.2249351, Time: 08_05_2022__21:39:14\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 2.0927430, Training accuracy: 0.2261218, Time: 08_05_2022__21:39:25\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 2.0900400, Training accuracy: 0.2273418, Time: 08_05_2022__21:39:36\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 2.0871494, Training accuracy: 0.2288125, Time: 08_05_2022__21:39:47\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 2.0843880, Training accuracy: 0.2300617, Time: 08_05_2022__21:39:58\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 2.0817623, Training accuracy: 0.2310366, Time: 08_05_2022__21:40:09\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 2.0786436, Training accuracy: 0.2325000, Time: 08_05_2022__21:40:20\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 2.0758518, Training accuracy: 0.2336310, Time: 08_05_2022__21:40:32\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 2.0730511, Training accuracy: 0.2346176, Time: 08_05_2022__21:40:43\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 2.0694904, Training accuracy: 0.2364244, Time: 08_05_2022__21:40:54\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 2.0668811, Training accuracy: 0.2374713, Time: 08_05_2022__21:41:05\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 2.0633819, Training accuracy: 0.2389205, Time: 08_05_2022__21:41:16\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 2.0605143, Training accuracy: 0.2398315, Time: 08_05_2022__21:41:27\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 2.0586489, Training accuracy: 0.2405278, Time: 08_05_2022__21:41:38\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 2.0560179, Training accuracy: 0.2415110, Time: 08_05_2022__21:41:49\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 2.0534535, Training accuracy: 0.2425815, Time: 08_05_2022__21:42:01\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 2.0511335, Training accuracy: 0.2437634, Time: 08_05_2022__21:42:12\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 2.0487437, Training accuracy: 0.2448670, Time: 08_05_2022__21:42:23\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 2.0474317, Training accuracy: 0.2455263, Time: 08_05_2022__21:42:34\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 2.0444228, Training accuracy: 0.2467969, Time: 08_05_2022__21:42:45\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 2.0412467, Training accuracy: 0.2479897, Time: 08_05_2022__21:42:56\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 2.0381229, Training accuracy: 0.2493112, Time: 08_05_2022__21:43:07\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 2.0361023, Training accuracy: 0.2501515, Time: 08_05_2022__21:43:18\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 2.0344334, Training accuracy: 0.2505750, Time: 08_05_2022__21:43:30\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 2.0329440, Training accuracy: 0.2512871, Time: 08_05_2022__21:43:41\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 2.0303856, Training accuracy: 0.2523775, Time: 08_05_2022__21:43:52\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 2.0282577, Training accuracy: 0.2533981, Time: 08_05_2022__21:44:03\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 2.0251975, Training accuracy: 0.2548317, Time: 08_05_2022__21:44:14\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 2.0233776, Training accuracy: 0.2555952, Time: 08_05_2022__21:44:25\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 2.0209769, Training accuracy: 0.2563915, Time: 08_05_2022__21:44:36\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 2.0186579, Training accuracy: 0.2571028, Time: 08_05_2022__21:44:47\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 2.0161414, Training accuracy: 0.2582639, Time: 08_05_2022__21:44:59\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 2.0143038, Training accuracy: 0.2591284, Time: 08_05_2022__21:45:10\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 2.0127701, Training accuracy: 0.2595909, Time: 08_05_2022__21:45:21\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 2.0102551, Training accuracy: 0.2606081, Time: 08_05_2022__21:45:32\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 2.0082524, Training accuracy: 0.2610714, Time: 08_05_2022__21:45:43\n","Epoch 1 of 5, Average training loss: 2.0073254, Average training accuracy: 0.2612667, Time: 08_05_2022__21:45:49\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b1d295a87f14e81899eb2985d0833a9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.6936420, Validation accuracy: 0.3800000, Time: 08_05_2022__21:45:52 | Loss decreased from inf to 1.6941959 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.6719456, Validation accuracy: 0.3937500, Time: 08_05_2022__21:45:58 | Loss decreased from 1.6941959 to 1.6744291 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.6749294, Validation accuracy: 0.3858333, Time: 08_05_2022__21:46:04 | Loss decreased from 1.6744291 to 1.6739620 .... Saving the model\n","Step: 400 of 1250, Validation loss: 1.6865170, Validation accuracy: 0.3793750, Time: 08_05_2022__21:46:10\n","Step: 500 of 1250, Validation loss: 1.6972551, Validation accuracy: 0.3790000, Time: 08_05_2022__21:46:14\n","Step: 600 of 1250, Validation loss: 1.6909036, Validation accuracy: 0.3833333, Time: 08_05_2022__21:46:17\n","Step: 700 of 1250, Validation loss: 1.6862459, Validation accuracy: 0.3875000, Time: 08_05_2022__21:46:21\n","Step: 800 of 1250, Validation loss: 1.6814337, Validation accuracy: 0.3850000, Time: 08_05_2022__21:46:25\n","Step: 900 of 1250, Validation loss: 1.6825954, Validation accuracy: 0.3838889, Time: 08_05_2022__21:46:29\n","Step: 1000 of 1250, Validation loss: 1.6820180, Validation accuracy: 0.3817500, Time: 08_05_2022__21:46:32\n","Step: 1100 of 1250, Validation loss: 1.6862725, Validation accuracy: 0.3797727, Time: 08_05_2022__21:46:36\n","Step: 1200 of 1250, Validation loss: 1.6877622, Validation accuracy: 0.3820833, Time: 08_05_2022__21:46:40\n","Average validation loss: 1.6848709, Average validation accuracy: 0.3832000, Time: 08_05_2022__21:46:41\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be3b2bf0ba8b4c178074ec14dbdd3dfe"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.6209826, Training accuracy: 0.4250000, Time: 08_05_2022__21:46:53\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.6990699, Training accuracy: 0.3787500, Time: 08_05_2022__21:47:04\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.7349300, Training accuracy: 0.3658333, Time: 08_05_2022__21:47:15\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.7393780, Training accuracy: 0.3650000, Time: 08_05_2022__21:47:26\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.7352525, Training accuracy: 0.3635000, Time: 08_05_2022__21:47:37\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.7351786, Training accuracy: 0.3650000, Time: 08_05_2022__21:47:48\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.7463848, Training accuracy: 0.3635714, Time: 08_05_2022__21:47:59\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.7466068, Training accuracy: 0.3634375, Time: 08_05_2022__21:48:10\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.7451644, Training accuracy: 0.3616667, Time: 08_05_2022__21:48:21\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.7465495, Training accuracy: 0.3612500, Time: 08_05_2022__21:48:33\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.7472330, Training accuracy: 0.3615909, Time: 08_05_2022__21:48:44\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.7492230, Training accuracy: 0.3581250, Time: 08_05_2022__21:48:55\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.7475837, Training accuracy: 0.3601923, Time: 08_05_2022__21:49:06\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.7419542, Training accuracy: 0.3625000, Time: 08_05_2022__21:49:17\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.7414881, Training accuracy: 0.3631667, Time: 08_05_2022__21:49:28\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.7416874, Training accuracy: 0.3639062, Time: 08_05_2022__21:49:39\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.7420540, Training accuracy: 0.3638235, Time: 08_05_2022__21:49:50\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.7379570, Training accuracy: 0.3648611, Time: 08_05_2022__21:50:02\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.7367069, Training accuracy: 0.3648684, Time: 08_05_2022__21:50:13\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.7367191, Training accuracy: 0.3657500, Time: 08_05_2022__21:50:24\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.7336043, Training accuracy: 0.3672619, Time: 08_05_2022__21:50:35\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.7346707, Training accuracy: 0.3659091, Time: 08_05_2022__21:50:46\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.7319716, Training accuracy: 0.3670652, Time: 08_05_2022__21:50:57\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.7302387, Training accuracy: 0.3680208, Time: 08_05_2022__21:51:08\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.7257965, Training accuracy: 0.3705000, Time: 08_05_2022__21:51:19\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.7244060, Training accuracy: 0.3718269, Time: 08_05_2022__21:51:31\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.7231279, Training accuracy: 0.3717593, Time: 08_05_2022__21:51:42\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.7240963, Training accuracy: 0.3712500, Time: 08_05_2022__21:51:53\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.7241872, Training accuracy: 0.3706034, Time: 08_05_2022__21:52:04\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.7237742, Training accuracy: 0.3700833, Time: 08_05_2022__21:52:15\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.7206225, Training accuracy: 0.3711290, Time: 08_05_2022__21:52:26\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.7176925, Training accuracy: 0.3723437, Time: 08_05_2022__21:52:37\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.7200365, Training accuracy: 0.3720455, Time: 08_05_2022__21:52:48\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.7195283, Training accuracy: 0.3716176, Time: 08_05_2022__21:53:00\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.7186911, Training accuracy: 0.3718571, Time: 08_05_2022__21:53:11\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.7181186, Training accuracy: 0.3721528, Time: 08_05_2022__21:53:22\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.7188233, Training accuracy: 0.3716892, Time: 08_05_2022__21:53:33\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.7183380, Training accuracy: 0.3720395, Time: 08_05_2022__21:53:44\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.7182534, Training accuracy: 0.3719231, Time: 08_05_2022__21:53:55\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.7172629, Training accuracy: 0.3730625, Time: 08_05_2022__21:54:06\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.7176651, Training accuracy: 0.3726829, Time: 08_05_2022__21:54:17\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.7161632, Training accuracy: 0.3733333, Time: 08_05_2022__21:54:29\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.7161459, Training accuracy: 0.3730233, Time: 08_05_2022__21:54:40\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.7131545, Training accuracy: 0.3736932, Time: 08_05_2022__21:54:51\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.7108008, Training accuracy: 0.3750000, Time: 08_05_2022__21:55:02\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.7099612, Training accuracy: 0.3754348, Time: 08_05_2022__21:55:13\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.7084717, Training accuracy: 0.3761170, Time: 08_05_2022__21:55:24\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.7086879, Training accuracy: 0.3754688, Time: 08_05_2022__21:55:35\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.7087909, Training accuracy: 0.3753571, Time: 08_05_2022__21:55:47\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.7089842, Training accuracy: 0.3756000, Time: 08_05_2022__21:55:58\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.7066293, Training accuracy: 0.3766667, Time: 08_05_2022__21:56:09\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.7077686, Training accuracy: 0.3767788, Time: 08_05_2022__21:56:20\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.7063896, Training accuracy: 0.3768868, Time: 08_05_2022__21:56:32\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.7057805, Training accuracy: 0.3778241, Time: 08_05_2022__21:56:43\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.7041147, Training accuracy: 0.3783636, Time: 08_05_2022__21:56:54\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.7029054, Training accuracy: 0.3790625, Time: 08_05_2022__21:57:05\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.7023477, Training accuracy: 0.3794298, Time: 08_05_2022__21:57:16\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.7019532, Training accuracy: 0.3795690, Time: 08_05_2022__21:57:27\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.7012603, Training accuracy: 0.3801695, Time: 08_05_2022__21:57:39\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.7002769, Training accuracy: 0.3805417, Time: 08_05_2022__21:57:50\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.6998540, Training accuracy: 0.3806557, Time: 08_05_2022__21:58:01\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.6983724, Training accuracy: 0.3811694, Time: 08_05_2022__21:58:12\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.6983244, Training accuracy: 0.3811905, Time: 08_05_2022__21:58:23\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.6978006, Training accuracy: 0.3813281, Time: 08_05_2022__21:58:34\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.6960783, Training accuracy: 0.3822692, Time: 08_05_2022__21:58:45\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.6956513, Training accuracy: 0.3823106, Time: 08_05_2022__21:58:56\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.6951855, Training accuracy: 0.3816045, Time: 08_05_2022__21:59:08\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.6947488, Training accuracy: 0.3817279, Time: 08_05_2022__21:59:19\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.6934715, Training accuracy: 0.3818116, Time: 08_05_2022__21:59:30\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.6926368, Training accuracy: 0.3819643, Time: 08_05_2022__21:59:41\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.6919635, Training accuracy: 0.3819014, Time: 08_05_2022__21:59:52\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.6907229, Training accuracy: 0.3821875, Time: 08_05_2022__22:00:03\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.6901964, Training accuracy: 0.3817808, Time: 08_05_2022__22:00:14\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.6907451, Training accuracy: 0.3821284, Time: 08_05_2022__22:00:25\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.6910110, Training accuracy: 0.3822333, Time: 08_05_2022__22:00:37\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.6902379, Training accuracy: 0.3823684, Time: 08_05_2022__22:00:48\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.6896152, Training accuracy: 0.3828896, Time: 08_05_2022__22:00:59\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.6872651, Training accuracy: 0.3838782, Time: 08_05_2022__22:01:10\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.6860827, Training accuracy: 0.3843038, Time: 08_05_2022__22:01:21\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.6852038, Training accuracy: 0.3845000, Time: 08_05_2022__22:01:32\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.6845309, Training accuracy: 0.3847840, Time: 08_05_2022__22:01:43\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.6838339, Training accuracy: 0.3849390, Time: 08_05_2022__22:01:55\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.6827003, Training accuracy: 0.3853012, Time: 08_05_2022__22:02:06\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.6819636, Training accuracy: 0.3855060, Time: 08_05_2022__22:02:17\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.6807869, Training accuracy: 0.3861471, Time: 08_05_2022__22:02:28\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.6793062, Training accuracy: 0.3866279, Time: 08_05_2022__22:02:39\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.6783280, Training accuracy: 0.3867816, Time: 08_05_2022__22:02:50\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.6771394, Training accuracy: 0.3873011, Time: 08_05_2022__22:03:01\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.6759856, Training accuracy: 0.3876404, Time: 08_05_2022__22:03:12\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.6758459, Training accuracy: 0.3874444, Time: 08_05_2022__22:03:24\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.6749502, Training accuracy: 0.3878022, Time: 08_05_2022__22:03:35\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.6735882, Training accuracy: 0.3880978, Time: 08_05_2022__22:03:46\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.6727691, Training accuracy: 0.3883602, Time: 08_05_2022__22:03:57\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.6718244, Training accuracy: 0.3887234, Time: 08_05_2022__22:04:08\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.6726682, Training accuracy: 0.3887632, Time: 08_05_2022__22:04:19\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.6715467, Training accuracy: 0.3890885, Time: 08_05_2022__22:04:30\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.6698493, Training accuracy: 0.3898454, Time: 08_05_2022__22:04:42\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.6680638, Training accuracy: 0.3905357, Time: 08_05_2022__22:04:53\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.6676452, Training accuracy: 0.3906566, Time: 08_05_2022__22:05:04\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.6673372, Training accuracy: 0.3906500, Time: 08_05_2022__22:05:15\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.6676155, Training accuracy: 0.3907921, Time: 08_05_2022__22:05:26\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.6668977, Training accuracy: 0.3908333, Time: 08_05_2022__22:05:37\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.6662326, Training accuracy: 0.3911408, Time: 08_05_2022__22:05:49\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.6653893, Training accuracy: 0.3914183, Time: 08_05_2022__22:06:00\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.6651185, Training accuracy: 0.3917381, Time: 08_05_2022__22:06:11\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.6644558, Training accuracy: 0.3919575, Time: 08_05_2022__22:06:22\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.6639316, Training accuracy: 0.3920327, Time: 08_05_2022__22:06:33\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.6631837, Training accuracy: 0.3924074, Time: 08_05_2022__22:06:44\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.6627767, Training accuracy: 0.3930505, Time: 08_05_2022__22:06:55\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.6628643, Training accuracy: 0.3929773, Time: 08_05_2022__22:07:06\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.6616265, Training accuracy: 0.3935360, Time: 08_05_2022__22:07:18\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.6608008, Training accuracy: 0.3938393, Time: 08_05_2022__22:07:29\n","Epoch 2 of 5, Average training loss: 1.6606516, Average training accuracy: 0.3938000, Time: 08_05_2022__22:07:34\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b11743b4c5754e3d8c954b93082e7b73"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.4439490, Validation accuracy: 0.4875000, Time: 08_05_2022__22:07:38 | Loss decreased from 1.6739620 to 1.4438530 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.4447022, Validation accuracy: 0.4850000, Time: 08_05_2022__22:07:44\n","Step: 300 of 1250, Validation loss: 1.4755344, Validation accuracy: 0.4575000, Time: 08_05_2022__22:07:48\n","Step: 400 of 1250, Validation loss: 1.4828705, Validation accuracy: 0.4562500, Time: 08_05_2022__22:07:51\n","Step: 500 of 1250, Validation loss: 1.4886649, Validation accuracy: 0.4590000, Time: 08_05_2022__22:07:55\n","Step: 600 of 1250, Validation loss: 1.4867199, Validation accuracy: 0.4595833, Time: 08_05_2022__22:07:59\n","Step: 700 of 1250, Validation loss: 1.4792641, Validation accuracy: 0.4675000, Time: 08_05_2022__22:08:03\n","Step: 800 of 1250, Validation loss: 1.4748171, Validation accuracy: 0.4681250, Time: 08_05_2022__22:08:06\n","Step: 900 of 1250, Validation loss: 1.4772727, Validation accuracy: 0.4677778, Time: 08_05_2022__22:08:10\n","Step: 1000 of 1250, Validation loss: 1.4793878, Validation accuracy: 0.4650000, Time: 08_05_2022__22:08:14\n","Step: 1100 of 1250, Validation loss: 1.4819151, Validation accuracy: 0.4645455, Time: 08_05_2022__22:08:17\n","Step: 1200 of 1250, Validation loss: 1.4843657, Validation accuracy: 0.4620833, Time: 08_05_2022__22:08:21\n","Average validation loss: 1.4841712, Average validation accuracy: 0.4626000, Time: 08_05_2022__22:08:23\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b5c3645f433411e881c40973a725697"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.4863986, Training accuracy: 0.4600000, Time: 08_05_2022__22:08:34\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.5317882, Training accuracy: 0.4450000, Time: 08_05_2022__22:08:45\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.5543426, Training accuracy: 0.4366667, Time: 08_05_2022__22:08:56\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.5631483, Training accuracy: 0.4343750, Time: 08_05_2022__22:09:08\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.5649440, Training accuracy: 0.4280000, Time: 08_05_2022__22:09:19\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.5607295, Training accuracy: 0.4283333, Time: 08_05_2022__22:09:30\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.5727582, Training accuracy: 0.4228571, Time: 08_05_2022__22:09:41\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.5718270, Training accuracy: 0.4250000, Time: 08_05_2022__22:09:53\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.5672789, Training accuracy: 0.4291667, Time: 08_05_2022__22:10:04\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.5691795, Training accuracy: 0.4285000, Time: 08_05_2022__22:10:15\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.5674995, Training accuracy: 0.4315909, Time: 08_05_2022__22:10:26\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.5679125, Training accuracy: 0.4306250, Time: 08_05_2022__22:10:38\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.5645674, Training accuracy: 0.4334615, Time: 08_05_2022__22:10:49\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.5615064, Training accuracy: 0.4366071, Time: 08_05_2022__22:11:00\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.5652481, Training accuracy: 0.4340000, Time: 08_05_2022__22:11:11\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.5670014, Training accuracy: 0.4320312, Time: 08_05_2022__22:11:22\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.5682390, Training accuracy: 0.4320588, Time: 08_05_2022__22:11:34\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.5659898, Training accuracy: 0.4323611, Time: 08_05_2022__22:11:45\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.5651200, Training accuracy: 0.4319737, Time: 08_05_2022__22:11:56\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.5656334, Training accuracy: 0.4317500, Time: 08_05_2022__22:12:07\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.5638681, Training accuracy: 0.4328571, Time: 08_05_2022__22:12:19\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.5626786, Training accuracy: 0.4336364, Time: 08_05_2022__22:12:30\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.5624129, Training accuracy: 0.4334783, Time: 08_05_2022__22:12:41\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.5581664, Training accuracy: 0.4351042, Time: 08_05_2022__22:12:52\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.5545598, Training accuracy: 0.4370000, Time: 08_05_2022__22:13:03\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.5539878, Training accuracy: 0.4368269, Time: 08_05_2022__22:13:15\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.5518947, Training accuracy: 0.4376852, Time: 08_05_2022__22:13:26\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.5523349, Training accuracy: 0.4376786, Time: 08_05_2022__22:13:37\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.5542441, Training accuracy: 0.4363793, Time: 08_05_2022__22:13:48\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.5538723, Training accuracy: 0.4355833, Time: 08_05_2022__22:14:00\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.5506274, Training accuracy: 0.4362097, Time: 08_05_2022__22:14:11\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.5482349, Training accuracy: 0.4375781, Time: 08_05_2022__22:14:22\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.5494917, Training accuracy: 0.4378788, Time: 08_05_2022__22:14:33\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.5494422, Training accuracy: 0.4372059, Time: 08_05_2022__22:14:44\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.5475777, Training accuracy: 0.4379286, Time: 08_05_2022__22:14:56\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.5485594, Training accuracy: 0.4378472, Time: 08_05_2022__22:15:07\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.5500469, Training accuracy: 0.4366892, Time: 08_05_2022__22:15:18\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.5508029, Training accuracy: 0.4363816, Time: 08_05_2022__22:15:29\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.5490139, Training accuracy: 0.4368590, Time: 08_05_2022__22:15:41\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.5500668, Training accuracy: 0.4368125, Time: 08_05_2022__22:15:52\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.5527704, Training accuracy: 0.4362805, Time: 08_05_2022__22:16:03\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.5509113, Training accuracy: 0.4370238, Time: 08_05_2022__22:16:14\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.5511382, Training accuracy: 0.4358721, Time: 08_05_2022__22:16:25\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.5482959, Training accuracy: 0.4372727, Time: 08_05_2022__22:16:37\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.5461354, Training accuracy: 0.4378889, Time: 08_05_2022__22:16:48\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.5449077, Training accuracy: 0.4386957, Time: 08_05_2022__22:16:59\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.5440168, Training accuracy: 0.4389362, Time: 08_05_2022__22:17:10\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.5435606, Training accuracy: 0.4390104, Time: 08_05_2022__22:17:22\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.5438344, Training accuracy: 0.4387755, Time: 08_05_2022__22:17:33\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.5444534, Training accuracy: 0.4387500, Time: 08_05_2022__22:17:44\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.5427042, Training accuracy: 0.4393627, Time: 08_05_2022__22:17:55\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.5435691, Training accuracy: 0.4389904, Time: 08_05_2022__22:18:06\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.5420126, Training accuracy: 0.4398585, Time: 08_05_2022__22:18:18\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.5419564, Training accuracy: 0.4397222, Time: 08_05_2022__22:18:29\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.5416752, Training accuracy: 0.4396364, Time: 08_05_2022__22:18:40\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.5409105, Training accuracy: 0.4395536, Time: 08_05_2022__22:18:51\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.5403218, Training accuracy: 0.4398684, Time: 08_05_2022__22:19:03\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.5406277, Training accuracy: 0.4399138, Time: 08_05_2022__22:19:14\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.5408475, Training accuracy: 0.4396610, Time: 08_05_2022__22:19:25\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.5399217, Training accuracy: 0.4399583, Time: 08_05_2022__22:19:36\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.5402875, Training accuracy: 0.4396721, Time: 08_05_2022__22:19:47\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.5390338, Training accuracy: 0.4402823, Time: 08_05_2022__22:19:59\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.5394894, Training accuracy: 0.4399603, Time: 08_05_2022__22:20:10\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.5395444, Training accuracy: 0.4398437, Time: 08_05_2022__22:20:21\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.5388694, Training accuracy: 0.4405385, Time: 08_05_2022__22:20:32\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.5391486, Training accuracy: 0.4410227, Time: 08_05_2022__22:20:44\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.5389029, Training accuracy: 0.4404851, Time: 08_05_2022__22:20:55\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.5398527, Training accuracy: 0.4405147, Time: 08_05_2022__22:21:06\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.5390758, Training accuracy: 0.4410145, Time: 08_05_2022__22:21:17\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.5381523, Training accuracy: 0.4413571, Time: 08_05_2022__22:21:29\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.5377318, Training accuracy: 0.4411620, Time: 08_05_2022__22:21:40\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.5375325, Training accuracy: 0.4416667, Time: 08_05_2022__22:21:51\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.5373841, Training accuracy: 0.4416438, Time: 08_05_2022__22:22:02\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.5388224, Training accuracy: 0.4410473, Time: 08_05_2022__22:22:13\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.5391205, Training accuracy: 0.4409667, Time: 08_05_2022__22:22:25\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.5377757, Training accuracy: 0.4413487, Time: 08_05_2022__22:22:36\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.5372185, Training accuracy: 0.4415909, Time: 08_05_2022__22:22:47\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.5357157, Training accuracy: 0.4423397, Time: 08_05_2022__22:22:58\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.5354601, Training accuracy: 0.4421835, Time: 08_05_2022__22:23:10\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.5354336, Training accuracy: 0.4420000, Time: 08_05_2022__22:23:21\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.5353177, Training accuracy: 0.4418519, Time: 08_05_2022__22:23:32\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.5351664, Training accuracy: 0.4416159, Time: 08_05_2022__22:23:43\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.5339184, Training accuracy: 0.4427410, Time: 08_05_2022__22:23:55\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.5339241, Training accuracy: 0.4428274, Time: 08_05_2022__22:24:06\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.5337343, Training accuracy: 0.4428235, Time: 08_05_2022__22:24:17\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.5331538, Training accuracy: 0.4430233, Time: 08_05_2022__22:24:28\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.5328498, Training accuracy: 0.4435057, Time: 08_05_2022__22:24:40\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.5317127, Training accuracy: 0.4442045, Time: 08_05_2022__22:24:51\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 1.5305774, Training accuracy: 0.4445787, Time: 08_05_2022__22:25:02\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 1.5304963, Training accuracy: 0.4446389, Time: 08_05_2022__22:25:13\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 1.5298384, Training accuracy: 0.4449725, Time: 08_05_2022__22:25:24\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 1.5287257, Training accuracy: 0.4455978, Time: 08_05_2022__22:25:36\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 1.5286190, Training accuracy: 0.4457258, Time: 08_05_2022__22:25:47\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 1.5284316, Training accuracy: 0.4457447, Time: 08_05_2022__22:25:58\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 1.5292503, Training accuracy: 0.4457632, Time: 08_05_2022__22:26:09\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 1.5280359, Training accuracy: 0.4459896, Time: 08_05_2022__22:26:21\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 1.5264196, Training accuracy: 0.4465464, Time: 08_05_2022__22:26:32\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 1.5248951, Training accuracy: 0.4473214, Time: 08_05_2022__22:26:43\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 1.5245762, Training accuracy: 0.4473485, Time: 08_05_2022__22:26:54\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 1.5239664, Training accuracy: 0.4476750, Time: 08_05_2022__22:27:05\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 1.5244379, Training accuracy: 0.4475743, Time: 08_05_2022__22:27:17\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 1.5241127, Training accuracy: 0.4476716, Time: 08_05_2022__22:27:28\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 1.5237479, Training accuracy: 0.4476456, Time: 08_05_2022__22:27:39\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 1.5228420, Training accuracy: 0.4483413, Time: 08_05_2022__22:27:50\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 1.5229288, Training accuracy: 0.4483333, Time: 08_05_2022__22:28:01\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 1.5227076, Training accuracy: 0.4485613, Time: 08_05_2022__22:28:12\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 1.5221590, Training accuracy: 0.4482944, Time: 08_05_2022__22:28:23\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 1.5218663, Training accuracy: 0.4483333, Time: 08_05_2022__22:28:35\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 1.5218766, Training accuracy: 0.4485092, Time: 08_05_2022__22:28:46\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 1.5215350, Training accuracy: 0.4489091, Time: 08_05_2022__22:28:57\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 1.5207797, Training accuracy: 0.4490090, Time: 08_05_2022__22:29:08\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 1.5207237, Training accuracy: 0.4491741, Time: 08_05_2022__22:29:19\n","Epoch 3 of 5, Average training loss: 1.5208599, Average training accuracy: 0.4489333, Time: 08_05_2022__22:29:25\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df55a6f6d4644f6a882d4ce6762c89a3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.3187813, Validation accuracy: 0.5275000, Time: 08_05_2022__22:29:28 | Loss decreased from 1.4438530 to 1.3170544 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.3275116, Validation accuracy: 0.5325000, Time: 08_05_2022__22:29:34\n","Step: 300 of 1250, Validation loss: 1.3513214, Validation accuracy: 0.5058333, Time: 08_05_2022__22:29:38\n","Step: 400 of 1250, Validation loss: 1.3510828, Validation accuracy: 0.5118750, Time: 08_05_2022__22:29:42\n","Step: 500 of 1250, Validation loss: 1.3522309, Validation accuracy: 0.5140000, Time: 08_05_2022__22:29:46\n","Step: 600 of 1250, Validation loss: 1.3445965, Validation accuracy: 0.5179167, Time: 08_05_2022__22:29:49\n","Step: 700 of 1250, Validation loss: 1.3362123, Validation accuracy: 0.5228571, Time: 08_05_2022__22:29:53\n","Step: 800 of 1250, Validation loss: 1.3339734, Validation accuracy: 0.5209375, Time: 08_05_2022__22:29:57\n","Step: 900 of 1250, Validation loss: 1.3371530, Validation accuracy: 0.5200000, Time: 08_05_2022__22:30:00\n","Step: 1000 of 1250, Validation loss: 1.3417424, Validation accuracy: 0.5152500, Time: 08_05_2022__22:30:04\n","Step: 1100 of 1250, Validation loss: 1.3422178, Validation accuracy: 0.5168182, Time: 08_05_2022__22:30:08\n","Step: 1200 of 1250, Validation loss: 1.3463394, Validation accuracy: 0.5141667, Time: 08_05_2022__22:30:11\n","Average validation loss: 1.3453388, Average validation accuracy: 0.5158000, Time: 08_05_2022__22:30:13\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f71884cc8b7e4c70b151a5081627926b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 1.3557437, Training accuracy: 0.5225000, Time: 08_05_2022__22:30:24\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 1.3946368, Training accuracy: 0.4987500, Time: 08_05_2022__22:30:36\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 1.4425763, Training accuracy: 0.4733333, Time: 08_05_2022__22:30:47\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 1.4390734, Training accuracy: 0.4693750, Time: 08_05_2022__22:30:58\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 1.4393254, Training accuracy: 0.4690000, Time: 08_05_2022__22:31:09\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 1.4357472, Training accuracy: 0.4700000, Time: 08_05_2022__22:31:20\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 1.4483609, Training accuracy: 0.4703571, Time: 08_05_2022__22:31:31\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 1.4469130, Training accuracy: 0.4734375, Time: 08_05_2022__22:31:42\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 1.4463462, Training accuracy: 0.4775000, Time: 08_05_2022__22:31:54\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 1.4474389, Training accuracy: 0.4777500, Time: 08_05_2022__22:32:05\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 1.4453777, Training accuracy: 0.4790909, Time: 08_05_2022__22:32:16\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 1.4457478, Training accuracy: 0.4791667, Time: 08_05_2022__22:32:27\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 1.4479358, Training accuracy: 0.4796154, Time: 08_05_2022__22:32:38\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 1.4472583, Training accuracy: 0.4801786, Time: 08_05_2022__22:32:49\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 1.4477496, Training accuracy: 0.4785000, Time: 08_05_2022__22:33:00\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 1.4472262, Training accuracy: 0.4778125, Time: 08_05_2022__22:33:11\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 1.4478234, Training accuracy: 0.4755882, Time: 08_05_2022__22:33:22\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 1.4469957, Training accuracy: 0.4751389, Time: 08_05_2022__22:33:34\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 1.4474755, Training accuracy: 0.4764474, Time: 08_05_2022__22:33:45\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 1.4507487, Training accuracy: 0.4755000, Time: 08_05_2022__22:33:56\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 1.4500235, Training accuracy: 0.4748810, Time: 08_05_2022__22:34:07\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 1.4497446, Training accuracy: 0.4752273, Time: 08_05_2022__22:34:18\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 1.4495906, Training accuracy: 0.4750000, Time: 08_05_2022__22:34:29\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 1.4457293, Training accuracy: 0.4757292, Time: 08_05_2022__22:34:40\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 1.4436458, Training accuracy: 0.4765000, Time: 08_05_2022__22:34:52\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 1.4438759, Training accuracy: 0.4768269, Time: 08_05_2022__22:35:03\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 1.4415264, Training accuracy: 0.4781481, Time: 08_05_2022__22:35:14\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 1.4415725, Training accuracy: 0.4777679, Time: 08_05_2022__22:35:25\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 1.4405683, Training accuracy: 0.4785345, Time: 08_05_2022__22:35:36\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 1.4412581, Training accuracy: 0.4786667, Time: 08_05_2022__22:35:47\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 1.4387103, Training accuracy: 0.4784677, Time: 08_05_2022__22:35:58\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 1.4362087, Training accuracy: 0.4793750, Time: 08_05_2022__22:36:09\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 1.4380893, Training accuracy: 0.4790909, Time: 08_05_2022__22:36:21\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 1.4376796, Training accuracy: 0.4786765, Time: 08_05_2022__22:36:32\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 1.4362518, Training accuracy: 0.4795714, Time: 08_05_2022__22:36:43\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 1.4380475, Training accuracy: 0.4779861, Time: 08_05_2022__22:36:54\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 1.4396068, Training accuracy: 0.4779054, Time: 08_05_2022__22:37:05\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 1.4381353, Training accuracy: 0.4787500, Time: 08_05_2022__22:37:16\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 1.4369677, Training accuracy: 0.4796795, Time: 08_05_2022__22:37:27\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 1.4363316, Training accuracy: 0.4797500, Time: 08_05_2022__22:37:39\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 1.4377391, Training accuracy: 0.4790244, Time: 08_05_2022__22:37:50\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 1.4353345, Training accuracy: 0.4802381, Time: 08_05_2022__22:38:01\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 1.4345344, Training accuracy: 0.4798837, Time: 08_05_2022__22:38:12\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 1.4329430, Training accuracy: 0.4802841, Time: 08_05_2022__22:38:23\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 1.4308479, Training accuracy: 0.4809444, Time: 08_05_2022__22:38:34\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 1.4309397, Training accuracy: 0.4811957, Time: 08_05_2022__22:38:45\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 1.4307719, Training accuracy: 0.4816489, Time: 08_05_2022__22:38:56\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 1.4298329, Training accuracy: 0.4821354, Time: 08_05_2022__22:39:08\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 1.4298462, Training accuracy: 0.4820918, Time: 08_05_2022__22:39:19\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 1.4303809, Training accuracy: 0.4821500, Time: 08_05_2022__22:39:30\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 1.4291430, Training accuracy: 0.4830392, Time: 08_05_2022__22:39:41\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 1.4291073, Training accuracy: 0.4828365, Time: 08_05_2022__22:39:52\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 1.4284385, Training accuracy: 0.4836321, Time: 08_05_2022__22:40:03\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 1.4284694, Training accuracy: 0.4837500, Time: 08_05_2022__22:40:14\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 1.4289869, Training accuracy: 0.4840000, Time: 08_05_2022__22:40:25\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 1.4283695, Training accuracy: 0.4841964, Time: 08_05_2022__22:40:37\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 1.4285657, Training accuracy: 0.4839474, Time: 08_05_2022__22:40:48\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 1.4276708, Training accuracy: 0.4846552, Time: 08_05_2022__22:40:59\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 1.4276299, Training accuracy: 0.4846610, Time: 08_05_2022__22:41:10\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 1.4267285, Training accuracy: 0.4851250, Time: 08_05_2022__22:41:21\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 1.4268322, Training accuracy: 0.4856148, Time: 08_05_2022__22:41:32\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 1.4256391, Training accuracy: 0.4859274, Time: 08_05_2022__22:41:43\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 1.4255510, Training accuracy: 0.4857540, Time: 08_05_2022__22:41:55\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 1.4249584, Training accuracy: 0.4858594, Time: 08_05_2022__22:42:06\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 1.4236877, Training accuracy: 0.4863846, Time: 08_05_2022__22:42:17\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 1.4241708, Training accuracy: 0.4861364, Time: 08_05_2022__22:42:28\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 1.4233418, Training accuracy: 0.4860448, Time: 08_05_2022__22:42:39\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 1.4239653, Training accuracy: 0.4854044, Time: 08_05_2022__22:42:50\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 1.4229012, Training accuracy: 0.4859058, Time: 08_05_2022__22:43:01\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 1.4212065, Training accuracy: 0.4870714, Time: 08_05_2022__22:43:12\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 1.4217267, Training accuracy: 0.4866197, Time: 08_05_2022__22:43:24\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 1.4211138, Training accuracy: 0.4865278, Time: 08_05_2022__22:43:35\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 1.4207650, Training accuracy: 0.4867808, Time: 08_05_2022__22:43:46\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 1.4216535, Training accuracy: 0.4861824, Time: 08_05_2022__22:43:57\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 1.4217177, Training accuracy: 0.4861667, Time: 08_05_2022__22:44:08\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 1.4211602, Training accuracy: 0.4860526, Time: 08_05_2022__22:44:19\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 1.4207097, Training accuracy: 0.4866558, Time: 08_05_2022__22:44:30\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 1.4190685, Training accuracy: 0.4873397, Time: 08_05_2022__22:44:42\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 1.4181384, Training accuracy: 0.4875000, Time: 08_05_2022__22:44:53\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 1.4171342, Training accuracy: 0.4876875, Time: 08_05_2022__22:45:04\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 1.4167612, Training accuracy: 0.4875309, Time: 08_05_2022__22:45:15\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 1.4165365, Training accuracy: 0.4873171, Time: 08_05_2022__22:45:26\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 1.4157703, Training accuracy: 0.4877711, Time: 08_05_2022__22:45:37\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 1.4156592, Training accuracy: 0.4875298, Time: 08_05_2022__22:45:48\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 1.4152200, Training accuracy: 0.4875882, Time: 08_05_2022__22:45:59\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 1.4142142, Training accuracy: 0.4881105, Time: 08_05_2022__22:46:11\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 1.4137291, Training accuracy: 0.4884195, Time: 08_05_2022__22:46:22\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 1.4130676, Training accuracy: 0.4884659, Time: 08_05_2022__22:46:33\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 1.4122782, Training accuracy: 0.4888202, Time: 08_05_2022__22:46:44\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 1.4122215, Training accuracy: 0.4888889, Time: 08_05_2022__22:46:55\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 1.4116835, Training accuracy: 0.4890110, Time: 08_05_2022__22:47:06\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 1.4102756, Training accuracy: 0.4897011, Time: 08_05_2022__22:47:17\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 1.4100795, Training accuracy: 0.4897312, Time: 08_05_2022__22:47:28\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 1.4097757, Training accuracy: 0.4899202, Time: 08_05_2022__22:47:40\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 1.4112270, Training accuracy: 0.4892368, Time: 08_05_2022__22:47:51\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 1.4100430, Training accuracy: 0.4895833, Time: 08_05_2022__22:48:02\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 1.4082833, Training accuracy: 0.4904381, Time: 08_05_2022__22:48:13\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 1.4068162, Training accuracy: 0.4908673, Time: 08_05_2022__22:48:24\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 1.4066969, Training accuracy: 0.4909091, Time: 08_05_2022__22:48:35\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 1.4063849, Training accuracy: 0.4909000, Time: 08_05_2022__22:48:46\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 1.4071522, Training accuracy: 0.4909653, Time: 08_05_2022__22:48:57\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 1.4067614, Training accuracy: 0.4909559, Time: 08_05_2022__22:49:09\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 1.4066845, Training accuracy: 0.4910680, Time: 08_05_2022__22:49:20\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 1.4062109, Training accuracy: 0.4914904, Time: 08_05_2022__22:49:31\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 1.4064236, Training accuracy: 0.4913333, Time: 08_05_2022__22:49:42\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 1.4062055, Training accuracy: 0.4914151, Time: 08_05_2022__22:49:53\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 1.4055793, Training accuracy: 0.4914486, Time: 08_05_2022__22:50:04\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 1.4049346, Training accuracy: 0.4918287, Time: 08_05_2022__22:50:15\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 1.4050488, Training accuracy: 0.4920183, Time: 08_05_2022__22:50:26\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 1.4053095, Training accuracy: 0.4919091, Time: 08_05_2022__22:50:38\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 1.4042977, Training accuracy: 0.4921622, Time: 08_05_2022__22:50:49\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 1.4038365, Training accuracy: 0.4924330, Time: 08_05_2022__22:51:00\n","Epoch 4 of 5, Average training loss: 1.4040401, Average training accuracy: 0.4924444, Time: 08_05_2022__22:51:05\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbce709588074412b0bf8265b905f098"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.2360900, Validation accuracy: 0.5600000, Time: 08_05_2022__22:51:09 | Loss decreased from 1.3170544 to 1.2339666 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.2490862, Validation accuracy: 0.5537500, Time: 08_05_2022__22:51:15\n","Step: 300 of 1250, Validation loss: 1.2606144, Validation accuracy: 0.5333333, Time: 08_05_2022__22:51:19\n","Step: 400 of 1250, Validation loss: 1.2603388, Validation accuracy: 0.5393750, Time: 08_05_2022__22:51:22\n","Step: 500 of 1250, Validation loss: 1.2637572, Validation accuracy: 0.5420000, Time: 08_05_2022__22:51:26\n","Step: 600 of 1250, Validation loss: 1.2636213, Validation accuracy: 0.5475000, Time: 08_05_2022__22:51:30\n","Step: 700 of 1250, Validation loss: 1.2544845, Validation accuracy: 0.5525000, Time: 08_05_2022__22:51:34\n","Step: 800 of 1250, Validation loss: 1.2480114, Validation accuracy: 0.5543750, Time: 08_05_2022__22:51:37\n","Step: 900 of 1250, Validation loss: 1.2526912, Validation accuracy: 0.5541667, Time: 08_05_2022__22:51:41\n","Step: 1000 of 1250, Validation loss: 1.2610155, Validation accuracy: 0.5462500, Time: 08_05_2022__22:51:45\n","Step: 1100 of 1250, Validation loss: 1.2621917, Validation accuracy: 0.5468182, Time: 08_05_2022__22:51:48\n","Step: 1200 of 1250, Validation loss: 1.2670348, Validation accuracy: 0.5452083, Time: 08_05_2022__22:51:52\n","Average validation loss: 1.2671687, Average validation accuracy: 0.5458000, Time: 08_05_2022__22:51:54\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"060cfaef6eb2492aab15e41f6bea90e4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 1.2552732, Training accuracy: 0.5325000, Time: 08_05_2022__22:52:05\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 1.2942280, Training accuracy: 0.5150000, Time: 08_05_2022__22:52:16\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 1.3284818, Training accuracy: 0.5058333, Time: 08_05_2022__22:52:27\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 1.3187831, Training accuracy: 0.5062500, Time: 08_05_2022__22:52:38\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 1.3216896, Training accuracy: 0.5045000, Time: 08_05_2022__22:52:49\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 1.3180126, Training accuracy: 0.5116667, Time: 08_05_2022__22:53:01\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 1.3313692, Training accuracy: 0.5096429, Time: 08_05_2022__22:53:12\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 1.3251190, Training accuracy: 0.5118750, Time: 08_05_2022__22:53:23\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 1.3320143, Training accuracy: 0.5116667, Time: 08_05_2022__22:53:34\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 1.3353984, Training accuracy: 0.5125000, Time: 08_05_2022__22:53:45\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 1.3355157, Training accuracy: 0.5122727, Time: 08_05_2022__22:53:56\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 1.3384892, Training accuracy: 0.5114583, Time: 08_05_2022__22:54:07\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 1.3382254, Training accuracy: 0.5100000, Time: 08_05_2022__22:54:18\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 1.3351201, Training accuracy: 0.5123214, Time: 08_05_2022__22:54:30\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 1.3384609, Training accuracy: 0.5110000, Time: 08_05_2022__22:54:41\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 1.3372032, Training accuracy: 0.5109375, Time: 08_05_2022__22:54:52\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 1.3384518, Training accuracy: 0.5127941, Time: 08_05_2022__22:55:03\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 1.3390232, Training accuracy: 0.5127778, Time: 08_05_2022__22:55:14\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 1.3376010, Training accuracy: 0.5131579, Time: 08_05_2022__22:55:25\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 1.3395961, Training accuracy: 0.5125000, Time: 08_05_2022__22:55:36\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 1.3395201, Training accuracy: 0.5126190, Time: 08_05_2022__22:55:47\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 1.3382086, Training accuracy: 0.5143182, Time: 08_05_2022__22:55:59\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 1.3351616, Training accuracy: 0.5160870, Time: 08_05_2022__22:56:10\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 1.3312787, Training accuracy: 0.5161458, Time: 08_05_2022__22:56:21\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 1.3303648, Training accuracy: 0.5168000, Time: 08_05_2022__22:56:32\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 1.3297416, Training accuracy: 0.5179808, Time: 08_05_2022__22:56:43\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 1.3264830, Training accuracy: 0.5198148, Time: 08_05_2022__22:56:54\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 1.3296460, Training accuracy: 0.5182143, Time: 08_05_2022__22:57:05\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 1.3297770, Training accuracy: 0.5187069, Time: 08_05_2022__22:57:16\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 1.3302791, Training accuracy: 0.5183333, Time: 08_05_2022__22:57:28\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 1.3285722, Training accuracy: 0.5187097, Time: 08_05_2022__22:57:39\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 1.3259679, Training accuracy: 0.5198438, Time: 08_05_2022__22:57:50\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 1.3272387, Training accuracy: 0.5191667, Time: 08_05_2022__22:58:01\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 1.3276850, Training accuracy: 0.5186029, Time: 08_05_2022__22:58:12\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 1.3267932, Training accuracy: 0.5192143, Time: 08_05_2022__22:58:23\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 1.3284967, Training accuracy: 0.5186111, Time: 08_05_2022__22:58:34\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 1.3301678, Training accuracy: 0.5179054, Time: 08_05_2022__22:58:45\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 1.3300257, Training accuracy: 0.5181579, Time: 08_05_2022__22:58:57\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 1.3284989, Training accuracy: 0.5182692, Time: 08_05_2022__22:59:08\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 1.3270574, Training accuracy: 0.5187500, Time: 08_05_2022__22:59:19\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 1.3285404, Training accuracy: 0.5187805, Time: 08_05_2022__22:59:30\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 1.3253252, Training accuracy: 0.5202976, Time: 08_05_2022__22:59:41\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 1.3242820, Training accuracy: 0.5206977, Time: 08_05_2022__22:59:52\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 1.3223506, Training accuracy: 0.5213636, Time: 08_05_2022__23:00:04\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 1.3210848, Training accuracy: 0.5216667, Time: 08_05_2022__23:00:15\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 1.3208381, Training accuracy: 0.5223913, Time: 08_05_2022__23:00:26\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 1.3212049, Training accuracy: 0.5227660, Time: 08_05_2022__23:00:37\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 1.3209484, Training accuracy: 0.5228125, Time: 08_05_2022__23:00:48\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 1.3204780, Training accuracy: 0.5226020, Time: 08_05_2022__23:00:59\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 1.3212487, Training accuracy: 0.5228000, Time: 08_05_2022__23:01:10\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 1.3199837, Training accuracy: 0.5235784, Time: 08_05_2022__23:01:21\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 1.3203689, Training accuracy: 0.5240385, Time: 08_05_2022__23:01:33\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 1.3194823, Training accuracy: 0.5244340, Time: 08_05_2022__23:01:44\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 1.3197445, Training accuracy: 0.5238426, Time: 08_05_2022__23:01:55\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 1.3205748, Training accuracy: 0.5232273, Time: 08_05_2022__23:02:06\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 1.3201198, Training accuracy: 0.5234375, Time: 08_05_2022__23:02:17\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 1.3200210, Training accuracy: 0.5234649, Time: 08_05_2022__23:02:28\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 1.3194112, Training accuracy: 0.5239655, Time: 08_05_2022__23:02:39\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 1.3195963, Training accuracy: 0.5242373, Time: 08_05_2022__23:02:51\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 1.3191501, Training accuracy: 0.5245417, Time: 08_05_2022__23:03:02\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 1.3193832, Training accuracy: 0.5244672, Time: 08_05_2022__23:03:13\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 1.3182211, Training accuracy: 0.5252419, Time: 08_05_2022__23:03:24\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 1.3184294, Training accuracy: 0.5253968, Time: 08_05_2022__23:03:35\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 1.3181233, Training accuracy: 0.5255859, Time: 08_05_2022__23:03:46\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 1.3176215, Training accuracy: 0.5262308, Time: 08_05_2022__23:03:57\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 1.3174960, Training accuracy: 0.5268182, Time: 08_05_2022__23:04:08\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 1.3167052, Training accuracy: 0.5267537, Time: 08_05_2022__23:04:20\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 1.3174043, Training accuracy: 0.5262500, Time: 08_05_2022__23:04:31\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 1.3163401, Training accuracy: 0.5267391, Time: 08_05_2022__23:04:42\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 1.3154583, Training accuracy: 0.5272143, Time: 08_05_2022__23:04:53\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 1.3157295, Training accuracy: 0.5268662, Time: 08_05_2022__23:05:04\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 1.3150889, Training accuracy: 0.5267361, Time: 08_05_2022__23:05:15\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 1.3147878, Training accuracy: 0.5270890, Time: 08_05_2022__23:05:26\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 1.3157119, Training accuracy: 0.5267568, Time: 08_05_2022__23:05:37\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 1.3157057, Training accuracy: 0.5264667, Time: 08_05_2022__23:05:49\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 1.3149863, Training accuracy: 0.5265789, Time: 08_05_2022__23:06:00\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 1.3154039, Training accuracy: 0.5266234, Time: 08_05_2022__23:06:11\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 1.3139859, Training accuracy: 0.5271154, Time: 08_05_2022__23:06:22\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 1.3134784, Training accuracy: 0.5271835, Time: 08_05_2022__23:06:33\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 1.3130994, Training accuracy: 0.5269375, Time: 08_05_2022__23:06:44\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 1.3128335, Training accuracy: 0.5271605, Time: 08_05_2022__23:06:55\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 1.3129579, Training accuracy: 0.5272866, Time: 08_05_2022__23:07:07\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 1.3126707, Training accuracy: 0.5274398, Time: 08_05_2022__23:07:18\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 1.3123421, Training accuracy: 0.5274702, Time: 08_05_2022__23:07:29\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 1.3123235, Training accuracy: 0.5279412, Time: 08_05_2022__23:07:40\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 1.3113381, Training accuracy: 0.5285465, Time: 08_05_2022__23:07:51\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 1.3110601, Training accuracy: 0.5286207, Time: 08_05_2022__23:08:02\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 1.3096324, Training accuracy: 0.5292898, Time: 08_05_2022__23:08:13\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 1.3089165, Training accuracy: 0.5296910, Time: 08_05_2022__23:08:24\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 1.3088244, Training accuracy: 0.5298056, Time: 08_05_2022__23:08:36\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 1.3087394, Training accuracy: 0.5299176, Time: 08_05_2022__23:08:47\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 1.3076371, Training accuracy: 0.5306522, Time: 08_05_2022__23:08:58\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 1.3075119, Training accuracy: 0.5306452, Time: 08_05_2022__23:09:09\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 1.3074587, Training accuracy: 0.5307713, Time: 08_05_2022__23:09:20\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 1.3084628, Training accuracy: 0.5303421, Time: 08_05_2022__23:09:31\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 1.3072217, Training accuracy: 0.5308594, Time: 08_05_2022__23:09:42\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 1.3057308, Training accuracy: 0.5314691, Time: 08_05_2022__23:09:53\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 1.3046535, Training accuracy: 0.5321429, Time: 08_05_2022__23:10:05\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 1.3046938, Training accuracy: 0.5320455, Time: 08_05_2022__23:10:16\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 1.3045651, Training accuracy: 0.5320500, Time: 08_05_2022__23:10:27\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 1.3046503, Training accuracy: 0.5320545, Time: 08_05_2022__23:10:38\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 1.3039742, Training accuracy: 0.5323284, Time: 08_05_2022__23:10:49\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 1.3037405, Training accuracy: 0.5322330, Time: 08_05_2022__23:11:00\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 1.3033020, Training accuracy: 0.5324279, Time: 08_05_2022__23:11:11\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 1.3031521, Training accuracy: 0.5325238, Time: 08_05_2022__23:11:23\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 1.3032599, Training accuracy: 0.5324292, Time: 08_05_2022__23:11:34\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 1.3026426, Training accuracy: 0.5324065, Time: 08_05_2022__23:11:45\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 1.3022010, Training accuracy: 0.5326852, Time: 08_05_2022__23:11:56\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 1.3024983, Training accuracy: 0.5327523, Time: 08_05_2022__23:12:07\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 1.3026548, Training accuracy: 0.5328409, Time: 08_05_2022__23:12:18\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 1.3018193, Training accuracy: 0.5330856, Time: 08_05_2022__23:12:29\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 1.3012986, Training accuracy: 0.5333705, Time: 08_05_2022__23:12:40\n","Epoch 5 of 5, Average training loss: 1.3012249, Average training accuracy: 0.5332222, Time: 08_05_2022__23:12:46\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56c6090e3a464d46a99f8e8b4f603538"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.2200149, Validation accuracy: 0.5525000, Time: 08_05_2022__23:12:50 | Loss decreased from 1.2339666 to 1.2198842 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.2076956, Validation accuracy: 0.5600000, Time: 08_05_2022__23:12:55 | Loss decreased from 1.2198842 to 1.2094059 .... Saving the model\n","Step: 300 of 1250, Validation loss: 1.2143009, Validation accuracy: 0.5508333, Time: 08_05_2022__23:13:01\n","Step: 400 of 1250, Validation loss: 1.2011580, Validation accuracy: 0.5587500, Time: 08_05_2022__23:13:05 | Loss decreased from 1.2094059 to 1.1986914 .... Saving the model\n","Step: 500 of 1250, Validation loss: 1.2059286, Validation accuracy: 0.5620000, Time: 08_05_2022__23:13:11\n","Step: 600 of 1250, Validation loss: 1.1982071, Validation accuracy: 0.5633333, Time: 08_05_2022__23:13:14\n","Step: 700 of 1250, Validation loss: 1.1844929, Validation accuracy: 0.5703571, Time: 08_05_2022__23:13:18 | Loss decreased from 1.1986914 to 1.1849498 .... Saving the model\n","Step: 800 of 1250, Validation loss: 1.1827721, Validation accuracy: 0.5696875, Time: 08_05_2022__23:13:25 | Loss decreased from 1.1849498 to 1.1830462 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.1878394, Validation accuracy: 0.5702778, Time: 08_05_2022__23:13:30\n","Step: 1000 of 1250, Validation loss: 1.1958505, Validation accuracy: 0.5640000, Time: 08_05_2022__23:13:34\n","Step: 1100 of 1250, Validation loss: 1.1979086, Validation accuracy: 0.5622727, Time: 08_05_2022__23:13:38\n","Step: 1200 of 1250, Validation loss: 1.2038883, Validation accuracy: 0.5614583, Time: 08_05_2022__23:13:42\n","Average validation loss: 1.2053411, Average validation accuracy: 0.5616000, Time: 08_05_2022__23:13:44\n","###################### Testing vgg19_batch_norm SGD, lr_0.0001, momentum_0.6 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dabd6b2acd70417b90a517c19de95bae"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.5425000, Time: 08_05_2022__23:13:56\n","Step: 200 of 2500, Test accuracy: 0.5425000, Time: 08_05_2022__23:13:59\n","Step: 300 of 2500, Test accuracy: 0.5616667, Time: 08_05_2022__23:14:03\n","Step: 400 of 2500, Test accuracy: 0.5568750, Time: 08_05_2022__23:14:07\n","Step: 500 of 2500, Test accuracy: 0.5610000, Time: 08_05_2022__23:14:10\n","Step: 600 of 2500, Test accuracy: 0.5629167, Time: 08_05_2022__23:14:14\n","Step: 700 of 2500, Test accuracy: 0.5589286, Time: 08_05_2022__23:14:18\n","Step: 800 of 2500, Test accuracy: 0.5612500, Time: 08_05_2022__23:14:21\n","Step: 900 of 2500, Test accuracy: 0.5622222, Time: 08_05_2022__23:14:25\n","Step: 1000 of 2500, Test accuracy: 0.5595000, Time: 08_05_2022__23:14:29\n","Step: 1100 of 2500, Test accuracy: 0.5631818, Time: 08_05_2022__23:14:32\n","Step: 1200 of 2500, Test accuracy: 0.5666667, Time: 08_05_2022__23:14:36\n","Step: 1300 of 2500, Test accuracy: 0.5678846, Time: 08_05_2022__23:14:40\n","Step: 1400 of 2500, Test accuracy: 0.5655357, Time: 08_05_2022__23:14:43\n","Step: 1500 of 2500, Test accuracy: 0.5681667, Time: 08_05_2022__23:14:47\n","Step: 1600 of 2500, Test accuracy: 0.5693750, Time: 08_05_2022__23:14:51\n","Step: 1700 of 2500, Test accuracy: 0.5689706, Time: 08_05_2022__23:14:54\n","Step: 1800 of 2500, Test accuracy: 0.5675000, Time: 08_05_2022__23:14:58\n","Step: 1900 of 2500, Test accuracy: 0.5650000, Time: 08_05_2022__23:15:01\n","Step: 2000 of 2500, Test accuracy: 0.5643750, Time: 08_05_2022__23:15:05\n","Step: 2100 of 2500, Test accuracy: 0.5641667, Time: 08_05_2022__23:15:09\n","Step: 2200 of 2500, Test accuracy: 0.5630682, Time: 08_05_2022__23:15:12\n","Step: 2300 of 2500, Test accuracy: 0.5631522, Time: 08_05_2022__23:15:16\n","Step: 2400 of 2500, Test accuracy: 0.5638542, Time: 08_05_2022__23:15:20\n","Step: 2500 of 2500, Test accuracy: 0.5625000, Time: 08_05_2022__23:15:23\n","Average testing accuracy: 0.5625000, Time: 08_05_2022__23:15:23\n","###################### Training vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model for 5 epochs ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c80750836ad465d846009a69e5d37b1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 of 5, Step: 100 of 11250, Training loss: 2.4949261, Training accuracy: 0.0925000, Time: 08_05_2022__23:15:37\n","Epoch 1 of 5, Step: 200 of 11250, Training loss: 2.4647323, Training accuracy: 0.1150000, Time: 08_05_2022__23:15:48\n","Epoch 1 of 5, Step: 300 of 11250, Training loss: 2.4418227, Training accuracy: 0.1200000, Time: 08_05_2022__23:15:59\n","Epoch 1 of 5, Step: 400 of 11250, Training loss: 2.4176341, Training accuracy: 0.1287500, Time: 08_05_2022__23:16:10\n","Epoch 1 of 5, Step: 500 of 11250, Training loss: 2.3983545, Training accuracy: 0.1280000, Time: 08_05_2022__23:16:21\n","Epoch 1 of 5, Step: 600 of 11250, Training loss: 2.3844581, Training accuracy: 0.1329167, Time: 08_05_2022__23:16:32\n","Epoch 1 of 5, Step: 700 of 11250, Training loss: 2.3709944, Training accuracy: 0.1357143, Time: 08_05_2022__23:16:43\n","Epoch 1 of 5, Step: 800 of 11250, Training loss: 2.3521686, Training accuracy: 0.1421875, Time: 08_05_2022__23:16:55\n","Epoch 1 of 5, Step: 900 of 11250, Training loss: 2.3417237, Training accuracy: 0.1466667, Time: 08_05_2022__23:17:06\n","Epoch 1 of 5, Step: 1000 of 11250, Training loss: 2.3237428, Training accuracy: 0.1520000, Time: 08_05_2022__23:17:17\n","Epoch 1 of 5, Step: 1100 of 11250, Training loss: 2.3102482, Training accuracy: 0.1568182, Time: 08_05_2022__23:17:28\n","Epoch 1 of 5, Step: 1200 of 11250, Training loss: 2.2952980, Training accuracy: 0.1608333, Time: 08_05_2022__23:17:39\n","Epoch 1 of 5, Step: 1300 of 11250, Training loss: 2.2787949, Training accuracy: 0.1651923, Time: 08_05_2022__23:17:50\n","Epoch 1 of 5, Step: 1400 of 11250, Training loss: 2.2624584, Training accuracy: 0.1696429, Time: 08_05_2022__23:18:01\n","Epoch 1 of 5, Step: 1500 of 11250, Training loss: 2.2516671, Training accuracy: 0.1733333, Time: 08_05_2022__23:18:13\n","Epoch 1 of 5, Step: 1600 of 11250, Training loss: 2.2397515, Training accuracy: 0.1776562, Time: 08_05_2022__23:18:24\n","Epoch 1 of 5, Step: 1700 of 11250, Training loss: 2.2257904, Training accuracy: 0.1829412, Time: 08_05_2022__23:18:35\n","Epoch 1 of 5, Step: 1800 of 11250, Training loss: 2.2105608, Training accuracy: 0.1884722, Time: 08_05_2022__23:18:46\n","Epoch 1 of 5, Step: 1900 of 11250, Training loss: 2.1982748, Training accuracy: 0.1936842, Time: 08_05_2022__23:18:57\n","Epoch 1 of 5, Step: 2000 of 11250, Training loss: 2.1861951, Training accuracy: 0.1968750, Time: 08_05_2022__23:19:08\n","Epoch 1 of 5, Step: 2100 of 11250, Training loss: 2.1742261, Training accuracy: 0.2013095, Time: 08_05_2022__23:19:20\n","Epoch 1 of 5, Step: 2200 of 11250, Training loss: 2.1641712, Training accuracy: 0.2048864, Time: 08_05_2022__23:19:31\n","Epoch 1 of 5, Step: 2300 of 11250, Training loss: 2.1529216, Training accuracy: 0.2095652, Time: 08_05_2022__23:19:42\n","Epoch 1 of 5, Step: 2400 of 11250, Training loss: 2.1415909, Training accuracy: 0.2141667, Time: 08_05_2022__23:19:53\n","Epoch 1 of 5, Step: 2500 of 11250, Training loss: 2.1298035, Training accuracy: 0.2188000, Time: 08_05_2022__23:20:04\n","Epoch 1 of 5, Step: 2600 of 11250, Training loss: 2.1183085, Training accuracy: 0.2239423, Time: 08_05_2022__23:20:15\n","Epoch 1 of 5, Step: 2700 of 11250, Training loss: 2.1094455, Training accuracy: 0.2268519, Time: 08_05_2022__23:20:26\n","Epoch 1 of 5, Step: 2800 of 11250, Training loss: 2.1014817, Training accuracy: 0.2292857, Time: 08_05_2022__23:20:38\n","Epoch 1 of 5, Step: 2900 of 11250, Training loss: 2.0939906, Training accuracy: 0.2318103, Time: 08_05_2022__23:20:49\n","Epoch 1 of 5, Step: 3000 of 11250, Training loss: 2.0865893, Training accuracy: 0.2349167, Time: 08_05_2022__23:21:00\n","Epoch 1 of 5, Step: 3100 of 11250, Training loss: 2.0765936, Training accuracy: 0.2387903, Time: 08_05_2022__23:21:11\n","Epoch 1 of 5, Step: 3200 of 11250, Training loss: 2.0672246, Training accuracy: 0.2414062, Time: 08_05_2022__23:21:22\n","Epoch 1 of 5, Step: 3300 of 11250, Training loss: 2.0614167, Training accuracy: 0.2431061, Time: 08_05_2022__23:21:33\n","Epoch 1 of 5, Step: 3400 of 11250, Training loss: 2.0544607, Training accuracy: 0.2455147, Time: 08_05_2022__23:21:44\n","Epoch 1 of 5, Step: 3500 of 11250, Training loss: 2.0479286, Training accuracy: 0.2485714, Time: 08_05_2022__23:21:56\n","Epoch 1 of 5, Step: 3600 of 11250, Training loss: 2.0435455, Training accuracy: 0.2495139, Time: 08_05_2022__23:22:07\n","Epoch 1 of 5, Step: 3700 of 11250, Training loss: 2.0389317, Training accuracy: 0.2512162, Time: 08_05_2022__23:22:18\n","Epoch 1 of 5, Step: 3800 of 11250, Training loss: 2.0320817, Training accuracy: 0.2532895, Time: 08_05_2022__23:22:29\n","Epoch 1 of 5, Step: 3900 of 11250, Training loss: 2.0269593, Training accuracy: 0.2555769, Time: 08_05_2022__23:22:40\n","Epoch 1 of 5, Step: 4000 of 11250, Training loss: 2.0225436, Training accuracy: 0.2576875, Time: 08_05_2022__23:22:51\n","Epoch 1 of 5, Step: 4100 of 11250, Training loss: 2.0178937, Training accuracy: 0.2590854, Time: 08_05_2022__23:23:02\n","Epoch 1 of 5, Step: 4200 of 11250, Training loss: 2.0113745, Training accuracy: 0.2617857, Time: 08_05_2022__23:23:14\n","Epoch 1 of 5, Step: 4300 of 11250, Training loss: 2.0057927, Training accuracy: 0.2642442, Time: 08_05_2022__23:23:25\n","Epoch 1 of 5, Step: 4400 of 11250, Training loss: 1.9989408, Training accuracy: 0.2667045, Time: 08_05_2022__23:23:36\n","Epoch 1 of 5, Step: 4500 of 11250, Training loss: 1.9922998, Training accuracy: 0.2695000, Time: 08_05_2022__23:23:47\n","Epoch 1 of 5, Step: 4600 of 11250, Training loss: 1.9876525, Training accuracy: 0.2710326, Time: 08_05_2022__23:23:58\n","Epoch 1 of 5, Step: 4700 of 11250, Training loss: 1.9827485, Training accuracy: 0.2729255, Time: 08_05_2022__23:24:09\n","Epoch 1 of 5, Step: 4800 of 11250, Training loss: 1.9789498, Training accuracy: 0.2742708, Time: 08_05_2022__23:24:20\n","Epoch 1 of 5, Step: 4900 of 11250, Training loss: 1.9749322, Training accuracy: 0.2754592, Time: 08_05_2022__23:24:32\n","Epoch 1 of 5, Step: 5000 of 11250, Training loss: 1.9712155, Training accuracy: 0.2770500, Time: 08_05_2022__23:24:43\n","Epoch 1 of 5, Step: 5100 of 11250, Training loss: 1.9650441, Training accuracy: 0.2786275, Time: 08_05_2022__23:24:54\n","Epoch 1 of 5, Step: 5200 of 11250, Training loss: 1.9628913, Training accuracy: 0.2796154, Time: 08_05_2022__23:25:05\n","Epoch 1 of 5, Step: 5300 of 11250, Training loss: 1.9587210, Training accuracy: 0.2815094, Time: 08_05_2022__23:25:16\n","Epoch 1 of 5, Step: 5400 of 11250, Training loss: 1.9557670, Training accuracy: 0.2831019, Time: 08_05_2022__23:25:27\n","Epoch 1 of 5, Step: 5500 of 11250, Training loss: 1.9512714, Training accuracy: 0.2849091, Time: 08_05_2022__23:25:38\n","Epoch 1 of 5, Step: 5600 of 11250, Training loss: 1.9478746, Training accuracy: 0.2864286, Time: 08_05_2022__23:25:50\n","Epoch 1 of 5, Step: 5700 of 11250, Training loss: 1.9434319, Training accuracy: 0.2882895, Time: 08_05_2022__23:26:01\n","Epoch 1 of 5, Step: 5800 of 11250, Training loss: 1.9404445, Training accuracy: 0.2892672, Time: 08_05_2022__23:26:12\n","Epoch 1 of 5, Step: 5900 of 11250, Training loss: 1.9365096, Training accuracy: 0.2909322, Time: 08_05_2022__23:26:23\n","Epoch 1 of 5, Step: 6000 of 11250, Training loss: 1.9325323, Training accuracy: 0.2923750, Time: 08_05_2022__23:26:34\n","Epoch 1 of 5, Step: 6100 of 11250, Training loss: 1.9299435, Training accuracy: 0.2929508, Time: 08_05_2022__23:26:45\n","Epoch 1 of 5, Step: 6200 of 11250, Training loss: 1.9260346, Training accuracy: 0.2942339, Time: 08_05_2022__23:26:56\n","Epoch 1 of 5, Step: 6300 of 11250, Training loss: 1.9216153, Training accuracy: 0.2955159, Time: 08_05_2022__23:27:08\n","Epoch 1 of 5, Step: 6400 of 11250, Training loss: 1.9185367, Training accuracy: 0.2965625, Time: 08_05_2022__23:27:19\n","Epoch 1 of 5, Step: 6500 of 11250, Training loss: 1.9138315, Training accuracy: 0.2991154, Time: 08_05_2022__23:27:30\n","Epoch 1 of 5, Step: 6600 of 11250, Training loss: 1.9110200, Training accuracy: 0.3002273, Time: 08_05_2022__23:27:41\n","Epoch 1 of 5, Step: 6700 of 11250, Training loss: 1.9075547, Training accuracy: 0.3012687, Time: 08_05_2022__23:27:52\n","Epoch 1 of 5, Step: 6800 of 11250, Training loss: 1.9045438, Training accuracy: 0.3022059, Time: 08_05_2022__23:28:03\n","Epoch 1 of 5, Step: 6900 of 11250, Training loss: 1.9010727, Training accuracy: 0.3035145, Time: 08_05_2022__23:28:14\n","Epoch 1 of 5, Step: 7000 of 11250, Training loss: 1.8976201, Training accuracy: 0.3048571, Time: 08_05_2022__23:28:26\n","Epoch 1 of 5, Step: 7100 of 11250, Training loss: 1.8947198, Training accuracy: 0.3055282, Time: 08_05_2022__23:28:37\n","Epoch 1 of 5, Step: 7200 of 11250, Training loss: 1.8909904, Training accuracy: 0.3072222, Time: 08_05_2022__23:28:48\n","Epoch 1 of 5, Step: 7300 of 11250, Training loss: 1.8880053, Training accuracy: 0.3080822, Time: 08_05_2022__23:28:59\n","Epoch 1 of 5, Step: 7400 of 11250, Training loss: 1.8860638, Training accuracy: 0.3089189, Time: 08_05_2022__23:29:10\n","Epoch 1 of 5, Step: 7500 of 11250, Training loss: 1.8837941, Training accuracy: 0.3098333, Time: 08_05_2022__23:29:21\n","Epoch 1 of 5, Step: 7600 of 11250, Training loss: 1.8809068, Training accuracy: 0.3108553, Time: 08_05_2022__23:29:32\n","Epoch 1 of 5, Step: 7700 of 11250, Training loss: 1.8777088, Training accuracy: 0.3121429, Time: 08_05_2022__23:29:44\n","Epoch 1 of 5, Step: 7800 of 11250, Training loss: 1.8741246, Training accuracy: 0.3133013, Time: 08_05_2022__23:29:55\n","Epoch 1 of 5, Step: 7900 of 11250, Training loss: 1.8710155, Training accuracy: 0.3143987, Time: 08_05_2022__23:30:06\n","Epoch 1 of 5, Step: 8000 of 11250, Training loss: 1.8685826, Training accuracy: 0.3153750, Time: 08_05_2022__23:30:17\n","Epoch 1 of 5, Step: 8100 of 11250, Training loss: 1.8663498, Training accuracy: 0.3163272, Time: 08_05_2022__23:30:28\n","Epoch 1 of 5, Step: 8200 of 11250, Training loss: 1.8642582, Training accuracy: 0.3173476, Time: 08_05_2022__23:30:39\n","Epoch 1 of 5, Step: 8300 of 11250, Training loss: 1.8604970, Training accuracy: 0.3189458, Time: 08_05_2022__23:30:50\n","Epoch 1 of 5, Step: 8400 of 11250, Training loss: 1.8579781, Training accuracy: 0.3197619, Time: 08_05_2022__23:31:01\n","Epoch 1 of 5, Step: 8500 of 11250, Training loss: 1.8553798, Training accuracy: 0.3212647, Time: 08_05_2022__23:31:12\n","Epoch 1 of 5, Step: 8600 of 11250, Training loss: 1.8521111, Training accuracy: 0.3227035, Time: 08_05_2022__23:31:24\n","Epoch 1 of 5, Step: 8700 of 11250, Training loss: 1.8492247, Training accuracy: 0.3236494, Time: 08_05_2022__23:31:35\n","Epoch 1 of 5, Step: 8800 of 11250, Training loss: 1.8456388, Training accuracy: 0.3249432, Time: 08_05_2022__23:31:46\n","Epoch 1 of 5, Step: 8900 of 11250, Training loss: 1.8425777, Training accuracy: 0.3258989, Time: 08_05_2022__23:31:57\n","Epoch 1 of 5, Step: 9000 of 11250, Training loss: 1.8402978, Training accuracy: 0.3268333, Time: 08_05_2022__23:32:08\n","Epoch 1 of 5, Step: 9100 of 11250, Training loss: 1.8375780, Training accuracy: 0.3275824, Time: 08_05_2022__23:32:19\n","Epoch 1 of 5, Step: 9200 of 11250, Training loss: 1.8347152, Training accuracy: 0.3286413, Time: 08_05_2022__23:32:30\n","Epoch 1 of 5, Step: 9300 of 11250, Training loss: 1.8324344, Training accuracy: 0.3296237, Time: 08_05_2022__23:32:41\n","Epoch 1 of 5, Step: 9400 of 11250, Training loss: 1.8302409, Training accuracy: 0.3303457, Time: 08_05_2022__23:32:53\n","Epoch 1 of 5, Step: 9500 of 11250, Training loss: 1.8289602, Training accuracy: 0.3308684, Time: 08_05_2022__23:33:04\n","Epoch 1 of 5, Step: 9600 of 11250, Training loss: 1.8260446, Training accuracy: 0.3319531, Time: 08_05_2022__23:33:15\n","Epoch 1 of 5, Step: 9700 of 11250, Training loss: 1.8224487, Training accuracy: 0.3334536, Time: 08_05_2022__23:33:26\n","Epoch 1 of 5, Step: 9800 of 11250, Training loss: 1.8197899, Training accuracy: 0.3343622, Time: 08_05_2022__23:33:37\n","Epoch 1 of 5, Step: 9900 of 11250, Training loss: 1.8180602, Training accuracy: 0.3351010, Time: 08_05_2022__23:33:48\n","Epoch 1 of 5, Step: 10000 of 11250, Training loss: 1.8161717, Training accuracy: 0.3358000, Time: 08_05_2022__23:33:59\n","Epoch 1 of 5, Step: 10100 of 11250, Training loss: 1.8146332, Training accuracy: 0.3365347, Time: 08_05_2022__23:34:10\n","Epoch 1 of 5, Step: 10200 of 11250, Training loss: 1.8127032, Training accuracy: 0.3370588, Time: 08_05_2022__23:34:21\n","Epoch 1 of 5, Step: 10300 of 11250, Training loss: 1.8104442, Training accuracy: 0.3383010, Time: 08_05_2022__23:34:33\n","Epoch 1 of 5, Step: 10400 of 11250, Training loss: 1.8078578, Training accuracy: 0.3391346, Time: 08_05_2022__23:34:44\n","Epoch 1 of 5, Step: 10500 of 11250, Training loss: 1.8062310, Training accuracy: 0.3397381, Time: 08_05_2022__23:34:55\n","Epoch 1 of 5, Step: 10600 of 11250, Training loss: 1.8041847, Training accuracy: 0.3404481, Time: 08_05_2022__23:35:06\n","Epoch 1 of 5, Step: 10700 of 11250, Training loss: 1.8021241, Training accuracy: 0.3409579, Time: 08_05_2022__23:35:17\n","Epoch 1 of 5, Step: 10800 of 11250, Training loss: 1.7996563, Training accuracy: 0.3419444, Time: 08_05_2022__23:35:28\n","Epoch 1 of 5, Step: 10900 of 11250, Training loss: 1.7984935, Training accuracy: 0.3426376, Time: 08_05_2022__23:35:39\n","Epoch 1 of 5, Step: 11000 of 11250, Training loss: 1.7968061, Training accuracy: 0.3433636, Time: 08_05_2022__23:35:50\n","Epoch 1 of 5, Step: 11100 of 11250, Training loss: 1.7942735, Training accuracy: 0.3441892, Time: 08_05_2022__23:36:01\n","Epoch 1 of 5, Step: 11200 of 11250, Training loss: 1.7923665, Training accuracy: 0.3451116, Time: 08_05_2022__23:36:13\n","Epoch 1 of 5, Average training loss: 1.7914240, Average training accuracy: 0.3454222, Time: 08_05_2022__23:36:18\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb06464af0004628a2745e54b653aac4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.4565260, Validation accuracy: 0.4850000, Time: 08_05_2022__23:36:22 | Loss decreased from inf to 1.4555640 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.4627261, Validation accuracy: 0.4775000, Time: 08_05_2022__23:36:28\n","Step: 300 of 1250, Validation loss: 1.4814271, Validation accuracy: 0.4600000, Time: 08_05_2022__23:36:31\n","Step: 400 of 1250, Validation loss: 1.4754725, Validation accuracy: 0.4556250, Time: 08_05_2022__23:36:35\n","Step: 500 of 1250, Validation loss: 1.4778075, Validation accuracy: 0.4585000, Time: 08_05_2022__23:36:39\n","Step: 600 of 1250, Validation loss: 1.4646704, Validation accuracy: 0.4625000, Time: 08_05_2022__23:36:43\n","Step: 700 of 1250, Validation loss: 1.4578358, Validation accuracy: 0.4700000, Time: 08_05_2022__23:36:46\n","Step: 800 of 1250, Validation loss: 1.4516407, Validation accuracy: 0.4721875, Time: 08_05_2022__23:36:50 | Loss decreased from 1.4555640 to 1.4526138 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.4521740, Validation accuracy: 0.4741667, Time: 08_05_2022__23:36:56 | Loss decreased from 1.4526138 to 1.4517697 .... Saving the model\n","Step: 1000 of 1250, Validation loss: 1.4582748, Validation accuracy: 0.4717500, Time: 08_05_2022__23:37:02\n","Step: 1100 of 1250, Validation loss: 1.4595944, Validation accuracy: 0.4700000, Time: 08_05_2022__23:37:05\n","Step: 1200 of 1250, Validation loss: 1.4615350, Validation accuracy: 0.4670833, Time: 08_05_2022__23:37:09\n","Average validation loss: 1.4591200, Average validation accuracy: 0.4674000, Time: 08_05_2022__23:37:11\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbf48a82935c442392bf528f6551dafa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 2 of 5, Step: 100 of 11250, Training loss: 1.4613283, Training accuracy: 0.4625000, Time: 08_05_2022__23:37:22\n","Epoch 2 of 5, Step: 200 of 11250, Training loss: 1.5172292, Training accuracy: 0.4537500, Time: 08_05_2022__23:37:34\n","Epoch 2 of 5, Step: 300 of 11250, Training loss: 1.5392801, Training accuracy: 0.4350000, Time: 08_05_2022__23:37:45\n","Epoch 2 of 5, Step: 400 of 11250, Training loss: 1.5419495, Training accuracy: 0.4293750, Time: 08_05_2022__23:37:56\n","Epoch 2 of 5, Step: 500 of 11250, Training loss: 1.5387726, Training accuracy: 0.4355000, Time: 08_05_2022__23:38:07\n","Epoch 2 of 5, Step: 600 of 11250, Training loss: 1.5333743, Training accuracy: 0.4379167, Time: 08_05_2022__23:38:18\n","Epoch 2 of 5, Step: 700 of 11250, Training loss: 1.5489179, Training accuracy: 0.4307143, Time: 08_05_2022__23:38:29\n","Epoch 2 of 5, Step: 800 of 11250, Training loss: 1.5477352, Training accuracy: 0.4315625, Time: 08_05_2022__23:38:40\n","Epoch 2 of 5, Step: 900 of 11250, Training loss: 1.5455591, Training accuracy: 0.4361111, Time: 08_05_2022__23:38:51\n","Epoch 2 of 5, Step: 1000 of 11250, Training loss: 1.5462571, Training accuracy: 0.4365000, Time: 08_05_2022__23:39:02\n","Epoch 2 of 5, Step: 1100 of 11250, Training loss: 1.5438521, Training accuracy: 0.4363636, Time: 08_05_2022__23:39:13\n","Epoch 2 of 5, Step: 1200 of 11250, Training loss: 1.5444807, Training accuracy: 0.4360417, Time: 08_05_2022__23:39:24\n","Epoch 2 of 5, Step: 1300 of 11250, Training loss: 1.5383853, Training accuracy: 0.4386538, Time: 08_05_2022__23:39:36\n","Epoch 2 of 5, Step: 1400 of 11250, Training loss: 1.5333704, Training accuracy: 0.4414286, Time: 08_05_2022__23:39:47\n","Epoch 2 of 5, Step: 1500 of 11250, Training loss: 1.5324525, Training accuracy: 0.4421667, Time: 08_05_2022__23:39:58\n","Epoch 2 of 5, Step: 1600 of 11250, Training loss: 1.5325813, Training accuracy: 0.4414062, Time: 08_05_2022__23:40:09\n","Epoch 2 of 5, Step: 1700 of 11250, Training loss: 1.5326772, Training accuracy: 0.4411765, Time: 08_05_2022__23:40:20\n","Epoch 2 of 5, Step: 1800 of 11250, Training loss: 1.5303477, Training accuracy: 0.4413889, Time: 08_05_2022__23:40:31\n","Epoch 2 of 5, Step: 1900 of 11250, Training loss: 1.5284790, Training accuracy: 0.4426316, Time: 08_05_2022__23:40:42\n","Epoch 2 of 5, Step: 2000 of 11250, Training loss: 1.5283523, Training accuracy: 0.4431250, Time: 08_05_2022__23:40:53\n","Epoch 2 of 5, Step: 2100 of 11250, Training loss: 1.5266770, Training accuracy: 0.4433333, Time: 08_05_2022__23:41:04\n","Epoch 2 of 5, Step: 2200 of 11250, Training loss: 1.5261722, Training accuracy: 0.4440909, Time: 08_05_2022__23:41:15\n","Epoch 2 of 5, Step: 2300 of 11250, Training loss: 1.5264007, Training accuracy: 0.4444565, Time: 08_05_2022__23:41:26\n","Epoch 2 of 5, Step: 2400 of 11250, Training loss: 1.5212322, Training accuracy: 0.4460417, Time: 08_05_2022__23:41:38\n","Epoch 2 of 5, Step: 2500 of 11250, Training loss: 1.5183795, Training accuracy: 0.4467000, Time: 08_05_2022__23:41:49\n","Epoch 2 of 5, Step: 2600 of 11250, Training loss: 1.5172260, Training accuracy: 0.4476923, Time: 08_05_2022__23:42:00\n","Epoch 2 of 5, Step: 2700 of 11250, Training loss: 1.5154307, Training accuracy: 0.4474074, Time: 08_05_2022__23:42:11\n","Epoch 2 of 5, Step: 2800 of 11250, Training loss: 1.5151371, Training accuracy: 0.4469643, Time: 08_05_2022__23:42:22\n","Epoch 2 of 5, Step: 2900 of 11250, Training loss: 1.5161509, Training accuracy: 0.4461207, Time: 08_05_2022__23:42:33\n","Epoch 2 of 5, Step: 3000 of 11250, Training loss: 1.5137792, Training accuracy: 0.4469167, Time: 08_05_2022__23:42:44\n","Epoch 2 of 5, Step: 3100 of 11250, Training loss: 1.5116324, Training accuracy: 0.4486290, Time: 08_05_2022__23:42:55\n","Epoch 2 of 5, Step: 3200 of 11250, Training loss: 1.5074694, Training accuracy: 0.4497656, Time: 08_05_2022__23:43:06\n","Epoch 2 of 5, Step: 3300 of 11250, Training loss: 1.5093912, Training accuracy: 0.4500000, Time: 08_05_2022__23:43:17\n","Epoch 2 of 5, Step: 3400 of 11250, Training loss: 1.5101043, Training accuracy: 0.4488235, Time: 08_05_2022__23:43:28\n","Epoch 2 of 5, Step: 3500 of 11250, Training loss: 1.5077627, Training accuracy: 0.4507857, Time: 08_05_2022__23:43:40\n","Epoch 2 of 5, Step: 3600 of 11250, Training loss: 1.5078030, Training accuracy: 0.4504861, Time: 08_05_2022__23:43:51\n","Epoch 2 of 5, Step: 3700 of 11250, Training loss: 1.5082146, Training accuracy: 0.4502703, Time: 08_05_2022__23:44:02\n","Epoch 2 of 5, Step: 3800 of 11250, Training loss: 1.5066802, Training accuracy: 0.4513158, Time: 08_05_2022__23:44:13\n","Epoch 2 of 5, Step: 3900 of 11250, Training loss: 1.5041958, Training accuracy: 0.4521795, Time: 08_05_2022__23:44:24\n","Epoch 2 of 5, Step: 4000 of 11250, Training loss: 1.5024653, Training accuracy: 0.4531875, Time: 08_05_2022__23:44:35\n","Epoch 2 of 5, Step: 4100 of 11250, Training loss: 1.5019892, Training accuracy: 0.4536585, Time: 08_05_2022__23:44:46\n","Epoch 2 of 5, Step: 4200 of 11250, Training loss: 1.4995393, Training accuracy: 0.4545833, Time: 08_05_2022__23:44:57\n","Epoch 2 of 5, Step: 4300 of 11250, Training loss: 1.4981198, Training accuracy: 0.4547674, Time: 08_05_2022__23:45:08\n","Epoch 2 of 5, Step: 4400 of 11250, Training loss: 1.4954226, Training accuracy: 0.4554545, Time: 08_05_2022__23:45:19\n","Epoch 2 of 5, Step: 4500 of 11250, Training loss: 1.4922591, Training accuracy: 0.4565000, Time: 08_05_2022__23:45:31\n","Epoch 2 of 5, Step: 4600 of 11250, Training loss: 1.4905685, Training accuracy: 0.4571739, Time: 08_05_2022__23:45:42\n","Epoch 2 of 5, Step: 4700 of 11250, Training loss: 1.4888692, Training accuracy: 0.4580319, Time: 08_05_2022__23:45:53\n","Epoch 2 of 5, Step: 4800 of 11250, Training loss: 1.4876953, Training accuracy: 0.4582812, Time: 08_05_2022__23:46:04\n","Epoch 2 of 5, Step: 4900 of 11250, Training loss: 1.4870256, Training accuracy: 0.4583673, Time: 08_05_2022__23:46:15\n","Epoch 2 of 5, Step: 5000 of 11250, Training loss: 1.4866645, Training accuracy: 0.4589000, Time: 08_05_2022__23:46:26\n","Epoch 2 of 5, Step: 5100 of 11250, Training loss: 1.4838989, Training accuracy: 0.4600000, Time: 08_05_2022__23:46:37\n","Epoch 2 of 5, Step: 5200 of 11250, Training loss: 1.4838119, Training accuracy: 0.4603846, Time: 08_05_2022__23:46:48\n","Epoch 2 of 5, Step: 5300 of 11250, Training loss: 1.4827303, Training accuracy: 0.4608491, Time: 08_05_2022__23:46:59\n","Epoch 2 of 5, Step: 5400 of 11250, Training loss: 1.4820569, Training accuracy: 0.4612037, Time: 08_05_2022__23:47:10\n","Epoch 2 of 5, Step: 5500 of 11250, Training loss: 1.4820585, Training accuracy: 0.4609545, Time: 08_05_2022__23:47:22\n","Epoch 2 of 5, Step: 5600 of 11250, Training loss: 1.4808423, Training accuracy: 0.4615625, Time: 08_05_2022__23:47:33\n","Epoch 2 of 5, Step: 5700 of 11250, Training loss: 1.4798072, Training accuracy: 0.4619298, Time: 08_05_2022__23:47:44\n","Epoch 2 of 5, Step: 5800 of 11250, Training loss: 1.4791183, Training accuracy: 0.4624138, Time: 08_05_2022__23:47:55\n","Epoch 2 of 5, Step: 5900 of 11250, Training loss: 1.4787076, Training accuracy: 0.4627966, Time: 08_05_2022__23:48:06\n","Epoch 2 of 5, Step: 6000 of 11250, Training loss: 1.4775383, Training accuracy: 0.4633333, Time: 08_05_2022__23:48:17\n","Epoch 2 of 5, Step: 6100 of 11250, Training loss: 1.4779041, Training accuracy: 0.4638525, Time: 08_05_2022__23:48:28\n","Epoch 2 of 5, Step: 6200 of 11250, Training loss: 1.4759387, Training accuracy: 0.4652016, Time: 08_05_2022__23:48:39\n","Epoch 2 of 5, Step: 6300 of 11250, Training loss: 1.4761135, Training accuracy: 0.4648810, Time: 08_05_2022__23:48:50\n","Epoch 2 of 5, Step: 6400 of 11250, Training loss: 1.4749249, Training accuracy: 0.4653125, Time: 08_05_2022__23:49:01\n","Epoch 2 of 5, Step: 6500 of 11250, Training loss: 1.4743281, Training accuracy: 0.4658462, Time: 08_05_2022__23:49:12\n","Epoch 2 of 5, Step: 6600 of 11250, Training loss: 1.4735557, Training accuracy: 0.4662879, Time: 08_05_2022__23:49:23\n","Epoch 2 of 5, Step: 6700 of 11250, Training loss: 1.4727886, Training accuracy: 0.4664925, Time: 08_05_2022__23:49:35\n","Epoch 2 of 5, Step: 6800 of 11250, Training loss: 1.4727852, Training accuracy: 0.4668382, Time: 08_05_2022__23:49:46\n","Epoch 2 of 5, Step: 6900 of 11250, Training loss: 1.4717359, Training accuracy: 0.4669928, Time: 08_05_2022__23:49:57\n","Epoch 2 of 5, Step: 7000 of 11250, Training loss: 1.4697862, Training accuracy: 0.4677500, Time: 08_05_2022__23:50:08\n","Epoch 2 of 5, Step: 7100 of 11250, Training loss: 1.4695743, Training accuracy: 0.4674648, Time: 08_05_2022__23:50:19\n","Epoch 2 of 5, Step: 7200 of 11250, Training loss: 1.4687876, Training accuracy: 0.4679861, Time: 08_05_2022__23:50:30\n","Epoch 2 of 5, Step: 7300 of 11250, Training loss: 1.4685195, Training accuracy: 0.4680137, Time: 08_05_2022__23:50:41\n","Epoch 2 of 5, Step: 7400 of 11250, Training loss: 1.4679914, Training accuracy: 0.4683108, Time: 08_05_2022__23:50:52\n","Epoch 2 of 5, Step: 7500 of 11250, Training loss: 1.4672286, Training accuracy: 0.4683667, Time: 08_05_2022__23:51:03\n","Epoch 2 of 5, Step: 7600 of 11250, Training loss: 1.4656453, Training accuracy: 0.4690461, Time: 08_05_2022__23:51:14\n","Epoch 2 of 5, Step: 7700 of 11250, Training loss: 1.4648898, Training accuracy: 0.4695455, Time: 08_05_2022__23:51:25\n","Epoch 2 of 5, Step: 7800 of 11250, Training loss: 1.4629219, Training accuracy: 0.4700000, Time: 08_05_2022__23:51:37\n","Epoch 2 of 5, Step: 7900 of 11250, Training loss: 1.4616195, Training accuracy: 0.4701899, Time: 08_05_2022__23:51:48\n","Epoch 2 of 5, Step: 8000 of 11250, Training loss: 1.4603193, Training accuracy: 0.4705625, Time: 08_05_2022__23:51:59\n","Epoch 2 of 5, Step: 8100 of 11250, Training loss: 1.4596284, Training accuracy: 0.4706790, Time: 08_05_2022__23:52:10\n","Epoch 2 of 5, Step: 8200 of 11250, Training loss: 1.4592830, Training accuracy: 0.4703659, Time: 08_05_2022__23:52:21\n","Epoch 2 of 5, Step: 8300 of 11250, Training loss: 1.4580725, Training accuracy: 0.4710241, Time: 08_05_2022__23:52:32\n","Epoch 2 of 5, Step: 8400 of 11250, Training loss: 1.4575487, Training accuracy: 0.4709821, Time: 08_05_2022__23:52:43\n","Epoch 2 of 5, Step: 8500 of 11250, Training loss: 1.4563534, Training accuracy: 0.4717647, Time: 08_05_2022__23:52:54\n","Epoch 2 of 5, Step: 8600 of 11250, Training loss: 1.4549878, Training accuracy: 0.4721512, Time: 08_05_2022__23:53:05\n","Epoch 2 of 5, Step: 8700 of 11250, Training loss: 1.4536233, Training accuracy: 0.4727874, Time: 08_05_2022__23:53:17\n","Epoch 2 of 5, Step: 8800 of 11250, Training loss: 1.4517227, Training accuracy: 0.4733523, Time: 08_05_2022__23:53:28\n","Epoch 2 of 5, Step: 8900 of 11250, Training loss: 1.4500053, Training accuracy: 0.4741854, Time: 08_05_2022__23:53:39\n","Epoch 2 of 5, Step: 9000 of 11250, Training loss: 1.4496363, Training accuracy: 0.4745278, Time: 08_05_2022__23:53:50\n","Epoch 2 of 5, Step: 9100 of 11250, Training loss: 1.4487677, Training accuracy: 0.4749176, Time: 08_05_2022__23:54:01\n","Epoch 2 of 5, Step: 9200 of 11250, Training loss: 1.4469401, Training accuracy: 0.4758696, Time: 08_05_2022__23:54:12\n","Epoch 2 of 5, Step: 9300 of 11250, Training loss: 1.4461060, Training accuracy: 0.4762903, Time: 08_05_2022__23:54:23\n","Epoch 2 of 5, Step: 9400 of 11250, Training loss: 1.4448429, Training accuracy: 0.4768617, Time: 08_05_2022__23:54:34\n","Epoch 2 of 5, Step: 9500 of 11250, Training loss: 1.4455975, Training accuracy: 0.4766842, Time: 08_05_2022__23:54:45\n","Epoch 2 of 5, Step: 9600 of 11250, Training loss: 1.4438924, Training accuracy: 0.4776563, Time: 08_05_2022__23:54:56\n","Epoch 2 of 5, Step: 9700 of 11250, Training loss: 1.4417697, Training accuracy: 0.4783247, Time: 08_05_2022__23:55:08\n","Epoch 2 of 5, Step: 9800 of 11250, Training loss: 1.4406484, Training accuracy: 0.4787755, Time: 08_05_2022__23:55:19\n","Epoch 2 of 5, Step: 9900 of 11250, Training loss: 1.4403937, Training accuracy: 0.4786111, Time: 08_05_2022__23:55:30\n","Epoch 2 of 5, Step: 10000 of 11250, Training loss: 1.4391323, Training accuracy: 0.4792250, Time: 08_05_2022__23:55:41\n","Epoch 2 of 5, Step: 10100 of 11250, Training loss: 1.4392219, Training accuracy: 0.4794554, Time: 08_05_2022__23:55:52\n","Epoch 2 of 5, Step: 10200 of 11250, Training loss: 1.4383334, Training accuracy: 0.4798775, Time: 08_05_2022__23:56:03\n","Epoch 2 of 5, Step: 10300 of 11250, Training loss: 1.4372179, Training accuracy: 0.4801456, Time: 08_05_2022__23:56:14\n","Epoch 2 of 5, Step: 10400 of 11250, Training loss: 1.4360296, Training accuracy: 0.4803606, Time: 08_05_2022__23:56:25\n","Epoch 2 of 5, Step: 10500 of 11250, Training loss: 1.4349401, Training accuracy: 0.4808095, Time: 08_05_2022__23:56:36\n","Epoch 2 of 5, Step: 10600 of 11250, Training loss: 1.4338549, Training accuracy: 0.4812500, Time: 08_05_2022__23:56:47\n","Epoch 2 of 5, Step: 10700 of 11250, Training loss: 1.4331624, Training accuracy: 0.4812850, Time: 08_05_2022__23:56:59\n","Epoch 2 of 5, Step: 10800 of 11250, Training loss: 1.4319491, Training accuracy: 0.4816667, Time: 08_05_2022__23:57:10\n","Epoch 2 of 5, Step: 10900 of 11250, Training loss: 1.4318438, Training accuracy: 0.4820183, Time: 08_05_2022__23:57:21\n","Epoch 2 of 5, Step: 11000 of 11250, Training loss: 1.4310762, Training accuracy: 0.4822273, Time: 08_05_2022__23:57:32\n","Epoch 2 of 5, Step: 11100 of 11250, Training loss: 1.4297507, Training accuracy: 0.4827477, Time: 08_05_2022__23:57:43\n","Epoch 2 of 5, Step: 11200 of 11250, Training loss: 1.4292753, Training accuracy: 0.4827679, Time: 08_05_2022__23:57:54\n","Epoch 2 of 5, Average training loss: 1.4288990, Average training accuracy: 0.4828667, Time: 08_05_2022__23:58:00\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bedf703e512a401e9f3c5f104dcb3b1b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.2625478, Validation accuracy: 0.5550000, Time: 08_05_2022__23:58:03 | Loss decreased from 1.4517697 to 1.2597004 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.2598186, Validation accuracy: 0.5450000, Time: 08_05_2022__23:58:09\n","Step: 300 of 1250, Validation loss: 1.2666910, Validation accuracy: 0.5366667, Time: 08_05_2022__23:58:13\n","Step: 400 of 1250, Validation loss: 1.2653522, Validation accuracy: 0.5350000, Time: 08_05_2022__23:58:17\n","Step: 500 of 1250, Validation loss: 1.2707797, Validation accuracy: 0.5300000, Time: 08_05_2022__23:58:21\n","Step: 600 of 1250, Validation loss: 1.2610690, Validation accuracy: 0.5358333, Time: 08_05_2022__23:58:24\n","Step: 700 of 1250, Validation loss: 1.2436768, Validation accuracy: 0.5428571, Time: 08_05_2022__23:58:28 | Loss decreased from 1.2597004 to 1.2439330 .... Saving the model\n","Step: 800 of 1250, Validation loss: 1.2402111, Validation accuracy: 0.5425000, Time: 08_05_2022__23:58:34 | Loss decreased from 1.2439330 to 1.2411196 .... Saving the model\n","Step: 900 of 1250, Validation loss: 1.2407232, Validation accuracy: 0.5438889, Time: 08_05_2022__23:58:40 | Loss decreased from 1.2411196 to 1.2406830 .... Saving the model\n","Step: 1000 of 1250, Validation loss: 1.2518919, Validation accuracy: 0.5365000, Time: 08_05_2022__23:58:45\n","Step: 1100 of 1250, Validation loss: 1.2527047, Validation accuracy: 0.5365909, Time: 08_05_2022__23:58:49\n","Step: 1200 of 1250, Validation loss: 1.2577964, Validation accuracy: 0.5368750, Time: 08_05_2022__23:58:53\n","Average validation loss: 1.2575767, Average validation accuracy: 0.5382000, Time: 08_05_2022__23:58:55\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12fb751cbe6b45a8aa72d783e32acd8f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 3 of 5, Step: 100 of 11250, Training loss: 1.2170507, Training accuracy: 0.5750000, Time: 08_05_2022__23:59:06\n","Epoch 3 of 5, Step: 200 of 11250, Training loss: 1.2691049, Training accuracy: 0.5575000, Time: 08_05_2022__23:59:17\n","Epoch 3 of 5, Step: 300 of 11250, Training loss: 1.2933869, Training accuracy: 0.5425000, Time: 08_05_2022__23:59:28\n","Epoch 3 of 5, Step: 400 of 11250, Training loss: 1.2936339, Training accuracy: 0.5337500, Time: 08_05_2022__23:59:39\n","Epoch 3 of 5, Step: 500 of 11250, Training loss: 1.3017227, Training accuracy: 0.5255000, Time: 08_05_2022__23:59:50\n","Epoch 3 of 5, Step: 600 of 11250, Training loss: 1.3025221, Training accuracy: 0.5262500, Time: 09_05_2022__00:00:02\n","Epoch 3 of 5, Step: 700 of 11250, Training loss: 1.3148933, Training accuracy: 0.5228571, Time: 09_05_2022__00:00:13\n","Epoch 3 of 5, Step: 800 of 11250, Training loss: 1.3098043, Training accuracy: 0.5253125, Time: 09_05_2022__00:00:24\n","Epoch 3 of 5, Step: 900 of 11250, Training loss: 1.3056245, Training accuracy: 0.5277778, Time: 09_05_2022__00:00:35\n","Epoch 3 of 5, Step: 1000 of 11250, Training loss: 1.3077957, Training accuracy: 0.5285000, Time: 09_05_2022__00:00:46\n","Epoch 3 of 5, Step: 1100 of 11250, Training loss: 1.3054023, Training accuracy: 0.5277273, Time: 09_05_2022__00:00:57\n","Epoch 3 of 5, Step: 1200 of 11250, Training loss: 1.3078246, Training accuracy: 0.5262500, Time: 09_05_2022__00:01:08\n","Epoch 3 of 5, Step: 1300 of 11250, Training loss: 1.3076534, Training accuracy: 0.5269231, Time: 09_05_2022__00:01:19\n","Epoch 3 of 5, Step: 1400 of 11250, Training loss: 1.3048437, Training accuracy: 0.5307143, Time: 09_05_2022__00:01:30\n","Epoch 3 of 5, Step: 1500 of 11250, Training loss: 1.3051572, Training accuracy: 0.5308333, Time: 09_05_2022__00:01:41\n","Epoch 3 of 5, Step: 1600 of 11250, Training loss: 1.3062993, Training accuracy: 0.5309375, Time: 09_05_2022__00:01:52\n","Epoch 3 of 5, Step: 1700 of 11250, Training loss: 1.3057467, Training accuracy: 0.5310294, Time: 09_05_2022__00:02:03\n","Epoch 3 of 5, Step: 1800 of 11250, Training loss: 1.3055528, Training accuracy: 0.5305556, Time: 09_05_2022__00:02:14\n","Epoch 3 of 5, Step: 1900 of 11250, Training loss: 1.3041949, Training accuracy: 0.5311842, Time: 09_05_2022__00:02:26\n","Epoch 3 of 5, Step: 2000 of 11250, Training loss: 1.3044838, Training accuracy: 0.5311250, Time: 09_05_2022__00:02:37\n","Epoch 3 of 5, Step: 2100 of 11250, Training loss: 1.3035041, Training accuracy: 0.5311905, Time: 09_05_2022__00:02:48\n","Epoch 3 of 5, Step: 2200 of 11250, Training loss: 1.3011824, Training accuracy: 0.5326136, Time: 09_05_2022__00:02:59\n","Epoch 3 of 5, Step: 2300 of 11250, Training loss: 1.2975336, Training accuracy: 0.5348913, Time: 09_05_2022__00:03:10\n","Epoch 3 of 5, Step: 2400 of 11250, Training loss: 1.2949147, Training accuracy: 0.5365625, Time: 09_05_2022__00:03:21\n","Epoch 3 of 5, Step: 2500 of 11250, Training loss: 1.2919531, Training accuracy: 0.5376000, Time: 09_05_2022__00:03:32\n","Epoch 3 of 5, Step: 2600 of 11250, Training loss: 1.2916470, Training accuracy: 0.5381731, Time: 09_05_2022__00:03:43\n","Epoch 3 of 5, Step: 2700 of 11250, Training loss: 1.2895188, Training accuracy: 0.5388889, Time: 09_05_2022__00:03:54\n","Epoch 3 of 5, Step: 2800 of 11250, Training loss: 1.2899171, Training accuracy: 0.5385714, Time: 09_05_2022__00:04:05\n","Epoch 3 of 5, Step: 2900 of 11250, Training loss: 1.2920471, Training accuracy: 0.5369828, Time: 09_05_2022__00:04:16\n","Epoch 3 of 5, Step: 3000 of 11250, Training loss: 1.2911655, Training accuracy: 0.5376667, Time: 09_05_2022__00:04:27\n","Epoch 3 of 5, Step: 3100 of 11250, Training loss: 1.2885349, Training accuracy: 0.5377419, Time: 09_05_2022__00:04:39\n","Epoch 3 of 5, Step: 3200 of 11250, Training loss: 1.2842875, Training accuracy: 0.5385156, Time: 09_05_2022__00:04:50\n","Epoch 3 of 5, Step: 3300 of 11250, Training loss: 1.2853617, Training accuracy: 0.5382576, Time: 09_05_2022__00:05:01\n","Epoch 3 of 5, Step: 3400 of 11250, Training loss: 1.2851144, Training accuracy: 0.5383088, Time: 09_05_2022__00:05:12\n","Epoch 3 of 5, Step: 3500 of 11250, Training loss: 1.2855634, Training accuracy: 0.5375000, Time: 09_05_2022__00:05:23\n","Epoch 3 of 5, Step: 3600 of 11250, Training loss: 1.2855858, Training accuracy: 0.5373611, Time: 09_05_2022__00:05:34\n","Epoch 3 of 5, Step: 3700 of 11250, Training loss: 1.2869068, Training accuracy: 0.5364189, Time: 09_05_2022__00:05:45\n","Epoch 3 of 5, Step: 3800 of 11250, Training loss: 1.2853438, Training accuracy: 0.5369737, Time: 09_05_2022__00:05:56\n","Epoch 3 of 5, Step: 3900 of 11250, Training loss: 1.2823569, Training accuracy: 0.5387821, Time: 09_05_2022__00:06:07\n","Epoch 3 of 5, Step: 4000 of 11250, Training loss: 1.2818542, Training accuracy: 0.5391875, Time: 09_05_2022__00:06:18\n","Epoch 3 of 5, Step: 4100 of 11250, Training loss: 1.2826431, Training accuracy: 0.5392073, Time: 09_05_2022__00:06:29\n","Epoch 3 of 5, Step: 4200 of 11250, Training loss: 1.2800228, Training accuracy: 0.5406548, Time: 09_05_2022__00:06:41\n","Epoch 3 of 5, Step: 4300 of 11250, Training loss: 1.2774464, Training accuracy: 0.5412791, Time: 09_05_2022__00:06:52\n","Epoch 3 of 5, Step: 4400 of 11250, Training loss: 1.2750024, Training accuracy: 0.5415909, Time: 09_05_2022__00:07:03\n","Epoch 3 of 5, Step: 4500 of 11250, Training loss: 1.2730442, Training accuracy: 0.5425000, Time: 09_05_2022__00:07:14\n","Epoch 3 of 5, Step: 4600 of 11250, Training loss: 1.2715934, Training accuracy: 0.5430435, Time: 09_05_2022__00:07:25\n","Epoch 3 of 5, Step: 4700 of 11250, Training loss: 1.2705885, Training accuracy: 0.5437766, Time: 09_05_2022__00:07:36\n","Epoch 3 of 5, Step: 4800 of 11250, Training loss: 1.2686594, Training accuracy: 0.5440625, Time: 09_05_2022__00:07:47\n","Epoch 3 of 5, Step: 4900 of 11250, Training loss: 1.2677062, Training accuracy: 0.5444388, Time: 09_05_2022__00:07:58\n","Epoch 3 of 5, Step: 5000 of 11250, Training loss: 1.2677534, Training accuracy: 0.5452000, Time: 09_05_2022__00:08:09\n","Epoch 3 of 5, Step: 5100 of 11250, Training loss: 1.2659228, Training accuracy: 0.5460294, Time: 09_05_2022__00:08:20\n","Epoch 3 of 5, Step: 5200 of 11250, Training loss: 1.2647719, Training accuracy: 0.5466346, Time: 09_05_2022__00:08:31\n","Epoch 3 of 5, Step: 5300 of 11250, Training loss: 1.2634453, Training accuracy: 0.5470283, Time: 09_05_2022__00:08:42\n","Epoch 3 of 5, Step: 5400 of 11250, Training loss: 1.2624859, Training accuracy: 0.5475463, Time: 09_05_2022__00:08:53\n","Epoch 3 of 5, Step: 5500 of 11250, Training loss: 1.2621916, Training accuracy: 0.5480455, Time: 09_05_2022__00:09:05\n","Epoch 3 of 5, Step: 5600 of 11250, Training loss: 1.2613353, Training accuracy: 0.5484821, Time: 09_05_2022__00:09:16\n","Epoch 3 of 5, Step: 5700 of 11250, Training loss: 1.2610496, Training accuracy: 0.5478947, Time: 09_05_2022__00:09:27\n","Epoch 3 of 5, Step: 5800 of 11250, Training loss: 1.2606461, Training accuracy: 0.5476724, Time: 09_05_2022__00:09:38\n","Epoch 3 of 5, Step: 5900 of 11250, Training loss: 1.2608915, Training accuracy: 0.5473729, Time: 09_05_2022__00:09:49\n","Epoch 3 of 5, Step: 6000 of 11250, Training loss: 1.2605619, Training accuracy: 0.5474167, Time: 09_05_2022__00:10:00\n","Epoch 3 of 5, Step: 6100 of 11250, Training loss: 1.2610305, Training accuracy: 0.5475410, Time: 09_05_2022__00:10:11\n","Epoch 3 of 5, Step: 6200 of 11250, Training loss: 1.2595335, Training accuracy: 0.5482258, Time: 09_05_2022__00:10:22\n","Epoch 3 of 5, Step: 6300 of 11250, Training loss: 1.2599342, Training accuracy: 0.5479365, Time: 09_05_2022__00:10:33\n","Epoch 3 of 5, Step: 6400 of 11250, Training loss: 1.2590815, Training accuracy: 0.5478906, Time: 09_05_2022__00:10:44\n","Epoch 3 of 5, Step: 6500 of 11250, Training loss: 1.2585317, Training accuracy: 0.5484231, Time: 09_05_2022__00:10:55\n","Epoch 3 of 5, Step: 6600 of 11250, Training loss: 1.2575362, Training accuracy: 0.5492045, Time: 09_05_2022__00:11:07\n","Epoch 3 of 5, Step: 6700 of 11250, Training loss: 1.2569648, Training accuracy: 0.5490672, Time: 09_05_2022__00:11:18\n","Epoch 3 of 5, Step: 6800 of 11250, Training loss: 1.2577764, Training accuracy: 0.5488603, Time: 09_05_2022__00:11:29\n","Epoch 3 of 5, Step: 6900 of 11250, Training loss: 1.2567093, Training accuracy: 0.5492029, Time: 09_05_2022__00:11:40\n","Epoch 3 of 5, Step: 7000 of 11250, Training loss: 1.2549997, Training accuracy: 0.5499643, Time: 09_05_2022__00:11:51\n","Epoch 3 of 5, Step: 7100 of 11250, Training loss: 1.2552138, Training accuracy: 0.5498592, Time: 09_05_2022__00:12:02\n","Epoch 3 of 5, Step: 7200 of 11250, Training loss: 1.2540490, Training accuracy: 0.5504514, Time: 09_05_2022__00:12:13\n","Epoch 3 of 5, Step: 7300 of 11250, Training loss: 1.2535286, Training accuracy: 0.5505822, Time: 09_05_2022__00:12:24\n","Epoch 3 of 5, Step: 7400 of 11250, Training loss: 1.2529909, Training accuracy: 0.5509797, Time: 09_05_2022__00:12:35\n","Epoch 3 of 5, Step: 7500 of 11250, Training loss: 1.2519706, Training accuracy: 0.5511667, Time: 09_05_2022__00:12:46\n","Epoch 3 of 5, Step: 7600 of 11250, Training loss: 1.2501199, Training accuracy: 0.5519079, Time: 09_05_2022__00:12:58\n","Epoch 3 of 5, Step: 7700 of 11250, Training loss: 1.2494764, Training accuracy: 0.5519805, Time: 09_05_2022__00:13:09\n","Epoch 3 of 5, Step: 7800 of 11250, Training loss: 1.2476552, Training accuracy: 0.5523718, Time: 09_05_2022__00:13:20\n","Epoch 3 of 5, Step: 7900 of 11250, Training loss: 1.2468485, Training accuracy: 0.5520570, Time: 09_05_2022__00:13:31\n","Epoch 3 of 5, Step: 8000 of 11250, Training loss: 1.2456263, Training accuracy: 0.5519688, Time: 09_05_2022__00:13:42\n","Epoch 3 of 5, Step: 8100 of 11250, Training loss: 1.2455751, Training accuracy: 0.5517593, Time: 09_05_2022__00:13:53\n","Epoch 3 of 5, Step: 8200 of 11250, Training loss: 1.2458975, Training accuracy: 0.5519512, Time: 09_05_2022__00:14:04\n","Epoch 3 of 5, Step: 8300 of 11250, Training loss: 1.2451253, Training accuracy: 0.5522289, Time: 09_05_2022__00:14:15\n","Epoch 3 of 5, Step: 8400 of 11250, Training loss: 1.2449312, Training accuracy: 0.5522024, Time: 09_05_2022__00:14:26\n","Epoch 3 of 5, Step: 8500 of 11250, Training loss: 1.2442726, Training accuracy: 0.5526176, Time: 09_05_2022__00:14:37\n","Epoch 3 of 5, Step: 8600 of 11250, Training loss: 1.2431705, Training accuracy: 0.5529651, Time: 09_05_2022__00:14:48\n","Epoch 3 of 5, Step: 8700 of 11250, Training loss: 1.2423154, Training accuracy: 0.5535345, Time: 09_05_2022__00:15:00\n","Epoch 3 of 5, Step: 8800 of 11250, Training loss: 1.2401544, Training accuracy: 0.5545455, Time: 09_05_2022__00:15:11\n","Epoch 3 of 5, Step: 8900 of 11250, Training loss: 1.2385603, Training accuracy: 0.5550281, Time: 09_05_2022__00:15:22\n","Epoch 3 of 5, Step: 9000 of 11250, Training loss: 1.2381006, Training accuracy: 0.5553889, Time: 09_05_2022__00:15:33\n","Epoch 3 of 5, Step: 9100 of 11250, Training loss: 1.2378652, Training accuracy: 0.5556593, Time: 09_05_2022__00:15:44\n","Epoch 3 of 5, Step: 9200 of 11250, Training loss: 1.2368020, Training accuracy: 0.5564130, Time: 09_05_2022__00:15:55\n","Epoch 3 of 5, Step: 9300 of 11250, Training loss: 1.2369025, Training accuracy: 0.5567742, Time: 09_05_2022__00:16:06\n","Epoch 3 of 5, Step: 9400 of 11250, Training loss: 1.2364707, Training accuracy: 0.5567021, Time: 09_05_2022__00:16:17\n","Epoch 3 of 5, Step: 9500 of 11250, Training loss: 1.2370269, Training accuracy: 0.5564737, Time: 09_05_2022__00:16:28\n","Epoch 3 of 5, Step: 9600 of 11250, Training loss: 1.2356815, Training accuracy: 0.5567708, Time: 09_05_2022__00:16:39\n","Epoch 3 of 5, Step: 9700 of 11250, Training loss: 1.2338677, Training accuracy: 0.5572680, Time: 09_05_2022__00:16:50\n","Epoch 3 of 5, Step: 9800 of 11250, Training loss: 1.2323831, Training accuracy: 0.5578571, Time: 09_05_2022__00:17:01\n","Epoch 3 of 5, Step: 9900 of 11250, Training loss: 1.2321959, Training accuracy: 0.5580051, Time: 09_05_2022__00:17:13\n","Epoch 3 of 5, Step: 10000 of 11250, Training loss: 1.2311782, Training accuracy: 0.5584000, Time: 09_05_2022__00:17:24\n","Epoch 3 of 5, Step: 10100 of 11250, Training loss: 1.2316549, Training accuracy: 0.5583663, Time: 09_05_2022__00:17:35\n","Epoch 3 of 5, Step: 10200 of 11250, Training loss: 1.2307467, Training accuracy: 0.5586029, Time: 09_05_2022__00:17:46\n","Epoch 3 of 5, Step: 10300 of 11250, Training loss: 1.2295058, Training accuracy: 0.5590291, Time: 09_05_2022__00:17:57\n","Epoch 3 of 5, Step: 10400 of 11250, Training loss: 1.2281223, Training accuracy: 0.5596635, Time: 09_05_2022__00:18:08\n","Epoch 3 of 5, Step: 10500 of 11250, Training loss: 1.2274121, Training accuracy: 0.5602381, Time: 09_05_2022__00:18:19\n","Epoch 3 of 5, Step: 10600 of 11250, Training loss: 1.2269269, Training accuracy: 0.5604009, Time: 09_05_2022__00:18:30\n","Epoch 3 of 5, Step: 10700 of 11250, Training loss: 1.2259765, Training accuracy: 0.5606308, Time: 09_05_2022__00:18:41\n","Epoch 3 of 5, Step: 10800 of 11250, Training loss: 1.2252162, Training accuracy: 0.5610185, Time: 09_05_2022__00:18:52\n","Epoch 3 of 5, Step: 10900 of 11250, Training loss: 1.2253791, Training accuracy: 0.5611927, Time: 09_05_2022__00:19:03\n","Epoch 3 of 5, Step: 11000 of 11250, Training loss: 1.2247453, Training accuracy: 0.5615000, Time: 09_05_2022__00:19:15\n","Epoch 3 of 5, Step: 11100 of 11250, Training loss: 1.2233924, Training accuracy: 0.5620495, Time: 09_05_2022__00:19:26\n","Epoch 3 of 5, Step: 11200 of 11250, Training loss: 1.2230985, Training accuracy: 0.5620982, Time: 09_05_2022__00:19:37\n","Epoch 3 of 5, Average training loss: 1.2230218, Average training accuracy: 0.5620222, Time: 09_05_2022__00:19:42\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f43a910cd9a34aec93395e1c464aa448"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 1.0943473, Validation accuracy: 0.5850000, Time: 09_05_2022__00:19:46 | Loss decreased from 1.2406830 to 1.0949917 .... Saving the model\n","Step: 200 of 1250, Validation loss: 1.0960708, Validation accuracy: 0.5825000, Time: 09_05_2022__00:19:52\n","Step: 300 of 1250, Validation loss: 1.1166845, Validation accuracy: 0.5783333, Time: 09_05_2022__00:19:55\n","Step: 400 of 1250, Validation loss: 1.1186793, Validation accuracy: 0.5818750, Time: 09_05_2022__00:19:59\n","Step: 500 of 1250, Validation loss: 1.1331435, Validation accuracy: 0.5805000, Time: 09_05_2022__00:20:03\n","Step: 600 of 1250, Validation loss: 1.1226481, Validation accuracy: 0.5879167, Time: 09_05_2022__00:20:07\n","Step: 700 of 1250, Validation loss: 1.1083649, Validation accuracy: 0.5964286, Time: 09_05_2022__00:20:10\n","Step: 800 of 1250, Validation loss: 1.0972743, Validation accuracy: 0.6003125, Time: 09_05_2022__00:20:14\n","Step: 900 of 1250, Validation loss: 1.1043803, Validation accuracy: 0.5997222, Time: 09_05_2022__00:20:18\n","Step: 1000 of 1250, Validation loss: 1.1105936, Validation accuracy: 0.5947500, Time: 09_05_2022__00:20:21\n","Step: 1100 of 1250, Validation loss: 1.1102740, Validation accuracy: 0.5968182, Time: 09_05_2022__00:20:25\n","Step: 1200 of 1250, Validation loss: 1.1182736, Validation accuracy: 0.5956250, Time: 09_05_2022__00:20:29\n","Average validation loss: 1.1200102, Average validation accuracy: 0.5948000, Time: 09_05_2022__00:20:30\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"830e8af7072e4e30a64da627c1d74e06"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 4 of 5, Step: 100 of 11250, Training loss: 1.0114404, Training accuracy: 0.6300000, Time: 09_05_2022__00:20:42\n","Epoch 4 of 5, Step: 200 of 11250, Training loss: 1.0749114, Training accuracy: 0.6175000, Time: 09_05_2022__00:20:53\n","Epoch 4 of 5, Step: 300 of 11250, Training loss: 1.1053736, Training accuracy: 0.6058333, Time: 09_05_2022__00:21:04\n","Epoch 4 of 5, Step: 400 of 11250, Training loss: 1.0978233, Training accuracy: 0.6050000, Time: 09_05_2022__00:21:15\n","Epoch 4 of 5, Step: 500 of 11250, Training loss: 1.0969923, Training accuracy: 0.6060000, Time: 09_05_2022__00:21:26\n","Epoch 4 of 5, Step: 600 of 11250, Training loss: 1.0981075, Training accuracy: 0.6058333, Time: 09_05_2022__00:21:37\n","Epoch 4 of 5, Step: 700 of 11250, Training loss: 1.1116684, Training accuracy: 0.5985714, Time: 09_05_2022__00:21:48\n","Epoch 4 of 5, Step: 800 of 11250, Training loss: 1.1075478, Training accuracy: 0.6012500, Time: 09_05_2022__00:21:59\n","Epoch 4 of 5, Step: 900 of 11250, Training loss: 1.1057376, Training accuracy: 0.6041667, Time: 09_05_2022__00:22:10\n","Epoch 4 of 5, Step: 1000 of 11250, Training loss: 1.1053794, Training accuracy: 0.6067500, Time: 09_05_2022__00:22:21\n","Epoch 4 of 5, Step: 1100 of 11250, Training loss: 1.1048434, Training accuracy: 0.6068182, Time: 09_05_2022__00:22:32\n","Epoch 4 of 5, Step: 1200 of 11250, Training loss: 1.1053245, Training accuracy: 0.6062500, Time: 09_05_2022__00:22:44\n","Epoch 4 of 5, Step: 1300 of 11250, Training loss: 1.1082861, Training accuracy: 0.6067308, Time: 09_05_2022__00:22:55\n","Epoch 4 of 5, Step: 1400 of 11250, Training loss: 1.1066338, Training accuracy: 0.6071429, Time: 09_05_2022__00:23:06\n","Epoch 4 of 5, Step: 1500 of 11250, Training loss: 1.1069176, Training accuracy: 0.6078333, Time: 09_05_2022__00:23:17\n","Epoch 4 of 5, Step: 1600 of 11250, Training loss: 1.1047137, Training accuracy: 0.6096875, Time: 09_05_2022__00:23:28\n","Epoch 4 of 5, Step: 1700 of 11250, Training loss: 1.1066979, Training accuracy: 0.6077941, Time: 09_05_2022__00:23:39\n","Epoch 4 of 5, Step: 1800 of 11250, Training loss: 1.1092360, Training accuracy: 0.6059722, Time: 09_05_2022__00:23:50\n","Epoch 4 of 5, Step: 1900 of 11250, Training loss: 1.1068566, Training accuracy: 0.6072368, Time: 09_05_2022__00:24:01\n","Epoch 4 of 5, Step: 2000 of 11250, Training loss: 1.1071509, Training accuracy: 0.6065000, Time: 09_05_2022__00:24:12\n","Epoch 4 of 5, Step: 2100 of 11250, Training loss: 1.1055426, Training accuracy: 0.6067857, Time: 09_05_2022__00:24:23\n","Epoch 4 of 5, Step: 2200 of 11250, Training loss: 1.1051085, Training accuracy: 0.6064773, Time: 09_05_2022__00:24:34\n","Epoch 4 of 5, Step: 2300 of 11250, Training loss: 1.1042566, Training accuracy: 0.6079348, Time: 09_05_2022__00:24:45\n","Epoch 4 of 5, Step: 2400 of 11250, Training loss: 1.1013156, Training accuracy: 0.6078125, Time: 09_05_2022__00:24:57\n","Epoch 4 of 5, Step: 2500 of 11250, Training loss: 1.0985868, Training accuracy: 0.6081000, Time: 09_05_2022__00:25:08\n","Epoch 4 of 5, Step: 2600 of 11250, Training loss: 1.0962013, Training accuracy: 0.6083654, Time: 09_05_2022__00:25:19\n","Epoch 4 of 5, Step: 2700 of 11250, Training loss: 1.0939874, Training accuracy: 0.6088889, Time: 09_05_2022__00:25:30\n","Epoch 4 of 5, Step: 2800 of 11250, Training loss: 1.0938041, Training accuracy: 0.6089286, Time: 09_05_2022__00:25:41\n","Epoch 4 of 5, Step: 2900 of 11250, Training loss: 1.0940386, Training accuracy: 0.6083621, Time: 09_05_2022__00:25:52\n","Epoch 4 of 5, Step: 3000 of 11250, Training loss: 1.0955537, Training accuracy: 0.6070000, Time: 09_05_2022__00:26:03\n","Epoch 4 of 5, Step: 3100 of 11250, Training loss: 1.0931044, Training accuracy: 0.6075000, Time: 09_05_2022__00:26:14\n","Epoch 4 of 5, Step: 3200 of 11250, Training loss: 1.0899336, Training accuracy: 0.6089062, Time: 09_05_2022__00:26:25\n","Epoch 4 of 5, Step: 3300 of 11250, Training loss: 1.0924920, Training accuracy: 0.6079545, Time: 09_05_2022__00:26:36\n","Epoch 4 of 5, Step: 3400 of 11250, Training loss: 1.0922470, Training accuracy: 0.6076471, Time: 09_05_2022__00:26:47\n","Epoch 4 of 5, Step: 3500 of 11250, Training loss: 1.0936600, Training accuracy: 0.6067143, Time: 09_05_2022__00:26:59\n","Epoch 4 of 5, Step: 3600 of 11250, Training loss: 1.0930370, Training accuracy: 0.6064583, Time: 09_05_2022__00:27:10\n","Epoch 4 of 5, Step: 3700 of 11250, Training loss: 1.0926436, Training accuracy: 0.6061486, Time: 09_05_2022__00:27:21\n","Epoch 4 of 5, Step: 3800 of 11250, Training loss: 1.0915212, Training accuracy: 0.6065789, Time: 09_05_2022__00:27:32\n","Epoch 4 of 5, Step: 3900 of 11250, Training loss: 1.0900442, Training accuracy: 0.6061538, Time: 09_05_2022__00:27:43\n","Epoch 4 of 5, Step: 4000 of 11250, Training loss: 1.0894908, Training accuracy: 0.6069375, Time: 09_05_2022__00:27:54\n","Epoch 4 of 5, Step: 4100 of 11250, Training loss: 1.0902431, Training accuracy: 0.6068902, Time: 09_05_2022__00:28:05\n","Epoch 4 of 5, Step: 4200 of 11250, Training loss: 1.0863347, Training accuracy: 0.6082143, Time: 09_05_2022__00:28:16\n","Epoch 4 of 5, Step: 4300 of 11250, Training loss: 1.0836832, Training accuracy: 0.6090698, Time: 09_05_2022__00:28:27\n","Epoch 4 of 5, Step: 4400 of 11250, Training loss: 1.0823003, Training accuracy: 0.6096023, Time: 09_05_2022__00:28:38\n","Epoch 4 of 5, Step: 4500 of 11250, Training loss: 1.0807956, Training accuracy: 0.6103333, Time: 09_05_2022__00:28:50\n","Epoch 4 of 5, Step: 4600 of 11250, Training loss: 1.0814571, Training accuracy: 0.6101630, Time: 09_05_2022__00:29:01\n","Epoch 4 of 5, Step: 4700 of 11250, Training loss: 1.0800491, Training accuracy: 0.6107979, Time: 09_05_2022__00:29:12\n","Epoch 4 of 5, Step: 4800 of 11250, Training loss: 1.0786307, Training accuracy: 0.6111458, Time: 09_05_2022__00:29:23\n","Epoch 4 of 5, Step: 4900 of 11250, Training loss: 1.0786572, Training accuracy: 0.6111735, Time: 09_05_2022__00:29:34\n","Epoch 4 of 5, Step: 5000 of 11250, Training loss: 1.0785588, Training accuracy: 0.6118000, Time: 09_05_2022__00:29:45\n","Epoch 4 of 5, Step: 5100 of 11250, Training loss: 1.0767780, Training accuracy: 0.6124510, Time: 09_05_2022__00:29:56\n","Epoch 4 of 5, Step: 5200 of 11250, Training loss: 1.0757409, Training accuracy: 0.6129327, Time: 09_05_2022__00:30:07\n","Epoch 4 of 5, Step: 5300 of 11250, Training loss: 1.0756645, Training accuracy: 0.6126887, Time: 09_05_2022__00:30:18\n","Epoch 4 of 5, Step: 5400 of 11250, Training loss: 1.0744250, Training accuracy: 0.6135185, Time: 09_05_2022__00:30:29\n","Epoch 4 of 5, Step: 5500 of 11250, Training loss: 1.0750426, Training accuracy: 0.6136818, Time: 09_05_2022__00:30:40\n","Epoch 4 of 5, Step: 5600 of 11250, Training loss: 1.0740104, Training accuracy: 0.6139732, Time: 09_05_2022__00:30:52\n","Epoch 4 of 5, Step: 5700 of 11250, Training loss: 1.0740172, Training accuracy: 0.6139035, Time: 09_05_2022__00:31:03\n","Epoch 4 of 5, Step: 5800 of 11250, Training loss: 1.0733013, Training accuracy: 0.6140086, Time: 09_05_2022__00:31:14\n","Epoch 4 of 5, Step: 5900 of 11250, Training loss: 1.0734340, Training accuracy: 0.6138559, Time: 09_05_2022__00:31:25\n","Epoch 4 of 5, Step: 6000 of 11250, Training loss: 1.0734630, Training accuracy: 0.6137500, Time: 09_05_2022__00:31:36\n","Epoch 4 of 5, Step: 6100 of 11250, Training loss: 1.0735603, Training accuracy: 0.6140574, Time: 09_05_2022__00:31:47\n","Epoch 4 of 5, Step: 6200 of 11250, Training loss: 1.0729426, Training accuracy: 0.6141935, Time: 09_05_2022__00:31:58\n","Epoch 4 of 5, Step: 6300 of 11250, Training loss: 1.0735301, Training accuracy: 0.6143254, Time: 09_05_2022__00:32:09\n","Epoch 4 of 5, Step: 6400 of 11250, Training loss: 1.0725817, Training accuracy: 0.6147266, Time: 09_05_2022__00:32:20\n","Epoch 4 of 5, Step: 6500 of 11250, Training loss: 1.0710637, Training accuracy: 0.6153077, Time: 09_05_2022__00:32:31\n","Epoch 4 of 5, Step: 6600 of 11250, Training loss: 1.0708065, Training accuracy: 0.6160227, Time: 09_05_2022__00:32:43\n","Epoch 4 of 5, Step: 6700 of 11250, Training loss: 1.0698130, Training accuracy: 0.6161940, Time: 09_05_2022__00:32:54\n","Epoch 4 of 5, Step: 6800 of 11250, Training loss: 1.0698121, Training accuracy: 0.6164338, Time: 09_05_2022__00:33:05\n","Epoch 4 of 5, Step: 6900 of 11250, Training loss: 1.0680472, Training accuracy: 0.6168841, Time: 09_05_2022__00:33:16\n","Epoch 4 of 5, Step: 7000 of 11250, Training loss: 1.0659820, Training accuracy: 0.6176429, Time: 09_05_2022__00:33:27\n","Epoch 4 of 5, Step: 7100 of 11250, Training loss: 1.0664375, Training accuracy: 0.6173239, Time: 09_05_2022__00:33:38\n","Epoch 4 of 5, Step: 7200 of 11250, Training loss: 1.0648798, Training accuracy: 0.6178125, Time: 09_05_2022__00:33:49\n","Epoch 4 of 5, Step: 7300 of 11250, Training loss: 1.0643286, Training accuracy: 0.6179110, Time: 09_05_2022__00:34:00\n","Epoch 4 of 5, Step: 7400 of 11250, Training loss: 1.0636399, Training accuracy: 0.6181757, Time: 09_05_2022__00:34:11\n","Epoch 4 of 5, Step: 7500 of 11250, Training loss: 1.0627053, Training accuracy: 0.6185000, Time: 09_05_2022__00:34:22\n","Epoch 4 of 5, Step: 7600 of 11250, Training loss: 1.0612023, Training accuracy: 0.6192105, Time: 09_05_2022__00:34:33\n","Epoch 4 of 5, Step: 7700 of 11250, Training loss: 1.0614813, Training accuracy: 0.6192857, Time: 09_05_2022__00:34:45\n","Epoch 4 of 5, Step: 7800 of 11250, Training loss: 1.0599545, Training accuracy: 0.6197436, Time: 09_05_2022__00:34:56\n","Epoch 4 of 5, Step: 7900 of 11250, Training loss: 1.0590682, Training accuracy: 0.6200000, Time: 09_05_2022__00:35:07\n","Epoch 4 of 5, Step: 8000 of 11250, Training loss: 1.0569866, Training accuracy: 0.6205000, Time: 09_05_2022__00:35:18\n","Epoch 4 of 5, Step: 8100 of 11250, Training loss: 1.0567223, Training accuracy: 0.6208642, Time: 09_05_2022__00:35:29\n","Epoch 4 of 5, Step: 8200 of 11250, Training loss: 1.0565358, Training accuracy: 0.6210671, Time: 09_05_2022__00:35:40\n","Epoch 4 of 5, Step: 8300 of 11250, Training loss: 1.0561904, Training accuracy: 0.6211747, Time: 09_05_2022__00:35:51\n","Epoch 4 of 5, Step: 8400 of 11250, Training loss: 1.0569527, Training accuracy: 0.6211607, Time: 09_05_2022__00:36:02\n","Epoch 4 of 5, Step: 8500 of 11250, Training loss: 1.0569965, Training accuracy: 0.6213824, Time: 09_05_2022__00:36:13\n","Epoch 4 of 5, Step: 8600 of 11250, Training loss: 1.0568395, Training accuracy: 0.6211337, Time: 09_05_2022__00:36:25\n","Epoch 4 of 5, Step: 8700 of 11250, Training loss: 1.0559925, Training accuracy: 0.6217529, Time: 09_05_2022__00:36:36\n","Epoch 4 of 5, Step: 8800 of 11250, Training loss: 1.0541497, Training accuracy: 0.6224716, Time: 09_05_2022__00:36:47\n","Epoch 4 of 5, Step: 8900 of 11250, Training loss: 1.0528144, Training accuracy: 0.6228090, Time: 09_05_2022__00:36:58\n","Epoch 4 of 5, Step: 9000 of 11250, Training loss: 1.0526519, Training accuracy: 0.6228611, Time: 09_05_2022__00:37:09\n","Epoch 4 of 5, Step: 9100 of 11250, Training loss: 1.0527040, Training accuracy: 0.6226648, Time: 09_05_2022__00:37:20\n","Epoch 4 of 5, Step: 9200 of 11250, Training loss: 1.0510546, Training accuracy: 0.6233967, Time: 09_05_2022__00:37:31\n","Epoch 4 of 5, Step: 9300 of 11250, Training loss: 1.0508297, Training accuracy: 0.6237903, Time: 09_05_2022__00:37:43\n","Epoch 4 of 5, Step: 9400 of 11250, Training loss: 1.0501281, Training accuracy: 0.6239628, Time: 09_05_2022__00:37:54\n","Epoch 4 of 5, Step: 9500 of 11250, Training loss: 1.0508717, Training accuracy: 0.6236579, Time: 09_05_2022__00:38:05\n","Epoch 4 of 5, Step: 9600 of 11250, Training loss: 1.0495871, Training accuracy: 0.6241927, Time: 09_05_2022__00:38:16\n","Epoch 4 of 5, Step: 9700 of 11250, Training loss: 1.0477082, Training accuracy: 0.6251289, Time: 09_05_2022__00:38:27\n","Epoch 4 of 5, Step: 9800 of 11250, Training loss: 1.0465538, Training accuracy: 0.6257653, Time: 09_05_2022__00:38:38\n","Epoch 4 of 5, Step: 9900 of 11250, Training loss: 1.0464496, Training accuracy: 0.6260606, Time: 09_05_2022__00:38:49\n","Epoch 4 of 5, Step: 10000 of 11250, Training loss: 1.0458319, Training accuracy: 0.6263750, Time: 09_05_2022__00:39:00\n","Epoch 4 of 5, Step: 10100 of 11250, Training loss: 1.0461780, Training accuracy: 0.6261881, Time: 09_05_2022__00:39:11\n","Epoch 4 of 5, Step: 10200 of 11250, Training loss: 1.0454910, Training accuracy: 0.6265931, Time: 09_05_2022__00:39:23\n","Epoch 4 of 5, Step: 10300 of 11250, Training loss: 1.0444685, Training accuracy: 0.6271117, Time: 09_05_2022__00:39:34\n","Epoch 4 of 5, Step: 10400 of 11250, Training loss: 1.0436136, Training accuracy: 0.6275240, Time: 09_05_2022__00:39:45\n","Epoch 4 of 5, Step: 10500 of 11250, Training loss: 1.0432576, Training accuracy: 0.6276190, Time: 09_05_2022__00:39:56\n","Epoch 4 of 5, Step: 10600 of 11250, Training loss: 1.0432876, Training accuracy: 0.6275708, Time: 09_05_2022__00:40:07\n","Epoch 4 of 5, Step: 10700 of 11250, Training loss: 1.0425464, Training accuracy: 0.6279206, Time: 09_05_2022__00:40:18\n","Epoch 4 of 5, Step: 10800 of 11250, Training loss: 1.0419822, Training accuracy: 0.6280787, Time: 09_05_2022__00:40:29\n","Epoch 4 of 5, Step: 10900 of 11250, Training loss: 1.0421768, Training accuracy: 0.6282110, Time: 09_05_2022__00:40:40\n","Epoch 4 of 5, Step: 11000 of 11250, Training loss: 1.0415190, Training accuracy: 0.6284318, Time: 09_05_2022__00:40:51\n","Epoch 4 of 5, Step: 11100 of 11250, Training loss: 1.0404215, Training accuracy: 0.6290766, Time: 09_05_2022__00:41:02\n","Epoch 4 of 5, Step: 11200 of 11250, Training loss: 1.0402630, Training accuracy: 0.6290625, Time: 09_05_2022__00:41:14\n","Epoch 4 of 5, Average training loss: 1.0399328, Average training accuracy: 0.6290222, Time: 09_05_2022__00:41:19\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29ac7b12b7044ca58b3ca711dbfc1e2f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.9454928, Validation accuracy: 0.6450000, Time: 09_05_2022__00:41:23 | Loss decreased from 1.0949917 to 0.9465317 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.9543870, Validation accuracy: 0.6400000, Time: 09_05_2022__00:41:29\n","Step: 300 of 1250, Validation loss: 0.9881313, Validation accuracy: 0.6416667, Time: 09_05_2022__00:41:32\n","Step: 400 of 1250, Validation loss: 0.9931167, Validation accuracy: 0.6387500, Time: 09_05_2022__00:41:36\n","Step: 500 of 1250, Validation loss: 1.0148226, Validation accuracy: 0.6330000, Time: 09_05_2022__00:41:40\n","Step: 600 of 1250, Validation loss: 1.0054249, Validation accuracy: 0.6387500, Time: 09_05_2022__00:41:43\n","Step: 700 of 1250, Validation loss: 0.9934012, Validation accuracy: 0.6435714, Time: 09_05_2022__00:41:47\n","Step: 800 of 1250, Validation loss: 0.9743302, Validation accuracy: 0.6525000, Time: 09_05_2022__00:41:51\n","Step: 900 of 1250, Validation loss: 0.9815795, Validation accuracy: 0.6500000, Time: 09_05_2022__00:41:54\n","Step: 1000 of 1250, Validation loss: 0.9899510, Validation accuracy: 0.6470000, Time: 09_05_2022__00:41:58\n","Step: 1100 of 1250, Validation loss: 0.9914148, Validation accuracy: 0.6488636, Time: 09_05_2022__00:42:02\n","Step: 1200 of 1250, Validation loss: 0.9997871, Validation accuracy: 0.6468750, Time: 09_05_2022__00:42:05\n","Average validation loss: 1.0043141, Average validation accuracy: 0.6456000, Time: 09_05_2022__00:42:07\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f639999fa254eb1af618b7d10596fa5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 5 of 5, Step: 100 of 11250, Training loss: 0.9347558, Training accuracy: 0.6775000, Time: 09_05_2022__00:42:18\n","Epoch 5 of 5, Step: 200 of 11250, Training loss: 0.9494213, Training accuracy: 0.6712500, Time: 09_05_2022__00:42:29\n","Epoch 5 of 5, Step: 300 of 11250, Training loss: 0.9655393, Training accuracy: 0.6550000, Time: 09_05_2022__00:42:40\n","Epoch 5 of 5, Step: 400 of 11250, Training loss: 0.9426223, Training accuracy: 0.6625000, Time: 09_05_2022__00:42:52\n","Epoch 5 of 5, Step: 500 of 11250, Training loss: 0.9472997, Training accuracy: 0.6605000, Time: 09_05_2022__00:43:03\n","Epoch 5 of 5, Step: 600 of 11250, Training loss: 0.9482928, Training accuracy: 0.6612500, Time: 09_05_2022__00:43:14\n","Epoch 5 of 5, Step: 700 of 11250, Training loss: 0.9597937, Training accuracy: 0.6592857, Time: 09_05_2022__00:43:25\n","Epoch 5 of 5, Step: 800 of 11250, Training loss: 0.9532236, Training accuracy: 0.6637500, Time: 09_05_2022__00:43:36\n","Epoch 5 of 5, Step: 900 of 11250, Training loss: 0.9607317, Training accuracy: 0.6591667, Time: 09_05_2022__00:43:47\n","Epoch 5 of 5, Step: 1000 of 11250, Training loss: 0.9586197, Training accuracy: 0.6595000, Time: 09_05_2022__00:43:58\n","Epoch 5 of 5, Step: 1100 of 11250, Training loss: 0.9612952, Training accuracy: 0.6579545, Time: 09_05_2022__00:44:09\n","Epoch 5 of 5, Step: 1200 of 11250, Training loss: 0.9637769, Training accuracy: 0.6568750, Time: 09_05_2022__00:44:20\n","Epoch 5 of 5, Step: 1300 of 11250, Training loss: 0.9665004, Training accuracy: 0.6569231, Time: 09_05_2022__00:44:32\n","Epoch 5 of 5, Step: 1400 of 11250, Training loss: 0.9628796, Training accuracy: 0.6601786, Time: 09_05_2022__00:44:43\n","Epoch 5 of 5, Step: 1500 of 11250, Training loss: 0.9648771, Training accuracy: 0.6598333, Time: 09_05_2022__00:44:54\n","Epoch 5 of 5, Step: 1600 of 11250, Training loss: 0.9615040, Training accuracy: 0.6601562, Time: 09_05_2022__00:45:05\n","Epoch 5 of 5, Step: 1700 of 11250, Training loss: 0.9628242, Training accuracy: 0.6602941, Time: 09_05_2022__00:45:16\n","Epoch 5 of 5, Step: 1800 of 11250, Training loss: 0.9673219, Training accuracy: 0.6579167, Time: 09_05_2022__00:45:27\n","Epoch 5 of 5, Step: 1900 of 11250, Training loss: 0.9642196, Training accuracy: 0.6589474, Time: 09_05_2022__00:45:38\n","Epoch 5 of 5, Step: 2000 of 11250, Training loss: 0.9605838, Training accuracy: 0.6592500, Time: 09_05_2022__00:45:49\n","Epoch 5 of 5, Step: 2100 of 11250, Training loss: 0.9575429, Training accuracy: 0.6602381, Time: 09_05_2022__00:46:00\n","Epoch 5 of 5, Step: 2200 of 11250, Training loss: 0.9569386, Training accuracy: 0.6617045, Time: 09_05_2022__00:46:12\n","Epoch 5 of 5, Step: 2300 of 11250, Training loss: 0.9540383, Training accuracy: 0.6628261, Time: 09_05_2022__00:46:23\n","Epoch 5 of 5, Step: 2400 of 11250, Training loss: 0.9517001, Training accuracy: 0.6627083, Time: 09_05_2022__00:46:34\n","Epoch 5 of 5, Step: 2500 of 11250, Training loss: 0.9499069, Training accuracy: 0.6641000, Time: 09_05_2022__00:46:45\n","Epoch 5 of 5, Step: 2600 of 11250, Training loss: 0.9485189, Training accuracy: 0.6647115, Time: 09_05_2022__00:46:56\n","Epoch 5 of 5, Step: 2700 of 11250, Training loss: 0.9463168, Training accuracy: 0.6650926, Time: 09_05_2022__00:47:07\n","Epoch 5 of 5, Step: 2800 of 11250, Training loss: 0.9458791, Training accuracy: 0.6647321, Time: 09_05_2022__00:47:18\n","Epoch 5 of 5, Step: 2900 of 11250, Training loss: 0.9459636, Training accuracy: 0.6636207, Time: 09_05_2022__00:47:29\n","Epoch 5 of 5, Step: 3000 of 11250, Training loss: 0.9448199, Training accuracy: 0.6635000, Time: 09_05_2022__00:47:41\n","Epoch 5 of 5, Step: 3100 of 11250, Training loss: 0.9415637, Training accuracy: 0.6647581, Time: 09_05_2022__00:47:52\n","Epoch 5 of 5, Step: 3200 of 11250, Training loss: 0.9360724, Training accuracy: 0.6669531, Time: 09_05_2022__00:48:03\n","Epoch 5 of 5, Step: 3300 of 11250, Training loss: 0.9392716, Training accuracy: 0.6665152, Time: 09_05_2022__00:48:14\n","Epoch 5 of 5, Step: 3400 of 11250, Training loss: 0.9397181, Training accuracy: 0.6670588, Time: 09_05_2022__00:48:25\n","Epoch 5 of 5, Step: 3500 of 11250, Training loss: 0.9396878, Training accuracy: 0.6667143, Time: 09_05_2022__00:48:36\n","Epoch 5 of 5, Step: 3600 of 11250, Training loss: 0.9402501, Training accuracy: 0.6663889, Time: 09_05_2022__00:48:47\n","Epoch 5 of 5, Step: 3700 of 11250, Training loss: 0.9395377, Training accuracy: 0.6667568, Time: 09_05_2022__00:48:58\n","Epoch 5 of 5, Step: 3800 of 11250, Training loss: 0.9387046, Training accuracy: 0.6673026, Time: 09_05_2022__00:49:10\n","Epoch 5 of 5, Step: 3900 of 11250, Training loss: 0.9384087, Training accuracy: 0.6674359, Time: 09_05_2022__00:49:21\n","Epoch 5 of 5, Step: 4000 of 11250, Training loss: 0.9361592, Training accuracy: 0.6686250, Time: 09_05_2022__00:49:32\n","Epoch 5 of 5, Step: 4100 of 11250, Training loss: 0.9371442, Training accuracy: 0.6683537, Time: 09_05_2022__00:49:43\n","Epoch 5 of 5, Step: 4200 of 11250, Training loss: 0.9336472, Training accuracy: 0.6697024, Time: 09_05_2022__00:49:54\n","Epoch 5 of 5, Step: 4300 of 11250, Training loss: 0.9315683, Training accuracy: 0.6705814, Time: 09_05_2022__00:50:05\n","Epoch 5 of 5, Step: 4400 of 11250, Training loss: 0.9292914, Training accuracy: 0.6711932, Time: 09_05_2022__00:50:16\n","Epoch 5 of 5, Step: 4500 of 11250, Training loss: 0.9282841, Training accuracy: 0.6717778, Time: 09_05_2022__00:50:27\n","Epoch 5 of 5, Step: 4600 of 11250, Training loss: 0.9297933, Training accuracy: 0.6715761, Time: 09_05_2022__00:50:38\n","Epoch 5 of 5, Step: 4700 of 11250, Training loss: 0.9285360, Training accuracy: 0.6720745, Time: 09_05_2022__00:50:49\n","Epoch 5 of 5, Step: 4800 of 11250, Training loss: 0.9278038, Training accuracy: 0.6718750, Time: 09_05_2022__00:51:01\n","Epoch 5 of 5, Step: 4900 of 11250, Training loss: 0.9275877, Training accuracy: 0.6717347, Time: 09_05_2022__00:51:12\n","Epoch 5 of 5, Step: 5000 of 11250, Training loss: 0.9276215, Training accuracy: 0.6720500, Time: 09_05_2022__00:51:23\n","Epoch 5 of 5, Step: 5100 of 11250, Training loss: 0.9260935, Training accuracy: 0.6723039, Time: 09_05_2022__00:51:34\n","Epoch 5 of 5, Step: 5200 of 11250, Training loss: 0.9250734, Training accuracy: 0.6728365, Time: 09_05_2022__00:51:45\n","Epoch 5 of 5, Step: 5300 of 11250, Training loss: 0.9246287, Training accuracy: 0.6725000, Time: 09_05_2022__00:51:56\n","Epoch 5 of 5, Step: 5400 of 11250, Training loss: 0.9238084, Training accuracy: 0.6729167, Time: 09_05_2022__00:52:07\n","Epoch 5 of 5, Step: 5500 of 11250, Training loss: 0.9244741, Training accuracy: 0.6730000, Time: 09_05_2022__00:52:18\n","Epoch 5 of 5, Step: 5600 of 11250, Training loss: 0.9240107, Training accuracy: 0.6732143, Time: 09_05_2022__00:52:30\n","Epoch 5 of 5, Step: 5700 of 11250, Training loss: 0.9233103, Training accuracy: 0.6731579, Time: 09_05_2022__00:52:41\n","Epoch 5 of 5, Step: 5800 of 11250, Training loss: 0.9229700, Training accuracy: 0.6727586, Time: 09_05_2022__00:52:52\n","Epoch 5 of 5, Step: 5900 of 11250, Training loss: 0.9234247, Training accuracy: 0.6728390, Time: 09_05_2022__00:53:03\n","Epoch 5 of 5, Step: 6000 of 11250, Training loss: 0.9242595, Training accuracy: 0.6722500, Time: 09_05_2022__00:53:14\n","Epoch 5 of 5, Step: 6100 of 11250, Training loss: 0.9244200, Training accuracy: 0.6720902, Time: 09_05_2022__00:53:25\n","Epoch 5 of 5, Step: 6200 of 11250, Training loss: 0.9237165, Training accuracy: 0.6722177, Time: 09_05_2022__00:53:36\n","Epoch 5 of 5, Step: 6300 of 11250, Training loss: 0.9235585, Training accuracy: 0.6718651, Time: 09_05_2022__00:53:47\n","Epoch 5 of 5, Step: 6400 of 11250, Training loss: 0.9229406, Training accuracy: 0.6720703, Time: 09_05_2022__00:53:58\n","Epoch 5 of 5, Step: 6500 of 11250, Training loss: 0.9219614, Training accuracy: 0.6721923, Time: 09_05_2022__00:54:10\n","Epoch 5 of 5, Step: 6600 of 11250, Training loss: 0.9218537, Training accuracy: 0.6723106, Time: 09_05_2022__00:54:21\n","Epoch 5 of 5, Step: 6700 of 11250, Training loss: 0.9215771, Training accuracy: 0.6723507, Time: 09_05_2022__00:54:32\n","Epoch 5 of 5, Step: 6800 of 11250, Training loss: 0.9217121, Training accuracy: 0.6722426, Time: 09_05_2022__00:54:43\n","Epoch 5 of 5, Step: 6900 of 11250, Training loss: 0.9201575, Training accuracy: 0.6726449, Time: 09_05_2022__00:54:54\n","Epoch 5 of 5, Step: 7000 of 11250, Training loss: 0.9188416, Training accuracy: 0.6731786, Time: 09_05_2022__00:55:05\n","Epoch 5 of 5, Step: 7100 of 11250, Training loss: 0.9194010, Training accuracy: 0.6729225, Time: 09_05_2022__00:55:16\n","Epoch 5 of 5, Step: 7200 of 11250, Training loss: 0.9170343, Training accuracy: 0.6738889, Time: 09_05_2022__00:55:27\n","Epoch 5 of 5, Step: 7300 of 11250, Training loss: 0.9165733, Training accuracy: 0.6741096, Time: 09_05_2022__00:55:38\n","Epoch 5 of 5, Step: 7400 of 11250, Training loss: 0.9163059, Training accuracy: 0.6742568, Time: 09_05_2022__00:55:49\n","Epoch 5 of 5, Step: 7500 of 11250, Training loss: 0.9145356, Training accuracy: 0.6751667, Time: 09_05_2022__00:56:01\n","Epoch 5 of 5, Step: 7600 of 11250, Training loss: 0.9133560, Training accuracy: 0.6758553, Time: 09_05_2022__00:56:12\n","Epoch 5 of 5, Step: 7700 of 11250, Training loss: 0.9135549, Training accuracy: 0.6761364, Time: 09_05_2022__00:56:23\n","Epoch 5 of 5, Step: 7800 of 11250, Training loss: 0.9122813, Training accuracy: 0.6762500, Time: 09_05_2022__00:56:34\n","Epoch 5 of 5, Step: 7900 of 11250, Training loss: 0.9116963, Training accuracy: 0.6763291, Time: 09_05_2022__00:56:45\n","Epoch 5 of 5, Step: 8000 of 11250, Training loss: 0.9106277, Training accuracy: 0.6767188, Time: 09_05_2022__00:56:56\n","Epoch 5 of 5, Step: 8100 of 11250, Training loss: 0.9111407, Training accuracy: 0.6765432, Time: 09_05_2022__00:57:07\n","Epoch 5 of 5, Step: 8200 of 11250, Training loss: 0.9105540, Training accuracy: 0.6769207, Time: 09_05_2022__00:57:18\n","Epoch 5 of 5, Step: 8300 of 11250, Training loss: 0.9105111, Training accuracy: 0.6767169, Time: 09_05_2022__00:57:29\n","Epoch 5 of 5, Step: 8400 of 11250, Training loss: 0.9113137, Training accuracy: 0.6764881, Time: 09_05_2022__00:57:41\n","Epoch 5 of 5, Step: 8500 of 11250, Training loss: 0.9113168, Training accuracy: 0.6765588, Time: 09_05_2022__00:57:52\n","Epoch 5 of 5, Step: 8600 of 11250, Training loss: 0.9110840, Training accuracy: 0.6764535, Time: 09_05_2022__00:58:03\n","Epoch 5 of 5, Step: 8700 of 11250, Training loss: 0.9112556, Training accuracy: 0.6763506, Time: 09_05_2022__00:58:14\n","Epoch 5 of 5, Step: 8800 of 11250, Training loss: 0.9092303, Training accuracy: 0.6769318, Time: 09_05_2022__00:58:25\n","Epoch 5 of 5, Step: 8900 of 11250, Training loss: 0.9085332, Training accuracy: 0.6771910, Time: 09_05_2022__00:58:36\n","Epoch 5 of 5, Step: 9000 of 11250, Training loss: 0.9086948, Training accuracy: 0.6770278, Time: 09_05_2022__00:58:47\n","Epoch 5 of 5, Step: 9100 of 11250, Training loss: 0.9086375, Training accuracy: 0.6769505, Time: 09_05_2022__00:58:59\n","Epoch 5 of 5, Step: 9200 of 11250, Training loss: 0.9073603, Training accuracy: 0.6775272, Time: 09_05_2022__00:59:10\n","Epoch 5 of 5, Step: 9300 of 11250, Training loss: 0.9075597, Training accuracy: 0.6777688, Time: 09_05_2022__00:59:21\n","Epoch 5 of 5, Step: 9400 of 11250, Training loss: 0.9073851, Training accuracy: 0.6778989, Time: 09_05_2022__00:59:32\n","Epoch 5 of 5, Step: 9500 of 11250, Training loss: 0.9082752, Training accuracy: 0.6778684, Time: 09_05_2022__00:59:43\n","Epoch 5 of 5, Step: 9600 of 11250, Training loss: 0.9070909, Training accuracy: 0.6785677, Time: 09_05_2022__00:59:54\n","Epoch 5 of 5, Step: 9700 of 11250, Training loss: 0.9055713, Training accuracy: 0.6792010, Time: 09_05_2022__01:00:05\n","Epoch 5 of 5, Step: 9800 of 11250, Training loss: 0.9043035, Training accuracy: 0.6798469, Time: 09_05_2022__01:00:16\n","Epoch 5 of 5, Step: 9900 of 11250, Training loss: 0.9040583, Training accuracy: 0.6800253, Time: 09_05_2022__01:00:28\n","Epoch 5 of 5, Step: 10000 of 11250, Training loss: 0.9039350, Training accuracy: 0.6800500, Time: 09_05_2022__01:00:39\n","Epoch 5 of 5, Step: 10100 of 11250, Training loss: 0.9041662, Training accuracy: 0.6798267, Time: 09_05_2022__01:00:50\n","Epoch 5 of 5, Step: 10200 of 11250, Training loss: 0.9039092, Training accuracy: 0.6799020, Time: 09_05_2022__01:01:01\n","Epoch 5 of 5, Step: 10300 of 11250, Training loss: 0.9032852, Training accuracy: 0.6801699, Time: 09_05_2022__01:01:12\n","Epoch 5 of 5, Step: 10400 of 11250, Training loss: 0.9025797, Training accuracy: 0.6805288, Time: 09_05_2022__01:01:23\n","Epoch 5 of 5, Step: 10500 of 11250, Training loss: 0.9019427, Training accuracy: 0.6807143, Time: 09_05_2022__01:01:34\n","Epoch 5 of 5, Step: 10600 of 11250, Training loss: 0.9023562, Training accuracy: 0.6805425, Time: 09_05_2022__01:01:45\n","Epoch 5 of 5, Step: 10700 of 11250, Training loss: 0.9010763, Training accuracy: 0.6807944, Time: 09_05_2022__01:01:57\n","Epoch 5 of 5, Step: 10800 of 11250, Training loss: 0.9007115, Training accuracy: 0.6810648, Time: 09_05_2022__01:02:08\n","Epoch 5 of 5, Step: 10900 of 11250, Training loss: 0.9010083, Training accuracy: 0.6811009, Time: 09_05_2022__01:02:19\n","Epoch 5 of 5, Step: 11000 of 11250, Training loss: 0.9006601, Training accuracy: 0.6813182, Time: 09_05_2022__01:02:30\n","Epoch 5 of 5, Step: 11100 of 11250, Training loss: 0.9001360, Training accuracy: 0.6814865, Time: 09_05_2022__01:02:41\n","Epoch 5 of 5, Step: 11200 of 11250, Training loss: 0.8998310, Training accuracy: 0.6815402, Time: 09_05_2022__01:02:52\n","Epoch 5 of 5, Average training loss: 0.8996598, Average training accuracy: 0.6816000, Time: 09_05_2022__01:02:58\n","###################### Validating vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16f81a44a442453095e687223154ecde"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 1250, Validation loss: 0.8817830, Validation accuracy: 0.6775000, Time: 09_05_2022__01:03:01 | Loss decreased from 0.9465317 to 0.8870669 .... Saving the model\n","Step: 200 of 1250, Validation loss: 0.8675649, Validation accuracy: 0.6725000, Time: 09_05_2022__01:03:07 | Loss decreased from 0.8870669 to 0.8699546 .... Saving the model\n","Step: 300 of 1250, Validation loss: 0.8963527, Validation accuracy: 0.6733333, Time: 09_05_2022__01:03:13\n","Step: 400 of 1250, Validation loss: 0.8796912, Validation accuracy: 0.6843750, Time: 09_05_2022__01:03:17\n","Step: 500 of 1250, Validation loss: 0.8982340, Validation accuracy: 0.6805000, Time: 09_05_2022__01:03:21\n","Step: 600 of 1250, Validation loss: 0.8868633, Validation accuracy: 0.6858333, Time: 09_05_2022__01:03:25\n","Step: 700 of 1250, Validation loss: 0.8765842, Validation accuracy: 0.6921429, Time: 09_05_2022__01:03:28\n","Step: 800 of 1250, Validation loss: 0.8613843, Validation accuracy: 0.6950000, Time: 09_05_2022__01:03:32 | Loss decreased from 0.8699546 to 0.8600718 .... Saving the model\n","Step: 900 of 1250, Validation loss: 0.8679922, Validation accuracy: 0.6944444, Time: 09_05_2022__01:03:38\n","Step: 1000 of 1250, Validation loss: 0.8707115, Validation accuracy: 0.6942500, Time: 09_05_2022__01:03:42\n","Step: 1100 of 1250, Validation loss: 0.8712007, Validation accuracy: 0.6963636, Time: 09_05_2022__01:03:45\n","Step: 1200 of 1250, Validation loss: 0.8821171, Validation accuracy: 0.6947917, Time: 09_05_2022__01:03:49\n","Average validation loss: 0.8854901, Average validation accuracy: 0.6940000, Time: 09_05_2022__01:03:51\n","###################### Testing vgg19_batch_norm SGD, lr_0.0001, momentum_0.9 model ######################\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7136f2d2d2d34a7cabfb83caa4c822d8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step: 100 of 2500, Test accuracy: 0.7000000, Time: 09_05_2022__01:04:02\n","Step: 200 of 2500, Test accuracy: 0.7087500, Time: 09_05_2022__01:04:06\n","Step: 300 of 2500, Test accuracy: 0.7075000, Time: 09_05_2022__01:04:10\n","Step: 400 of 2500, Test accuracy: 0.6937500, Time: 09_05_2022__01:04:13\n","Step: 500 of 2500, Test accuracy: 0.6875000, Time: 09_05_2022__01:04:17\n","Step: 600 of 2500, Test accuracy: 0.6841667, Time: 09_05_2022__01:04:21\n","Step: 700 of 2500, Test accuracy: 0.6814286, Time: 09_05_2022__01:04:24\n","Step: 800 of 2500, Test accuracy: 0.6834375, Time: 09_05_2022__01:04:28\n","Step: 900 of 2500, Test accuracy: 0.6833333, Time: 09_05_2022__01:04:32\n","Step: 1000 of 2500, Test accuracy: 0.6825000, Time: 09_05_2022__01:04:35\n","Step: 1100 of 2500, Test accuracy: 0.6856818, Time: 09_05_2022__01:04:39\n","Step: 1200 of 2500, Test accuracy: 0.6852083, Time: 09_05_2022__01:04:42\n","Step: 1300 of 2500, Test accuracy: 0.6863462, Time: 09_05_2022__01:04:46\n","Step: 1400 of 2500, Test accuracy: 0.6869643, Time: 09_05_2022__01:04:50\n","Step: 1500 of 2500, Test accuracy: 0.6880000, Time: 09_05_2022__01:04:53\n","Step: 1600 of 2500, Test accuracy: 0.6875000, Time: 09_05_2022__01:04:57\n","Step: 1700 of 2500, Test accuracy: 0.6875000, Time: 09_05_2022__01:05:01\n","Step: 1800 of 2500, Test accuracy: 0.6869444, Time: 09_05_2022__01:05:04\n","Step: 1900 of 2500, Test accuracy: 0.6884211, Time: 09_05_2022__01:05:08\n","Step: 2000 of 2500, Test accuracy: 0.6882500, Time: 09_05_2022__01:05:12\n","Step: 2100 of 2500, Test accuracy: 0.6870238, Time: 09_05_2022__01:05:15\n","Step: 2200 of 2500, Test accuracy: 0.6863636, Time: 09_05_2022__01:05:19\n","Step: 2300 of 2500, Test accuracy: 0.6864130, Time: 09_05_2022__01:05:23\n","Step: 2400 of 2500, Test accuracy: 0.6871875, Time: 09_05_2022__01:05:26\n","Step: 2500 of 2500, Test accuracy: 0.6867000, Time: 09_05_2022__01:05:30\n","Average testing accuracy: 0.6867000, Time: 09_05_2022__01:05:30\n","time: 12h 43min 54s (started: 2022-05-08 12:21:35 +00:00)\n"]}],"source":["#-- Parameters\n","epochs = 5\n","\n","for learning_rate in [0.1, 0.01, 0.001, 0.0001]:\n","  for mom in [0, 0.3, 0.6, 0.9]:\n","    #-- Freeze the randomness\n","    seed()\n","    model = vgg19_bn(pretrained=False)\n","    model_name = 'vgg19_batch_norm'\n","\n","    lr = learning_rate\n","    momentum = mom\n","    parameters = 'SGD, lr_{}, momentum_{}'.format(lr, momentum)\n","\n","    #-- Initiating a tensorboard writer that contains all logs for training, validation, and testing\n","    tb_writer = SummaryWriter('./models/CIFAR/runs', filename_suffix='_'+model_name+'_'+parameters)\n","\n","    #-- Create the model's critrion loss function and a optimization function \n","    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","\n","    #-- Train and valiate the model\n","    model, model_save_path = model_train(model, model_name, lr, momentum, optimizer, epochs, tb_writer, parameters)\n","\n","    #-- Load the best saved model for testing\n","    model.load_state_dict(torch.load(model_save_path))\n","    model.to(device)\n","\n","    #-- Set the model mode to evaluation to prepare for testing\n","    model.eval()\n","    model_test(model, model_name, tb_writer, parameters) \n","\n","    #-- Close the Tensoboard writer\n","    tb_writer.close()\n","\n","    #-- Delete the model\n","    del model"],"id":"6wfRoiUOKBdD"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"VGG_v4_history3_all.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8c4c8f731ae6481884ad3f58fb627ca1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10761583a686408d8163027d13df4165","IPY_MODEL_25bbaebf704942c49d0d5ff0e5770e3b","IPY_MODEL_95480473830048a29631d7b91d9570b3"],"layout":"IPY_MODEL_58542fa9bcbe419793754cb6f2e77e88"}},"10761583a686408d8163027d13df4165":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8163b7de04945ca9a387270d0514321","placeholder":"​","style":"IPY_MODEL_a76f940488fe497283fbaf9f6df68739","value":""}},"25bbaebf704942c49d0d5ff0e5770e3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f93738cbca814f6cb120b8eeb3ac24a8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60c684df641a46a2aa842bd8d61d7b9e","value":1}},"95480473830048a29631d7b91d9570b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a3df10ed2964448b91398aa469a9625","placeholder":"​","style":"IPY_MODEL_43afc900ee0143f2a7808b589a2fdc32","value":" 13750/? [45:02&lt;00:00,  5.04it/s]"}},"58542fa9bcbe419793754cb6f2e77e88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8163b7de04945ca9a387270d0514321":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a76f940488fe497283fbaf9f6df68739":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f93738cbca814f6cb120b8eeb3ac24a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"60c684df641a46a2aa842bd8d61d7b9e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a3df10ed2964448b91398aa469a9625":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43afc900ee0143f2a7808b589a2fdc32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79d824a4a5a04eafb5c6a6e795b1642f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b95d5ac469694199ba017e208843cc86","IPY_MODEL_555cb9f817404a999f14b550ae260fbf","IPY_MODEL_dfe60f16f0cf479aa3ecf3846c38aa10"],"layout":"IPY_MODEL_3281b244d1ee4077aa054243798594ea"}},"b95d5ac469694199ba017e208843cc86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_069431d84a674a74b73e0f7c8a36a3d7","placeholder":"​","style":"IPY_MODEL_3b623df4c8694e59a24c347c11fd74db","value":""}},"555cb9f817404a999f14b550ae260fbf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2477aac0dec248b09f63b4dfc0de2885","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4449653518bc479b9fcd91503231743d","value":1}},"dfe60f16f0cf479aa3ecf3846c38aa10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6a9acd403314a89b5abc7d5bafb08d6","placeholder":"​","style":"IPY_MODEL_0479eaa34a5e4cee9ddda60f00865242","value":" 1250/? [01:12&lt;00:00, 19.66it/s]"}},"3281b244d1ee4077aa054243798594ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"069431d84a674a74b73e0f7c8a36a3d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b623df4c8694e59a24c347c11fd74db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2477aac0dec248b09f63b4dfc0de2885":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"4449653518bc479b9fcd91503231743d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c6a9acd403314a89b5abc7d5bafb08d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0479eaa34a5e4cee9ddda60f00865242":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83af5c88c0ff46f08674edb6123eaf7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17ee361190164ee78266be8ea6bc8128","IPY_MODEL_1f016edfea424f4ca43a8017f95704fb","IPY_MODEL_a6d167b8cfdc4b7380b9208f6abd022b"],"layout":"IPY_MODEL_8611b33cfc6a4754a4b1b50f2d8d93ee"}},"17ee361190164ee78266be8ea6bc8128":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d21a9f1d33d41f4a7900545f14a9467","placeholder":"​","style":"IPY_MODEL_d148031e2c09499682546e5c0f4afab5","value":""}},"1f016edfea424f4ca43a8017f95704fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd87cb5f076b4fd687cfb9131034f333","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4d99463276a42aea49cb8b9aebdf011","value":1}},"a6d167b8cfdc4b7380b9208f6abd022b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6abb9e9a015416da88efc5b247cef6f","placeholder":"​","style":"IPY_MODEL_e5e64bc33b9741c688883570cd308da7","value":" 13750/? [45:10&lt;00:00,  5.08it/s]"}},"8611b33cfc6a4754a4b1b50f2d8d93ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d21a9f1d33d41f4a7900545f14a9467":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d148031e2c09499682546e5c0f4afab5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd87cb5f076b4fd687cfb9131034f333":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f4d99463276a42aea49cb8b9aebdf011":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6abb9e9a015416da88efc5b247cef6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5e64bc33b9741c688883570cd308da7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e036c87206384edaa2b08285f373ebb8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17de12ae1e614c4f92243fd84256358f","IPY_MODEL_a0bf5962f7c740d7b7522804b380c8dd","IPY_MODEL_a8d4825def8d4469ad481464990bba88"],"layout":"IPY_MODEL_fbab56b1c4c9408ba61b28c8750232c6"}},"17de12ae1e614c4f92243fd84256358f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc13f4303be446278715f71fc6ade3fe","placeholder":"​","style":"IPY_MODEL_93ab4d9cfc084a9cb64d0b9d87628291","value":""}},"a0bf5962f7c740d7b7522804b380c8dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b29436299df447fb15761741325ec10","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4d942362de3486a96bc79b8524ebe89","value":1}},"a8d4825def8d4469ad481464990bba88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f93823075cb44a66934de0985a9158c6","placeholder":"​","style":"IPY_MODEL_5d6144115a564c949c33832cde92a48c","value":" 1250/? [01:11&lt;00:00, 19.49it/s]"}},"fbab56b1c4c9408ba61b28c8750232c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc13f4303be446278715f71fc6ade3fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93ab4d9cfc084a9cb64d0b9d87628291":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b29436299df447fb15761741325ec10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c4d942362de3486a96bc79b8524ebe89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f93823075cb44a66934de0985a9158c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d6144115a564c949c33832cde92a48c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d908177b90b4b5281968ddefd3269a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31f7499b9cc941ebb587cb4ac226f6e2","IPY_MODEL_62f6cc52cf3d4d6d843bb6265e8cfafc","IPY_MODEL_b7a503c8dfb744ec972983bf54ea2fa0"],"layout":"IPY_MODEL_818e9fea5f4145029cb4266477c1faa6"}},"31f7499b9cc941ebb587cb4ac226f6e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad65845f89124836be11755e9ba67e25","placeholder":"​","style":"IPY_MODEL_5043cbedf51b4960846921956f9b8c10","value":""}},"62f6cc52cf3d4d6d843bb6265e8cfafc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_333048cd075b4f4198636232c94ede83","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05d78297f96f48988072dd89c507b3e0","value":1}},"b7a503c8dfb744ec972983bf54ea2fa0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30682558099743709f5a8c4f97c4dda3","placeholder":"​","style":"IPY_MODEL_c75184024a144881985e991b786590b7","value":" 13750/? [45:10&lt;00:00,  5.06it/s]"}},"818e9fea5f4145029cb4266477c1faa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad65845f89124836be11755e9ba67e25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5043cbedf51b4960846921956f9b8c10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"333048cd075b4f4198636232c94ede83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"05d78297f96f48988072dd89c507b3e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30682558099743709f5a8c4f97c4dda3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c75184024a144881985e991b786590b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d21682052b994d6bae9d1b1ab4eed6c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1cc7f02fae164923bd67cd07f53ede56","IPY_MODEL_9d400cc9e02244fd96f9e8745d29ed13","IPY_MODEL_c997258009bd43f383711a36876192b7"],"layout":"IPY_MODEL_735825ee44eb4d4a84b853574a4c2b12"}},"1cc7f02fae164923bd67cd07f53ede56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_254473fa23c44d4d891484a2e2d8d25b","placeholder":"​","style":"IPY_MODEL_1d470758e0354a2baf3bc1c0d190615b","value":""}},"9d400cc9e02244fd96f9e8745d29ed13":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc1ed05cbe874817bb0685bd3d737b69","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f5793c7a89e498a8fdb840bed017f1f","value":1}},"c997258009bd43f383711a36876192b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44168802b35a465783d6046dbd271015","placeholder":"​","style":"IPY_MODEL_f8e3d0f74e964773a23fb6d0b922f494","value":" 1250/? [01:11&lt;00:00, 19.59it/s]"}},"735825ee44eb4d4a84b853574a4c2b12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"254473fa23c44d4d891484a2e2d8d25b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d470758e0354a2baf3bc1c0d190615b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc1ed05cbe874817bb0685bd3d737b69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9f5793c7a89e498a8fdb840bed017f1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44168802b35a465783d6046dbd271015":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e3d0f74e964773a23fb6d0b922f494":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"876f9f1513634376a175d68a9f38c7e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_332119c04d0b4b31a38c5c0b35a50a75","IPY_MODEL_a71953325a704ad68e63c947dc23b159","IPY_MODEL_d92f80ee4b96499794e700287cbd14f7"],"layout":"IPY_MODEL_8439cbc24a0a4b4789ca7537a3aca3bf"}},"332119c04d0b4b31a38c5c0b35a50a75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2db3d1fb1f94458aae970ab53f6af42","placeholder":"​","style":"IPY_MODEL_964c0790a60e4b73a4597e548af57800","value":""}},"a71953325a704ad68e63c947dc23b159":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8174ac30b9c24664b3b303dfccd464ff","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b65678eb5a04de8887ddce4a92fcc3c","value":1}},"d92f80ee4b96499794e700287cbd14f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a294a23f5e354dd8a7b0445828cb99cc","placeholder":"​","style":"IPY_MODEL_2bb8feb4a5174ee1b43bd577d2d45166","value":" 13750/? [45:14&lt;00:00,  5.04it/s]"}},"8439cbc24a0a4b4789ca7537a3aca3bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2db3d1fb1f94458aae970ab53f6af42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"964c0790a60e4b73a4597e548af57800":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8174ac30b9c24664b3b303dfccd464ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"0b65678eb5a04de8887ddce4a92fcc3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a294a23f5e354dd8a7b0445828cb99cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bb8feb4a5174ee1b43bd577d2d45166":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed2320c12bfd4c478e90546caeebfb63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b86e1703f3314be984699cf72316116d","IPY_MODEL_a282367b207e43d6bd404c4d99dc4268","IPY_MODEL_2607e72472984ceda603a8999b206133"],"layout":"IPY_MODEL_d1cb0116419d4b80b1f1b73bb1389a2f"}},"b86e1703f3314be984699cf72316116d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c034173c304d4b8da0baaae2527ad965","placeholder":"​","style":"IPY_MODEL_dbb41404ac074f1381830b1d67bde10d","value":""}},"a282367b207e43d6bd404c4d99dc4268":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f90d4df8f764858871c1f7f0271c209","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9aba9339dfb24fdaadecf5b296c796a6","value":1}},"2607e72472984ceda603a8999b206133":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a66f63bedd7405fb8e84a9d6fc6f6ac","placeholder":"​","style":"IPY_MODEL_0880b88e106f4b0388813637648b612a","value":" 1250/? [01:06&lt;00:00, 19.58it/s]"}},"d1cb0116419d4b80b1f1b73bb1389a2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c034173c304d4b8da0baaae2527ad965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbb41404ac074f1381830b1d67bde10d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f90d4df8f764858871c1f7f0271c209":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9aba9339dfb24fdaadecf5b296c796a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a66f63bedd7405fb8e84a9d6fc6f6ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0880b88e106f4b0388813637648b612a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"caefaa2c8eee426aaaf176e148dbb270":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc1085bea0894807847dda6143d45aee","IPY_MODEL_0cc25f8afe3e424e9b1221b7eb7f2c74","IPY_MODEL_f20e1c0212d1431cafd70526b4262b8a"],"layout":"IPY_MODEL_43856f64ef8b492dbc60aefb6c28db53"}},"fc1085bea0894807847dda6143d45aee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bfa326c227d43ccac6feb974a7184ad","placeholder":"​","style":"IPY_MODEL_55fe9ba47e274fe7b7c6f7139381eecd","value":""}},"0cc25f8afe3e424e9b1221b7eb7f2c74":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f1d5409987940939e6bb254e95f5c51","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7cddd084dbc4917b480690f905495fd","value":1}},"f20e1c0212d1431cafd70526b4262b8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5126bbb66b44f37979e70e35c76ae70","placeholder":"​","style":"IPY_MODEL_6805ec6e01804d61a2e6766d2044b29d","value":" 13750/? [45:13&lt;00:00,  5.06it/s]"}},"43856f64ef8b492dbc60aefb6c28db53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bfa326c227d43ccac6feb974a7184ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55fe9ba47e274fe7b7c6f7139381eecd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f1d5409987940939e6bb254e95f5c51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d7cddd084dbc4917b480690f905495fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5126bbb66b44f37979e70e35c76ae70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6805ec6e01804d61a2e6766d2044b29d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94380945025a422c9f79cb45ac83e89d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31c63e2868cf44efa9daecf6d3ef9195","IPY_MODEL_3728255eddb34c2c893c9fe0f615297f","IPY_MODEL_bb14b0a8d80046d293189c5019aa44de"],"layout":"IPY_MODEL_71390e23e082447791c84c9c41ec1dde"}},"31c63e2868cf44efa9daecf6d3ef9195":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88b7981ee86a4b5489f9332f5d5c4b8a","placeholder":"​","style":"IPY_MODEL_3b6ab3955b6745cb930d6cecd6b9b792","value":""}},"3728255eddb34c2c893c9fe0f615297f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc90c0db651d4eb4bc04706396af18f1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cac29c8591a482baacee7d7fb3f4242","value":1}},"bb14b0a8d80046d293189c5019aa44de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01f0d457baed4bd8b8a6779b264ef369","placeholder":"​","style":"IPY_MODEL_d01f29cad6bb4a03af8f6d3b6674f75f","value":" 1250/? [01:06&lt;00:00, 19.68it/s]"}},"71390e23e082447791c84c9c41ec1dde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88b7981ee86a4b5489f9332f5d5c4b8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b6ab3955b6745cb930d6cecd6b9b792":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc90c0db651d4eb4bc04706396af18f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8cac29c8591a482baacee7d7fb3f4242":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"01f0d457baed4bd8b8a6779b264ef369":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d01f29cad6bb4a03af8f6d3b6674f75f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63172a7c5f514cbeb45932de1e9668e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1e7166b5f9a42c4b155be3c933fc3fb","IPY_MODEL_23f01273cf75446aa584b1e62d43d57e","IPY_MODEL_3eaa74034b644021937cbedb3c5248f9"],"layout":"IPY_MODEL_4aa5a3ff9a594a87ae7a0fa2fc99d2df"}},"c1e7166b5f9a42c4b155be3c933fc3fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa744b9534154260a01c3d2cb70d3266","placeholder":"​","style":"IPY_MODEL_701c6b1c05a5467ab6b70c7edd3be2ec","value":""}},"23f01273cf75446aa584b1e62d43d57e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8fbc9a477b44b9ba144996ca71cb1d6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50f8ad9d72fd40febd8202f98fec1b44","value":1}},"3eaa74034b644021937cbedb3c5248f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a88b4aff1f24e9f83eee99b2849d269","placeholder":"​","style":"IPY_MODEL_e3dbf418326d47f6bed7e0a9b3d3a9e2","value":" 2500/? [02:18&lt;00:00, 19.38it/s]"}},"4aa5a3ff9a594a87ae7a0fa2fc99d2df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa744b9534154260a01c3d2cb70d3266":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"701c6b1c05a5467ab6b70c7edd3be2ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8fbc9a477b44b9ba144996ca71cb1d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"50f8ad9d72fd40febd8202f98fec1b44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a88b4aff1f24e9f83eee99b2849d269":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3dbf418326d47f6bed7e0a9b3d3a9e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a31667afc0d4599b071c96b73945abe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f09bcccdc314a64bb957f7f9ac33d3c","IPY_MODEL_c4f1d8f4f03d451a859ce7a7917c3297","IPY_MODEL_684b5010ddfd4987939df5464fcd0723"],"layout":"IPY_MODEL_2ddafa21637742eaa61176c1653207e8"}},"9f09bcccdc314a64bb957f7f9ac33d3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0dbddea6c50450d8d8e76c870d69808","placeholder":"​","style":"IPY_MODEL_9eb276acd2544bb89b7185dd3b732be6","value":""}},"c4f1d8f4f03d451a859ce7a7917c3297":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a3342c19ab84382a3d7b29fa166f03e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b569e3c02c942bba8fd2a41cde02135","value":1}},"684b5010ddfd4987939df5464fcd0723":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c31ef7318f594742a5e9f891ab3b2279","placeholder":"​","style":"IPY_MODEL_420c28ff9487476b931aafa988f39f40","value":" 13750/? [47:51&lt;00:00,  4.79it/s]"}},"2ddafa21637742eaa61176c1653207e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0dbddea6c50450d8d8e76c870d69808":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eb276acd2544bb89b7185dd3b732be6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a3342c19ab84382a3d7b29fa166f03e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"2b569e3c02c942bba8fd2a41cde02135":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c31ef7318f594742a5e9f891ab3b2279":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"420c28ff9487476b931aafa988f39f40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06eebef75d1d47f899ee115d42b49eb8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_996f5a64a8024efea37bcc3e567871fd","IPY_MODEL_6f7418d7a0024907a395e607aaccf6c6","IPY_MODEL_eeacb562b02643c89c7f890683713bee"],"layout":"IPY_MODEL_e96aaa5c2cfa4be8b47974e7bc014c9e"}},"996f5a64a8024efea37bcc3e567871fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf7829e58c51491bab2e03e12ca98dc7","placeholder":"​","style":"IPY_MODEL_71e62f9ed5db430cb357a498676785fb","value":""}},"6f7418d7a0024907a395e607aaccf6c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a28558311ba84702bd627f64f5d86579","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42687bb647d046af889992261f279d3b","value":1}},"eeacb562b02643c89c7f890683713bee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf9a51f8d3414766bf20d25e98ce84ac","placeholder":"​","style":"IPY_MODEL_2d7e6571344f4dbfadda201286eb8b3d","value":" 1250/? [01:14&lt;00:00, 19.43it/s]"}},"e96aaa5c2cfa4be8b47974e7bc014c9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf7829e58c51491bab2e03e12ca98dc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71e62f9ed5db430cb357a498676785fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a28558311ba84702bd627f64f5d86579":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"42687bb647d046af889992261f279d3b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf9a51f8d3414766bf20d25e98ce84ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d7e6571344f4dbfadda201286eb8b3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94106dcff9174189aefc11e139c6084c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3acfa82b74764f02b430cdc1e3b31936","IPY_MODEL_c0c8d887952743efa417cd6d50834d6b","IPY_MODEL_d291cbba0b5841739f7a806b86566c71"],"layout":"IPY_MODEL_f44bdc6477db4d198c67336a65b44157"}},"3acfa82b74764f02b430cdc1e3b31936":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b27e2f5a49c7464f8edbd9809a3540d9","placeholder":"​","style":"IPY_MODEL_a422405f854e4475860c5fd07f9f304c","value":""}},"c0c8d887952743efa417cd6d50834d6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b94bc624b854b9ca51c195445750da2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fde1d0e50c1b4f178e3f2421dc107d19","value":1}},"d291cbba0b5841739f7a806b86566c71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d967bb54eeda4905b972aacf81cdcdf6","placeholder":"​","style":"IPY_MODEL_76cac93eef9c422fbce327279575090b","value":" 13750/? [47:50&lt;00:00,  4.78it/s]"}},"f44bdc6477db4d198c67336a65b44157":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b27e2f5a49c7464f8edbd9809a3540d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a422405f854e4475860c5fd07f9f304c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b94bc624b854b9ca51c195445750da2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"fde1d0e50c1b4f178e3f2421dc107d19":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d967bb54eeda4905b972aacf81cdcdf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76cac93eef9c422fbce327279575090b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bc8fd38c05a4b889f6a25b521591fc2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f5bcf621bd94460a9df06f534e4bb718","IPY_MODEL_443bf8d7b36e44a58767f21754cf9ff6","IPY_MODEL_c570c039116b41b18c208ba024393e62"],"layout":"IPY_MODEL_109cce74e3034c56a5b422f0d6858ef1"}},"f5bcf621bd94460a9df06f534e4bb718":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_515398c92c124ca9a99b4b4dbbfc8c3c","placeholder":"​","style":"IPY_MODEL_c01e13fd9ec34c0b89a4c3ae059a823c","value":""}},"443bf8d7b36e44a58767f21754cf9ff6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_78e7a42263504d96ac060fea68325f05","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2b126a422554a738cb1aa706de1c58a","value":1}},"c570c039116b41b18c208ba024393e62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe4a9b6df3cf4350ae3760c5c339260b","placeholder":"​","style":"IPY_MODEL_abb53c7e5a7648f6b655d2fe9c3458d8","value":" 1250/? [01:16&lt;00:00, 19.29it/s]"}},"109cce74e3034c56a5b422f0d6858ef1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"515398c92c124ca9a99b4b4dbbfc8c3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c01e13fd9ec34c0b89a4c3ae059a823c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78e7a42263504d96ac060fea68325f05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b2b126a422554a738cb1aa706de1c58a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fe4a9b6df3cf4350ae3760c5c339260b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abb53c7e5a7648f6b655d2fe9c3458d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c46a71e0bc941e1968d8443f3f68dc4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98c4c7e35e2f458b9561e9d622ad9cbf","IPY_MODEL_4b318c3c35e44429a91c4b3983d7856c","IPY_MODEL_ea7ddc32b0b743b68d78b17c0d137dbb"],"layout":"IPY_MODEL_e689a51f3bc248ac877f555664a86906"}},"98c4c7e35e2f458b9561e9d622ad9cbf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14e7de82dda8469dab5b3cc825379329","placeholder":"​","style":"IPY_MODEL_be8d2c7e049b4c03927805292015e73e","value":""}},"4b318c3c35e44429a91c4b3983d7856c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_94921abf4edf41a5b69b8ec968ad748a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50f66a774c3b4bb3906678f36c3a6aa7","value":1}},"ea7ddc32b0b743b68d78b17c0d137dbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff887b70b9394e1ab7b484f80c1cd41f","placeholder":"​","style":"IPY_MODEL_28cec4e34c4949af90ee918710b84b1b","value":" 13750/? [47:51&lt;00:00,  4.79it/s]"}},"e689a51f3bc248ac877f555664a86906":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14e7de82dda8469dab5b3cc825379329":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be8d2c7e049b4c03927805292015e73e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94921abf4edf41a5b69b8ec968ad748a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"50f66a774c3b4bb3906678f36c3a6aa7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff887b70b9394e1ab7b484f80c1cd41f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28cec4e34c4949af90ee918710b84b1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a11ebfd732cd4b9695a3cc8561f51b5b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73ed5a778fec4ef28f38fd970eedb7e8","IPY_MODEL_2e2974c2903e4d048c438af35d2638c6","IPY_MODEL_85354e26e29744e78c76a231408bba7c"],"layout":"IPY_MODEL_df12419ff8974da1b7baf13f9bdda7cb"}},"73ed5a778fec4ef28f38fd970eedb7e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30b5512d2b994afda3aae92034b0de24","placeholder":"​","style":"IPY_MODEL_714279eb03b144168d79a2c81f0fe6f8","value":""}},"2e2974c2903e4d048c438af35d2638c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e445d1841ce43e6b4ee6b98ea747d57","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c83041b6271e4549b7d3b4fea6a7e9bb","value":1}},"85354e26e29744e78c76a231408bba7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05cc3f5045bc4cffbd1549cf1da7a3f0","placeholder":"​","style":"IPY_MODEL_1ff64a66efc14656827ed21f32085605","value":" 1250/? [01:15&lt;00:00, 19.12it/s]"}},"df12419ff8974da1b7baf13f9bdda7cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30b5512d2b994afda3aae92034b0de24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"714279eb03b144168d79a2c81f0fe6f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e445d1841ce43e6b4ee6b98ea747d57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c83041b6271e4549b7d3b4fea6a7e9bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05cc3f5045bc4cffbd1549cf1da7a3f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ff64a66efc14656827ed21f32085605":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df88d6001af54345ade6e7a9197fcf3d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8da14e2a44ea4d73a00168a2c90f7040","IPY_MODEL_831dd82a1f184a76a877d97be364b2a6","IPY_MODEL_22aa0d378d9147048ff2265c821244d3"],"layout":"IPY_MODEL_f749fbb799ae4546943cd41dcf235ef8"}},"8da14e2a44ea4d73a00168a2c90f7040":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76706ff0286b40908026cec3023ad2eb","placeholder":"​","style":"IPY_MODEL_820eb0a7d6d2492b98683cc4b28e9c60","value":""}},"831dd82a1f184a76a877d97be364b2a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c290027764d4ee1979492e641339370","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8fabaf2179b435db26d78ba94055298","value":1}},"22aa0d378d9147048ff2265c821244d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_463365f327994a58b4ecea91ef653b8c","placeholder":"​","style":"IPY_MODEL_3ffd083c88c7484abc9d5f61c6e36b38","value":" 13750/? [47:53&lt;00:00,  4.79it/s]"}},"f749fbb799ae4546943cd41dcf235ef8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76706ff0286b40908026cec3023ad2eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"820eb0a7d6d2492b98683cc4b28e9c60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c290027764d4ee1979492e641339370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a8fabaf2179b435db26d78ba94055298":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"463365f327994a58b4ecea91ef653b8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffd083c88c7484abc9d5f61c6e36b38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00919d8ee5f44d1c850841009b6e53aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11e46d47191f4ebda2e5df179375055c","IPY_MODEL_134bc08709e1430da4e216516722631c","IPY_MODEL_9acfee58033340cba8446e02b7de429a"],"layout":"IPY_MODEL_580a7544479d48f495a05397328e0f3f"}},"11e46d47191f4ebda2e5df179375055c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0db11ec73d804ed1a7842a27440ad2f4","placeholder":"​","style":"IPY_MODEL_2501d0bdb50f4ec4aea3ade7b77d723e","value":""}},"134bc08709e1430da4e216516722631c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_320d07bfeb02410fa6219c9c9e13696c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9380c4ac7d034a5ebca8c8f2888696fe","value":1}},"9acfee58033340cba8446e02b7de429a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_372cea71d30d4511a6e74be81433b9d4","placeholder":"​","style":"IPY_MODEL_79f731ed94af4909898dbb2943162175","value":" 1250/? [01:18&lt;00:00, 19.46it/s]"}},"580a7544479d48f495a05397328e0f3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0db11ec73d804ed1a7842a27440ad2f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2501d0bdb50f4ec4aea3ade7b77d723e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"320d07bfeb02410fa6219c9c9e13696c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9380c4ac7d034a5ebca8c8f2888696fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"372cea71d30d4511a6e74be81433b9d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79f731ed94af4909898dbb2943162175":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"110d6216f4b2491a9f2145e5751824d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_367faa90e77245b085259f2f1ab221e1","IPY_MODEL_850660bf5ac54f628669f085eb8631ec","IPY_MODEL_98093a0e9018490c8db85d1f02efd510"],"layout":"IPY_MODEL_eb6e61cb71e34b559a7b49c44385517c"}},"367faa90e77245b085259f2f1ab221e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0141a3312a2c440d8b041902722c3b0f","placeholder":"​","style":"IPY_MODEL_4dcecc13a732438785622b5efc8daa17","value":""}},"850660bf5ac54f628669f085eb8631ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d23e9f3cefef4e61bff001e8ed160cee","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_095c6735afa74d7085c501dde02f6532","value":1}},"98093a0e9018490c8db85d1f02efd510":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7bdd5b60b6c4605b63621a0472faa25","placeholder":"​","style":"IPY_MODEL_5f8c860caea84e3f985031ec4ac3acf5","value":" 13750/? [47:54&lt;00:00,  4.79it/s]"}},"eb6e61cb71e34b559a7b49c44385517c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0141a3312a2c440d8b041902722c3b0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dcecc13a732438785622b5efc8daa17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d23e9f3cefef4e61bff001e8ed160cee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"095c6735afa74d7085c501dde02f6532":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7bdd5b60b6c4605b63621a0472faa25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f8c860caea84e3f985031ec4ac3acf5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"429c92391fef42ad882703ba721bef85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8fef86ab95c4c5d88a233f17c148f08","IPY_MODEL_0db76d27bc0743dcb79264341866c6f2","IPY_MODEL_4ff9497d19a741ebab02d5248934d673"],"layout":"IPY_MODEL_61b8f7c8f65942cf8ae7c025b6380c3f"}},"c8fef86ab95c4c5d88a233f17c148f08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dda3e4d36201429a8214f01bd0a4fc3f","placeholder":"​","style":"IPY_MODEL_0a307bbbd2d84c5ea9073a17ac7f5858","value":""}},"0db76d27bc0743dcb79264341866c6f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbc00246ce25453d9242660c1d51e9ec","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e76a7d3c6e54221a75b7c2634807d5e","value":1}},"4ff9497d19a741ebab02d5248934d673":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80b6864075c54eaca953422fff19b6ee","placeholder":"​","style":"IPY_MODEL_594ced9d38cf476196ff77673d2dc842","value":" 1250/? [01:06&lt;00:00, 19.39it/s]"}},"61b8f7c8f65942cf8ae7c025b6380c3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dda3e4d36201429a8214f01bd0a4fc3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a307bbbd2d84c5ea9073a17ac7f5858":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbc00246ce25453d9242660c1d51e9ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7e76a7d3c6e54221a75b7c2634807d5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80b6864075c54eaca953422fff19b6ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"594ced9d38cf476196ff77673d2dc842":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6b9a42d3d5a43f8b7337342b73df3e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_816fcbee3366416487b9bfb79f57ff4e","IPY_MODEL_ee0ec0eaeb5d427eae3998960af504e3","IPY_MODEL_d42d8fd669bd4fd196ea752765b1267b"],"layout":"IPY_MODEL_3834c42cc5c54d21b0d2e92c558a9317"}},"816fcbee3366416487b9bfb79f57ff4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9330d948fcfd45d1aaa07a636c6a8be5","placeholder":"​","style":"IPY_MODEL_63a57c4ccd4245afa8faa646388f81bd","value":""}},"ee0ec0eaeb5d427eae3998960af504e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aff2fa41c1244ac19ca2fc1c5b03d1ff","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4a3dee47c724c0b8b9b571a8ef07772","value":1}},"d42d8fd669bd4fd196ea752765b1267b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_266bf26654724326a1b3e28ec1ea5738","placeholder":"​","style":"IPY_MODEL_c6e145622b20463bb2830521b2360b3c","value":" 2500/? [02:17&lt;00:00, 19.20it/s]"}},"3834c42cc5c54d21b0d2e92c558a9317":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9330d948fcfd45d1aaa07a636c6a8be5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63a57c4ccd4245afa8faa646388f81bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aff2fa41c1244ac19ca2fc1c5b03d1ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a4a3dee47c724c0b8b9b571a8ef07772":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"266bf26654724326a1b3e28ec1ea5738":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6e145622b20463bb2830521b2360b3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fccd5aacbd584eb288d237792c0aeda2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_322b9c6efef54c81bf092140d37004d4","IPY_MODEL_34cbce1becc0489e9179d24c0e656112","IPY_MODEL_faef163acda8431888a8df7e1f2db9be"],"layout":"IPY_MODEL_8d11e5f76d684c2cb8a9ad337f47ea25"}},"322b9c6efef54c81bf092140d37004d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f3e135bc08649e4b2a2ddbdc7518fb0","placeholder":"​","style":"IPY_MODEL_1e2e621ab67f45fbb2cfd6ade49b3923","value":""}},"34cbce1becc0489e9179d24c0e656112":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f1e3a6f3d38458cbdc1dba56e4ab566","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02cea3ce34554a51a0b857849ee34d30","value":1}},"faef163acda8431888a8df7e1f2db9be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_495fa4666b5b42c89e29bd42b4f2da79","placeholder":"​","style":"IPY_MODEL_1e6a5be430bf4d938dff4a4cfa8d1122","value":" 13750/? [47:56&lt;00:00,  4.79it/s]"}},"8d11e5f76d684c2cb8a9ad337f47ea25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f3e135bc08649e4b2a2ddbdc7518fb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e2e621ab67f45fbb2cfd6ade49b3923":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f1e3a6f3d38458cbdc1dba56e4ab566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"02cea3ce34554a51a0b857849ee34d30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"495fa4666b5b42c89e29bd42b4f2da79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e6a5be430bf4d938dff4a4cfa8d1122":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d74cbd27fd7f41aa9c659f4423faff82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2edee44bda6c4496bedbde1d1b42b681","IPY_MODEL_d238061e81724440b297fc0d864470b8","IPY_MODEL_f22f83ccf08145e5897df519c188729b"],"layout":"IPY_MODEL_e76dd078fff94852b513cbc6359c0a1d"}},"2edee44bda6c4496bedbde1d1b42b681":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fee451d6ffdd48c692424c5e7416b1b4","placeholder":"​","style":"IPY_MODEL_061f8af0106e497d9292c8a436451341","value":""}},"d238061e81724440b297fc0d864470b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_087a130042864180b14ab2bf29d3a954","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a1ed6c53b7214120ab27b0b023381061","value":1}},"f22f83ccf08145e5897df519c188729b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8439aea20584bb982bd37d2fc9d96e6","placeholder":"​","style":"IPY_MODEL_d359e82b927e42dbb44d6dbeb6f079e0","value":" 1250/? [01:15&lt;00:00, 19.11it/s]"}},"e76dd078fff94852b513cbc6359c0a1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fee451d6ffdd48c692424c5e7416b1b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"061f8af0106e497d9292c8a436451341":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"087a130042864180b14ab2bf29d3a954":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a1ed6c53b7214120ab27b0b023381061":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8439aea20584bb982bd37d2fc9d96e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d359e82b927e42dbb44d6dbeb6f079e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9960b9457fd5437084eba4b28666c5e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba8a55c4fb664d2db89f3512b9009dec","IPY_MODEL_bc377684b7f94a2fab0602ece1b19f78","IPY_MODEL_763bdbcadb944f8aa4cd487ed2119df2"],"layout":"IPY_MODEL_b242d7f504d940fbb2ff40b238fa4c5f"}},"ba8a55c4fb664d2db89f3512b9009dec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b187e343a72461484555a1a12004ee3","placeholder":"​","style":"IPY_MODEL_1ad48934aafd4db189cdce0cf6713354","value":""}},"bc377684b7f94a2fab0602ece1b19f78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fa354c480a04eb6aed4bc4ece6b5b75","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f79b2072f0949d1a958aba53d024786","value":1}},"763bdbcadb944f8aa4cd487ed2119df2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ae7410aa6384499a9d69fec95f43e18","placeholder":"​","style":"IPY_MODEL_120e82ba948f4f6eb5b9e56dfa83597d","value":" 13750/? [48:01&lt;00:00,  4.79it/s]"}},"b242d7f504d940fbb2ff40b238fa4c5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b187e343a72461484555a1a12004ee3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ad48934aafd4db189cdce0cf6713354":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fa354c480a04eb6aed4bc4ece6b5b75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"4f79b2072f0949d1a958aba53d024786":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ae7410aa6384499a9d69fec95f43e18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"120e82ba948f4f6eb5b9e56dfa83597d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86fa20f1f0974fdba512e0a768291444":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6cb740897cb849d79ce89c3c09a0348a","IPY_MODEL_54ee59a1f24443ccbef385a2f057ff68","IPY_MODEL_1402f26e69884365bdb8e2f7f069250d"],"layout":"IPY_MODEL_7bc07df0eb67434c956d8d7bccfa78fd"}},"6cb740897cb849d79ce89c3c09a0348a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af3eb0543c414381a68c9ec9d2f6d853","placeholder":"​","style":"IPY_MODEL_8d47e1f70280434587b57dbb4556dc0a","value":""}},"54ee59a1f24443ccbef385a2f057ff68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72c9a9a2d6de46a0ac1c75c1092b6bce","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b210278462fc41eca9efc3c2240f66d0","value":1}},"1402f26e69884365bdb8e2f7f069250d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4bdeea4c6d848ca87ba93d1ec71689b","placeholder":"​","style":"IPY_MODEL_e1cc2fde68894591acf0793b27d99ddb","value":" 1250/? [01:19&lt;00:00, 19.16it/s]"}},"7bc07df0eb67434c956d8d7bccfa78fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af3eb0543c414381a68c9ec9d2f6d853":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d47e1f70280434587b57dbb4556dc0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72c9a9a2d6de46a0ac1c75c1092b6bce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b210278462fc41eca9efc3c2240f66d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4bdeea4c6d848ca87ba93d1ec71689b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1cc2fde68894591acf0793b27d99ddb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb42e8d2b2154066a0fcf44324ba7ee7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21569a0ddbde4e31acdd86f14f0c4f27","IPY_MODEL_c34838b455454812a7ad358a4919c441","IPY_MODEL_ef8720c024284f0bbc33075cd103f449"],"layout":"IPY_MODEL_514d233e1b6e42e38cd84ad67cae31a4"}},"21569a0ddbde4e31acdd86f14f0c4f27":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd5c2ef6a8164d0d92af19313023f877","placeholder":"​","style":"IPY_MODEL_5d53654842bd4f7191806ca3d5c2f27a","value":""}},"c34838b455454812a7ad358a4919c441":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_177702beb79249cdafef6e0ec8118e84","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb2915e039e2479798d42ad6777ebff8","value":1}},"ef8720c024284f0bbc33075cd103f449":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ec3b66035624444b371077f8ff38b9b","placeholder":"​","style":"IPY_MODEL_bf951211e0c542e4999daf349f16aad1","value":" 13750/? [48:04&lt;00:00,  4.76it/s]"}},"514d233e1b6e42e38cd84ad67cae31a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd5c2ef6a8164d0d92af19313023f877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d53654842bd4f7191806ca3d5c2f27a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"177702beb79249cdafef6e0ec8118e84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"cb2915e039e2479798d42ad6777ebff8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ec3b66035624444b371077f8ff38b9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf951211e0c542e4999daf349f16aad1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89b73f037ebf40b4b157acc88d0153dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5f3a8e9988244f28e684750e3f1f678","IPY_MODEL_0b49b37ce20d4c54b88890b9cbe3f1cd","IPY_MODEL_3c49651cdeb1497486e3c5f6d962e86e"],"layout":"IPY_MODEL_fd6d06412ec84945b9dbe81eaae7209d"}},"b5f3a8e9988244f28e684750e3f1f678":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f034b6ce4aa4808a37be8dda40a93e2","placeholder":"​","style":"IPY_MODEL_56f9d1dbf50740628b7e033e59fb9a91","value":""}},"0b49b37ce20d4c54b88890b9cbe3f1cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1756cf0f477a4607b36196bb0c257238","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4af73a14f3a3478b8cc1438978a979d5","value":1}},"3c49651cdeb1497486e3c5f6d962e86e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bcf5655502f4a19b3e21b032658b964","placeholder":"​","style":"IPY_MODEL_66cda6503de5420f803b03723d15b4f8","value":" 1250/? [01:10&lt;00:00, 19.23it/s]"}},"fd6d06412ec84945b9dbe81eaae7209d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f034b6ce4aa4808a37be8dda40a93e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56f9d1dbf50740628b7e033e59fb9a91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1756cf0f477a4607b36196bb0c257238":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"4af73a14f3a3478b8cc1438978a979d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bcf5655502f4a19b3e21b032658b964":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66cda6503de5420f803b03723d15b4f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c71e3570e3284807a8f238fda34518b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2aef8155248b43a5881e54344387a45b","IPY_MODEL_be82ac2f99c34838887d036763f7e92a","IPY_MODEL_97158e7a49364f138a04472d01e177ea"],"layout":"IPY_MODEL_b83a50959b874d8f9179cca75ee86047"}},"2aef8155248b43a5881e54344387a45b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_864f4582ae7246c89b0d2e4a30726a58","placeholder":"​","style":"IPY_MODEL_0cabe33574a94ca5a1a253bd411e06c9","value":""}},"be82ac2f99c34838887d036763f7e92a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_456f246193cc4d8d9348bb5269f1e384","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3441ca387b074f65808d964e3628bcb4","value":1}},"97158e7a49364f138a04472d01e177ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00544322d09642428aacb91ebcd66956","placeholder":"​","style":"IPY_MODEL_b73bf01c73a148c5932b73b2118700a4","value":" 13750/? [48:03&lt;00:00,  4.76it/s]"}},"b83a50959b874d8f9179cca75ee86047":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"864f4582ae7246c89b0d2e4a30726a58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cabe33574a94ca5a1a253bd411e06c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"456f246193cc4d8d9348bb5269f1e384":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3441ca387b074f65808d964e3628bcb4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00544322d09642428aacb91ebcd66956":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b73bf01c73a148c5932b73b2118700a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"352cb8b1dcf647788a2482fed75e5c94":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67e88bd195c442949465803aaf91282f","IPY_MODEL_ffe3ea66132445af9ee480e7f8b3f824","IPY_MODEL_b42d8df78bca47748d443aac11baef14"],"layout":"IPY_MODEL_7277bc7014d941b496793c1569de05b8"}},"67e88bd195c442949465803aaf91282f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50e5cc7c4c10407393ad3a940d5346f4","placeholder":"​","style":"IPY_MODEL_43fe70054c664a3094c353267fd39afa","value":""}},"ffe3ea66132445af9ee480e7f8b3f824":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a03fa97f93a40b888349631e09ec526","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8c76264337b494394b752be08fa45ef","value":1}},"b42d8df78bca47748d443aac11baef14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0986f4ad0d2c4857ac32623911d351a4","placeholder":"​","style":"IPY_MODEL_39aebe0573094272bee81894aa421611","value":" 1250/? [01:17&lt;00:00, 18.92it/s]"}},"7277bc7014d941b496793c1569de05b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50e5cc7c4c10407393ad3a940d5346f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43fe70054c664a3094c353267fd39afa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a03fa97f93a40b888349631e09ec526":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e8c76264337b494394b752be08fa45ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0986f4ad0d2c4857ac32623911d351a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39aebe0573094272bee81894aa421611":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa401d14edc6455f8e9e111f51518915":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_af2c91af09fc4ef3bc5287a9c106edd5","IPY_MODEL_93719c0467df46a7b9f7bf049414bfc1","IPY_MODEL_b4f97e2af0474b06a101959e4caf26b8"],"layout":"IPY_MODEL_ed09f82273eb4a688f550b92c193919b"}},"af2c91af09fc4ef3bc5287a9c106edd5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df80b1d14f4c41baa40ca4f7cb7399ad","placeholder":"​","style":"IPY_MODEL_3fb66ee77c394bfcb8f5963db485a703","value":""}},"93719c0467df46a7b9f7bf049414bfc1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_23cdd8a9e7ca4e288f8136be3d02495d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c84e33ab2af045a2a46b2fa818bc3124","value":1}},"b4f97e2af0474b06a101959e4caf26b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b87480e4ba7457ca143f3991999c85c","placeholder":"​","style":"IPY_MODEL_a098c33967ad40f893cad10f5e3c4497","value":" 13750/? [48:09&lt;00:00,  4.77it/s]"}},"ed09f82273eb4a688f550b92c193919b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df80b1d14f4c41baa40ca4f7cb7399ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fb66ee77c394bfcb8f5963db485a703":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23cdd8a9e7ca4e288f8136be3d02495d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c84e33ab2af045a2a46b2fa818bc3124":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b87480e4ba7457ca143f3991999c85c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a098c33967ad40f893cad10f5e3c4497":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf54fbae7a394b988ea0a03a4735a462":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ed65dde635a4f7db69332b6969cdab9","IPY_MODEL_571616fe0a6f44efbb2a311e4a78e37b","IPY_MODEL_a8443369630640c2beb24dff8bece714"],"layout":"IPY_MODEL_aae5b141d81a46a882a503d91bc5a496"}},"4ed65dde635a4f7db69332b6969cdab9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22239f0708934db7a1c430145d600815","placeholder":"​","style":"IPY_MODEL_8ac301f73daf457d95abe3b5fc194cdd","value":""}},"571616fe0a6f44efbb2a311e4a78e37b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34ef262442ca47028f02aa41f9d75cb4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc6973b42bac4b43aba50f17c71a9ce0","value":1}},"a8443369630640c2beb24dff8bece714":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b71b43591b264f9b80df6ac41ba2ce3c","placeholder":"​","style":"IPY_MODEL_5c7a77cb4845409b99301d36eb9edf51","value":" 1250/? [01:08&lt;00:00, 19.17it/s]"}},"aae5b141d81a46a882a503d91bc5a496":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22239f0708934db7a1c430145d600815":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ac301f73daf457d95abe3b5fc194cdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34ef262442ca47028f02aa41f9d75cb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"dc6973b42bac4b43aba50f17c71a9ce0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b71b43591b264f9b80df6ac41ba2ce3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c7a77cb4845409b99301d36eb9edf51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f369a7e6b73c4137b0b9e6a66fbaf953":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e9daa6d5e2d44af8fe4f1f94d617f52","IPY_MODEL_6586e7df45e840d0b3c430e826cf4f7f","IPY_MODEL_3cc1a19fe46d483bb2938dc98fe64ea8"],"layout":"IPY_MODEL_167a97ba943447d081f8354a28b606c7"}},"2e9daa6d5e2d44af8fe4f1f94d617f52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_861244358d3a4e8e8d98029728427ebb","placeholder":"​","style":"IPY_MODEL_feaa63c0bcbb4706a217ebf161a09224","value":""}},"6586e7df45e840d0b3c430e826cf4f7f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9efc869a69a4204ae89e32af3c7dfba","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a099f4e26fc447b68c248a0cbdc867ff","value":1}},"3cc1a19fe46d483bb2938dc98fe64ea8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0631f86b9d3d4c9198095558a43998be","placeholder":"​","style":"IPY_MODEL_1d468baaf5ec44958a9ff6697143bd4c","value":" 2500/? [02:17&lt;00:00, 19.24it/s]"}},"167a97ba943447d081f8354a28b606c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"861244358d3a4e8e8d98029728427ebb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feaa63c0bcbb4706a217ebf161a09224":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9efc869a69a4204ae89e32af3c7dfba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a099f4e26fc447b68c248a0cbdc867ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0631f86b9d3d4c9198095558a43998be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d468baaf5ec44958a9ff6697143bd4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf9626f28084445bb3961033c6cde6ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b656f2d9868a49d78ce85b8a1121e965","IPY_MODEL_993b6e8c4cc240318e9b24be269884e7","IPY_MODEL_1236f50319f54568ab76599513630a80"],"layout":"IPY_MODEL_f9a1a08252bb45f388a610492a9996c1"}},"b656f2d9868a49d78ce85b8a1121e965":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_284b6f6040c24de7b9611da9f187bd63","placeholder":"​","style":"IPY_MODEL_40bd03f0234245cfa781f59720ef223e","value":""}},"993b6e8c4cc240318e9b24be269884e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c82110c9c27d4edcbb7b6bcdee66134b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2b843f63f3e48c1ac54ddd6e6da0e8f","value":1}},"1236f50319f54568ab76599513630a80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b27a525ab6444cd9e2185f5607aba80","placeholder":"​","style":"IPY_MODEL_8fa03ac193c6471da242b7f00311d05f","value":" 13750/? [48:15&lt;00:00,  4.76it/s]"}},"f9a1a08252bb45f388a610492a9996c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"284b6f6040c24de7b9611da9f187bd63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40bd03f0234245cfa781f59720ef223e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c82110c9c27d4edcbb7b6bcdee66134b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d2b843f63f3e48c1ac54ddd6e6da0e8f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b27a525ab6444cd9e2185f5607aba80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fa03ac193c6471da242b7f00311d05f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21b86af3bfd44f4b8c145a745ae0b14c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_76683aef1706469b88ebba06c104bfe7","IPY_MODEL_7a3d0d94a8b54e68aac704656430af0a","IPY_MODEL_016ba34b4c2745c39a77e73d966a4eb7"],"layout":"IPY_MODEL_09ceafdabc7d40e194a719d23f801c2d"}},"76683aef1706469b88ebba06c104bfe7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f72ac6f2e32f42b99c8c530b60192530","placeholder":"​","style":"IPY_MODEL_c96c1c946d404c0f8ad967c9af998a33","value":""}},"7a3d0d94a8b54e68aac704656430af0a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_afcca26259da4d428721c6179fdf5dc5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8db1bdf60ccf4393addb1c427b020508","value":1}},"016ba34b4c2745c39a77e73d966a4eb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_660967e0c9364bf990bf15b22a78a331","placeholder":"​","style":"IPY_MODEL_e161e75e5e1d4fae9c522f86adddf658","value":" 1250/? [01:16&lt;00:00, 18.93it/s]"}},"09ceafdabc7d40e194a719d23f801c2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f72ac6f2e32f42b99c8c530b60192530":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c96c1c946d404c0f8ad967c9af998a33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afcca26259da4d428721c6179fdf5dc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8db1bdf60ccf4393addb1c427b020508":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"660967e0c9364bf990bf15b22a78a331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e161e75e5e1d4fae9c522f86adddf658":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ef027d6365447888677ab79a7a8b996":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47188d4751204e739118079159b2d1b9","IPY_MODEL_767e93d42b904b29b595dab10145fc76","IPY_MODEL_8a60a78bc026415a90d81549eaf095f3"],"layout":"IPY_MODEL_cacb4330aff540079323b31326121dfb"}},"47188d4751204e739118079159b2d1b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8028103bd5fa47e383a2f696d6e7a028","placeholder":"​","style":"IPY_MODEL_993cbd74aa0849f88800c526c3072465","value":""}},"767e93d42b904b29b595dab10145fc76":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d1e4a479c9c429bb8f45f0418d9f560","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_22ccd15ce04d431da194b7a3ecb39454","value":1}},"8a60a78bc026415a90d81549eaf095f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a2e0e22b28042859321170da312b047","placeholder":"​","style":"IPY_MODEL_b4940cdc15874adfa55b4dab3b543701","value":" 13750/? [48:12&lt;00:00,  4.77it/s]"}},"cacb4330aff540079323b31326121dfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8028103bd5fa47e383a2f696d6e7a028":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"993cbd74aa0849f88800c526c3072465":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d1e4a479c9c429bb8f45f0418d9f560":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"22ccd15ce04d431da194b7a3ecb39454":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a2e0e22b28042859321170da312b047":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4940cdc15874adfa55b4dab3b543701":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"436839a265974a1e9502a6878135f239":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8662666787ed4cadb87da14d68e5d4b6","IPY_MODEL_d8669ffb74ee4798ad9aea71129436db","IPY_MODEL_b16c9b262d6646c6b70a65c0fb1e840b"],"layout":"IPY_MODEL_6161c32b28e540b49c7c0c2e534740db"}},"8662666787ed4cadb87da14d68e5d4b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b20525b13de14b86bd1214ea41cc70c1","placeholder":"​","style":"IPY_MODEL_3429920725024d6884b12d2da9680067","value":""}},"d8669ffb74ee4798ad9aea71129436db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_452e2b63566149518b3cccf842f3d7cf","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3d212ab9dd649a58cce830b3b8bccd4","value":1}},"b16c9b262d6646c6b70a65c0fb1e840b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de0417f4cbf146de960f24991ae22a38","placeholder":"​","style":"IPY_MODEL_d2fc598b9f504c90a1f698e6b2e3443d","value":" 1250/? [01:16&lt;00:00, 19.15it/s]"}},"6161c32b28e540b49c7c0c2e534740db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b20525b13de14b86bd1214ea41cc70c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3429920725024d6884b12d2da9680067":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"452e2b63566149518b3cccf842f3d7cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b3d212ab9dd649a58cce830b3b8bccd4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de0417f4cbf146de960f24991ae22a38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2fc598b9f504c90a1f698e6b2e3443d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7071817d29934e84bd0cd2d2ecb08a91":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86573ccfddd14868b196313e46fb76db","IPY_MODEL_cc1470445d6c4b548a72c3da9b09d69e","IPY_MODEL_6c1d0b5780c34dd8a1201002de721438"],"layout":"IPY_MODEL_6a4c4094dd854831bca0d8aa6bd7c55d"}},"86573ccfddd14868b196313e46fb76db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f98844b1639f48efa00f93fe99548627","placeholder":"​","style":"IPY_MODEL_aa2c7654bb8940ac98838ff0c4f586f0","value":""}},"cc1470445d6c4b548a72c3da9b09d69e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93e8100ec67448198d836cdf0e5cf5c6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf6d5ad994d5442bad53a8733e5ebbe9","value":1}},"6c1d0b5780c34dd8a1201002de721438":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fe488e8defb4d5d9eb6ada349c621fd","placeholder":"​","style":"IPY_MODEL_b3047380558d432faac16dafeb7ff87c","value":" 13750/? [48:03&lt;00:00,  4.78it/s]"}},"6a4c4094dd854831bca0d8aa6bd7c55d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f98844b1639f48efa00f93fe99548627":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa2c7654bb8940ac98838ff0c4f586f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93e8100ec67448198d836cdf0e5cf5c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"cf6d5ad994d5442bad53a8733e5ebbe9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fe488e8defb4d5d9eb6ada349c621fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3047380558d432faac16dafeb7ff87c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5d7a7f04a15496eba8ddcb0aa8a6329":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_89f87b5a7cc043e88b92b785d8bfe72c","IPY_MODEL_5bf15aef927c4b7f88f5a6adbd42cc8b","IPY_MODEL_3c5e73074e0043cb903ce1354964bbe9"],"layout":"IPY_MODEL_ce30894b17ba4521837582ee3698e6f5"}},"89f87b5a7cc043e88b92b785d8bfe72c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9002de4513d94659baaee21d5b9c9fae","placeholder":"​","style":"IPY_MODEL_390bb9468f1d4891b5feade82178ef31","value":""}},"5bf15aef927c4b7f88f5a6adbd42cc8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b537d9e8bb104af1b5bb3fb32112994b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b68c6b6998f4aee965e2400ce424c20","value":1}},"3c5e73074e0043cb903ce1354964bbe9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba922c0d00a64a4e877659727e451986","placeholder":"​","style":"IPY_MODEL_f910f464a3c04619b74c2414e43a1ff1","value":" 1250/? [01:09&lt;00:00, 19.20it/s]"}},"ce30894b17ba4521837582ee3698e6f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9002de4513d94659baaee21d5b9c9fae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"390bb9468f1d4891b5feade82178ef31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b537d9e8bb104af1b5bb3fb32112994b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1b68c6b6998f4aee965e2400ce424c20":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba922c0d00a64a4e877659727e451986":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f910f464a3c04619b74c2414e43a1ff1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39e4b2397adf49ec95df6258c70e6acf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e05ae9c935345f58565494707306700","IPY_MODEL_1ead213580284aabbb44bb609de76166","IPY_MODEL_e1ce0176b2bc45ca8fd9bd6b4f35d69d"],"layout":"IPY_MODEL_8325851b23bf478ba2323ad1a2daaa5b"}},"5e05ae9c935345f58565494707306700":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d458943125941048ccca5759ab4c0b9","placeholder":"​","style":"IPY_MODEL_102bf9fbf4064c438b54c68550102e73","value":""}},"1ead213580284aabbb44bb609de76166":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58eb79b5f7ed440793ddc7686cb5f8f1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6495da9b25340cbba9905fc21c96448","value":1}},"e1ce0176b2bc45ca8fd9bd6b4f35d69d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bed5ad6ae7ca4737b3ce0f75610b6bda","placeholder":"​","style":"IPY_MODEL_3e7642a36e2d4890a54a93b60888d281","value":" 13750/? [48:04&lt;00:00,  4.77it/s]"}},"8325851b23bf478ba2323ad1a2daaa5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d458943125941048ccca5759ab4c0b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"102bf9fbf4064c438b54c68550102e73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58eb79b5f7ed440793ddc7686cb5f8f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d6495da9b25340cbba9905fc21c96448":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bed5ad6ae7ca4737b3ce0f75610b6bda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e7642a36e2d4890a54a93b60888d281":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f54df648e49841b3acd5839ba8b9ac43":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f372d9ba220146cdbd646ea1747dcb22","IPY_MODEL_d1d6403e929d464386b78786bcf95b17","IPY_MODEL_5608a2f99594433ba1beaa1678c45f9e"],"layout":"IPY_MODEL_6f176d32ccae416d9fd97985c97adc9c"}},"f372d9ba220146cdbd646ea1747dcb22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25d57a7a459e40bbb071a8376fe36fd6","placeholder":"​","style":"IPY_MODEL_651b1e11f0854989865b683ec1a27436","value":""}},"d1d6403e929d464386b78786bcf95b17":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50e29bc583594f58bb15a00d580226cd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c8d33f68df34703aefac0402e8cd4d7","value":1}},"5608a2f99594433ba1beaa1678c45f9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f83cc2cb446c4b35b1ab4476aeb714c2","placeholder":"​","style":"IPY_MODEL_aa040766abad4f7b91a553f4250c0d52","value":" 1250/? [01:14&lt;00:00, 19.29it/s]"}},"6f176d32ccae416d9fd97985c97adc9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25d57a7a459e40bbb071a8376fe36fd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"651b1e11f0854989865b683ec1a27436":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50e29bc583594f58bb15a00d580226cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"4c8d33f68df34703aefac0402e8cd4d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f83cc2cb446c4b35b1ab4476aeb714c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa040766abad4f7b91a553f4250c0d52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8198d3f4dc6e4a2c8f12fc51ff718eb6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47b10dc178ec462198d0d10d04508a4a","IPY_MODEL_c2c0fe35380340aea2d37b0afebb0fbb","IPY_MODEL_8ec4ea3a56dc45d18de6f34680e2fcf5"],"layout":"IPY_MODEL_e1270729e14e462d99bee5f004bcdfe2"}},"47b10dc178ec462198d0d10d04508a4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0507ad76e4fd4783971c32ad71762aac","placeholder":"​","style":"IPY_MODEL_cf1b25cca0584e3cb3a52649722bc985","value":""}},"c2c0fe35380340aea2d37b0afebb0fbb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9450f7644c6341559f11088ca90195c4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_355f5115681e479b8bacc172ed4714e2","value":1}},"8ec4ea3a56dc45d18de6f34680e2fcf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f451b1b928e4ae2bc3f182d8ea100db","placeholder":"​","style":"IPY_MODEL_c7de4c9f221942b080c3e41a35939b2e","value":" 13750/? [48:05&lt;00:00,  4.76it/s]"}},"e1270729e14e462d99bee5f004bcdfe2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0507ad76e4fd4783971c32ad71762aac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf1b25cca0584e3cb3a52649722bc985":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9450f7644c6341559f11088ca90195c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"355f5115681e479b8bacc172ed4714e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f451b1b928e4ae2bc3f182d8ea100db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7de4c9f221942b080c3e41a35939b2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f8973bd3b64492e96f4c0d2258b2678":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3104009aba1b4d0ab41bdc0a110b2ad3","IPY_MODEL_4301ae8415714ee0b121cbebfd7536b9","IPY_MODEL_6f4f08f9cc71453791d260fd798894bf"],"layout":"IPY_MODEL_bd10db7b40984617bff36db35cfc080a"}},"3104009aba1b4d0ab41bdc0a110b2ad3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb74dd7306ec435791db27e79cb14d6d","placeholder":"​","style":"IPY_MODEL_57bcecbaa15f4d29856a38c520749145","value":""}},"4301ae8415714ee0b121cbebfd7536b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f32b2d522f644d35a21a11bcb7be6b9f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd6997ee2869405f9c65821dd0b39369","value":1}},"6f4f08f9cc71453791d260fd798894bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ffdd5a4f391430f81a42d5fcb251e36","placeholder":"​","style":"IPY_MODEL_b9805eeb9f344bf8b16d1cd770c3c22b","value":" 1250/? [01:04&lt;00:00, 19.40it/s]"}},"bd10db7b40984617bff36db35cfc080a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb74dd7306ec435791db27e79cb14d6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57bcecbaa15f4d29856a38c520749145":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f32b2d522f644d35a21a11bcb7be6b9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"bd6997ee2869405f9c65821dd0b39369":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ffdd5a4f391430f81a42d5fcb251e36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9805eeb9f344bf8b16d1cd770c3c22b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0046e09c5d0746e1b45ce72057f0f3bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c36312eea2134530ac7f6a763b693fd8","IPY_MODEL_8488ed9d2887440c84a17cbae7c11213","IPY_MODEL_11ed85864ff54a2db2a0ecc66de4c5d4"],"layout":"IPY_MODEL_3d8f88b16a7c4d6da9c163ddc5507d0e"}},"c36312eea2134530ac7f6a763b693fd8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d171bb1b6c2045318b21e027aac4e7d4","placeholder":"​","style":"IPY_MODEL_1ffbcf8d68ad4133aa31045ecf9d86db","value":""}},"8488ed9d2887440c84a17cbae7c11213":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ed3226fe20a4da8893bb3904414f345","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58d1f98331bc471aa3214ba13bb9d559","value":1}},"11ed85864ff54a2db2a0ecc66de4c5d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8be509d6dad049b1b3c227c676ea6ec0","placeholder":"​","style":"IPY_MODEL_9f9b466830cb4528a76b167684322456","value":" 2500/? [02:16&lt;00:00, 19.25it/s]"}},"3d8f88b16a7c4d6da9c163ddc5507d0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d171bb1b6c2045318b21e027aac4e7d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ffbcf8d68ad4133aa31045ecf9d86db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ed3226fe20a4da8893bb3904414f345":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"58d1f98331bc471aa3214ba13bb9d559":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8be509d6dad049b1b3c227c676ea6ec0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f9b466830cb4528a76b167684322456":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b137ab55f23e432e8394affc3f50bd1f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc09d94cd83b42f1815d49c74134c9fc","IPY_MODEL_5b8b7702e9d847a495ad9714a74abe49","IPY_MODEL_57938843310c4c648f5832966b8a4fa5"],"layout":"IPY_MODEL_452673977a2742d0b312947537e6c34f"}},"fc09d94cd83b42f1815d49c74134c9fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78dd519a322742aabe2d402256097dc4","placeholder":"​","style":"IPY_MODEL_221af145d3c24e27857feffdcb4a50a3","value":""}},"5b8b7702e9d847a495ad9714a74abe49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dff6b9669dda418e9a6eba4e1af388db","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4aee99d1acd34c81907c6f5162edb983","value":1}},"57938843310c4c648f5832966b8a4fa5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_470db9784fe44ddc9353eda8ea70587e","placeholder":"​","style":"IPY_MODEL_be1277f684a34a24901a9dd2c4a8a893","value":" 11250/? [38:11&lt;00:00,  4.90it/s]"}},"452673977a2742d0b312947537e6c34f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78dd519a322742aabe2d402256097dc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"221af145d3c24e27857feffdcb4a50a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dff6b9669dda418e9a6eba4e1af388db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"4aee99d1acd34c81907c6f5162edb983":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"470db9784fe44ddc9353eda8ea70587e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be1277f684a34a24901a9dd2c4a8a893":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03ac0b134a764af6b5b80ff19d0100e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b34f243c6614bafa5fef4cff969722e","IPY_MODEL_580e376261c24b51aea191a9e069b468","IPY_MODEL_56b4aa4f189948aa940a521c1f1f795b"],"layout":"IPY_MODEL_5710be017f204824a6e92c385490285e"}},"0b34f243c6614bafa5fef4cff969722e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e7ca0bf6b554609b1cb8e2145f4b826","placeholder":"​","style":"IPY_MODEL_2a36aeec2a71431b8b41764f5cfe0053","value":""}},"580e376261c24b51aea191a9e069b468":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0be1584170e14cb893315f5a087973e3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95168bd8dfcb4a27953409bfb75d6705","value":1}},"56b4aa4f189948aa940a521c1f1f795b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05160d507e8d4c458a0dc0e8b0a9da7d","placeholder":"​","style":"IPY_MODEL_332f5f1c4cbb4d45bb2d265e28cf873d","value":" 1250/? [01:10&lt;00:00, 19.61it/s]"}},"5710be017f204824a6e92c385490285e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e7ca0bf6b554609b1cb8e2145f4b826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a36aeec2a71431b8b41764f5cfe0053":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0be1584170e14cb893315f5a087973e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"95168bd8dfcb4a27953409bfb75d6705":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05160d507e8d4c458a0dc0e8b0a9da7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"332f5f1c4cbb4d45bb2d265e28cf873d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db02b24dcf3c4489a222d46a3ee3f923":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b3c77162db749a887212517ae7e3d74","IPY_MODEL_e76bec898eb54d13aed62a03f5341b06","IPY_MODEL_f16757e6791a4fa98c4d7de83d3b446a"],"layout":"IPY_MODEL_7935b61f5b4d4087a3c9ce25eef7e514"}},"5b3c77162db749a887212517ae7e3d74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed674e76b2904f0aa3b5ee8087000d60","placeholder":"​","style":"IPY_MODEL_1b54b40371d240acb401a88cfd9922e5","value":""}},"e76bec898eb54d13aed62a03f5341b06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9359b3805ea54cce9dd32ba0d2fc7ba8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21e3860ec39b469da56c1b278e6287e8","value":1}},"f16757e6791a4fa98c4d7de83d3b446a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73600e2a97be4999a9bb6a4577ab8acc","placeholder":"​","style":"IPY_MODEL_9e8cbbc36b4a47b7a53de1cf7c4a74d7","value":" 11250/? [38:12&lt;00:00,  4.92it/s]"}},"7935b61f5b4d4087a3c9ce25eef7e514":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed674e76b2904f0aa3b5ee8087000d60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b54b40371d240acb401a88cfd9922e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9359b3805ea54cce9dd32ba0d2fc7ba8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"21e3860ec39b469da56c1b278e6287e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"73600e2a97be4999a9bb6a4577ab8acc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e8cbbc36b4a47b7a53de1cf7c4a74d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15ccceeaf8d440bea1f11b629fe49ab9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_443e3af5ae7e46068f140a81dd7e0189","IPY_MODEL_9fea46679d6340dab7dfaca2e9e002e4","IPY_MODEL_318973bcc17444fa913b260d90c66a10"],"layout":"IPY_MODEL_a40cfe6868bb451c88fc56b53be8f706"}},"443e3af5ae7e46068f140a81dd7e0189":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10aae37109534a13a0ce75159a0b1d21","placeholder":"​","style":"IPY_MODEL_e97d9b2615204cf8bbcb4b2afeea89d0","value":""}},"9fea46679d6340dab7dfaca2e9e002e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_52f12c1210c54783ae419183c804c852","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1f8c5e4d4e24d109803ca6a8fa9bd9d","value":1}},"318973bcc17444fa913b260d90c66a10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd3ceac13d174e21907ea9b838043730","placeholder":"​","style":"IPY_MODEL_826304450ba04384b9d0b06228004414","value":" 1250/? [01:12&lt;00:00, 19.77it/s]"}},"a40cfe6868bb451c88fc56b53be8f706":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10aae37109534a13a0ce75159a0b1d21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e97d9b2615204cf8bbcb4b2afeea89d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52f12c1210c54783ae419183c804c852":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d1f8c5e4d4e24d109803ca6a8fa9bd9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd3ceac13d174e21907ea9b838043730":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"826304450ba04384b9d0b06228004414":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9919ebc356a4afc8ec99152faef8079":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e19c4e5fecd445e59594e433e9719ef5","IPY_MODEL_8c9b1d97469c4b9e9d280db3eabca13e","IPY_MODEL_f00b3fa2f9504794a8b205593b6122b1"],"layout":"IPY_MODEL_daa04796c55a47dc88297093b88a023a"}},"e19c4e5fecd445e59594e433e9719ef5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1285303134d47c69465b3f77a6e4fd1","placeholder":"​","style":"IPY_MODEL_04d1c90925174d59b9786cf135bec4f9","value":""}},"8c9b1d97469c4b9e9d280db3eabca13e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1fc6bf2ead441b4a753d2061bb1368b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7888814373544dd586afa99f640700d4","value":1}},"f00b3fa2f9504794a8b205593b6122b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f1650b14da54697a5bdcdc777231f1f","placeholder":"​","style":"IPY_MODEL_f673a15872794d7491f829fe2f3f76da","value":" 11250/? [38:19&lt;00:00,  4.92it/s]"}},"daa04796c55a47dc88297093b88a023a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1285303134d47c69465b3f77a6e4fd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d1c90925174d59b9786cf135bec4f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1fc6bf2ead441b4a753d2061bb1368b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7888814373544dd586afa99f640700d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f1650b14da54697a5bdcdc777231f1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f673a15872794d7491f829fe2f3f76da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc83b7b437a544baa34cd352dfda80ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86b28039aa3e4d37b6afcd866e97f457","IPY_MODEL_51a1c8f4df1d43c7ba24f875db1ea8ff","IPY_MODEL_da719d513f2d44b3a0fad66303a0acf6"],"layout":"IPY_MODEL_b4fd352d6ae5459e9e418844633f5c3c"}},"86b28039aa3e4d37b6afcd866e97f457":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_929a29b2a21e4e9788156260cfb13189","placeholder":"​","style":"IPY_MODEL_47cfd447f24c48a2865ea9cfd957891a","value":""}},"51a1c8f4df1d43c7ba24f875db1ea8ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7effcac644a0410eb39df559c374eb52","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06a4c3a60ca54249abc7ec73211201b2","value":1}},"da719d513f2d44b3a0fad66303a0acf6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf666d69c3de41c8af46973a39d55853","placeholder":"​","style":"IPY_MODEL_919eddf6f91e430dbed135622cf46ab6","value":" 1250/? [01:08&lt;00:00, 19.65it/s]"}},"b4fd352d6ae5459e9e418844633f5c3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"929a29b2a21e4e9788156260cfb13189":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47cfd447f24c48a2865ea9cfd957891a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7effcac644a0410eb39df559c374eb52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"06a4c3a60ca54249abc7ec73211201b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf666d69c3de41c8af46973a39d55853":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"919eddf6f91e430dbed135622cf46ab6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4008122cd1754742aa9355b2c49705c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4748990e4fd3461f900f06907a483b1b","IPY_MODEL_7b1fdbabbf1b4e37a61a2bd05a294764","IPY_MODEL_d544a60c439b4da1894f4b95681f0069"],"layout":"IPY_MODEL_b90eda56b91b4891a81092e01dd48093"}},"4748990e4fd3461f900f06907a483b1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e394b3791fbb47c9948a1cf15b61ae5f","placeholder":"​","style":"IPY_MODEL_fab207a24bed415b92bc2ff7c9bddae3","value":""}},"7b1fdbabbf1b4e37a61a2bd05a294764":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a26310e1928846bd8ecc8d19126f534d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2223325959df4dd8b16a9e6c2182dc0b","value":1}},"d544a60c439b4da1894f4b95681f0069":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00d9e43c358246f481ae09823ab4507f","placeholder":"​","style":"IPY_MODEL_b861fb5970574db08f900e642d685547","value":" 11250/? [38:20&lt;00:00,  4.88it/s]"}},"b90eda56b91b4891a81092e01dd48093":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e394b3791fbb47c9948a1cf15b61ae5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fab207a24bed415b92bc2ff7c9bddae3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a26310e1928846bd8ecc8d19126f534d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"2223325959df4dd8b16a9e6c2182dc0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00d9e43c358246f481ae09823ab4507f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b861fb5970574db08f900e642d685547":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10d4c3071e2941ca9d40cae0b1ec3c32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_854e6d2d192b4e99be61e5cea6b7eb75","IPY_MODEL_fb502c77b1334ac7ae8f51111345390c","IPY_MODEL_4f093afc59204fc1938f1fc0d5e030d3"],"layout":"IPY_MODEL_4f8b20b001d54b63a359624a5f80125c"}},"854e6d2d192b4e99be61e5cea6b7eb75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c235f059666460fa58dd8a1bcc3d84b","placeholder":"​","style":"IPY_MODEL_9903a845ce454dd89c85251cc3b05e10","value":""}},"fb502c77b1334ac7ae8f51111345390c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5169a78ea6c4493f8b8eab899b1a835c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21e620c4e4c149dd891cd47de4d72770","value":1}},"4f093afc59204fc1938f1fc0d5e030d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b244cf5687c449bad38dd9f018531b9","placeholder":"​","style":"IPY_MODEL_5c2790f1675a4db4a8be472a779f3528","value":" 1250/? [01:06&lt;00:00, 19.54it/s]"}},"4f8b20b001d54b63a359624a5f80125c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c235f059666460fa58dd8a1bcc3d84b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9903a845ce454dd89c85251cc3b05e10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5169a78ea6c4493f8b8eab899b1a835c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"21e620c4e4c149dd891cd47de4d72770":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b244cf5687c449bad38dd9f018531b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c2790f1675a4db4a8be472a779f3528":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58ba3412a4bc4c208e8d67416bfd47e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42f43542482645b9b3e5e01bf5b0ef06","IPY_MODEL_83d8d5753f6b4d1e8f9a66fcf4f4a359","IPY_MODEL_a08749c412ce41eaafd410016ce1fb73"],"layout":"IPY_MODEL_0679e3eca6d943fca5fe29b1c174f05b"}},"42f43542482645b9b3e5e01bf5b0ef06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64188c70a0ce4cbebe081b696fe23ab9","placeholder":"​","style":"IPY_MODEL_e61c8db1f22e4fe5a6732e0f36862eb2","value":""}},"83d8d5753f6b4d1e8f9a66fcf4f4a359":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1544f6adcd5d4b119f7a5cece6b19c76","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a16d1d81698c4ddfab51bda62fa4cdae","value":1}},"a08749c412ce41eaafd410016ce1fb73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b33f9f7048c43feb7781df58e8a777f","placeholder":"​","style":"IPY_MODEL_42cf1a2235c54c26aaa7dc5a409f0aea","value":" 11250/? [38:22&lt;00:00,  4.91it/s]"}},"0679e3eca6d943fca5fe29b1c174f05b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64188c70a0ce4cbebe081b696fe23ab9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e61c8db1f22e4fe5a6732e0f36862eb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1544f6adcd5d4b119f7a5cece6b19c76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a16d1d81698c4ddfab51bda62fa4cdae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b33f9f7048c43feb7781df58e8a777f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42cf1a2235c54c26aaa7dc5a409f0aea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8e83ae36f6a4365a1e83060fa5fecd9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb779e8fdc764e11bda870ccee0408c9","IPY_MODEL_646532c313bc4d119f1088ec89e8ddd4","IPY_MODEL_38a682a57a134a6b84e5fd7c269718f7"],"layout":"IPY_MODEL_a4e902128164461bb1b87c55a2e20969"}},"fb779e8fdc764e11bda870ccee0408c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bdf1dd8e9dd4dbe8c552c440bc1ac1c","placeholder":"​","style":"IPY_MODEL_ae1a6ddaa75047719229de705063bd7f","value":""}},"646532c313bc4d119f1088ec89e8ddd4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad732eb193424e18800db01a478085f8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c75d583aea84190b36e1fa6bb9a317c","value":1}},"38a682a57a134a6b84e5fd7c269718f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dca118fbe4204016ba5be93f8481764c","placeholder":"​","style":"IPY_MODEL_e04139901dae4ddb83a0d515cdd8044c","value":" 1250/? [01:06&lt;00:00, 19.61it/s]"}},"a4e902128164461bb1b87c55a2e20969":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bdf1dd8e9dd4dbe8c552c440bc1ac1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae1a6ddaa75047719229de705063bd7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad732eb193424e18800db01a478085f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"0c75d583aea84190b36e1fa6bb9a317c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dca118fbe4204016ba5be93f8481764c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e04139901dae4ddb83a0d515cdd8044c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ea03632c23842928537a99bdf0db25b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12e6fd3147394938ad582e9a39abeebf","IPY_MODEL_844523e8f3184cae8679cb57f2f31a2d","IPY_MODEL_36f8e7f593384911a86e1c79a91f14f6"],"layout":"IPY_MODEL_b82e204dee3143b3853c65eabd5e259d"}},"12e6fd3147394938ad582e9a39abeebf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e18b178d1cc44ff9960ebdd8c74b55a","placeholder":"​","style":"IPY_MODEL_2b9371ba2fbc418f89793710758ca1f5","value":""}},"844523e8f3184cae8679cb57f2f31a2d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec98065cf827422d95d55db57e9664b3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd8932f1bb3f495599052d7ed08cd706","value":1}},"36f8e7f593384911a86e1c79a91f14f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1045460e3bb4a61bb5bf0833456beec","placeholder":"​","style":"IPY_MODEL_4ef2bbf66f28445fbb02e5e3b935d93d","value":" 2500/? [02:16&lt;00:00, 19.65it/s]"}},"b82e204dee3143b3853c65eabd5e259d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e18b178d1cc44ff9960ebdd8c74b55a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b9371ba2fbc418f89793710758ca1f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec98065cf827422d95d55db57e9664b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"fd8932f1bb3f495599052d7ed08cd706":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1045460e3bb4a61bb5bf0833456beec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ef2bbf66f28445fbb02e5e3b935d93d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc211b40720c4a6ca2bc1be418e9cc94":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4eeb959d1062437db3d82fc46d9f1b4e","IPY_MODEL_ce0d2d358aab483fb7041b631d977d3a","IPY_MODEL_aeff6114af804101b98da1b3abba1bae"],"layout":"IPY_MODEL_ef6e685a3b1e4edba2ff575e9ff6097d"}},"4eeb959d1062437db3d82fc46d9f1b4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4df332b5b6134f24906487309e3d4a01","placeholder":"​","style":"IPY_MODEL_f6684cf949464a0c984aa4200b1622e6","value":""}},"ce0d2d358aab483fb7041b631d977d3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cbf394aa1894eaa9509d373c676919f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b87b426dd8c24b84b246443dcaec245e","value":1}},"aeff6114af804101b98da1b3abba1bae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61699ee2c0484480b44d7cb0866393bd","placeholder":"​","style":"IPY_MODEL_b106d1ccf897494dbd506ce94a4cdf38","value":" 11250/? [36:12&lt;00:00,  5.19it/s]"}},"ef6e685a3b1e4edba2ff575e9ff6097d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4df332b5b6134f24906487309e3d4a01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6684cf949464a0c984aa4200b1622e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cbf394aa1894eaa9509d373c676919f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b87b426dd8c24b84b246443dcaec245e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61699ee2c0484480b44d7cb0866393bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b106d1ccf897494dbd506ce94a4cdf38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16371885b51d4bd8b7462b4c95da242a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba3f2fa5e3cc47b0be434f5a34e8a588","IPY_MODEL_16c9b8b7c93146d9b4a40bef37509c36","IPY_MODEL_5551f5880ccb4aabafb8ca0a28d9bf12"],"layout":"IPY_MODEL_c15f394fbd664dc089b81d9bab150559"}},"ba3f2fa5e3cc47b0be434f5a34e8a588":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_754220e5b81441d7a06e4f244db687b7","placeholder":"​","style":"IPY_MODEL_482cb5d948ba4e70b992ceea4b690c64","value":""}},"16c9b8b7c93146d9b4a40bef37509c36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cd289e7c50f43c1b97c6bd62b5013b5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da317a65ee9d48b0855bfc5c7de00b25","value":1}},"5551f5880ccb4aabafb8ca0a28d9bf12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ac1eee1b060459881e64303aea17152","placeholder":"​","style":"IPY_MODEL_c5c3428a0c44423fb6b0ca9aa6fdec69","value":" 1250/? [01:27&lt;00:00, 20.03it/s]"}},"c15f394fbd664dc089b81d9bab150559":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"754220e5b81441d7a06e4f244db687b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"482cb5d948ba4e70b992ceea4b690c64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cd289e7c50f43c1b97c6bd62b5013b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"da317a65ee9d48b0855bfc5c7de00b25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ac1eee1b060459881e64303aea17152":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5c3428a0c44423fb6b0ca9aa6fdec69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a5a0d5431c54046a998ff1484f6ed13":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b32674b494e4826b4bc6d5dea7f8f7e","IPY_MODEL_661c93bd7d9d464aa8b3d965b3f72ed4","IPY_MODEL_617d7a91bd4e4a80af51b8c6b899c90b"],"layout":"IPY_MODEL_c26506bb2b0c41239c5278c97ab17c6f"}},"8b32674b494e4826b4bc6d5dea7f8f7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cae4857863f948059f256aea0bd95340","placeholder":"​","style":"IPY_MODEL_05ce4de9c3ac4db19429c98a31fe3128","value":""}},"661c93bd7d9d464aa8b3d965b3f72ed4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d092201041d42aab7155a2cbca24e91","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae366fe171fc409889eaa0438c167ff7","value":1}},"617d7a91bd4e4a80af51b8c6b899c90b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56e68ece4332473d9ac7c63fbd899c74","placeholder":"​","style":"IPY_MODEL_4a1e45140f4c4df6956f010d6258a08a","value":" 11250/? [36:10&lt;00:00,  5.22it/s]"}},"c26506bb2b0c41239c5278c97ab17c6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cae4857863f948059f256aea0bd95340":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05ce4de9c3ac4db19429c98a31fe3128":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d092201041d42aab7155a2cbca24e91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ae366fe171fc409889eaa0438c167ff7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56e68ece4332473d9ac7c63fbd899c74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a1e45140f4c4df6956f010d6258a08a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdd0091d200a4725a28027ca23972336":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d584347b8b894fd6b13c64f46a23d76c","IPY_MODEL_d85e92c5762f49f28bbaee27b9f0633f","IPY_MODEL_447cdd5b087f44daa1b72d227eaf7191"],"layout":"IPY_MODEL_3cd014b0b51e4415947132c2a617ccff"}},"d584347b8b894fd6b13c64f46a23d76c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cba178fe12264ad9bee4dd57abc1a5f0","placeholder":"​","style":"IPY_MODEL_68dd18b3e0ac4730bd7d0e9060c1e1d9","value":""}},"d85e92c5762f49f28bbaee27b9f0633f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_249af08dd24643b889b63851924cff56","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c91b67e5a4dd487896038e45d1f06d69","value":1}},"447cdd5b087f44daa1b72d227eaf7191":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb72e1e70b7e45e3ab50040362cd2695","placeholder":"​","style":"IPY_MODEL_65a3c724b26b470eb20e5695c41b45e4","value":" 1250/? [01:15&lt;00:00, 19.72it/s]"}},"3cd014b0b51e4415947132c2a617ccff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cba178fe12264ad9bee4dd57abc1a5f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68dd18b3e0ac4730bd7d0e9060c1e1d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"249af08dd24643b889b63851924cff56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c91b67e5a4dd487896038e45d1f06d69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb72e1e70b7e45e3ab50040362cd2695":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65a3c724b26b470eb20e5695c41b45e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aad8fc5e82644f83b9b59c076f34d7e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db046d68c3134c7280d06e0783a32fc4","IPY_MODEL_e21c1045b717432c9edaf96953c163ab","IPY_MODEL_714b4015fab1447f9e3277c1a6bbfcbf"],"layout":"IPY_MODEL_cf47ca87e1d54d6c8f699b90106604d7"}},"db046d68c3134c7280d06e0783a32fc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1508ce305012454c80d8744b667c67f4","placeholder":"​","style":"IPY_MODEL_81f5194024394b8cac37a46225444b5f","value":""}},"e21c1045b717432c9edaf96953c163ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b793d055b6a4266b6c221a1cdb49bb2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df42d35c6e6b40f9bd4be958b0468c7f","value":1}},"714b4015fab1447f9e3277c1a6bbfcbf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba91591f84f84a5eade16dd2f935f0c8","placeholder":"​","style":"IPY_MODEL_a36497eb02894c5ba602aff4904215bb","value":" 11250/? [36:12&lt;00:00,  5.19it/s]"}},"cf47ca87e1d54d6c8f699b90106604d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1508ce305012454c80d8744b667c67f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81f5194024394b8cac37a46225444b5f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b793d055b6a4266b6c221a1cdb49bb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"df42d35c6e6b40f9bd4be958b0468c7f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba91591f84f84a5eade16dd2f935f0c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a36497eb02894c5ba602aff4904215bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2732ba59aa5a4414981b1c4f4c4d83ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f450e415a9774334a88b00a94c17bb6c","IPY_MODEL_83db264293da44e49f57cf46c7090253","IPY_MODEL_7a39156e95514c9ca522e6c06d75c11e"],"layout":"IPY_MODEL_812279f190bc4a03ac12130e059a4ac5"}},"f450e415a9774334a88b00a94c17bb6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8761039ccb6743f8a3680e6341c16df8","placeholder":"​","style":"IPY_MODEL_e681cb8c22774b41a3f1a2b56f6fc935","value":""}},"83db264293da44e49f57cf46c7090253":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30601e539f724fb5b3104d1f0298374e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_504171dad4c54b1cbcce27d4593cb7c6","value":1}},"7a39156e95514c9ca522e6c06d75c11e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6462f5180e7642c9b01dbe0208394f1a","placeholder":"​","style":"IPY_MODEL_0834d667a88c47c6ab9b8cc92e0433bc","value":" 1250/? [01:10&lt;00:00, 19.42it/s]"}},"812279f190bc4a03ac12130e059a4ac5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8761039ccb6743f8a3680e6341c16df8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e681cb8c22774b41a3f1a2b56f6fc935":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30601e539f724fb5b3104d1f0298374e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"504171dad4c54b1cbcce27d4593cb7c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6462f5180e7642c9b01dbe0208394f1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0834d667a88c47c6ab9b8cc92e0433bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0db87686a8c045eeae025bc41287933d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f48cc98d78d4a5999d64776b19485a3","IPY_MODEL_c2bd6d4fe10d484d9d9bd66f55ebe80d","IPY_MODEL_b477248e9366419bbdb5c4631b5828e6"],"layout":"IPY_MODEL_fcf30655c13f4c6181495ad45500922b"}},"9f48cc98d78d4a5999d64776b19485a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1c598f03b1043f499f3fafc2d085d84","placeholder":"​","style":"IPY_MODEL_5a7081e0b4ea407984a7b5b169eccc98","value":""}},"c2bd6d4fe10d484d9d9bd66f55ebe80d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b55483d31244708a919a7c9fddad8bd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e356910e1e00499ca3e9f6f3ade9946e","value":1}},"b477248e9366419bbdb5c4631b5828e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e01835ea96ab41e4b07d16fc14ab8b33","placeholder":"​","style":"IPY_MODEL_18f14e151e7943e8a8710af2bac73a96","value":" 11250/? [36:11&lt;00:00,  5.18it/s]"}},"fcf30655c13f4c6181495ad45500922b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c598f03b1043f499f3fafc2d085d84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a7081e0b4ea407984a7b5b169eccc98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b55483d31244708a919a7c9fddad8bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e356910e1e00499ca3e9f6f3ade9946e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e01835ea96ab41e4b07d16fc14ab8b33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18f14e151e7943e8a8710af2bac73a96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c4d8ea2bb58491490d588796541ee9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85a346d032df4581a758b98bfde069c2","IPY_MODEL_395ee44c2181492090c326ea38dcf891","IPY_MODEL_291fe0eb226d4195af3c7371133ac8db"],"layout":"IPY_MODEL_0767a9ddea264849b9103e2f15f59c96"}},"85a346d032df4581a758b98bfde069c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4ca4b242a484cd080b1f6c2dbad91af","placeholder":"​","style":"IPY_MODEL_a50939b46435413f8d97692b96ea12b7","value":""}},"395ee44c2181492090c326ea38dcf891":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c144eaeb2eb34c3791af70fd5c1862d9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13e2c4d78b5145fba6f43be687de85b6","value":1}},"291fe0eb226d4195af3c7371133ac8db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bd968874bbf4cacaf56687ad1bfa2ee","placeholder":"​","style":"IPY_MODEL_571fce62112f44d796d42de4e13413e6","value":" 1250/? [01:08&lt;00:00, 19.85it/s]"}},"0767a9ddea264849b9103e2f15f59c96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4ca4b242a484cd080b1f6c2dbad91af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a50939b46435413f8d97692b96ea12b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c144eaeb2eb34c3791af70fd5c1862d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"13e2c4d78b5145fba6f43be687de85b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bd968874bbf4cacaf56687ad1bfa2ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"571fce62112f44d796d42de4e13413e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f11fb58c50ba40478d8f8b4d3dc6c678":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b4600fd824549289cb012508e3b5029","IPY_MODEL_2f58d5305309493fb835d058dd58dc76","IPY_MODEL_64c1b1fb89904c859e46c23412b8941d"],"layout":"IPY_MODEL_818897db4df04344b758c9d4900ad072"}},"7b4600fd824549289cb012508e3b5029":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de223909d749477f818e8ef9f16c8a26","placeholder":"​","style":"IPY_MODEL_11247a21d9284fe2b1a5364e39a0e6d8","value":""}},"2f58d5305309493fb835d058dd58dc76":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa23da4a290a49cc98f95ad085d8459b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d178ee02f28244f3b54748e9f82a39da","value":1}},"64c1b1fb89904c859e46c23412b8941d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5d7a08ba0e845cb89395966e919f84d","placeholder":"​","style":"IPY_MODEL_41821533da57438c9f5668cfaa813727","value":" 11250/? [36:11&lt;00:00,  5.19it/s]"}},"818897db4df04344b758c9d4900ad072":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de223909d749477f818e8ef9f16c8a26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11247a21d9284fe2b1a5364e39a0e6d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa23da4a290a49cc98f95ad085d8459b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d178ee02f28244f3b54748e9f82a39da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5d7a08ba0e845cb89395966e919f84d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41821533da57438c9f5668cfaa813727":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0061ca8f11b44527bc04c67e53254e57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6eed5e4e5bd84a0c90aed51128ff7164","IPY_MODEL_4787410bb7b44440a94fa8a6946ac52d","IPY_MODEL_e36c65689e3747989197eba50014fd8f"],"layout":"IPY_MODEL_677947ed8f284492ac93bdaa0f02b612"}},"6eed5e4e5bd84a0c90aed51128ff7164":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b9382460d104f6cbd056d7e3b3a94ec","placeholder":"​","style":"IPY_MODEL_57a3bffa55974445bec8ee8ece38f607","value":""}},"4787410bb7b44440a94fa8a6946ac52d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6ba29532d17472da6d1d53e8e1cdd35","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7dc406cc8a97427987e3a49db7100a79","value":1}},"e36c65689e3747989197eba50014fd8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cda5033a70814c4d9ac1ff52b84f71ff","placeholder":"​","style":"IPY_MODEL_9af518e92d094809ac6ed0932bd2b9ea","value":" 1250/? [01:03&lt;00:00, 19.54it/s]"}},"677947ed8f284492ac93bdaa0f02b612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b9382460d104f6cbd056d7e3b3a94ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57a3bffa55974445bec8ee8ece38f607":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6ba29532d17472da6d1d53e8e1cdd35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7dc406cc8a97427987e3a49db7100a79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cda5033a70814c4d9ac1ff52b84f71ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9af518e92d094809ac6ed0932bd2b9ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a168f90c9d9453881b8971f76d90942":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b320f15d29b4acc8bdd0a93b6d17904","IPY_MODEL_2925b21bc9974663a4f6ee4d97790887","IPY_MODEL_cde3e003d9e64628a0a1612c3b7b28f4"],"layout":"IPY_MODEL_1fb14c3193714e809040da3eff6b119b"}},"2b320f15d29b4acc8bdd0a93b6d17904":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6e85c9d3fb847e8bf2289d3e4a62c52","placeholder":"​","style":"IPY_MODEL_d495c71117eb43f7ac165b3f1c11d657","value":""}},"2925b21bc9974663a4f6ee4d97790887":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b3a405b06954bafa333c41140b29d52","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bad327727a21494e859d53054a2c59ae","value":1}},"cde3e003d9e64628a0a1612c3b7b28f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25c6d2a0720f4a6e90ae1e5a9a784166","placeholder":"​","style":"IPY_MODEL_d6275172d41444dd8504d6bafca1cd6c","value":" 2500/? [02:13&lt;00:00, 19.78it/s]"}},"1fb14c3193714e809040da3eff6b119b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6e85c9d3fb847e8bf2289d3e4a62c52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d495c71117eb43f7ac165b3f1c11d657":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b3a405b06954bafa333c41140b29d52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"bad327727a21494e859d53054a2c59ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25c6d2a0720f4a6e90ae1e5a9a784166":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6275172d41444dd8504d6bafca1cd6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15e034948c0b45488d4b0c9b42105628":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d9c7e38097b4f4fae5e75a49e632eae","IPY_MODEL_69d2108eb0f94306a8c1447ef6ddf644","IPY_MODEL_c202e9b42ce14bf09915d279a07cdda3"],"layout":"IPY_MODEL_0be6c26da5254262be9d5a9519ffd508"}},"4d9c7e38097b4f4fae5e75a49e632eae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bce7ed908d7e4507a2fea1c8028eb9fa","placeholder":"​","style":"IPY_MODEL_6b9006118d884161bf9da1ae99547874","value":""}},"69d2108eb0f94306a8c1447ef6ddf644":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1523a22c4e74f6bbadae4f69057975a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a542d289065d41f7ad15dec51fa5c467","value":1}},"c202e9b42ce14bf09915d279a07cdda3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_688146ea3f954cb5bb108078128f9abc","placeholder":"​","style":"IPY_MODEL_a067fe09641e492d8b08e64610d14c7b","value":" 11250/? [36:27&lt;00:00,  5.14it/s]"}},"0be6c26da5254262be9d5a9519ffd508":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bce7ed908d7e4507a2fea1c8028eb9fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b9006118d884161bf9da1ae99547874":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1523a22c4e74f6bbadae4f69057975a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a542d289065d41f7ad15dec51fa5c467":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"688146ea3f954cb5bb108078128f9abc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a067fe09641e492d8b08e64610d14c7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bba9dbc3060437da8c6c1d9bda5a8ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a45f95d1408641bdbc8b633cf9c93ce8","IPY_MODEL_6bdb9b2228cf4a82947c5d3ede460398","IPY_MODEL_2f32356db7d64f909ee782b1e744fafe"],"layout":"IPY_MODEL_bf226838ea13481ea90b871cf529c5ae"}},"a45f95d1408641bdbc8b633cf9c93ce8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d78d837ea1264487adb013d032f6128b","placeholder":"​","style":"IPY_MODEL_e8f6ca7617b84bdf8b64808ca1dec30e","value":""}},"6bdb9b2228cf4a82947c5d3ede460398":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dd52fd934e74bdb99e34ba801876493","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b552957995d949beb4f9e85ed1036f13","value":1}},"2f32356db7d64f909ee782b1e744fafe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7683e8f501eb43e490322bff82bdc99f","placeholder":"​","style":"IPY_MODEL_1144ae41a5c24c3c88951db7138d46f3","value":" 1250/? [01:11&lt;00:00, 19.71it/s]"}},"bf226838ea13481ea90b871cf529c5ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d78d837ea1264487adb013d032f6128b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8f6ca7617b84bdf8b64808ca1dec30e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8dd52fd934e74bdb99e34ba801876493":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b552957995d949beb4f9e85ed1036f13":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7683e8f501eb43e490322bff82bdc99f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1144ae41a5c24c3c88951db7138d46f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"591d28d4c44b406692bcc443f0a2ea83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ba9e7b9ed6f45079674ef49a0af6569","IPY_MODEL_c960982ebc8b47a0b575a52eb6e4d755","IPY_MODEL_08152c3a01074eefb09cf0815855249e"],"layout":"IPY_MODEL_10068dd373dc44a6a53ea9b566a273a7"}},"2ba9e7b9ed6f45079674ef49a0af6569":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e13a85b1948e4b869ddcc8d36a83a86b","placeholder":"​","style":"IPY_MODEL_f37de2fba4dc4e5793177cae2fda4f85","value":""}},"c960982ebc8b47a0b575a52eb6e4d755":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c081e8700fb4d6880061707dd7c4328","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_920ad56b4cba42139a3531a36321265e","value":1}},"08152c3a01074eefb09cf0815855249e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_827ee04103f749039a9a2b7a599e56af","placeholder":"​","style":"IPY_MODEL_5e87f076b94a4bea927857ccc146c93e","value":" 11250/? [36:29&lt;00:00,  5.11it/s]"}},"10068dd373dc44a6a53ea9b566a273a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e13a85b1948e4b869ddcc8d36a83a86b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f37de2fba4dc4e5793177cae2fda4f85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c081e8700fb4d6880061707dd7c4328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"920ad56b4cba42139a3531a36321265e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"827ee04103f749039a9a2b7a599e56af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e87f076b94a4bea927857ccc146c93e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88b2e0a6e0e94c9aa6b5d3c2167af601":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3104a86693bb49bf816dcbdceb0d1870","IPY_MODEL_1d60d0560a66426a91ad5b24c5c73b6d","IPY_MODEL_6e91f3d738cf47f391bfa69006a77356"],"layout":"IPY_MODEL_1acabd04c44543f881503727f805efe5"}},"3104a86693bb49bf816dcbdceb0d1870":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29aea2619b72461e9ba8e90733c29a30","placeholder":"​","style":"IPY_MODEL_cc64f5b4eb5741f4a9ca014a04a60c24","value":""}},"1d60d0560a66426a91ad5b24c5c73b6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_99a980a96cbc4a07a1ee0afca9d844b8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b20150f327fb42e68a1884ae318d54aa","value":1}},"6e91f3d738cf47f391bfa69006a77356":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e66fd8486c474ac4b4df80ba8ef41884","placeholder":"​","style":"IPY_MODEL_f4b78de041d945eeac51644bf4270f76","value":" 1250/? [01:08&lt;00:00, 19.69it/s]"}},"1acabd04c44543f881503727f805efe5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29aea2619b72461e9ba8e90733c29a30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc64f5b4eb5741f4a9ca014a04a60c24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99a980a96cbc4a07a1ee0afca9d844b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b20150f327fb42e68a1884ae318d54aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e66fd8486c474ac4b4df80ba8ef41884":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4b78de041d945eeac51644bf4270f76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef5084e78a0f435aa76348c681447f0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0340de7e4374f13b9feccf43e73a8ff","IPY_MODEL_c9f7452d0e1c414bb5880e789918d938","IPY_MODEL_cad5696d607f4ddbb4f6501060bf872f"],"layout":"IPY_MODEL_9f780510bfed4f84b365cafdfbdfd754"}},"e0340de7e4374f13b9feccf43e73a8ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f8556d570c24e94a295c8e6ff4fd440","placeholder":"​","style":"IPY_MODEL_8e42de80fa414f7596e1d1acfd83ad4d","value":""}},"c9f7452d0e1c414bb5880e789918d938":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_104efedf54b842a2bde784550010a093","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_487733aab4c24d25abccb7f26e71ab0d","value":1}},"cad5696d607f4ddbb4f6501060bf872f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c53b32f140724df6832b34f86e75ab5c","placeholder":"​","style":"IPY_MODEL_c18193c337cc48c39065cb561b34cca5","value":" 11250/? [36:36&lt;00:00,  5.11it/s]"}},"9f780510bfed4f84b365cafdfbdfd754":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f8556d570c24e94a295c8e6ff4fd440":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e42de80fa414f7596e1d1acfd83ad4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"104efedf54b842a2bde784550010a093":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"487733aab4c24d25abccb7f26e71ab0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c53b32f140724df6832b34f86e75ab5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c18193c337cc48c39065cb561b34cca5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97fc13ecbad04413a2b93731f0393119":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01bd70a936b5432280e4f281fa1965da","IPY_MODEL_c985c0c8ba2f4e79a51d7eac9d317618","IPY_MODEL_e720a064c0d040fe8573c7a44a33eb9f"],"layout":"IPY_MODEL_e4a8491cf80141eea499d12aebb5db06"}},"01bd70a936b5432280e4f281fa1965da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d1367e2634642e19a52caeb68ed5edd","placeholder":"​","style":"IPY_MODEL_186e64a9c86e4386b12d722d3dd8f5c8","value":""}},"c985c0c8ba2f4e79a51d7eac9d317618":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c31c0276d9e4fb795241cfbc89ab95c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af769834ff324b63a157d6f422105b6e","value":1}},"e720a064c0d040fe8573c7a44a33eb9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a90deebe4f9e49c09ceef164157f4bca","placeholder":"​","style":"IPY_MODEL_6c454dd6150e4dab8c0f8a88dba3e7fe","value":" 1250/? [01:14&lt;00:00, 19.51it/s]"}},"e4a8491cf80141eea499d12aebb5db06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d1367e2634642e19a52caeb68ed5edd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"186e64a9c86e4386b12d722d3dd8f5c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c31c0276d9e4fb795241cfbc89ab95c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"af769834ff324b63a157d6f422105b6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a90deebe4f9e49c09ceef164157f4bca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c454dd6150e4dab8c0f8a88dba3e7fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cc94c65663a468cb42833ba818a6435":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04c2092b70d243f2863dbdf61d4de33a","IPY_MODEL_01da0fad9d334b10a1aea516b067bc7c","IPY_MODEL_2fc083bfdd0c463c8b7afb30c930fbca"],"layout":"IPY_MODEL_16c0061323484810a5c74888748030da"}},"04c2092b70d243f2863dbdf61d4de33a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_859d0b0cfcf241a9a28f2a7db8f6654c","placeholder":"​","style":"IPY_MODEL_f51c0297b3644003ae65aad6fcdf5a6d","value":""}},"01da0fad9d334b10a1aea516b067bc7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc20a7d103014f309b3a78dc04dec157","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca99f5ade6f94759834812554a7b78bf","value":1}},"2fc083bfdd0c463c8b7afb30c930fbca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a48501ce8a6444fda0b1df6af6624ae6","placeholder":"​","style":"IPY_MODEL_8280ef48ddb14524b1eb3680d7976c72","value":" 11250/? [36:33&lt;00:00,  5.13it/s]"}},"16c0061323484810a5c74888748030da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"859d0b0cfcf241a9a28f2a7db8f6654c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f51c0297b3644003ae65aad6fcdf5a6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc20a7d103014f309b3a78dc04dec157":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ca99f5ade6f94759834812554a7b78bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a48501ce8a6444fda0b1df6af6624ae6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8280ef48ddb14524b1eb3680d7976c72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54228c6911ba414580c989d88e235a95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45aa5d38a0884ba9865936bd1a7f29c2","IPY_MODEL_e82339d5169a460689d6903788905fb5","IPY_MODEL_2d286314f585469bb860640e46b271b8"],"layout":"IPY_MODEL_df922521148d40798fdbdc7133d21eae"}},"45aa5d38a0884ba9865936bd1a7f29c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24f8c29fb4bd4ff6830d22794674b1c3","placeholder":"​","style":"IPY_MODEL_a3d998f827bc42549aafdd672b6544ba","value":""}},"e82339d5169a460689d6903788905fb5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93f27479f0194296938eea4fbbb6cef7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81863519ca60408da6a8ce14b1d9955c","value":1}},"2d286314f585469bb860640e46b271b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dca2bfaddc30467d9f6e908e8bb34856","placeholder":"​","style":"IPY_MODEL_97411f6ec50240c6a3b67ae1761b2cc9","value":" 1250/? [01:14&lt;00:00, 19.11it/s]"}},"df922521148d40798fdbdc7133d21eae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24f8c29fb4bd4ff6830d22794674b1c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3d998f827bc42549aafdd672b6544ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93f27479f0194296938eea4fbbb6cef7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"81863519ca60408da6a8ce14b1d9955c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dca2bfaddc30467d9f6e908e8bb34856":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97411f6ec50240c6a3b67ae1761b2cc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77257646902f43228469ad1464d9b48a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1fe76b7a863940bcab9f2cb1171cbd23","IPY_MODEL_4214213d8a364bd8a91a16d3b617f5f3","IPY_MODEL_8386d5334839491a9e7480d418724fde"],"layout":"IPY_MODEL_ffcb41b1bdb44b67a50dac28e32c5252"}},"1fe76b7a863940bcab9f2cb1171cbd23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfaed932c5344d12800a208ac22010cd","placeholder":"​","style":"IPY_MODEL_e9259dfa91dd49eb8ecbe7e419852dea","value":""}},"4214213d8a364bd8a91a16d3b617f5f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b44e674e9e045f89d1280dcd771b3db","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66cb272b2c6b485497fd5d8eb0627cec","value":1}},"8386d5334839491a9e7480d418724fde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc70285febdd42d7be1b0e18045dc104","placeholder":"​","style":"IPY_MODEL_ba7fea0909f345e696c45a579556facf","value":" 11250/? [36:33&lt;00:00,  5.15it/s]"}},"ffcb41b1bdb44b67a50dac28e32c5252":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfaed932c5344d12800a208ac22010cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9259dfa91dd49eb8ecbe7e419852dea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b44e674e9e045f89d1280dcd771b3db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"66cb272b2c6b485497fd5d8eb0627cec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc70285febdd42d7be1b0e18045dc104":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba7fea0909f345e696c45a579556facf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a96a0bf68aa445b2b253f55a099bef14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7dff75be2a0a47b0b395606da87a6731","IPY_MODEL_1ca752587f7e4534a0e00e095d0c5dbe","IPY_MODEL_1585e37b3c294b09a0720a763fa9a104"],"layout":"IPY_MODEL_fe13dc73723042a88ef4d04a6051c2c0"}},"7dff75be2a0a47b0b395606da87a6731":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6afdc798dca34e6dbd19ed3fd1014207","placeholder":"​","style":"IPY_MODEL_4875768f44544df2bc17d5cd1b453bd2","value":""}},"1ca752587f7e4534a0e00e095d0c5dbe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86ed0a0220294000b9eef7f385ed9dea","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71c38c19f6484321a1bf38988b84cd0e","value":1}},"1585e37b3c294b09a0720a763fa9a104":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3a842111f7e4d7c853722e8412283f0","placeholder":"​","style":"IPY_MODEL_a34ff9ebcbb34333a9f4b6336866630e","value":" 1250/? [01:11&lt;00:00, 19.15it/s]"}},"fe13dc73723042a88ef4d04a6051c2c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6afdc798dca34e6dbd19ed3fd1014207":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4875768f44544df2bc17d5cd1b453bd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86ed0a0220294000b9eef7f385ed9dea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"71c38c19f6484321a1bf38988b84cd0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b3a842111f7e4d7c853722e8412283f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a34ff9ebcbb34333a9f4b6336866630e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ccd8bed5b904a86b88b1ac378df2e6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_945462a8c8d347318af3e8385714df5c","IPY_MODEL_8688400a52e247fbaa8bb9e0958a2605","IPY_MODEL_be90f4b669524fdea9b3755eb87493da"],"layout":"IPY_MODEL_e3e8b307281d4ca8a13098452d162c4b"}},"945462a8c8d347318af3e8385714df5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79a45f532dd54e278d12bcb8be34813e","placeholder":"​","style":"IPY_MODEL_200bb7e238a64f8baaf114524c39ddb3","value":""}},"8688400a52e247fbaa8bb9e0958a2605":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_990b09d4e08340a8bebe05f774811d1f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b623a00b213d4d5e987257f56d80ab29","value":1}},"be90f4b669524fdea9b3755eb87493da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d65bc777e0942f39101f2b7ea9fd67a","placeholder":"​","style":"IPY_MODEL_d7b4a30c8bb64f7896a8bf535f1f5af7","value":" 2500/? [02:16&lt;00:00, 19.37it/s]"}},"e3e8b307281d4ca8a13098452d162c4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79a45f532dd54e278d12bcb8be34813e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"200bb7e238a64f8baaf114524c39ddb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"990b09d4e08340a8bebe05f774811d1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b623a00b213d4d5e987257f56d80ab29":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d65bc777e0942f39101f2b7ea9fd67a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7b4a30c8bb64f7896a8bf535f1f5af7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c7868dcad1a448ab0ad99e09d29b475":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f73c74616aef4aaca3f92e5512b3638a","IPY_MODEL_61fcc3f5644943fc8c8076e065ec6aa6","IPY_MODEL_4cad372a00ed47cfbe4a6f593dcb8ef6"],"layout":"IPY_MODEL_c95d8e281e6343c3a737b5bf47ab760e"}},"f73c74616aef4aaca3f92e5512b3638a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_977de746c6534be081e46d8143f05afd","placeholder":"​","style":"IPY_MODEL_6ad4d3e9aff64aa79a65b400fe937937","value":""}},"61fcc3f5644943fc8c8076e065ec6aa6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e6bc15251d345bbb60b3326313f4162","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9aaaae3f7a3b4759b83aa29c25aa3d38","value":1}},"4cad372a00ed47cfbe4a6f593dcb8ef6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a92ec19967c4e6f993291fb1d37e52d","placeholder":"​","style":"IPY_MODEL_50c13715b43447a3826719a5c6a14ab1","value":" 11250/? [38:34&lt;00:00,  4.81it/s]"}},"c95d8e281e6343c3a737b5bf47ab760e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"977de746c6534be081e46d8143f05afd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ad4d3e9aff64aa79a65b400fe937937":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e6bc15251d345bbb60b3326313f4162":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9aaaae3f7a3b4759b83aa29c25aa3d38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a92ec19967c4e6f993291fb1d37e52d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50c13715b43447a3826719a5c6a14ab1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48a9571be6cd478cb05ed546a0f77ec6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78527103db9b4e049d3fc19f73b18cf5","IPY_MODEL_3d5e22766f5048628847c6fee3443a16","IPY_MODEL_7b0d2b6e096842029fbd5f2a0893896b"],"layout":"IPY_MODEL_961637a87d0e4512b83c98d523341d03"}},"78527103db9b4e049d3fc19f73b18cf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5978a6029f8647e9a8132b776b931354","placeholder":"​","style":"IPY_MODEL_6fd6cfec48354b7ea751aa43149d07a3","value":""}},"3d5e22766f5048628847c6fee3443a16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdcbac8fd0ea44d3b81f4661da3e303d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c47ecc9da58b41b7a903e12cdec8f348","value":1}},"7b0d2b6e096842029fbd5f2a0893896b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b35fa6ca9684b42ac955ad689a76952","placeholder":"​","style":"IPY_MODEL_bd780b9fd0034df09656944d19f40dc0","value":" 1250/? [01:14&lt;00:00, 19.53it/s]"}},"961637a87d0e4512b83c98d523341d03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5978a6029f8647e9a8132b776b931354":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fd6cfec48354b7ea751aa43149d07a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdcbac8fd0ea44d3b81f4661da3e303d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c47ecc9da58b41b7a903e12cdec8f348":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b35fa6ca9684b42ac955ad689a76952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd780b9fd0034df09656944d19f40dc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68c8fe144f8b422eb10b5715d88fef48":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d349e44d2de4158bbaf8272d8a7ceda","IPY_MODEL_9f9f29566cfe43b4b22dec156f46d101","IPY_MODEL_f5aff0437dcf42099b3f93f1170a9d55"],"layout":"IPY_MODEL_36220c67290743fab933c7b80db0a6c6"}},"5d349e44d2de4158bbaf8272d8a7ceda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc28e34725c04597a44c2a7aa97fd51b","placeholder":"​","style":"IPY_MODEL_d517b17388c947208e480d732161df31","value":""}},"9f9f29566cfe43b4b22dec156f46d101":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_367161e6664e41cdbdc03e96df67d030","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5af30103df844111b96df3f80ab61d32","value":1}},"f5aff0437dcf42099b3f93f1170a9d55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85026770f4c34d418cd270bbbe85872d","placeholder":"​","style":"IPY_MODEL_307b2eaccac645028a5770a5de1ed525","value":" 11250/? [38:37&lt;00:00,  4.86it/s]"}},"36220c67290743fab933c7b80db0a6c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc28e34725c04597a44c2a7aa97fd51b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d517b17388c947208e480d732161df31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"367161e6664e41cdbdc03e96df67d030":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"5af30103df844111b96df3f80ab61d32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85026770f4c34d418cd270bbbe85872d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"307b2eaccac645028a5770a5de1ed525":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1de98dffa1841968378d7869c2bf78a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6481d900805646979ecb68fc0af11ffe","IPY_MODEL_ac9c76a4bc3840748ecb5e50a77c9c11","IPY_MODEL_8bce746496c94e7b9be8b561351f4a6a"],"layout":"IPY_MODEL_e67fb7f081624ac8844bb14d844e55ae"}},"6481d900805646979ecb68fc0af11ffe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_952d57fd4b444f58a074370cfee296df","placeholder":"​","style":"IPY_MODEL_0a1ebe35d6be4fcb9b0936cc5c487cbd","value":""}},"ac9c76a4bc3840748ecb5e50a77c9c11":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a97d1eb145194596a512a66d97e60997","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6f099f0a5e64bfe8eb6f4d3d7be021d","value":1}},"8bce746496c94e7b9be8b561351f4a6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c8e01fd75e54d698c6f0e9c2170be39","placeholder":"​","style":"IPY_MODEL_4f640e8e7ada45269c05e27a4f3e87ec","value":" 1250/? [01:13&lt;00:00, 19.50it/s]"}},"e67fb7f081624ac8844bb14d844e55ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"952d57fd4b444f58a074370cfee296df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a1ebe35d6be4fcb9b0936cc5c487cbd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a97d1eb145194596a512a66d97e60997":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c6f099f0a5e64bfe8eb6f4d3d7be021d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c8e01fd75e54d698c6f0e9c2170be39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f640e8e7ada45269c05e27a4f3e87ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a911299bdc34a028f24e7db71c5e232":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_723d2d2ad8214c2c9edc05aca467f10c","IPY_MODEL_c117bb7adb834dbc9c85b62c3d1f06db","IPY_MODEL_f9ce76722db84dd9800845a67be33dcc"],"layout":"IPY_MODEL_d8783733aba34de9841782db810bfd7a"}},"723d2d2ad8214c2c9edc05aca467f10c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48b028f67e994871852a6b5c2de509f9","placeholder":"​","style":"IPY_MODEL_9f3223695ed7436bbb25c0fd2c1904fa","value":""}},"c117bb7adb834dbc9c85b62c3d1f06db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_77f917ba72784b648b86aaa1a15ce614","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b95e2e767aa645a3921e4f7448bce73f","value":1}},"f9ce76722db84dd9800845a67be33dcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00ae29b37d5c42228b2555b20cc072cc","placeholder":"​","style":"IPY_MODEL_dda355cce9f44ec3a97aef24fb33843a","value":" 11250/? [38:40&lt;00:00,  4.83it/s]"}},"d8783733aba34de9841782db810bfd7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48b028f67e994871852a6b5c2de509f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f3223695ed7436bbb25c0fd2c1904fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77f917ba72784b648b86aaa1a15ce614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b95e2e767aa645a3921e4f7448bce73f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00ae29b37d5c42228b2555b20cc072cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dda355cce9f44ec3a97aef24fb33843a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab76070935834008b0c56f9bb8e465be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_671d607cfedc48ba8891a8d787d9420b","IPY_MODEL_1ab0c6770d4a45dabcfee719f89ccf4e","IPY_MODEL_daf6d43b0e06497a9f543b7eadfbc7e8"],"layout":"IPY_MODEL_21894835c2c149abb18ec48ba6059779"}},"671d607cfedc48ba8891a8d787d9420b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07aef66f4f68476cb629a62adc03ac03","placeholder":"​","style":"IPY_MODEL_b03568c3144a4f138d83331adf3a8223","value":""}},"1ab0c6770d4a45dabcfee719f89ccf4e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0072ad6860c84b0982762a77727b1725","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1dcc37d3b04f46968bd182d62c946a62","value":1}},"daf6d43b0e06497a9f543b7eadfbc7e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f3ed85d335e4f38bc07e3ae499d2e3e","placeholder":"​","style":"IPY_MODEL_d5f04c1cf34c43088bef52238eb219c6","value":" 1250/? [01:14&lt;00:00, 19.51it/s]"}},"21894835c2c149abb18ec48ba6059779":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07aef66f4f68476cb629a62adc03ac03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b03568c3144a4f138d83331adf3a8223":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0072ad6860c84b0982762a77727b1725":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1dcc37d3b04f46968bd182d62c946a62":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f3ed85d335e4f38bc07e3ae499d2e3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5f04c1cf34c43088bef52238eb219c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ec18c0f2aa84e6e85a06c24aee4a6cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b11b45ba7bdd47afbb4a4f7bba1a7f2b","IPY_MODEL_d23fa5080b4e4ff08ef15c9f27601f1e","IPY_MODEL_23a30e55f4cc41358f2ab761177aeea0"],"layout":"IPY_MODEL_92823f1e90014aea881f9a1b8fca955b"}},"b11b45ba7bdd47afbb4a4f7bba1a7f2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f67f499c8514e98a352a089dd1330e0","placeholder":"​","style":"IPY_MODEL_9e4b1a2f0bf3458dab4501283e4ce4bd","value":""}},"d23fa5080b4e4ff08ef15c9f27601f1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e54bb091a29e411ca841d16bf9a7b7e2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f19e960dbb324164824f103130ce1a01","value":1}},"23a30e55f4cc41358f2ab761177aeea0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85100766c7304d33b2c087da09b3c3a1","placeholder":"​","style":"IPY_MODEL_80aec800626f4baaac880c56f88a9747","value":" 11250/? [38:41&lt;00:00,  4.85it/s]"}},"92823f1e90014aea881f9a1b8fca955b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f67f499c8514e98a352a089dd1330e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e4b1a2f0bf3458dab4501283e4ce4bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e54bb091a29e411ca841d16bf9a7b7e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f19e960dbb324164824f103130ce1a01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85100766c7304d33b2c087da09b3c3a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80aec800626f4baaac880c56f88a9747":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42f8e6c0aa4c4e3a94e804722788dc90":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8835a2a6826543c39e9ce4b3148973aa","IPY_MODEL_4404445b3b7942a58dc09b4f1db02443","IPY_MODEL_c0f7aff39d1a438b96616e091081af76"],"layout":"IPY_MODEL_91b090b2f16143e19c6c2cef75964c6d"}},"8835a2a6826543c39e9ce4b3148973aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f4c3ad96b664096849da61176e19fb7","placeholder":"​","style":"IPY_MODEL_96c438b296e847faa8b0858151d8905a","value":""}},"4404445b3b7942a58dc09b4f1db02443":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4236581690c54480b0bd8802a69c759f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb127c5237b543e5b9c65f96e3038120","value":1}},"c0f7aff39d1a438b96616e091081af76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1e3207fec794c3099277eb028d6e37b","placeholder":"​","style":"IPY_MODEL_a624e0fd368f4c648253a2f5322ab345","value":" 1250/? [01:14&lt;00:00, 19.06it/s]"}},"91b090b2f16143e19c6c2cef75964c6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f4c3ad96b664096849da61176e19fb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96c438b296e847faa8b0858151d8905a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4236581690c54480b0bd8802a69c759f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"fb127c5237b543e5b9c65f96e3038120":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1e3207fec794c3099277eb028d6e37b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a624e0fd368f4c648253a2f5322ab345":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a580f946fdc443709e7594c4d878f7c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74de04f4a78e44f7a3f9aeffdb7afe96","IPY_MODEL_4313686751164d3ba7fda7953e0c64ef","IPY_MODEL_79a27e5bad1b4e339dabbbfb36a3f3e0"],"layout":"IPY_MODEL_5a21fa9e75534daabfc34d803b1015f7"}},"74de04f4a78e44f7a3f9aeffdb7afe96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c5f211abd394d8cac941c611cef53b5","placeholder":"​","style":"IPY_MODEL_ea126b0d63b14ba0b1d7de436bee63cb","value":""}},"4313686751164d3ba7fda7953e0c64ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96d00656da434fbe969b162930f1acce","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6da378bac40941d5b108af255a466446","value":1}},"79a27e5bad1b4e339dabbbfb36a3f3e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02552448cdf549f0b98b0130a80f7a31","placeholder":"​","style":"IPY_MODEL_54c3796f4519423ea7793426f173f065","value":" 11250/? [38:42&lt;00:00,  4.86it/s]"}},"5a21fa9e75534daabfc34d803b1015f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c5f211abd394d8cac941c611cef53b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea126b0d63b14ba0b1d7de436bee63cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96d00656da434fbe969b162930f1acce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"6da378bac40941d5b108af255a466446":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02552448cdf549f0b98b0130a80f7a31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54c3796f4519423ea7793426f173f065":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e803f7144fa4786b9079bf276fb8e71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e4d540b06d14e77a7366c0c27c778a7","IPY_MODEL_81a5673ef4d3458ba285d3602df197f2","IPY_MODEL_525eb116e33b427fa9f714e386ebc69e"],"layout":"IPY_MODEL_0e63d35f604643a6abdbd0e4a168f5bb"}},"1e4d540b06d14e77a7366c0c27c778a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d13a7cb55c3b4ac7b9515577b76a11e6","placeholder":"​","style":"IPY_MODEL_e05d678547014318946f9f2e224e20cd","value":""}},"81a5673ef4d3458ba285d3602df197f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d7becc2c9af454bb08efe183f0fa17b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c600b0269dc54307917069685d9f200c","value":1}},"525eb116e33b427fa9f714e386ebc69e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca6a838e9ba0411bb26d469127cdbe08","placeholder":"​","style":"IPY_MODEL_d46a00d45a29480ea57965a75c3d8bbf","value":" 1250/? [01:09&lt;00:00, 19.29it/s]"}},"0e63d35f604643a6abdbd0e4a168f5bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d13a7cb55c3b4ac7b9515577b76a11e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e05d678547014318946f9f2e224e20cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d7becc2c9af454bb08efe183f0fa17b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c600b0269dc54307917069685d9f200c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca6a838e9ba0411bb26d469127cdbe08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d46a00d45a29480ea57965a75c3d8bbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f902b17ae2d948818d03e25e9602fb81":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43fb350e29704aea9969cdfd50310f35","IPY_MODEL_c8c9a9b770454f83a616e9259f05322d","IPY_MODEL_dcca604792234140ad9995cb7485d3b1"],"layout":"IPY_MODEL_fc406f11e32743a1a39c97d3aa7d9169"}},"43fb350e29704aea9969cdfd50310f35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb9d308d0f434bcf83110a07b14dbb32","placeholder":"​","style":"IPY_MODEL_9d178e12b5c14bac8f71fd3c0cfdf372","value":""}},"c8c9a9b770454f83a616e9259f05322d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_080d0a5b8b8d4d5b9ae9f18a471a603e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0810f5f755145ff91a3fe4670ff14cf","value":1}},"dcca604792234140ad9995cb7485d3b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd9c6c1276bc45cc905c558d3f721159","placeholder":"​","style":"IPY_MODEL_fa63b2073f0a48a6a1ef895ce06acb4b","value":" 2500/? [02:15&lt;00:00, 19.59it/s]"}},"fc406f11e32743a1a39c97d3aa7d9169":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb9d308d0f434bcf83110a07b14dbb32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d178e12b5c14bac8f71fd3c0cfdf372":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"080d0a5b8b8d4d5b9ae9f18a471a603e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c0810f5f755145ff91a3fe4670ff14cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd9c6c1276bc45cc905c558d3f721159":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa63b2073f0a48a6a1ef895ce06acb4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92063a0fd32844899ded29d36b10050e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb85bebd600d42d79946c4ebb87110fe","IPY_MODEL_4337d622c0cd47b59736d4c82bd121b3","IPY_MODEL_6104efc61e064d3fa102742912a12ebc"],"layout":"IPY_MODEL_9d12a00f6f3f4657945ced8e0ac5bdf4"}},"eb85bebd600d42d79946c4ebb87110fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddfe57d909c04ba3a1b7d4a46a66283a","placeholder":"​","style":"IPY_MODEL_5e867af739fe41b987d774339682f899","value":""}},"4337d622c0cd47b59736d4c82bd121b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_561f9d7430f94d72b6e8b4cf80aec0e4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e97a2299e8c461288bdcb79da610edb","value":1}},"6104efc61e064d3fa102742912a12ebc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_278d4379834749a48c60119a21726c48","placeholder":"​","style":"IPY_MODEL_c8ff67b1f3b346dc935453d605a88edb","value":" 11250/? [38:35&lt;00:00,  4.87it/s]"}},"9d12a00f6f3f4657945ced8e0ac5bdf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddfe57d909c04ba3a1b7d4a46a66283a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e867af739fe41b987d774339682f899":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"561f9d7430f94d72b6e8b4cf80aec0e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"2e97a2299e8c461288bdcb79da610edb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"278d4379834749a48c60119a21726c48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8ff67b1f3b346dc935453d605a88edb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8763dc389884a2baa867712da03bca9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f9b554b33f44bd78ebb72c29868c183","IPY_MODEL_23f5550f4bdc4f53a9ce792686c92e9f","IPY_MODEL_d39e0010aed7474294835eedba55efe2"],"layout":"IPY_MODEL_e5e76a70b90b4edb877fc51739c5e159"}},"2f9b554b33f44bd78ebb72c29868c183":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43e75373b7044f638358e840cf009a87","placeholder":"​","style":"IPY_MODEL_dd560becd85541279f65b21de47613a8","value":""}},"23f5550f4bdc4f53a9ce792686c92e9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2958af2d5eb3452785c6f2870e2c74ba","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f888d15235dd460c99b7fe7d965bef3f","value":1}},"d39e0010aed7474294835eedba55efe2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8669bb437df7464a9d7da7c583296440","placeholder":"​","style":"IPY_MODEL_9c2f108181184f1a8d57cc3b760045d4","value":" 1250/? [01:08&lt;00:00, 19.63it/s]"}},"e5e76a70b90b4edb877fc51739c5e159":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43e75373b7044f638358e840cf009a87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd560becd85541279f65b21de47613a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2958af2d5eb3452785c6f2870e2c74ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f888d15235dd460c99b7fe7d965bef3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8669bb437df7464a9d7da7c583296440":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c2f108181184f1a8d57cc3b760045d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1e276799585476bb41ecebf66d3a04a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87f9ffce012a4d0bbe4c95c1e6490cef","IPY_MODEL_9c376f293bc24f88b334149b69a40810","IPY_MODEL_c78ecb2d075d4871b413e26997817abc"],"layout":"IPY_MODEL_7cade2e6cb4147e3a67445ab83be689d"}},"87f9ffce012a4d0bbe4c95c1e6490cef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80bf8a964a3248bf97376e07135d961f","placeholder":"​","style":"IPY_MODEL_3ccd36ef8a464745a0583da299ddd3bf","value":""}},"9c376f293bc24f88b334149b69a40810":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0634be87228e4b539c27f455f88a8ddf","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_efde767f445f44b6856addc6c88c361b","value":1}},"c78ecb2d075d4871b413e26997817abc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_777c4480550f47f7b504c6422d6d31bc","placeholder":"​","style":"IPY_MODEL_0c6d1d72c076463ca412f395dcd210ce","value":" 11250/? [38:42&lt;00:00,  4.86it/s]"}},"7cade2e6cb4147e3a67445ab83be689d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80bf8a964a3248bf97376e07135d961f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ccd36ef8a464745a0583da299ddd3bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0634be87228e4b539c27f455f88a8ddf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"efde767f445f44b6856addc6c88c361b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"777c4480550f47f7b504c6422d6d31bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c6d1d72c076463ca412f395dcd210ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01765cbe201945ae84539f584847ace4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71637189905c44d4adb547be62c2a15d","IPY_MODEL_d161083b58534121a1478b49bb163fe4","IPY_MODEL_10bab8ce38724cd9b0a1ff4a6ab7a066"],"layout":"IPY_MODEL_56852ee6401a4c77b9cc1dd686c1c954"}},"71637189905c44d4adb547be62c2a15d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b1a4c2a88d2436eb381b20edb1731ae","placeholder":"​","style":"IPY_MODEL_7029217fab1c47358806c810faa7a997","value":""}},"d161083b58534121a1478b49bb163fe4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92c43838546c44ddb0f28835d7a59738","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c77abe8f34e4e0f86152c7ba4e1ddda","value":1}},"10bab8ce38724cd9b0a1ff4a6ab7a066":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff220babb4ec467991f5ae555ab29c47","placeholder":"​","style":"IPY_MODEL_55c7c4e4eb4d4a95a81cc95347801240","value":" 1250/? [01:06&lt;00:00, 19.63it/s]"}},"56852ee6401a4c77b9cc1dd686c1c954":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b1a4c2a88d2436eb381b20edb1731ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7029217fab1c47358806c810faa7a997":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92c43838546c44ddb0f28835d7a59738":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"6c77abe8f34e4e0f86152c7ba4e1ddda":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff220babb4ec467991f5ae555ab29c47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55c7c4e4eb4d4a95a81cc95347801240":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa01ef68dd1e4ea399b4a5cd21076492":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbcb353588b24f749537b1dc0192f48e","IPY_MODEL_9f5b47faa54d4064834843de9e7cb60b","IPY_MODEL_fd66977905144345bf929c2156a237b4"],"layout":"IPY_MODEL_919b809f294140c6883f634cbd4c1d0b"}},"bbcb353588b24f749537b1dc0192f48e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20dcdad3faf24825af52299d4b1ccda3","placeholder":"​","style":"IPY_MODEL_59551f855d3c4fa8be70647106e5b66d","value":""}},"9f5b47faa54d4064834843de9e7cb60b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed68349fcd9b44c1a346261134baf746","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_219b6c39c8de46828a7404e3e35d7f24","value":1}},"fd66977905144345bf929c2156a237b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3327e7fc3e640dc956f07e2667d89a0","placeholder":"​","style":"IPY_MODEL_53c6555d23b540a783c9dde944bd3c73","value":" 11250/? [38:44&lt;00:00,  4.80it/s]"}},"919b809f294140c6883f634cbd4c1d0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20dcdad3faf24825af52299d4b1ccda3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59551f855d3c4fa8be70647106e5b66d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed68349fcd9b44c1a346261134baf746":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"219b6c39c8de46828a7404e3e35d7f24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3327e7fc3e640dc956f07e2667d89a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53c6555d23b540a783c9dde944bd3c73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc8c02a59d00495daf786e9e5b5e9379":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66c5da1965594655a5e0ef606cdf329f","IPY_MODEL_322ade7011af459bba623cb4235cb89f","IPY_MODEL_7d1bf14b3f884408a844c5fea0d4a978"],"layout":"IPY_MODEL_c1334353e0b149608e359c7c00e77971"}},"66c5da1965594655a5e0ef606cdf329f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0759711c6ac24815acf272a98a893f0f","placeholder":"​","style":"IPY_MODEL_700f36dcb3d347ec8a4fdb19da892016","value":""}},"322ade7011af459bba623cb4235cb89f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a7dd85576514a45b8b8adbae8a52e23","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eea245757bb64b44917a09743808d097","value":1}},"7d1bf14b3f884408a844c5fea0d4a978":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f929f736e6d24b11a9e3621fbefe4f5f","placeholder":"​","style":"IPY_MODEL_345d9092b59b46ff8833f4f7015c6f99","value":" 1250/? [01:06&lt;00:00, 19.51it/s]"}},"c1334353e0b149608e359c7c00e77971":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0759711c6ac24815acf272a98a893f0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"700f36dcb3d347ec8a4fdb19da892016":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a7dd85576514a45b8b8adbae8a52e23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"eea245757bb64b44917a09743808d097":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f929f736e6d24b11a9e3621fbefe4f5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"345d9092b59b46ff8833f4f7015c6f99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26dfcf5956ee4841b6894b89cf70d948":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41c29cb9ce4742a18713882e4eb97e4c","IPY_MODEL_dba63ca28a924fe681c986c88d704f44","IPY_MODEL_31c9d3b467ee4f47b298dc862e6877f0"],"layout":"IPY_MODEL_cb99eed43c814cafbaaa334c48fa367c"}},"41c29cb9ce4742a18713882e4eb97e4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e3f5445edb9412a83674ed2c6ca6488","placeholder":"​","style":"IPY_MODEL_b9ac3bf7fac343f6bd2b16c53a8d9b05","value":""}},"dba63ca28a924fe681c986c88d704f44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11a8b98b622845c4a78d4c3dc7896b21","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_373dc009c0104a00bed17d5d9d3e8609","value":1}},"31c9d3b467ee4f47b298dc862e6877f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2995df5958047a7a3a2b6defa86c02b","placeholder":"​","style":"IPY_MODEL_393d820d05ef4d5b9e1aef82ac7bb105","value":" 11250/? [38:46&lt;00:00,  4.84it/s]"}},"cb99eed43c814cafbaaa334c48fa367c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e3f5445edb9412a83674ed2c6ca6488":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9ac3bf7fac343f6bd2b16c53a8d9b05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11a8b98b622845c4a78d4c3dc7896b21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"373dc009c0104a00bed17d5d9d3e8609":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2995df5958047a7a3a2b6defa86c02b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"393d820d05ef4d5b9e1aef82ac7bb105":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55c5d97ce1414f8689d5fc8fdf6cd43e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_814fb7276f4842879f00a3c286594afc","IPY_MODEL_350474b595954737aa2a7133db38fc56","IPY_MODEL_8f4587428d8b4708be12c585395e69d7"],"layout":"IPY_MODEL_d3cf6ff3af3b4e01885baa1c0e52c1aa"}},"814fb7276f4842879f00a3c286594afc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_431890be19ac4cb3875396d040c75e00","placeholder":"​","style":"IPY_MODEL_40932f372c904ce3a9be10dd2f3cf348","value":""}},"350474b595954737aa2a7133db38fc56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cffb550d551943babc4d85f0fab752c2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df8b53662d0543768ffb974ecf3ea8d6","value":1}},"8f4587428d8b4708be12c585395e69d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3fc97e2732b4bb297984de189f3e254","placeholder":"​","style":"IPY_MODEL_029e2ed64fec4bb8b353486d16e439f8","value":" 1250/? [01:09&lt;00:00, 19.50it/s]"}},"d3cf6ff3af3b4e01885baa1c0e52c1aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"431890be19ac4cb3875396d040c75e00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40932f372c904ce3a9be10dd2f3cf348":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cffb550d551943babc4d85f0fab752c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"df8b53662d0543768ffb974ecf3ea8d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3fc97e2732b4bb297984de189f3e254":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"029e2ed64fec4bb8b353486d16e439f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0005bdd06414fcab7d8932ca691ef54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1174b72a20e747629f6e5112a3ba73a1","IPY_MODEL_7c9db69c4cc34bf7801c9b5f01a0e9c5","IPY_MODEL_7b5994faa7b048f89eb89fa15e0c0e12"],"layout":"IPY_MODEL_2656791a55c846cd9b6b2f4306a02cb4"}},"1174b72a20e747629f6e5112a3ba73a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd5022f7c6454f4896db82dda6b3c941","placeholder":"​","style":"IPY_MODEL_5027fc2e85b54d36bd451d3a8761bf09","value":""}},"7c9db69c4cc34bf7801c9b5f01a0e9c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e32eb8ed0f224eccb5057b3b48bc0b61","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1d75ffc0b7c4d3ca7a74a7739972028","value":1}},"7b5994faa7b048f89eb89fa15e0c0e12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1899f0769604124b9b5ee3286cf90cf","placeholder":"​","style":"IPY_MODEL_2012ed9c34db40cfb1bab180ac7290b3","value":" 11250/? [38:49&lt;00:00,  4.83it/s]"}},"2656791a55c846cd9b6b2f4306a02cb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd5022f7c6454f4896db82dda6b3c941":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5027fc2e85b54d36bd451d3a8761bf09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e32eb8ed0f224eccb5057b3b48bc0b61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c1d75ffc0b7c4d3ca7a74a7739972028":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1899f0769604124b9b5ee3286cf90cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2012ed9c34db40cfb1bab180ac7290b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1157c68c520c4da386aa8bbf9d21d402":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd4bb265b509409fb5fa10297a194d73","IPY_MODEL_c98e8a6e153e4db28baef5a560e1ebe4","IPY_MODEL_7ce17a664f264541828a39276280b959"],"layout":"IPY_MODEL_7fc1348e686e40ec8e2eed2efac71810"}},"dd4bb265b509409fb5fa10297a194d73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7860c57a3c8f4d3eb31ed53517050a2f","placeholder":"​","style":"IPY_MODEL_142be23e4d724825bbd1e6e9b8aff83e","value":""}},"c98e8a6e153e4db28baef5a560e1ebe4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_407c25e9225147da9395f0b9be8ca81c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ecef90c609174944a1fd2c365496a235","value":1}},"7ce17a664f264541828a39276280b959":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_200882d3451545bcaff41ceca8076cc8","placeholder":"​","style":"IPY_MODEL_8f0b2b5a6f674d76b86cea71e77e4f1e","value":" 1250/? [01:17&lt;00:00, 19.22it/s]"}},"7fc1348e686e40ec8e2eed2efac71810":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7860c57a3c8f4d3eb31ed53517050a2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"142be23e4d724825bbd1e6e9b8aff83e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"407c25e9225147da9395f0b9be8ca81c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ecef90c609174944a1fd2c365496a235":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"200882d3451545bcaff41ceca8076cc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f0b2b5a6f674d76b86cea71e77e4f1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eedf6372946c4ac3bf28d373c5ce5513":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4dc798d55d424a8b847fb76c4c2c2c23","IPY_MODEL_add7901c35ba415d9c1e20c6494768e3","IPY_MODEL_413b9a3ab65f488b8e2897e1c7915ba5"],"layout":"IPY_MODEL_5ab1ea7b721c4d9eaf35eaf5c6f76ff3"}},"4dc798d55d424a8b847fb76c4c2c2c23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e6bc7c21276440882a0688cf70890ba","placeholder":"​","style":"IPY_MODEL_77d84a78e105406abca34b949bfa520c","value":""}},"add7901c35ba415d9c1e20c6494768e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c21622a2b6d433f9b7014d9806cecbc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_174ec40df47a43cebdc27b10be166e64","value":1}},"413b9a3ab65f488b8e2897e1c7915ba5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f383b19be0e34c2ebff6af9c3d2b2049","placeholder":"​","style":"IPY_MODEL_8c7ff768979c4166a4b867af7e421324","value":" 2500/? [02:15&lt;00:00, 19.48it/s]"}},"5ab1ea7b721c4d9eaf35eaf5c6f76ff3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e6bc7c21276440882a0688cf70890ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77d84a78e105406abca34b949bfa520c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c21622a2b6d433f9b7014d9806cecbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"174ec40df47a43cebdc27b10be166e64":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f383b19be0e34c2ebff6af9c3d2b2049":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c7ff768979c4166a4b867af7e421324":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"100e8f71d8464f59a4b1fcaae7dace89":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77af75899f364293969a541a93ff18a7","IPY_MODEL_f44575fbf07145499407c93c6ce690a7","IPY_MODEL_d63227084ec64a4cada920ac9577667d"],"layout":"IPY_MODEL_cac3a3154e3e490a8612be46d9feb4e9"}},"77af75899f364293969a541a93ff18a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbf145b7ea014e22bdcb9f4c022bcac8","placeholder":"​","style":"IPY_MODEL_8c383f092f5441ddab91a6532e461f55","value":""}},"f44575fbf07145499407c93c6ce690a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfd6888f56d246758d1bf405f3bbe614","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff699c2972e54be6bf7b1813f2bd9627","value":1}},"d63227084ec64a4cada920ac9577667d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_006f3efa5f9b4fc0b1c97f35e7932e91","placeholder":"​","style":"IPY_MODEL_99608e4edbce4919b449f83c8692336c","value":" 11250/? [37:28&lt;00:00,  4.91it/s]"}},"cac3a3154e3e490a8612be46d9feb4e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbf145b7ea014e22bdcb9f4c022bcac8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c383f092f5441ddab91a6532e461f55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfd6888f56d246758d1bf405f3bbe614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ff699c2972e54be6bf7b1813f2bd9627":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"006f3efa5f9b4fc0b1c97f35e7932e91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99608e4edbce4919b449f83c8692336c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"072b2976f64148329937c1feef91aa8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a21ebeb50eba4057abbaba22d23e7eac","IPY_MODEL_4f5e94f31bd145b5b999fadf5f98ff9a","IPY_MODEL_f20ad2a947704b558ffa89e467f9ae3e"],"layout":"IPY_MODEL_10cfab65aa4d4a20aa2c84aaa854687e"}},"a21ebeb50eba4057abbaba22d23e7eac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa668b7239a445c786b5ab62deaa8ce3","placeholder":"​","style":"IPY_MODEL_2eae0ce3a0ad4593a913240ee55101a8","value":""}},"4f5e94f31bd145b5b999fadf5f98ff9a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1700d13d5d9c4fcc9f46eafe6ddebdda","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f9a8e05641045f6b52f9694820756ce","value":1}},"f20ad2a947704b558ffa89e467f9ae3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ec3399d554047fb92b17a861bb82e8e","placeholder":"​","style":"IPY_MODEL_b24bd684cea5428dab429906e3f3c7f2","value":" 1250/? [01:12&lt;00:00, 19.67it/s]"}},"10cfab65aa4d4a20aa2c84aaa854687e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa668b7239a445c786b5ab62deaa8ce3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eae0ce3a0ad4593a913240ee55101a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1700d13d5d9c4fcc9f46eafe6ddebdda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3f9a8e05641045f6b52f9694820756ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ec3399d554047fb92b17a861bb82e8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b24bd684cea5428dab429906e3f3c7f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89ae773cccc4487991539b8cda005baa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b2c6f4e723a413b8b478081c83523e8","IPY_MODEL_1cad13af917540e7bb5792fe267e12d1","IPY_MODEL_a8dd62c44bea47efa70389e3ee5b7e5a"],"layout":"IPY_MODEL_ee1f6ca8ba24434e97060489b2352896"}},"2b2c6f4e723a413b8b478081c83523e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37c26273624640a2a42152402f392cdf","placeholder":"​","style":"IPY_MODEL_30aeb59e467f4f3b855c6dd3aa6441c0","value":""}},"1cad13af917540e7bb5792fe267e12d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3a011bef73b4e389288ca6b7d0f87f4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b37f6f120bd840e5bd3273da00d4d152","value":1}},"a8dd62c44bea47efa70389e3ee5b7e5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b35b7e01d3fc4693b4e134a91dc7c2b4","placeholder":"​","style":"IPY_MODEL_1b312715316b4075a50cdc4ade5f435f","value":" 11250/? [38:27&lt;00:00,  4.90it/s]"}},"ee1f6ca8ba24434e97060489b2352896":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37c26273624640a2a42152402f392cdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30aeb59e467f4f3b855c6dd3aa6441c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3a011bef73b4e389288ca6b7d0f87f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b37f6f120bd840e5bd3273da00d4d152":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b35b7e01d3fc4693b4e134a91dc7c2b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b312715316b4075a50cdc4ade5f435f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"689b8b5da5d9490c91c722574d9dff69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_830463286f62498693f3cf633e9e58e0","IPY_MODEL_3a8eed575fcc4e4d8d5455bc9c958ec5","IPY_MODEL_adf121f38f164517be7ae690cb040ddc"],"layout":"IPY_MODEL_ab67c87855944c9b9b9bd417fe8c7eb3"}},"830463286f62498693f3cf633e9e58e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_763392b4d0ee43158c4dab59f163a29c","placeholder":"​","style":"IPY_MODEL_a011591d7a3e45f8b4351ee694d096f9","value":""}},"3a8eed575fcc4e4d8d5455bc9c958ec5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_450491d1f9e840a3b599be204e1eeb45","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24cf229e8962496fbbb5c7148232dc06","value":1}},"adf121f38f164517be7ae690cb040ddc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1397552d9e44403b980d1b4018af16b5","placeholder":"​","style":"IPY_MODEL_80687fc74b8d457dbb03f4768e11626e","value":" 1250/? [01:09&lt;00:00, 19.65it/s]"}},"ab67c87855944c9b9b9bd417fe8c7eb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"763392b4d0ee43158c4dab59f163a29c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a011591d7a3e45f8b4351ee694d096f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"450491d1f9e840a3b599be204e1eeb45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"24cf229e8962496fbbb5c7148232dc06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1397552d9e44403b980d1b4018af16b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80687fc74b8d457dbb03f4768e11626e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d60e3b48fdb94610a269f44cb9c200e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a585b26af1534e6ba8a6afd1f2d0ea28","IPY_MODEL_4b659f6e0028416e9bce3e27125b303f","IPY_MODEL_00047b39557343d59c672fbbe101d43c"],"layout":"IPY_MODEL_5a5a077bcbc4425a94f9a53b59af8bcd"}},"a585b26af1534e6ba8a6afd1f2d0ea28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2a856fbcb7e4a3f9b26eb4c974a5185","placeholder":"​","style":"IPY_MODEL_c159d31412234d2abd7b28efe98cb0b0","value":""}},"4b659f6e0028416e9bce3e27125b303f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aec15b09516144b886e03f41b8d68a78","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fdd47e2eef8548ca86817cba9ec4459d","value":1}},"00047b39557343d59c672fbbe101d43c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_407484b52c8a40f19c65d8a113eebc6e","placeholder":"​","style":"IPY_MODEL_a13b4f5728684f0f86cc0a3da33fd120","value":" 11250/? [38:36&lt;00:00,  4.84it/s]"}},"5a5a077bcbc4425a94f9a53b59af8bcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2a856fbcb7e4a3f9b26eb4c974a5185":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c159d31412234d2abd7b28efe98cb0b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aec15b09516144b886e03f41b8d68a78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"fdd47e2eef8548ca86817cba9ec4459d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"407484b52c8a40f19c65d8a113eebc6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a13b4f5728684f0f86cc0a3da33fd120":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8803f9a49af8413cbb2e2c64d2f42b13":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aeea479aaa9a4c8dafb44ce4a89801c3","IPY_MODEL_0844143b96d74efa973affa847111c8f","IPY_MODEL_a50938bbf7674d2296b6d91922664ec3"],"layout":"IPY_MODEL_ee7ec1a1aff14331b0d99e044e0a52a1"}},"aeea479aaa9a4c8dafb44ce4a89801c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2edbc8273f6b42ffbb96bba225c3caaf","placeholder":"​","style":"IPY_MODEL_16f16ed209cc4b1fa50b0068ca682c6c","value":""}},"0844143b96d74efa973affa847111c8f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93a89c43e8dd4779b2c990bccb3fca5c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a346bfdf2ebc41989d3105695d12b41e","value":1}},"a50938bbf7674d2296b6d91922664ec3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fb60565ffd34b63a194e6b80fc677dd","placeholder":"​","style":"IPY_MODEL_1b67548880ee4f96bda5ebcba9b724a5","value":" 1250/? [01:06&lt;00:00, 19.54it/s]"}},"ee7ec1a1aff14331b0d99e044e0a52a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2edbc8273f6b42ffbb96bba225c3caaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16f16ed209cc4b1fa50b0068ca682c6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93a89c43e8dd4779b2c990bccb3fca5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a346bfdf2ebc41989d3105695d12b41e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fb60565ffd34b63a194e6b80fc677dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b67548880ee4f96bda5ebcba9b724a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcac1741e9b240e998ac6e426047afbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8163a5e1223f4c79845148d9d23f63e5","IPY_MODEL_28be7f1699924b9bb01cb3bc014bd5b2","IPY_MODEL_d7b05c5b8a9749028b61b802c2ddef88"],"layout":"IPY_MODEL_184a74ac517049a9a1616645cc14f1d3"}},"8163a5e1223f4c79845148d9d23f63e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2c669293420448b9bb078561760e877","placeholder":"​","style":"IPY_MODEL_7915006778b44d95b254d86ea854e074","value":""}},"28be7f1699924b9bb01cb3bc014bd5b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_572cf2c227ef401c982938943e486216","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8138211d9b0c4ee096c29774119c1d0b","value":1}},"d7b05c5b8a9749028b61b802c2ddef88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9bf751d171547f787e935bf297b93d8","placeholder":"​","style":"IPY_MODEL_71838d49904c4f29970b14df003f48d4","value":" 11250/? [38:40&lt;00:00,  4.86it/s]"}},"184a74ac517049a9a1616645cc14f1d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2c669293420448b9bb078561760e877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7915006778b44d95b254d86ea854e074":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"572cf2c227ef401c982938943e486216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8138211d9b0c4ee096c29774119c1d0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9bf751d171547f787e935bf297b93d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71838d49904c4f29970b14df003f48d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93cb7ba95f034b71ad1b9d745d30d5c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51acfdb77cf442c3921bd97d952d1707","IPY_MODEL_1b1f704cb6ba48448e46059259868741","IPY_MODEL_bc67016f962e4307b6965d73ecad1d73"],"layout":"IPY_MODEL_014c33c3a3da457ab2f8789d925089d3"}},"51acfdb77cf442c3921bd97d952d1707":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82024472425d45588cac0cbc78e8187d","placeholder":"​","style":"IPY_MODEL_c3f22301c25a4c6da453c4a056220118","value":""}},"1b1f704cb6ba48448e46059259868741":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_caf2db15b7914f9da9d32c8d28188edf","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec67de78b9434d1ea8966b3dc39ea28c","value":1}},"bc67016f962e4307b6965d73ecad1d73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58492a8d8af94b5ba409c35836c648f0","placeholder":"​","style":"IPY_MODEL_3be5dff528b24ef79e002e188d2750d5","value":" 1250/? [01:07&lt;00:00, 19.59it/s]"}},"014c33c3a3da457ab2f8789d925089d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82024472425d45588cac0cbc78e8187d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3f22301c25a4c6da453c4a056220118":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"caf2db15b7914f9da9d32c8d28188edf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ec67de78b9434d1ea8966b3dc39ea28c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58492a8d8af94b5ba409c35836c648f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3be5dff528b24ef79e002e188d2750d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d696b25acce45e498e6435c7dd3e3a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0161a222d93647f3a8ae068c9579e645","IPY_MODEL_4a11f15807164d01913578eadda55c0c","IPY_MODEL_f73976e797e6462fa28b3bd984bc48e7"],"layout":"IPY_MODEL_9f9f74ae04904403962d27ab26a8da56"}},"0161a222d93647f3a8ae068c9579e645":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5873048b5a474d148104e7bb996a429a","placeholder":"​","style":"IPY_MODEL_27208263b9b54659909cedd0607cfb73","value":""}},"4a11f15807164d01913578eadda55c0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92a498f5468b4700800bf69daedde660","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d3ed4091fa24fd7812d4b1763cd19f1","value":1}},"f73976e797e6462fa28b3bd984bc48e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abcdf0cbc9fe47bab0be129ae31afb44","placeholder":"​","style":"IPY_MODEL_d5c2902bc4214061920444d203595a9e","value":" 11250/? [38:43&lt;00:00,  4.83it/s]"}},"9f9f74ae04904403962d27ab26a8da56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5873048b5a474d148104e7bb996a429a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27208263b9b54659909cedd0607cfb73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92a498f5468b4700800bf69daedde660":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"5d3ed4091fa24fd7812d4b1763cd19f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abcdf0cbc9fe47bab0be129ae31afb44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5c2902bc4214061920444d203595a9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ce5038050a24edfb4cdecda31d22f50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b70a21a181d84aabbb420d1edefb7b69","IPY_MODEL_bb4de79fb9ca41b18f1d791674d8a500","IPY_MODEL_5afe6f22cb5c464c98774822dc2c4593"],"layout":"IPY_MODEL_db777c60903e4bd8a49175c30231da29"}},"b70a21a181d84aabbb420d1edefb7b69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d38ba663408f482f9b65f65a741a14ff","placeholder":"​","style":"IPY_MODEL_a04a8941af8b4b20a1a1e3851493745a","value":""}},"bb4de79fb9ca41b18f1d791674d8a500":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8664a584101e4011b567cb29e7a97a95","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd16f369a15742388a96fdd87d930885","value":1}},"5afe6f22cb5c464c98774822dc2c4593":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d307c9c409f44782a2fa53e5abb1bfdd","placeholder":"​","style":"IPY_MODEL_98d74c46912843aa9cf5e96e81b58967","value":" 1250/? [01:06&lt;00:00, 19.53it/s]"}},"db777c60903e4bd8a49175c30231da29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d38ba663408f482f9b65f65a741a14ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a04a8941af8b4b20a1a1e3851493745a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8664a584101e4011b567cb29e7a97a95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"fd16f369a15742388a96fdd87d930885":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d307c9c409f44782a2fa53e5abb1bfdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98d74c46912843aa9cf5e96e81b58967":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2aa07520f53c4d1aa7530837e17088d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4309bde411764744af1cb1600a9a4442","IPY_MODEL_884efe8b219e47b1b44c0cef5d42db6e","IPY_MODEL_2618127275b24dbbadb037e017d80e46"],"layout":"IPY_MODEL_154408089e3f48d88865c93e7c4d01e6"}},"4309bde411764744af1cb1600a9a4442":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7f4642d9026462d958edededb0e3439","placeholder":"​","style":"IPY_MODEL_3a63e1c1fabe4480becf2fdf44bd9c04","value":""}},"884efe8b219e47b1b44c0cef5d42db6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f955baee22a4f2eaa917207a11221bd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adfac3c6043c424d8130ac567f9fe943","value":1}},"2618127275b24dbbadb037e017d80e46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa303bb5ccf84c9e89e14fefc6f0c273","placeholder":"​","style":"IPY_MODEL_6db6333eabdb4126862c1320f1dc9ed0","value":" 2500/? [02:15&lt;00:00, 19.57it/s]"}},"154408089e3f48d88865c93e7c4d01e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7f4642d9026462d958edededb0e3439":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a63e1c1fabe4480becf2fdf44bd9c04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f955baee22a4f2eaa917207a11221bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"adfac3c6043c424d8130ac567f9fe943":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa303bb5ccf84c9e89e14fefc6f0c273":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6db6333eabdb4126862c1320f1dc9ed0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9931f939ac14045a2979a0f8b114c53":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa86faccaeed49a59b770d26614efe5a","IPY_MODEL_b749f982dd754fb48c7360387e3702ee","IPY_MODEL_e7e0cd955ba149c58be36cebb6be03eb"],"layout":"IPY_MODEL_051a67c0f7f3432083bdb6841cddd4d9"}},"aa86faccaeed49a59b770d26614efe5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_564707e32fe047e9af7e7bbacf5bc446","placeholder":"​","style":"IPY_MODEL_b1003d79d147443dbf38ed7dac14fe8e","value":""}},"b749f982dd754fb48c7360387e3702ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e01297cc2a3a458a86e6c9e2a5166c9e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95da8775fd87496f8b2233736f2def92","value":1}},"e7e0cd955ba149c58be36cebb6be03eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ec28e584ad74140a38883ffbe1e6ab6","placeholder":"​","style":"IPY_MODEL_f9d80a4d281e4a069854bc0342ce8cea","value":" 11250/? [36:44&lt;00:00,  5.11it/s]"}},"051a67c0f7f3432083bdb6841cddd4d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"564707e32fe047e9af7e7bbacf5bc446":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1003d79d147443dbf38ed7dac14fe8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e01297cc2a3a458a86e6c9e2a5166c9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"95da8775fd87496f8b2233736f2def92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ec28e584ad74140a38883ffbe1e6ab6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9d80a4d281e4a069854bc0342ce8cea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4cfa05b8fe64d32816fbe3143dc3798":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5cca9a3194344b4fa251e8d7a43c4975","IPY_MODEL_f77f25e029434f3ab62b8c2dea49b939","IPY_MODEL_d2d60c4691fe4153a3cfcac19538d2d1"],"layout":"IPY_MODEL_defad190d8c14174a775b50405c653c7"}},"5cca9a3194344b4fa251e8d7a43c4975":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9e315afa2614f2cb4a178d9549dcf63","placeholder":"​","style":"IPY_MODEL_b6baeb02237d42f48baeef8b76bb10e5","value":""}},"f77f25e029434f3ab62b8c2dea49b939":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7e290823c514e20b63be2b63a98e6c6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f4da29338e141538436691eefa2a470","value":1}},"d2d60c4691fe4153a3cfcac19538d2d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4c07aaff09e4c61b7ed4aa5afa948ca","placeholder":"​","style":"IPY_MODEL_470c5c0db67b4e55bc0ad9e0a8418c0e","value":" 1250/? [01:12&lt;00:00, 19.58it/s]"}},"defad190d8c14174a775b50405c653c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9e315afa2614f2cb4a178d9549dcf63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6baeb02237d42f48baeef8b76bb10e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7e290823c514e20b63be2b63a98e6c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1f4da29338e141538436691eefa2a470":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4c07aaff09e4c61b7ed4aa5afa948ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"470c5c0db67b4e55bc0ad9e0a8418c0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bf44792175d4dea8788fce8a478216c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b678de52028448b4b20862df56086514","IPY_MODEL_85f95d3b712b4be3898e28ed4f349c8b","IPY_MODEL_3af815a0197641f3a3e9276d54a2173c"],"layout":"IPY_MODEL_6d48c2090f7b461289684dc04e8dfbf2"}},"b678de52028448b4b20862df56086514":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_599efe49a2784053b1f7900827674204","placeholder":"​","style":"IPY_MODEL_21d953c407494ebc80c5e0d1fbe4e770","value":""}},"85f95d3b712b4be3898e28ed4f349c8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f78c13e36dd4d9fa54e7f339527cf58","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aeb06c8fa2a54468b1d52023a1575fe4","value":1}},"3af815a0197641f3a3e9276d54a2173c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c25200fa6b944c3ab5b5f56a210f64d","placeholder":"​","style":"IPY_MODEL_f6c73802c6ad407485047962861a2ce5","value":" 526/? [01:43&lt;00:00,  5.09it/s]"}},"6d48c2090f7b461289684dc04e8dfbf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"599efe49a2784053b1f7900827674204":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21d953c407494ebc80c5e0d1fbe4e770":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f78c13e36dd4d9fa54e7f339527cf58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"aeb06c8fa2a54468b1d52023a1575fe4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c25200fa6b944c3ab5b5f56a210f64d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6c73802c6ad407485047962861a2ce5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}